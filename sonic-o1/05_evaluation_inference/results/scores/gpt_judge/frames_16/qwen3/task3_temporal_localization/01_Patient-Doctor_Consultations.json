{
  "topic_id": 1,
  "topic_name": "Patient-Doctor Consultations",
  "num_evaluated": 269,
  "aggregated_metrics": {
    "mean_iou": 0.02649090902036288,
    "std_iou": 0.08133461525131154,
    "median_iou": 0.0,
    "R@0.3": {
      "recall": 0.022304832713754646,
      "count": 6,
      "total": 269
    },
    "R@0.5": {
      "recall": 0.0037174721189591076,
      "count": 1,
      "total": 269
    },
    "R@0.7": {
      "recall": 0.0,
      "count": 0,
      "total": 269
    },
    "mae": {
      "start_mean": 135.79507063197025,
      "end_mean": 3614.196118959108,
      "average_mean": 1874.9955947955389
    },
    "rationale": {
      "rouge_l_mean": 0.2908631718451561,
      "rouge_l_std": 0.08069861703437636,
      "text_similarity_mean": 0.6940862268874193,
      "text_similarity_std": 0.1007222815031427,
      "llm_judge_score_mean": 2.802973977695167,
      "llm_judge_score_std": 1.6968784163627149
    },
    "rationale_cider": 0.0926815360787819
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "After the speaker welcomes viewers and introduces himself as 'Karma Medic', when does he state that he is a 'final year medical student'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 35.0,
        "end": 36.62
      },
      "pred_interval": {
        "start": 33.6,
        "end": 35.8
      },
      "iou": 0.26490066225165504,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3999999999999986,
        "end": 0.8200000000000003,
        "average": 1.1099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.5617977528089887,
        "text_similarity": 0.8997248411178589,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the target phrase and the 'after' relationship and is a valid paraphrase, but the time intervals differ from the reference (anchor span and target start/end times are shifted by about 1\u20132 seconds), so it's not an exact match."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'Now with that lovely disclaimer out of the way, let's get right into it', when does the text 'before the history' appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.06,
        "end": 57.06
      },
      "pred_interval": {
        "start": 55.0,
        "end": 56.2
      },
      "iou": 0.0679611650485439,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0600000000000023,
        "end": 0.8599999999999994,
        "average": 0.9600000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.3478260869565217,
        "text_similarity": 0.744356095790863,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the immediate/once-finished relationship, but the timestamps are off by about 1\u20131.1s from the reference and it omits the end time of the 'before the history' text, so it is partially but not fully accurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'So before starting the history, there's generally two things that I try and keep in mind', when does he begin describing 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 206.36,
        "end": 207.36
      },
      "pred_interval": {
        "start": 66.4,
        "end": 67.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 139.96,
        "end": 139.66000000000003,
        "average": 139.81
      },
      "rationale_metrics": {
        "rouge_l": 0.326530612244898,
        "text_similarity": 0.8118400573730469,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: both anchor and target timestamps differ substantially from the reference (anchor ~59.5s vs 66.4s; target ~206.4s vs 66.4\u201367.7s), and it wrongly asserts 'immediately after' rather than the separate later occurrence; only the general 'after' relation is weakly preserved."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the acronym 'ICE', when does he explain what it stands for?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 155.7,
        "end": 158.7
      },
      "pred_interval": {
        "start": 210.0,
        "end": 215.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.30000000000001,
        "end": 56.30000000000001,
        "average": 55.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.4000000000000001,
        "text_similarity": 0.5957713723182678,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the qualitative relation ('after') correct but the temporal boundaries are incorrect \u2014 both E1 and E2 times are shifted significantly from the ground truth and the predicted segments do not match the reference intervals or content."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the components of the WIPER acronym, when does he start elaborating on 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 212.0
      },
      "pred_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.0,
        "end": 28.0,
        "average": 28.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3950617283950617,
        "text_similarity": 0.7106266617774963,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events and the correct 'once_finished' relation, but the timestamps are substantially off (ground truth E1/E2 at 205.0s/207\u2013212s vs predicted 228\u2013235s/235\u2013240s), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what brought the patient in, when does he explain what the 'history of presenting complaint' is about?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 346.0,
        "end": 351.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 332.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.0,
        "end": 18.899999999999977,
        "average": 17.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307692,
        "text_similarity": 0.6561150550842285,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer captures the explanatory content but gives substantially incorrect event timings and wrongly labels the relation as 'immediately after' instead of occurring later (E2 at ~346s), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "How long after the speaker says he'll put a picture of all possible questions does the \"REVIEW OF SYSTEMS\" checklist first appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 539.8,
        "end": 543.7
      },
      "pred_interval": {
        "start": 520.0,
        "end": 522.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.799999999999955,
        "end": 21.700000000000045,
        "average": 20.75
      },
      "rationale_metrics": {
        "rouge_l": 0.1754385964912281,
        "text_similarity": 0.5782003402709961,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: both event timestamps disagree substantially with the reference (E1 520.0s vs 534.817s; E2 timing also mismatched) and it asserts a 'simultaneous' relation contrary to the correct 'after' relation, with added unfounded duration details."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is giving examples of systems review questions, when does he ask about \"tummy pain\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 565.74,
        "end": 566.422
      },
      "pred_interval": {
        "start": 555.0,
        "end": 556.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.740000000000009,
        "end": 10.422000000000025,
        "average": 10.581000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.18,
        "text_similarity": 0.6047648191452026,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction locates the 'tummy pain' question near the correct time and correctly states the relation 'during', but it mislabels/swaps the anchor and target, omits the required speaker-examples span (543.160\u2013567.700), and introduces an unsupported checklist timing\u2014so it's only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the \"JAM THREADS\" mnemonic, when does he say the name \"Sketchy Medical\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 696.0,
        "end": 699.531
      },
      "pred_interval": {
        "start": 619.0,
        "end": 620.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.0,
        "end": 79.53099999999995,
        "average": 78.26549999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.26506024096385544,
        "text_similarity": 0.6621657609939575,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer preserves the 'after' relation, it is factually incorrect about both timestamps and contradicts the ground truth timing (major discrepancies and unwarranted claims about when the name/text occur), so it fails to match the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker describes Sketchy Medical, when does he mention drugs' mechanism of action and side effects?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 701.0,
        "end": 703.982
      },
      "pred_interval": {
        "start": 690.0,
        "end": 690.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 13.981999999999971,
        "average": 12.490999999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.28260869565217395,
        "text_similarity": 0.6349949240684509,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that mechanism and side effects are mentioned during the Sketchy Medical description and preserves the 'during' relation, but it gives an incorrect anchor time (690.0s vs. 697.491s), omits the correct E2 time range (701.0\u2013703.982s), and wrongly asserts the mention occurs in the same sentence as the introduction."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks a general question about family health, when does he suggest being specific about asthma, diabetes, and hypertension?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 742.914,
        "end": 745.914
      },
      "pred_interval": {
        "start": 740.0,
        "end": 740.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.9139999999999873,
        "end": 5.913999999999987,
        "average": 4.413999999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.6377454996109009,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that the specific conditions occur after the general question, but it gives substantially different timestamps and incorrectly states the target begins immediately after the question, so the temporal locations are not accurately matched."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the importance of signposting, when does he ask if the patient uses any recreational drugs?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 811.123,
        "end": 812.664
      },
      "pred_interval": {
        "start": 760.0,
        "end": 760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.12300000000005,
        "end": 52.66399999999999,
        "average": 51.89350000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2588235294117647,
        "text_similarity": 0.7172594666481018,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the question follows the signpost but gives entirely incorrect timestamps (750\u2013760s and 760s instead of ~800.85\u2013802.58s and ~811.12\u2013812.66s), so it fails on key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"concerns from ICE\", when does he start saying \"Just generally, if you're feeling stuck\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 880.187,
        "end": 883.471
      },
      "pred_interval": {
        "start": 877.0,
        "end": 878.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.187000000000012,
        "end": 5.471000000000004,
        "average": 4.329000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.4935064935064935,
        "text_similarity": 0.6916050910949707,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target segments and the 'after' relation, but the provided timestamps are off by about 3.2 seconds from the ground truth, which is a significant temporal mismatch for this task."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"golden rulebook\", when does he open both hands outwards in a gesture?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 895.8,
        "end": 897.5
      },
      "pred_interval": {
        "start": 892.0,
        "end": 894.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.7999999999999545,
        "end": 3.5,
        "average": 3.6499999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.4776119402985074,
        "text_similarity": 0.701370894908905,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target events and their 'after' relation, but the reported timestamps deviate substantially from the ground truth (anchor off by ~1.65s; target start/end off by ~3.8s/~3.5s), so the timings are not factually accurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying \"I hope you find this video useful\", when does he say \"Peace\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 910.148,
        "end": 910.609
      },
      "pred_interval": {
        "start": 914.0,
        "end": 915.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.8519999999999754,
        "end": 4.390999999999963,
        "average": 4.121499999999969
      },
      "rationale_metrics": {
        "rouge_l": 0.5205479452054795,
        "text_similarity": 0.6905261278152466,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the events and the 'once_finished' relation, but the reported timestamps are off by about 3.3\u20134.5 seconds compared to the reference and the predicted answer omits the correct target interval, so the timing is materially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying he has an appointment at 10 am, when does the green text 'Sure, what's your name?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 6.1,
        "end": 8.2
      },
      "pred_interval": {
        "start": 2.4,
        "end": 3.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.6999999999999997,
        "end": 5.199999999999999,
        "average": 4.449999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7545583248138428,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly captures that the green text appears immediately after the man finishes speaking, but it gives completely incorrect timestamps (predicts 1.8\u20132.4s and 2.4\u20133.0s vs the ground truth 5.9s and 6.1\u20138.2s) and uses a less precise relation label, so it is largely factually wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes stating his name, when does the green text 'Thank you, Lucas. Please take a seat...' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 11.9,
        "end": 19.0
      },
      "pred_interval": {
        "start": 4.0,
        "end": 4.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.9,
        "end": 14.4,
        "average": 11.15
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.5217899084091187,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the reference on all key temporal facts (predicted times 3.4\u20134.6s vs reference 10.6s and 11.9\u201319.0s) and thus hallucinates incorrect timestamps; while both state E2 occurs after E1, the major timing details are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'How long is the wait?', when does the green text 'About 10 minutes. Would you like some water while you wait?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 22.1,
        "end": 25.3
      },
      "pred_interval": {
        "start": 10.0,
        "end": 10.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.100000000000001,
        "end": 14.700000000000001,
        "average": 13.400000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.19753086419753085,
        "text_similarity": 0.5997098684310913,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the relation as 'after' but gives entirely incorrect timestamps for both anchor and target (predicts ~9.6\u201310.6s vs the correct ~19.5\u201325.3s) and misstates the pause length, so it is largely wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the video explains the 'we're a team' approach with animated graphics, when does the speaker appear at his desk looking at a computer?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 34.6,
        "end": 36.0
      },
      "pred_interval": {
        "start": 13.3,
        "end": 15.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.3,
        "end": 20.8,
        "average": 21.05
      },
      "rationale_metrics": {
        "rouge_l": 0.26315789473684215,
        "text_similarity": 0.7504353523254395,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly identifies the 'we're a team' segment and the speaker-at-desk event, but the timestamps are substantially wrong (off by ~18s) and the temporal relation is mischaracterized as 'after' instead of overlapping/starting just before the audio ends."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker says 'take that extra bit of time to listen', when does the 'OK' hand gesture emoji appear?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 44.0,
        "end": 45.5
      },
      "pred_interval": {
        "start": 39.1,
        "end": 41.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.899999999999999,
        "end": 4.0,
        "average": 4.449999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.43636363636363634,
        "text_similarity": 0.7671665549278259,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the emoji overlaps the spoken phrase, but the reported timestamps for both E1 and E2 are substantially earlier and much shorter than the ground truth, so the temporal information is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After Nurse Kim mentions graduating as a registered nurse, when does she talk about working for many different pharmaceutical companies?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 43.0,
        "end": 50.475
      },
      "pred_interval": {
        "start": 42.2,
        "end": 45.2
      },
      "iou": 0.2658610271903327,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7999999999999972,
        "end": 5.274999999999999,
        "average": 3.037499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.19999999999999998,
        "text_similarity": 0.7285164594650269,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the semantic content and relation ('after') correct, but both event timestamps are substantially off (E1 ~10.6s late, E2 start ~8.6s late and end ~10.5s late), so it is factually incorrect on the key timing details."
      }
    },
    {
      "question_id": "002",
      "question": "Once Nurse Kim finishes describing her background as an 'incredible journey', when does she mention training side-by-side with Dr. Jugenberg for five years?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 149.87,
        "end": 153.25
      },
      "pred_interval": {
        "start": 97.8,
        "end": 100.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.07000000000001,
        "end": 52.45,
        "average": 52.260000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.26373626373626374,
        "text_similarity": 0.6778651475906372,
        "llm_judge_score": 1,
        "llm_judge_justification": "While the relation ('once_finished') matches, the predicted timestamps for both E1 and E2 are incorrect and the speaker's reference to the doctor is misstated, so the core factual temporal annotations do not align with the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "While Nurse Kim explains options and possible outcomes, when does she begin examining the patient's stomach?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 157.5,
        "end": 160.5
      },
      "pred_interval": {
        "start": 151.0,
        "end": 152.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 8.0,
        "average": 7.25
      },
      "rationale_metrics": {
        "rouge_l": 0.29473684210526313,
        "text_similarity": 0.7457810044288635,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction mostly misstates the timing: both anchor and target times are several seconds earlier than the ground truth and it contradicts the ground truth by implying the exam ends when she starts talking, despite the reference stating the exam occurs during her speech. Only the qualitative 'during' relation is retained, so the answer is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After Nurse Kim finishes discussing the benefits, risks, and possible complications of the procedure, when does she start talking about asymmetry?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 169.7,
        "end": 172.0
      },
      "pred_interval": {
        "start": 159.5,
        "end": 160.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.199999999999989,
        "end": 11.5,
        "average": 10.849999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.29411764705882354,
        "text_similarity": 0.786239743232727,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation right ('immediately after') but major factual errors exist: it lists times ~10 seconds earlier than the reference and wrongly labels the topic as 'symmetry' instead of 'asymmetry', so it does not match the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once Nurse Kim finishes explaining that the one-hour consultation cannot provide everything you need to know, when does she mention that they are always available?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 201.5,
        "end": 203.71
      },
      "pred_interval": {
        "start": 171.0,
        "end": 171.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.5,
        "end": 32.21000000000001,
        "average": 31.355000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.2828282828282828,
        "text_similarity": 0.6738656759262085,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that E2 immediately follows E1, but it gives substantially different timestamps (\u2248171s vs correct 201.5s), so it fails on the key factual timing detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces himself and the topic, when does the slide change to 'Objectives for today's lesson'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 24.379,
        "end": 24.5
      },
      "pred_interval": {
        "start": 25.0,
        "end": 28.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.6209999999999987,
        "end": 3.5,
        "average": 2.0604999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.2826086956521739,
        "text_similarity": 0.75132155418396,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') and roughly the slide change time, but it significantly misstates E1 (anchors the speaker's introduction as 0.0\u201324.9s versus the correct 4.014\u201314.567s) and introduces unsupported details about when the speaker finishes listing objectives, so it is largely incorrect/incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the objectives for the lesson, when does the slide change to 'Brain storming time'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 46.529,
        "end": 47.0
      },
      "pred_interval": {
        "start": 56.0,
        "end": 59.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.470999999999997,
        "end": 12.0,
        "average": 10.735499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.24444444444444446,
        "text_similarity": 0.6981867551803589,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer matches the temporal relation conceptually but gives substantially incorrect timestamps (56.0s vs 45.8s/46.529s) and adds an unfounded duration for the slide; these factual timing errors make it largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes defining communication as the successful passage of a message from one person to another, when does he start explaining how good communication manifests in medical practice by informing patients of their diagnosis?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 153.0,
        "end": 177.0
      },
      "pred_interval": {
        "start": 162.0,
        "end": 172.0
      },
      "iou": 0.4166666666666667,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.0,
        "end": 5.0,
        "average": 7.0
      },
      "rationale_metrics": {
        "rouge_l": 0.26373626373626374,
        "text_similarity": 0.5768702030181885,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor content and places the target content within the correct interval and quotes the applicable sentence, but it misstates the target start time (162.0s vs correct 153.0s) and therefore fails to mark that the target immediately follows the anchor."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the 'Importance of communication' slide, when does he begin discussing that good doctor-patient communication has been linked to improved patient satisfaction?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 190.0,
        "end": 198.0
      },
      "pred_interval": {
        "start": 177.0,
        "end": 182.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.0,
        "end": 16.0,
        "average": 14.5
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.6231732964515686,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the quoted content and the 'after' relation, but it misstates both timestamps significantly (anchor given as 172.0s vs 177.5\u2013179.5s and target as 177.0s vs 190.0\u2013198.0s), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker starts talking about how a lot of malpractice lawsuits have been documented, when does he explicitly advise being aware of communication's importance to avoid lawsuits?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 226.0,
        "end": 271.0
      },
      "pred_interval": {
        "start": 207.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.0,
        "end": 61.0,
        "average": 40.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2772277227722772,
        "text_similarity": 0.7532284259796143,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor content and even quotes the advice, but it places the target much earlier (207s) overlapping the anchor instead of at 226.0\u2013271.0s as given, so the temporal alignment is incorrect despite capturing the semantic relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the initial slide 'Communication is not just talking' is displayed, when does the speaker mention that physicians can improve health outcomes?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 339.28,
        "end": 346.0
      },
      "pred_interval": {
        "start": 353.5,
        "end": 368.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.220000000000027,
        "end": 22.0,
        "average": 18.110000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.4358974358974359,
        "text_similarity": 0.832283616065979,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the events and their 'after' relationship, but it gives substantially incorrect temporal boundaries (E2 shifted ~14\u201322s later) and omits the anchor's timestamp, so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide showing two images (bored girl vs. smiling doctor/patient), when does the speaker describe the first image as depicting a 'horribly bored' lady?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.8,
        "end": 359.0
      },
      "pred_interval": {
        "start": 300.8,
        "end": 308.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.0,
        "end": 50.5,
        "average": 52.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3058823529411765,
        "text_similarity": 0.709000825881958,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct phrase and relationship but gives incorrect timing: E2 is placed ~54\u201351 seconds earlier than the reference and thus not during the slide (E1) interval; E1 also lacks the correct timestamps, so the events are semantically misaligned."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker defines verbal communication as 'using spoken words', when is the next time they define non-verbal communication?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 428.87,
        "end": 433.596
      },
      "pred_interval": {
        "start": 337.6,
        "end": 348.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 91.26999999999998,
        "end": 85.19600000000003,
        "average": 88.233
      },
      "rationale_metrics": {
        "rouge_l": 0.2978723404255319,
        "text_similarity": 0.6966098546981812,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the non-verbal definition immediately follows the verbal one, but the reported start/end timestamps and durations conflict substantially with the ground-truth timings, so the answer is largely incorrect on key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the 'golden minute', when does he describe the patient's hypothetical response?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 613.818,
        "end": 630.0
      },
      "pred_interval": {
        "start": 599.4,
        "end": 615.3
      },
      "iou": 0.04843137254901862,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.418000000000006,
        "end": 14.700000000000045,
        "average": 14.559000000000026
      },
      "rationale_metrics": {
        "rouge_l": 0.3925233644859813,
        "text_similarity": 0.8527339696884155,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that the patient's response occurs after the 'golden minute' introduction, but the provided timestamps are significantly different from the reference (anchor time is off and the predicted target only partially overlaps and omits the later portion of the correct interval)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions 'Checking facts', when does he mention the next essential element of listening?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 641.157,
        "end": 642.461
      },
      "pred_interval": {
        "start": 635.1,
        "end": 643.1
      },
      "iou": 0.1629999999999967,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.057000000000016,
        "end": 0.63900000000001,
        "average": 3.348000000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.8450078964233398,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the next element ('Checking feelings') and its approximate time and relation ('immediately after'), but it misreports the anchor timestamp for 'Checking facts' (635.1s vs. 612.98s), a significant factual error in timing."
      }
    },
    {
      "question_id": "003",
      "question": "Before the speaker says 'So, for example, we have three main types of reflective listening', when does he explain what reflective listening involves?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 667.457,
        "end": 687.051
      },
      "pred_interval": {
        "start": 701.0,
        "end": 718.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.543000000000006,
        "end": 31.548999999999978,
        "average": 32.54599999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.23255813953488372,
        "text_similarity": 0.8028391003608704,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives different timestamps, swaps anchor/target roles, and asserts the explanation occurs after the examples, directly contradicting the ground truth that the definition happens before the examples; thus it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the three main types of reflective listening, when does he start explaining the 'Repeating' example?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 710.0,
        "end": 737.0
      },
      "pred_interval": {
        "start": 723.2,
        "end": 723.7
      },
      "iou": 0.018518518518518517,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.200000000000045,
        "end": 13.299999999999955,
        "average": 13.25
      },
      "rationale_metrics": {
        "rouge_l": 0.18947368421052632,
        "text_similarity": 0.6249136328697205,
        "llm_judge_score": 2,
        "llm_judge_justification": "While both answers agree the example occurs after the mention, the predicted timestamps for E1 and E2 are substantially different from the reference (and E2's duration is implausibly short), so the prediction fails to match the key temporal facts."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the 'Repeating' example, when does he introduce 'Rephrasing'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 720.0,
        "end": 720.4
      },
      "pred_interval": {
        "start": 736.3,
        "end": 736.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.299999999999955,
        "end": 16.300000000000068,
        "average": 16.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.27999999999999997,
        "text_similarity": 0.5610544681549072,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly identifies the relation and closely matches the introduction phrasing, but it gives significantly different timestamps (736.3/736.7s vs. 698.0/720.0s) and adds unsupported anchor detail, which contradicts the reference times."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing 'Reflection of feeling by showing empathy', when does the 'Non-verbal' slide appear?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 780.0,
        "end": 821.5
      },
      "pred_interval": {
        "start": 792.6,
        "end": 792.9
      },
      "iou": 0.007228915662649506,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.600000000000023,
        "end": 28.600000000000023,
        "average": 20.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.2391304347826087,
        "text_similarity": 0.617268443107605,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer gets the relation correct but the key factual elements (both event timestamps) are significantly off (~14s later than the reference), so it is largely incorrect despite matching the relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises to smile, when does he mention checking for signs of pain?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.045,
        "end": 882.0
      },
      "pred_interval": {
        "start": 870.0,
        "end": 873.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.044999999999959,
        "end": 9.0,
        "average": 6.0224999999999795
      },
      "rationale_metrics": {
        "rouge_l": 0.3373493975903614,
        "text_similarity": 0.6326830983161926,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives incorrect timestamps for both events (E1 off by ~0.9s and E2 starts/ends far earlier than the reference and omits the ~882.0s conclusion) and contradicts the correct temporal relation, so it fails to match the reference timeline."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the cultural interpretations of folding arms, when does he advise to avoid folding arms?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 932.0,
        "end": 936009.0
      },
      "pred_interval": {
        "start": 914.0,
        "end": 919.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.0,
        "end": 935090.0,
        "average": 467554.0
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.7496811151504517,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misplaces both event intervals (E1 and E2) and even has E2 overlapping E1, contradicting the correct timestamps; while it gets the qualitative 'after' relation, the temporal boundaries are substantially incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker instructs to introduce yourself to the patient, when does he advise to explain your role as a student or intern?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 985.0,
        "end": 990.853
      },
      "pred_interval": {
        "start": 956.0,
        "end": 959.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.0,
        "end": 31.852999999999952,
        "average": 30.426499999999976
      },
      "rationale_metrics": {
        "rouge_l": 0.3218390804597701,
        "text_similarity": 0.6135239601135254,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gets the content roughly right but is factually incorrect about timings and ordering: it places both events around 956\u2013959s rather than 982\u2013990.1s and misrepresents the temporal relation, so it fails on key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"if you're in the hospital\", when does he refer to \"inpatient patients\"?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1059.6,
        "end": 1059.8
      },
      "pred_interval": {
        "start": 1055.5,
        "end": 1057.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.099999999999909,
        "end": 2.7000000000000455,
        "average": 3.3999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.2933333333333333,
        "text_similarity": 0.6322202682495117,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target phrases and that the target follows the anchor, but the reported timestamps are substantially incorrect and the claim of being 'immediately after' contradicts the ground-truth timing (target occurs later at ~1059.6s), so the temporal relation and times are wrong."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining how to start a consultation, when does he give the example \"how can I help you today?\"",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1069.0,
        "end": 1070.0
      },
      "pred_interval": {
        "start": 1064.1,
        "end": 1066.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.900000000000091,
        "end": 3.400000000000091,
        "average": 4.150000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.23404255319148937,
        "text_similarity": 0.7399327158927917,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor vs. example and the relative 'after' relation, but the reported timestamps for both E1 and E2 significantly contradict the ground truth, so the answer is largely temporally incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes explaining the 'golden minute', when does he announce the end of the lecture?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1090.0,
        "end": 1094.0
      },
      "pred_interval": {
        "start": 1092.0,
        "end": 1095.2
      },
      "iou": 0.38461538461538125,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 1.2000000000000455,
        "average": 1.6000000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.2298850574712644,
        "text_similarity": 0.7779261469841003,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the events and their temporal relation ('after'), but the reported timestamps differ from the ground truth by about 1\u20132 seconds for both the anchor and target, so it is only a partial match."
      }
    },
    {
      "question_id": "001",
      "question": "While Raquel is talking about the hospital providing opportunities for nurses, when is she shown smiling and opening a package?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 2.0,
        "end": 4.5
      },
      "pred_interval": {
        "start": 28.96,
        "end": 29.79
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.96,
        "end": 25.29,
        "average": 26.125
      },
      "rationale_metrics": {
        "rouge_l": 0.17948717948717952,
        "text_similarity": 0.22884486615657806,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly matches the speech timing but gives a completely incorrect time for the visual (placing it at ~29s instead of 2\u20134.5s), contradicting the correct answer that the visual occurs during her speech."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria finishes saying that new nurses will be nudged to become lifelong learners, when does Precious state that the teamwork is strong?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 14.321,
        "end": 16.486
      },
      "pred_interval": {
        "start": 37.27,
        "end": 38.53
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.949000000000005,
        "end": 22.044,
        "average": 22.496500000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2571428571428572,
        "text_similarity": 0.5257630944252014,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (37.27\u201338.53s) conflict with the correct times (14.301\u201316.486s), so the answer is factually incorrect; noting 'immediately after' matches the relation but does not remedy the wrong timing."
      }
    },
    {
      "question_id": "003",
      "question": "After Reny states that the hospital does things up to a magnet level, when does Raquel say her values align with the hospital's values?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 42.854,
        "end": 50.692
      },
      "pred_interval": {
        "start": 50.07,
        "end": 52.03
      },
      "iou": 0.06778552746294679,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.216000000000001,
        "end": 1.338000000000001,
        "average": 4.277000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.26506024096385544,
        "text_similarity": 0.5046103000640869,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the event order but the timestamps are substantially incorrect (both E1 and E2 are shifted ~7\u20138s later and durations/endpoints don't match), so it fails to accurately align with the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that healthcare in Siem Reap is not the best, when is the Royal Angkor International Hospital first shown on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 94.0,
        "end": 99.1
      },
      "pred_interval": {
        "start": 87.5,
        "end": 90.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 9.0,
        "average": 7.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3185840707964602,
        "text_similarity": 0.7473404407501221,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly labels the roles and that E2 occurs after E1, but it gives substantially different timestamps for both the anchor and the target (E1 at 75.5\u201379.2s vs 82.215s; E2 at 87.5s/ends 90.1s vs start 94.0s and description at 99.100s), contradicting the ground truth and missing key timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he begin describing the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 180.289,
        "end": 185.074
      },
      "pred_interval": {
        "start": 161.6,
        "end": 164.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.688999999999993,
        "end": 20.874000000000024,
        "average": 19.78150000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.34408602150537637,
        "text_similarity": 0.7493062615394592,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction misidentifies both event boundaries and quoted text, giving entirely different start/end times and an incorrect 'immediately after' relation, which contradicts the reference timings and content."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he visited a clinic for chest congestion, when does he mention the Paschern Dental Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 209.8,
        "end": 211.4
      },
      "pred_interval": {
        "start": 298.5,
        "end": 300.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 88.69999999999999,
        "end": 89.4,
        "average": 89.05
      },
      "rationale_metrics": {
        "rouge_l": 0.22471910112359553,
        "text_similarity": 0.7167484164237976,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the two events and their temporal relation ('after') and quotes the dental-clinic mention, but the provided timestamps differ substantially from the reference (i.e., incorrect timing), so it is partially correct but factually mismatched on key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he introduce the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.0,
        "end": 184.8
      },
      "pred_interval": {
        "start": 130.7,
        "end": 132.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.30000000000001,
        "end": 52.5,
        "average": 52.900000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.38888888888888884,
        "text_similarity": 0.7333499789237976,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') and that E2 follows E1, but the provided timestamps and event boundaries are substantially incorrect compared to the ground-truth times, so the answer is largely factually misaligned."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker introduces the Cigna International Health Policy, when is the insurance quote form displayed with personal information?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 337.5,
        "end": 357.2
      },
      "iou": 0.27555555555555505,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.5,
        "end": 2.8000000000000114,
        "average": 8.150000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.2637362637362637,
        "text_similarity": 0.7937040328979492,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer identifies the correct events and relation, its timestamps differ substantially from the ground truth (E1 and E2 are shifted earlier by many seconds), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the voiceover states that the Cigna policy is \"fairly typical of policies of this type\", when does the Cigna website display the form for inputting personal details to get a quote?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 352.9,
        "end": 358.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 348.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.899999999999977,
        "end": 10.0,
        "average": 16.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7519263029098511,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') right but misstates the anchor and target times by roughly 15\u201325 seconds and gives incorrect visibility intervals, so it is largely factually incorrect despite the correct ordering."
      }
    },
    {
      "question_id": "003",
      "question": "After the voiceover mentions \"evacuation service, also part of Cigna plan\", when is the Global Rescue website displayed on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 384.0,
        "end": 431.0
      },
      "pred_interval": {
        "start": 348.0,
        "end": 360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.0,
        "end": 71.0,
        "average": 53.5
      },
      "rationale_metrics": {
        "rouge_l": 0.32075471698113206,
        "text_similarity": 0.8339806795120239,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the prediction correctly identifies the anchor/target types and that the target follows the anchor, the reported timestamps and duration are significantly incorrect (predicted E1 at 348\u2013354s vs 379s, predicted E2 at 354\u2013360s vs 384\u2013431s), so it fails on factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the host concludes his introduction about the fight in modern healthcare, when does he introduce Sarah?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 19.4,
        "end": 22.0
      },
      "pred_interval": {
        "start": 45.4,
        "end": 48.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.0,
        "end": 26.5,
        "average": 26.25
      },
      "rationale_metrics": {
        "rouge_l": 0.15841584158415842,
        "text_similarity": 0.6639748811721802,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events and their ordering, but the timestamps are significantly incorrect (predicted ~45s vs reference 18.0\u201322.0s) and thus misalign with the ground truth; the claimed 'immediately after' relation is a minor variation but does not redeem the wrong timing."
      }
    },
    {
      "question_id": "002",
      "question": "While Sarah is introducing herself and her genetic condition, when does she mention having her very first surgery?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.08,
        "end": 108.8
      },
      "pred_interval": {
        "start": 101.5,
        "end": 107.5
      },
      "iou": 0.4684931506849319,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5799999999999983,
        "end": 1.2999999999999972,
        "average": 1.9399999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.16842105263157894,
        "text_similarity": 0.7569292783737183,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same events and even quotes the surgery line, but the timestamps are shifted and it incorrectly labels the temporal relation as 'after' rather than 'during' (the correct answer has E2 occurring within E1), so key temporal facts are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sarah finishes describing her role as a volunteer patient representative for a non-profit organization, when does the static image showing her behind a 'CHILDREN'S TUMOR FOUNDATION' table appear?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 185.0,
        "end": 190.0
      },
      "pred_interval": {
        "start": 210.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.0,
        "end": 20.0,
        "average": 22.5
      },
      "rationale_metrics": {
        "rouge_l": 0.25688073394495414,
        "text_similarity": 0.72803795337677,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the static image content (Sarah at the CHILDREN'S TUMOR FOUNDATION table) but gives entirely incorrect timestamps and temporal relation\u2014it places E1/E2 at 210s with an instantaneous cut, contradicting the ground-truth timings (E1 at 150s; E2 185\u2013190s) and thus fails on key factual elements."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes explaining the purpose of the 'Shine a Light Walk' to raise money and awareness, when does the video clip showing children running at an outdoor event play?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 189.0,
        "end": 192.0
      },
      "pred_interval": {
        "start": 270.0,
        "end": 280.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.0,
        "end": 88.0,
        "average": 84.5
      },
      "rationale_metrics": {
        "rouge_l": 0.29213483146067415,
        "text_similarity": 0.6501904129981995,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives completely different timestamps (270s vs. 179s and 270\u2013280s vs. 189\u2013192s) and adds fabricated details (Cuban Zombie Run, different quote), though it correctly states the clip follows immediately; overall the key factual timing and content are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once Steve asks if the 'Shine a Light Walk' goes throughout the world, when does Sarah begin to explain that the walks do not?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 253.2,
        "end": 258.88
      },
      "pred_interval": {
        "start": 280.0,
        "end": 280.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.80000000000001,
        "end": 21.120000000000005,
        "average": 23.960000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.22916666666666663,
        "text_similarity": 0.7051369547843933,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes Sarah's immediate, content-matching response, but the timestamps are significantly wrong (predicted 280.0s vs. ground-truth 253.2s start), so it fails to provide the correct timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes asking Sarah what things in miscommunication can lead to delays or misdiagnosis, when does the woman start responding?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 362.48,
        "end": 365.44
      },
      "pred_interval": {
        "start": 329.53,
        "end": 330.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.950000000000045,
        "end": 35.44,
        "average": 34.19500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.3714285714285715,
        "text_similarity": 0.6522992849349976,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relative relation ('immediately after') but its absolute timestamps contradict the reference (predicted times are ~27s earlier than the ground truth), so it is factually inconsistent."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman gives the example of writing 'hyperthyroid instead of hypothyroid', when does the man respond with 'That that's pretty bad'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 389.2,
        "end": 432.5
      },
      "pred_interval": {
        "start": 57.24,
        "end": 57.52
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 331.96,
        "end": 374.98,
        "average": 353.47
      },
      "rationale_metrics": {
        "rouge_l": 0.3582089552238806,
        "text_similarity": 0.7196891903877258,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly identifies the events and their temporal relation: the woman's example ends before the man's response (57.24s \u2192 57.52s) and labels the relation 'after', matching the reference's relative timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the man says he tried researching miscommunication problems, when does he state his finding about thousands of preventable deaths?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 446.56,
        "end": 535.68
      },
      "pred_interval": {
        "start": 133.18,
        "end": 134.15
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 313.38,
        "end": 401.53,
        "average": 357.455
      },
      "rationale_metrics": {
        "rouge_l": 0.2162162162162162,
        "text_similarity": 0.5280446410179138,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the 'thousands of preventable deaths' statement occurs after the prior remark, but it misidentifies the first event, gives completely incorrect timestamps (off by ~300s), and thus fails to match the reference events and timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks, \"What's in my budget to fix it?\", when does she start asking, \"How important is it to me to fix this issue?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 518.66,
        "end": 522.26
      },
      "pred_interval": {
        "start": 526.0,
        "end": 529.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.340000000000032,
        "end": 6.740000000000009,
        "average": 7.0400000000000205
      },
      "rationale_metrics": {
        "rouge_l": 0.2954545454545454,
        "text_similarity": 0.6187386512756348,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the event order right (target after anchor) but the reported timestamps are significantly different from the ground truth, it omits the target end time, and it adds unverified commentary about intonation\u2014so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the man finishes saying, \"not continuing medical bills,\" when does he start asking, \"So, what does successful self-advocacy look like?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 643.04,
        "end": 646.32
      },
      "pred_interval": {
        "start": 585.0,
        "end": 586.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.039999999999964,
        "end": 60.32000000000005,
        "average": 59.18000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.617615818977356,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the prediction correctly identifies the qualitative relation ('after'), its timestamps are substantially wrong (off by ~50 seconds) and contradict the reference anchor/target times, so it fails to match the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining what a doctor's follow-up might entail, when does the woman start asking, \"Or will I actually be able to get into your office in two weeks?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 679.0,
        "end": 683.92
      },
      "pred_interval": {
        "start": 689.0,
        "end": 692.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 8.080000000000041,
        "average": 9.04000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.19780219780219782,
        "text_similarity": 0.7536089420318604,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the woman's question follows the man's explanation, but its timestamps are off by about 9\u201310 seconds (predicted 687.5/689.0s vs ground-truth 677.92/679.00s), so it contradicts the precise timing in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Immediately after the woman asks if she should follow up if she is still experiencing symptoms, when does the man ask what if the symptoms go away?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.38,
        "end": 707.15
      },
      "pred_interval": {
        "start": 88.9,
        "end": 91.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 610.48,
        "end": 615.9499999999999,
        "average": 613.2149999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.43956043956043955,
        "text_similarity": 0.8378340005874634,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the event order (man speaks immediately after woman) but gives completely incorrect absolute timestamps (88.9s vs ~699s), so the key factual timing is wrong and the answer is not acceptable."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying to voice symptoms and concerns clearly, when does he give an example about shoulder pain?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 734.59,
        "end": 737.0
      },
      "pred_interval": {
        "start": 111.8,
        "end": 115.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 622.7900000000001,
        "end": 621.8,
        "average": 622.2950000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.31683168316831684,
        "text_similarity": 0.7445418238639832,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two events and their immediate 'once_finished' relationship, but the reported timestamps are vastly different from the ground truth, so the answer is factually incorrect on the key temporal details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes warning not to try putting a hand in an electrical outlet, when does the woman agree and say not to try that?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 810.0,
        "end": 812.0
      },
      "pred_interval": {
        "start": 133.1,
        "end": 134.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 676.9,
        "end": 677.5,
        "average": 677.2
      },
      "rationale_metrics": {
        "rouge_l": 0.37499999999999994,
        "text_similarity": 0.7259343862533569,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target utterances and their immediate-after relation, but the reported timestamps differ substantially from the ground-truth times, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes saying to assume benevolence of your doctor, when does the man begin to speak?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.9,
        "end": 879.1
      },
      "pred_interval": {
        "start": 916.8,
        "end": 918.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.89999999999998,
        "end": 39.10000000000002,
        "average": 38.5
      },
      "rationale_metrics": {
        "rouge_l": 0.25806451612903225,
        "text_similarity": 0.5972334742546082,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures that the man speaks immediately after the woman, but it gives incorrect timestamps (916.8s vs the correct 878.0s/878.9s), even aligning the man's start simultaneous with the woman's end and adding an extraneous visual cue, so it is largely factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks about trying non-surgical options first, when does the woman reply 'Yes'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 899.7,
        "end": 900.1
      },
      "pred_interval": {
        "start": 931.0,
        "end": 932.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.299999999999955,
        "end": 31.899999999999977,
        "average": 31.599999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.20952380952380953,
        "text_similarity": 0.563862681388855,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the temporal relation (woman replies immediately after the man) but the timestamps are significantly off (predicted start 931.0s vs gold 899.7s, ~31s difference) and it adds an end time and visual cues not specified in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the man concludes his statement about how to ask for another opinion, when does the woman respond that asking for another opinion is definitely valid?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 982.0,
        "end": 988.72
      },
      "pred_interval": {
        "start": 952.5,
        "end": 954.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.5,
        "end": 34.72000000000003,
        "average": 32.110000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.5206623673439026,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the woman's affirmative reply, but the timestamps are substantially different from the reference (952.5s vs 976.0s/\u2248982s) and the temporal relation is mischaracterized (predicted 'immediately after' and overlapping times vs reference 'after'), so it fails on key factual timing and relation details."
      }
    },
    {
      "question_id": "001",
      "question": "After the man suggests bringing someone along if you're not feeling safe, when does the woman agree that it's advisable?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1127.0,
        "end": 1130.0
      },
      "pred_interval": {
        "start": 1105.8,
        "end": 1117.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.200000000000045,
        "end": 12.900000000000091,
        "average": 17.050000000000068
      },
      "rationale_metrics": {
        "rouge_l": 0.26804123711340205,
        "text_similarity": 0.7780433893203735,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the same exchange and the 'after' relationship and captures the woman's agreement, but the provided timestamps are substantially earlier than the reference and the predicted E2 span includes additional speech beyond the woman's initial agreement, so the temporal alignment and target span are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman talks about a doctor not trusting a patient's pain because they don't act like they're in pain, when does she give an example of a loved one vouching for the patient?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1167.68,
        "end": 1174.48
      },
      "pred_interval": {
        "start": 1120.4,
        "end": 1124.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.27999999999997,
        "end": 50.48000000000002,
        "average": 48.879999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.24590163934426226,
        "text_similarity": 0.6490722894668579,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence and even quotes the illustrative line, but the provided timestamps are substantially different from the ground truth (off by ~44\u201346 seconds), so the answer is factually incorrect on the key timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks if it is legal to be given your own medical records, when does the woman confirm that it is?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1268.6,
        "end": 1270.7
      },
      "pred_interval": {
        "start": 1231.2,
        "end": 1232.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.399999999999864,
        "end": 38.0,
        "average": 37.69999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.3181818181818182,
        "text_similarity": 0.6040353178977966,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that the woman's affirmative reply follows the man's question and even quotes her response, but the provided timecodes differ substantially from the reference, causing a significant factual mismatch in timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman mentions that things have changed a lot with electronic medical records, when does the man state that bureaucracy reminds him of common barriers?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1333.0,
        "end": 1339.5
      },
      "pred_interval": {
        "start": 1267.8,
        "end": 1270.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.20000000000005,
        "end": 69.29999999999995,
        "average": 67.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2888888888888889,
        "text_similarity": 0.8953633308410645,
        "llm_judge_score": 2,
        "llm_judge_justification": "While both answers label the relation as 'after,' the predicted timestamps are substantially different and place the man's remark almost immediately after the woman rather than significantly later as in the reference, so key factual timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks about common barriers and how to overcome them, when does the woman share her fear of ants?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.36,
        "end": 1383.7
      },
      "pred_interval": {
        "start": 1306.5,
        "end": 1309.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.8599999999999,
        "end": 74.70000000000005,
        "average": 72.77999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2826086956521739,
        "text_similarity": 0.8327767252922058,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly captures that the woman's fear occurs after the man's prompt, but it gives substantially incorrect anchor/target timestamps and misplaces the event (wrong timing and context), so it is largely factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says to write things down on paper and give it to the doctor, when does he mention a doctor refusing to look at the paper?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1484.96,
        "end": 1490.0
      },
      "pred_interval": {
        "start": 123.0,
        "end": 125.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1361.96,
        "end": 1365.0,
        "average": 1363.48
      },
      "rationale_metrics": {
        "rouge_l": 0.4153846153846154,
        "text_similarity": 0.8933985233306885,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the doctor-refusal phrase and preserves the 'after' relationship, but it mislabels and paraphrases the anchor (different wording/meaning) and gives completely incorrect timestamps for both events, so it fails on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "While the woman discusses prioritizing cognition, when does she state that she would rather be in pain than have her mental capacity harmed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1534.64,
        "end": 1542.24
      },
      "pred_interval": {
        "start": 142.0,
        "end": 145.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1392.64,
        "end": 1397.24,
        "average": 1394.94
      },
      "rationale_metrics": {
        "rouge_l": 0.4324324324324324,
        "text_similarity": 0.7053730487823486,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly quotes the target line and captures that it relates to prioritizing cognition, but the provided timestamps are wildly incorrect and it mischaracterizes the context as a friend's personal boundaries rather than the example within the broader discussion, so key factual details are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'Nord, what is that?', when does the woman state what NORD stands for?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.4,
        "end": 1615.4
      },
      "pred_interval": {
        "start": 1633.0,
        "end": 1638.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.59999999999991,
        "end": 22.59999999999991,
        "average": 21.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.38202247191011235,
        "text_similarity": 0.8156344890594482,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the woman's reply and the temporal ordering (the target occurs after the question) but gives inconsistent absolute timestamps (shifted) and is less precise than the reference about the target 'immediately' following the anchor; minor wording difference ('Diseases' vs 'Disease')."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says 'I read that I need to start this at 30', when does she explain why she needs the doctor to order it?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1692.24,
        "end": 1711.28
      },
      "pred_interval": {
        "start": 1731.0,
        "end": 1738.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.75999999999999,
        "end": 26.720000000000027,
        "average": 32.74000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.38016528925619836,
        "text_similarity": 0.6453707218170166,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies a direct continuation and the 'after' relationship, but the timestamps are substantially shifted (~39s later) and the explanation content diverges\u2014it introduces 'insurance needs to approve' and a plea rather than stating she needs the doctor to order it\u2014so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman explains how to mirror a planned course of action, when does she suggest asking the doctor what they heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.0,
        "end": 1799.8
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1770.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.0,
        "end": 29.799999999999955,
        "average": 28.399999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.6599714159965515,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly identifies the qualitative 'after' relationship and the quoted phrase, it gives completely incorrect timestamps (both events at 1770.0s and zero-duration), contradicting the correct absolute times where the anchor ends at 1789.4s and the target starts at 1797.0s. These major temporal inaccuracies make the prediction largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the man advises to 'just dig' and not use a medical dictionary, when does he ask if medical language can be 'dumbed down'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1836.56,
        "end": 1841.52
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1770.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.55999999999995,
        "end": 71.51999999999998,
        "average": 69.03999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.1836734693877551,
        "text_similarity": 0.5797595977783203,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relationship (the question follows the advice) but the timestamps are substantially wrong (E1 and E2 times do not match the reference, and E2 is given as a zero-length span), so it omits key factual timing information and contains incorrect details."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks what to do when doctors look rushed, when does the woman describe slowing down and capturing their attention?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1965.6,
        "end": 1973.5
      },
      "pred_interval": {
        "start": 26.7,
        "end": 35.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1938.8999999999999,
        "end": 1938.3,
        "average": 1938.6
      },
      "rationale_metrics": {
        "rouge_l": 0.28846153846153844,
        "text_similarity": 0.6527259349822998,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor ('What do you do?') and the target (woman's response about slowing down and making eye contact), and correctly labels the relation as 'after'; only the reported timestamps differ (likely due to a different time base), so I deduct one point for the timing mismatch."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes suggesting a doctor might be having a bad day, when does the man humorously ask if doctors have bad days?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2002.5,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 60.2,
        "end": 61.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1942.3,
        "end": 1942.2,
        "average": 1942.25
      },
      "rationale_metrics": {
        "rouge_l": 0.32075471698113206,
        "text_similarity": 0.6942388415336609,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and their 'immediately after' relationship, but the timestamps are significantly incorrect (60.2/61.8s vs. 2001.5/2002.5\u20132004.0s), so it fails on the key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the man introduces the 'five practical tips to advocate for yourself', when does the woman begin talking about writing down questions?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2195.28,
        "end": 2199.7
      },
      "pred_interval": {
        "start": 73.9,
        "end": 77.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2121.38,
        "end": 2121.7999999999997,
        "average": 2121.59
      },
      "rationale_metrics": {
        "rouge_l": 0.19230769230769232,
        "text_similarity": 0.6695063710212708,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor, the target utterance content, and the 'after' relationship, but the provided timestamps are far from the ground-truth ranges (major timing errors), so the answer is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "During the man's explanation about preparing beforehand, when does he demonstrate by pointing to his neck?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.0,
        "end": 2237.0
      },
      "pred_interval": {
        "start": 135.5,
        "end": 137.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2099.5,
        "end": 2099.9,
        "average": 2099.7
      },
      "rationale_metrics": {
        "rouge_l": 0.3010752688172043,
        "text_similarity": 0.7727452516555786,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the neck-pointing gesture occurs during the man's explanation and describes the gesture, but it gives completely different timestamps than the reference (mismatched absolute times) and adds an unverified quoted utterance, so it is largely incorrect on the key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "After the man describes getting dizzy when walking up and down stairs, when does the woman mention repeating back what was heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2316.0,
        "end": 2317.0
      },
      "pred_interval": {
        "start": 2391.0,
        "end": 2400.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.0,
        "end": 83.0,
        "average": 79.0
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.5997755527496338,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction misidentifies the anchor (wrong speaker and content), gives incorrect timestamps, and selects a different target event (man's advice) instead of the woman mentioning repeating back, so it contradicts the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman expresses her inability to distract herself from the pain, when does the man advise her to be specific?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.7,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2431.0,
        "end": 2442.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.30000000000018,
        "end": 72.5,
        "average": 67.40000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.2988505747126437,
        "text_similarity": 0.71901535987854,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the content and the 'after' relation, but the provided timestamps differ substantially from the ground truth (off by ~60\u201370 seconds), so the timing information is factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says 'document everything', when does the woman affirm the advice and tell viewers to take notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2504.5,
        "end": 2506.0
      },
      "pred_interval": {
        "start": 273.1,
        "end": 276.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2231.4,
        "end": 2229.5,
        "average": 2230.45
      },
      "rationale_metrics": {
        "rouge_l": 0.2962962962962963,
        "text_similarity": 0.611336350440979,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the content (woman affirms and tells viewers to take notes) but gives substantially incorrect timestamps and wrongly asserts the response is immediate, so the temporal information is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes asking if one should ask permission before recording their doctor, when does the woman respond?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2531.6,
        "end": 2533.5
      },
      "pred_interval": {
        "start": 281.7,
        "end": 283.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2249.9,
        "end": 2250.3,
        "average": 2250.1000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.3023255813953488,
        "text_similarity": 0.6181325912475586,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two events and their immediate temporal relation and even matches the utterances, but the timestamps are substantially incorrect (predicted ~281.7\u2013283.2s vs correct ~2531.3\u20132533.5s), so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman begins explaining the hope that doctors will focus more on patients with AI recording, when does she explain why she almost always checks her online appointment notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.0,
        "end": 2579.0
      },
      "pred_interval": {
        "start": 314.0,
        "end": 325.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2252.0,
        "end": 2253.5,
        "average": 2252.75
      },
      "rationale_metrics": {
        "rouge_l": 0.21818181818181817,
        "text_similarity": 0.5793588757514954,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely mismatches the reference: it misidentifies E1, gives completely incorrect timestamps and boundaries, and the relationship is wrong; it only loosely matches the quoted E2 content."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks if one should be assertive, when does he introduce the topic of emotional intelligence?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2701.0,
        "end": 2710.0
      },
      "pred_interval": {
        "start": 2734.4,
        "end": 2735.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.40000000000009,
        "end": 25.699999999999818,
        "average": 29.549999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.24528301886792453,
        "text_similarity": 0.6851156949996948,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the semantic relationship (the topic follows the question directly) and even quotes the utterance, but it gives substantially incorrect timestamps (off by ~38 seconds) and slightly misrepresents the pause length, so key factual timing details are wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man says 'You wanna learn some breathing control', when does he start describing box breathing?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.0,
        "end": 2747.0
      },
      "pred_interval": {
        "start": 2756.7,
        "end": 2760.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.699999999999818,
        "end": 13.599999999999909,
        "average": 15.149999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.7616232633590698,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the content and that the description follows immediately, but the provided timestamps are substantially offset (~20\u201327 seconds later) from the ground-truth times, so the timing is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the man is saying 'If you want, share your story in the comments', when is the 'COMMENT BELOW' graphic displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2925.8,
        "end": 2929.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.800000000000182,
        "end": 6.400000000000091,
        "average": 6.100000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.2678571428571429,
        "text_similarity": 0.7152819633483887,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are several seconds later and misstate the temporal relation (saying the graphic appears after the speech and overlaps its entire duration), which contradicts the correct answer that the graphic (2920.0\u20132923.0s) is displayed continuously during the man's speech; key timing and ordering are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the thumbs up icon appears on screen, when is the next graphic ('COMMENT BELOW') displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2909.8,
        "end": 2912.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.199999999999818,
        "end": 10.300000000000182,
        "average": 10.25
      },
      "rationale_metrics": {
        "rouge_l": 0.36781609195402293,
        "text_similarity": 0.7782094478607178,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction identifies the same two graphics but gives completely different timestamps and falsely states they overlap and disappear together, contradicting the correct answer that the thumbs-up is at 2862.0s and the COMMENT BELOW appears later at 2920.0\u20132923.0; therefore it is nearly entirely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After Marissa Fourie introduces herself, when does she mention cross-cultural communication?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 34.2,
        "end": 36.5
      },
      "pred_interval": {
        "start": 35.2,
        "end": 38.5
      },
      "iou": 0.3023255813953484,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 2.0,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2142857142857143,
        "text_similarity": 0.648712158203125,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer gets the temporal relation correct and roughly locates E2, but it incorrectly timestamps E1 (8.1s vs 20.5\u201324.2s) and slightly misaligns E2; it also adds extraneous detail about topic ordering. These timing errors are significant. "
      }
    },
    {
      "question_id": "002",
      "question": "After mentioning cross-cultural communication, when does Marissa Fourie next mention personality-specific communication skills?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 37.0,
        "end": 39.0
      },
      "pred_interval": {
        "start": 40.7,
        "end": 43.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.700000000000003,
        "end": 4.299999999999997,
        "average": 4.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2758620689655172,
        "text_similarity": 0.6037054061889648,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the ordering (mentions come in sequence) but the timestamps are several seconds off and the relation is mislabeled/contradicted (correctly 'next' but predicted as 'after' with inconsistent timing and a gap), so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After encouraging viewers to join PhysioPlus, when does Marissa Fourie say 'See you there!'?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 62.9,
        "end": 63.7
      },
      "pred_interval": {
        "start": 64.9,
        "end": 65.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.000000000000007,
        "end": 2.0999999999999943,
        "average": 2.0500000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.26373626373626374,
        "text_similarity": 0.6530488729476929,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same phrases and correctly labels the relation as 'after', but the reported timestamps are substantially inaccurate (E1 is ~12.5s later than the ground truth and E2 ~2s late) and it adds an unfounded comment about immediate follow-up/outro timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes mentioning \"the dosage in each area\", when does the woman in blue gloves point to the glabella area of the patient's forehead?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 4.469,
        "end": 4.8
      },
      "pred_interval": {
        "start": 3.4,
        "end": 4.7
      },
      "iou": 0.16499999999999992,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0690000000000004,
        "end": 0.09999999999999964,
        "average": 0.5845
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5818063020706177,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly identifies the 'after' relation and roughly matches the pointer end time, but both event timestamps are substantially earlier than the ground truth (E1: 2.8s vs 4.161s; E2 start: 3.4s vs 4.469s), so key factual timings are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the dosage for the brow lift, when does the woman in blue gloves point to the patient's upper lip?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 12.121,
        "end": 12.5
      },
      "pred_interval": {
        "start": 9.0,
        "end": 10.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.1210000000000004,
        "end": 2.4000000000000004,
        "average": 2.7605000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.7479915022850037,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives timestamps that are several seconds earlier than the ground truth for both events and a different temporal relation; it therefore contradicts key factual elements (event times and relation) despite roughly describing the same sequence. "
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the dosage for the lip flip, when does the text \"TIME TO INJECT!\" appear on screen?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 18.291,
        "end": 21.0
      },
      "pred_interval": {
        "start": 12.7,
        "end": 13.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.591000000000001,
        "end": 7.9,
        "average": 6.745500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.24096385542168675,
        "text_similarity": 0.578769862651825,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: E1 time is wrong and even refers to the chin rather than the lip flip, E2 timestamps and duration contradict the reference (18.291s to end vs 12.7\u201313.1s), and the relation/ordering is misaligned with the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host welcomes Rich, when does Rich begin his response?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 33.015,
        "end": 34.078
      },
      "pred_interval": {
        "start": 42.0,
        "end": 43.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.985,
        "end": 8.921999999999997,
        "average": 8.953499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424246,
        "text_similarity": 0.8308676481246948,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the sequence (Rich speaks immediately after the host) but the reported timestamps are substantially off (~9\u201310s later than the reference) and it introduces specific utterances not present in the ground truth, so it is largely incorrect. "
      }
    },
    {
      "question_id": "002",
      "question": "While Rich is explaining how medicine may have let relationships with patients deteriorate, when does he say that scientific facts will protect us?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 89.0,
        "end": 93.76
      },
      "pred_interval": {
        "start": 81.0,
        "end": 83.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.0,
        "end": 10.760000000000005,
        "average": 9.380000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.19718309859154928,
        "text_similarity": 0.7160078287124634,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the quoted phrase and that it occurs during his explanation, but the provided timestamps are inaccurate (E1 given as 77.0\u201380.0 vs correct start 73.611s and E2 placed at 81.0s instead of 89.0\u201393.760s), so it fails to locate the event correctly."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks what trust looks like in the future with intermediaries, when does Rich first discuss the stethoscope in relation to technology in medicine?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 112.0,
        "end": 113.0
      },
      "pred_interval": {
        "start": 110.0,
        "end": 111.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 2.0,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.1797752808988764,
        "text_similarity": 0.7114784717559814,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that Rich's stethoscope remark follows the host's question and includes relevant dialogue, but the reported timestamps are inaccurate (E1 end and especially E2 start differ from the reference) and the claim of 'immediately after' overstates the temporal proximity."
      }
    },
    {
      "question_id": "001",
      "question": "After the man in glasses finishes describing the giant TV screen in a new hospital exam room, when does the video show a patient interacting with a screen in a hospital bed?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 167.6,
        "end": 177.6
      },
      "pred_interval": {
        "start": 158.4,
        "end": 163.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.199999999999989,
        "end": 14.400000000000006,
        "average": 11.799999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.3232323232323232,
        "text_similarity": 0.8534568548202515,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation as 'after', but the provided timestamps are substantially different from the reference (anchor and target times are both off by several seconds), so the key factual details are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the interviewer asks if technology can bring doctors and patients closer together, when is he holding a small white 'Trust tv' card?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 178.0,
        "end": 183.5
      },
      "pred_interval": {
        "start": 192.0,
        "end": 193.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 10.099999999999994,
        "average": 12.049999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.43750000000000006,
        "text_similarity": 0.8351079225540161,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies a 'during' relationship (the card is visible while he speaks) but gives completely different timestamps and mislocalizes the interviewer's question relative to the ground truth, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the interviewer thanks Rich and says viewers learned a lot, when does Rich respond 'It's really a pleasure'?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 210.3,
        "end": 212.1
      },
      "pred_interval": {
        "start": 202.4,
        "end": 203.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.900000000000006,
        "end": 8.5,
        "average": 8.200000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3225806451612903,
        "text_similarity": 0.8523294925689697,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the 'immediately after' relationship, but the reported timestamps contradict the ground truth: the anchor/target boundaries and start times (201.2\u2013203.6s) do not match the reference (anchor at 200.0s, target 210.3\u2013212.1s), so the temporal localization is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions learning about 'patient rapport', when does he discuss charting and interacting with other healthcare providers?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 2.075,
        "end": 9.55
      },
      "pred_interval": {
        "start": 15.0,
        "end": 16.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.925,
        "end": 7.25,
        "average": 10.0875
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6486716270446777,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two topics and their order, but the timestamps are substantially incorrect and the relation is labeled 'after' rather than the correct immediate 'once_finished', so it fails on key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker talks about developing skills like putting an IV, when does he mention getting a patient discharged?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 15.42,
        "end": 24.583
      },
      "pred_interval": {
        "start": 24.6,
        "end": 25.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.180000000000001,
        "end": 1.2170000000000023,
        "average": 5.198500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.23404255319148934,
        "text_similarity": 0.7009010910987854,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct phrases but gives incorrect timestamps and the wrong temporal relation: E1/E2 times are misplaced (do not match the ground truth) and the relation should be 'once_finished' (immediately follows), not 'after'."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Make their problem, your problem', when does he introduce the importance of self-care?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 45.009,
        "end": 48.396
      },
      "pred_interval": {
        "start": 35.2,
        "end": 35.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.808999999999997,
        "end": 12.596000000000004,
        "average": 11.2025
      },
      "rationale_metrics": {
        "rouge_l": 0.45217391304347826,
        "text_similarity": 0.6812480688095093,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct phrases but gives substantially incorrect timestamps for both events and wrongly claims they are simultaneous/immediately adjacent, contradicting the reference which places E2 after E1 (45.009s\u201348.396s). These major temporal and relation errors justify a very low score."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker's introduction of herself, when does she mention specializing in wounds?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.605,
        "end": 26.329
      },
      "pred_interval": {
        "start": 38.6,
        "end": 42.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.995000000000001,
        "end": 15.970999999999997,
        "average": 15.982999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2117647058823529,
        "text_similarity": 0.42454293370246887,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures a thematically similar phrase ('specializing in wounds') but the timestamps and anchor identity are incorrect\u2014the correct anchor/name occurs at ~0:18 and the correct target at ~0:22\u20130:26, whereas the prediction places both events around 36\u201342s, so it largely fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of 'getting the most out of your GP consultation', when does she mention that GP practices are getting a huge injection of funding?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.82,
        "end": 75.533
      },
      "pred_interval": {
        "start": 74.2,
        "end": 87.9
      },
      "iou": 0.0663844621513943,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.38000000000001,
        "end": 12.367000000000004,
        "average": 9.373500000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.30476190476190484,
        "text_similarity": 0.5647769570350647,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer's timestamps are substantially later than the ground truth (anchor given as ~73.9s vs 62\u201365s; target as 74.2\u201387.9s vs 67.82\u201375.533s), so it misaligns the events despite correctly stating the target follows the anchor."
      }
    },
    {
      "question_id": "003",
      "question": "While the slide titled 'Appointments are precious' is on screen, when does the speaker mention that GP practices are moving back towards face-to-face appointments?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 123.0,
        "end": 129.0
      },
      "pred_interval": {
        "start": 137.0,
        "end": 140.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 11.699999999999989,
        "average": 12.849999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.4210526315789474,
        "text_similarity": 0.6956489086151123,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: both the anchor and target timestamps contradict the ground truth (predicted 5.0\u201315.5 and 137.0\u2013140.7 vs. correct ~100.74 and 123.0\u2013129.0) and it wrongly asserts the target occurs after the slide rather than concurrently."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that GP practices are very different places now, when does she begin listing the specific roles in a GP practice?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.0,
        "end": 204.0
      },
      "pred_interval": {
        "start": 189.0,
        "end": 190.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 13.5,
        "average": 13.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2413793103448276,
        "text_similarity": 0.5976698398590088,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it misidentifies the anchor utterance and its timing, places the start of the staff list ~14s too early (189.0s vs 203.0s), and incorrectly calls the relation 'immediately after' rather than the later 'after'. It only correctly notes 'GP' as a listed role but gets the key timings and relation wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide displays the question 'Does it need to be a GP?', when does the speaker mention that paramedics work in primary care?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "pred_interval": {
        "start": 198.5,
        "end": 199.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.5,
        "end": 40.5,
        "average": 38.5
      },
      "rationale_metrics": {
        "rouge_l": 0.396039603960396,
        "text_similarity": 0.7065389752388,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the quoted phrase but gives substantially incorrect timestamps (198.5\u2013199.5s vs. 235\u2013240s) and the wrong relation ('during' vs. correct 'after'), so it fails to match the temporal alignment."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker talks about paramedics working in primary care, when does she begin to explain the role of Advanced Clinical Practitioners?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 241.0,
        "end": 249.0
      },
      "pred_interval": {
        "start": 210.5,
        "end": 211.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.5,
        "end": 37.5,
        "average": 34.0
      },
      "rationale_metrics": {
        "rouge_l": 0.1553398058252427,
        "text_similarity": 0.7009145021438599,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly labels the relation as 'after' but the provided timestamps for E1 and E2 (\u2248210\u2013211s) conflict substantially with the ground truth (E1\u2248238.5s, E2\u2248241\u2013249s), so the answer is temporally inaccurate and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the problem of a wound on your foot, when does she strongly advise mentioning if you are diabetic?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 337.875,
        "end": 343.0
      },
      "pred_interval": {
        "start": 350.6,
        "end": 353.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.725000000000023,
        "end": 10.5,
        "average": 11.612500000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.6580570936203003,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer identifies the same utterances but the timestamps are substantially incorrect (anchor ~5s early, target ~13s late) and it misstates the relationship\u2014advice should immediately follow the problem introduction, not occur much later\u2014so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having a new wound on your leg, when does she suggest going to a local pharmacist for simple dressings?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 363.968,
        "end": 366.552
      },
      "pred_interval": {
        "start": 434.5,
        "end": 447.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.53199999999998,
        "end": 80.84799999999996,
        "average": 75.68999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.27184466019417475,
        "text_similarity": 0.823707103729248,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the content and the 'after' relationship (pharmacist advice given while waiting for a nurse), but the provided timestamps contradict the reference times\u2014significantly different anchor/target timings\u2014so the answer is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker explains that a nurse's appointment is needed for long-standing wounds, when does she advise to clearly state how long the wound has been there?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 409.579,
        "end": 439.62
      },
      "pred_interval": {
        "start": 482.1,
        "end": 487.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.52100000000002,
        "end": 47.48000000000002,
        "average": 60.00050000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2745098039215686,
        "text_similarity": 0.7853158712387085,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly reports that the advice comes immediately after the nurse-appointment remark and captures the instruction, but the provided timestamps conflict with the reference (are off by ~39s) and the anchor end time is omitted, so it is factually inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if you feel more short of breath, when does she state that a GP or nurse practitioner might be needed the same day?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 522.783,
        "end": 525.113
      },
      "pred_interval": {
        "start": 561.46,
        "end": 567.12
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.67700000000002,
        "end": 42.00699999999995,
        "average": 40.341999999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.26,
        "text_similarity": 0.5897652506828308,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer uses the correct utterances but gives timestamps that are substantially incorrect and claims the target begins immediately with the anchor, contradicting the reference's specified start/end times and temporal relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to measure your ankle and calf, when does she give an example of a calf measurement that would 'perk up more interest'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.623,
        "end": 586.297
      },
      "pred_interval": {
        "start": 612.98,
        "end": 618.62
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.35699999999997,
        "end": 32.32299999999998,
        "average": 30.839999999999975
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.503631591796875,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly identifies the anchor and the nature of the example, but the timestamps are substantially different from the reference and it adds an unsupported phrasing about making swelling 'really obvious,' so it fails temporal accuracy and includes a minor hallucination."
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Photography', when does the speaker advise to 'expect to be asked for a photo'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 670.384,
        "end": 672.807
      },
      "pred_interval": {
        "start": 671.42,
        "end": 675.46
      },
      "iou": 0.2732466509062355,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0359999999999445,
        "end": 2.65300000000002,
        "average": 1.8444999999999823
      },
      "rationale_metrics": {
        "rouge_l": 0.3132530120481928,
        "text_similarity": 0.7869812846183777,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the utterance content but gives substantially incorrect timing: the anchor slide transition is placed ~19s late and the target interval (671.42\u2013675.46s) does not match the ground-truth span (670.384\u2013672.807s). These timing errors and the unsupported claim about it being the first point make the answer only a partial match."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions some GP practices use video consultations, when does she state that a good quality photograph is better than a video?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.278,
        "end": 717.251
      },
      "pred_interval": {
        "start": 690.0,
        "end": 705.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.27800000000002,
        "end": 12.250999999999976,
        "average": 18.264499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.23157894736842105,
        "text_similarity": 0.6090587377548218,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the quoted content but gives substantially incorrect timestamps (events listed ~18\u201324s earlier, with E1 and E2 overlapping) and mischaracterizes the timing relation; thus it fails on key factual timing details from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the slide changes to 'Photography tips', when does the speaker begin discussing taking a close-up and further-away picture?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 738.601,
        "end": 740.91
      },
      "pred_interval": {
        "start": 723.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.600999999999999,
        "end": 10.909999999999968,
        "average": 13.255499999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.32098765432098764,
        "text_similarity": 0.6437720060348511,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mentions the same topic but the anchor and target timestamps differ substantially from the ground truth (E1/E2 off by ~13\u201315s) and the relation is contradicted ('at the same time as' vs. 'once_finished'), so it is largely incorrect despite matching the content."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide changes to 'General top tips- face to face appointments', when does the speaker advise to 'Go suitably dressed'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 860.136,
        "end": 860.846
      },
      "pred_interval": {
        "start": 755.0,
        "end": 760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 105.13599999999997,
        "end": 100.846,
        "average": 102.99099999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.24719101123595508,
        "text_similarity": 0.6249717473983765,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer contains the correct quoted phrase but gives completely different timestamps and incorrectly states the relation as 'at the same time' instead of 'after', contradicting the ground truth timing; therefore it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises not to wear tight socks, trousers, or wellies, when does she suggest wearing something with quick access to lower limbs?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.0,
        "end": 877.5
      },
      "pred_interval": {
        "start": 877.8,
        "end": 882.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.7999999999999545,
        "end": 5.100000000000023,
        "average": 4.949999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.1592920353982301,
        "text_similarity": 0.691813051700592,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction accurately captures the semantic content and labels the temporal relation as 'after'; timestamps differ slightly from the reference but the events and ordering are correctly identified."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes advising not to make chit-chat about the weather, when does she advise not to dodge the real problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 893.0,
        "end": 894.5
      },
      "pred_interval": {
        "start": 895.2,
        "end": 899.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.2000000000000455,
        "end": 4.5,
        "average": 3.3500000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.2680412371134021,
        "text_similarity": 0.623654842376709,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the correct relation and similar phrasing, but the event time spans are significantly shifted and incorrect (E1 and E2 boundaries do not match and even overlap/miss the ground-truth intervals), so the temporal localization is flawed."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker advises to take a list of the medications you are actually taking, when does she advise against describing tablets by their appearance?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 948.0,
        "end": 969.0
      },
      "pred_interval": {
        "start": 904.1,
        "end": 915.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.89999999999998,
        "end": 53.799999999999955,
        "average": 48.849999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.19672131147540986,
        "text_similarity": 0.7229117155075073,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the events' content and the 'after' relation, but it gives substantially different/incorrect timestamps for both E1 and E2, so the key factual timing information is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker advises speaking to the practice in advance about a relative, when does she explain the reason for this advance arrangement due to confidentiality?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1065.0,
        "end": 1095.0
      },
      "pred_interval": {
        "start": 1092.73,
        "end": 1112.62
      },
      "iou": 0.047669046619067346,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.730000000000018,
        "end": 17.61999999999989,
        "average": 22.674999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.15789473684210525,
        "text_similarity": 0.6193385720252991,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same two utterances (advance arrangement and confidentiality explanation) but gives incorrect timestamps and an incorrect temporal relation (places E2 starting simultaneously with E1 and later end time, whereas the ground truth has E1 ending at 1055s and E2 starting at 1065s with 'once_finished')."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker suggests writing things down before an appointment to help structure what you say, when does she first ask 'How did it start?' regarding the leg problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1130.415,
        "end": 1131.738
      },
      "pred_interval": {
        "start": 1117.46,
        "end": 1126.19
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.954999999999927,
        "end": 5.548000000000002,
        "average": 9.251499999999965
      },
      "rationale_metrics": {
        "rouge_l": 0.22033898305084745,
        "text_similarity": 0.6301343441009521,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same two utterances but gives substantially incorrect timestamps and the wrong temporal relation (overlapping/earlier E2 and 'after' vs the ground-truth immediate 'once_finished' start at 1130.415s), so it fails on key factual alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes advising to ask to be referred to a specialist service, when does she start introducing the referrals examples?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.105,
        "end": 1249.385
      },
      "pred_interval": {
        "start": 1290.0,
        "end": 1295.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.89499999999998,
        "end": 45.61500000000001,
        "average": 43.754999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.45646893978118896,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the events and their 'after' relation, but the provided timestamps are substantially different from the ground truth (off by ~53s) and the E2 duration/end time contradicts the reference, so the answer is largely temporally incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that lymphoedema services can be patchy, when does she first advise writing to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.0,
        "end": 1378.0
      },
      "pred_interval": {
        "start": 1378.0,
        "end": 1385.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 7.0,
        "average": 4.0
      },
      "rationale_metrics": {
        "rouge_l": 0.29545454545454547,
        "text_similarity": 0.6965296268463135,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies both events and the temporal relation ('after') and E2 timing is close, but it gives a significantly incorrect timestamp for E1 (1375.2s vs correct 1335.096s), a substantive factual error in the anchor event timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions that a GP will assess new leg swelling for onward referral, when does she explain there are many different causes?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1429.846,
        "end": 1432.0
      },
      "pred_interval": {
        "start": 1422.0,
        "end": 1435.0
      },
      "iou": 0.16569230769230742,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.846000000000004,
        "end": 3.0,
        "average": 5.423000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962262,
        "text_similarity": 0.6736220121383667,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies both events and their 'after' relation, but the timestamps are significantly inaccurate (E1 is ~16s late, E2 starts ~8s early and ends ~3s late), so it fails on temporal precision and completeness."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what information you could take with you, when does she suggest looking up the National Wound Care Strategy Lower Limb Recommendations?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1465.0,
        "end": 1469.5
      },
      "pred_interval": {
        "start": 151.5,
        "end": 153.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1313.5,
        "end": 1316.0,
        "average": 1314.75
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.6576321125030518,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and the 'after' relation, but the timestamps are substantially inaccurate (predicted ~151\u2013153s vs reference ~1450\u20131469s), so it is factually wrong on timing."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions escalating concerns to the practice manager, when does she mention escalating concerns to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.6,
        "end": 1525.7
      },
      "pred_interval": {
        "start": 161.5,
        "end": 163.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1362.1,
        "end": 1362.2,
        "average": 1362.15
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.7124701142311096,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the semantic order (practice manager then MP) and dialogue content, but it gives incorrect/ inconsistent timestamps (and omits the E1 end time) compared to the reference; the temporal relation wording is close but timing errors are significant."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'I'll stop sharing', when does she start reading the first question from a viewer?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1574.5,
        "end": 1578.5
      },
      "pred_interval": {
        "start": 169.0,
        "end": 170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1405.5,
        "end": 1408.5,
        "average": 1407.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3877551020408163,
        "text_similarity": 0.7626948952674866,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the temporal relation ('once_finished') right, but the timestamps and event spans are substantially incorrect (off by over 1,300s) and the quoted E2 content does not match the reference reading of the first viewer question, so it fails on factual alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially suggests the mum needs compression hosiery, when does she mention asking for an appointment with the nurse for stronger compression?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1654.942,
        "end": 1664.2
      },
      "pred_interval": {
        "start": 138.2,
        "end": 141.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1516.742,
        "end": 1522.6000000000001,
        "average": 1519.671
      },
      "rationale_metrics": {
        "rouge_l": 0.25490196078431376,
        "text_similarity": 0.7172318696975708,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction partially mentions relevant concepts (nurse/compression hosiery) but misidentifies the anchor/target events and gives incorrect timestamps (138.2\u2013141.6s vs correct ~1601\u20131664s) and an inconsistent temporal relation, so it fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'That is such a good question', when does she state that self-diagnosis via the internet is never a good idea?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1757.815,
        "end": 1762.821
      },
      "pred_interval": {
        "start": 184.3,
        "end": 190.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1573.515,
        "end": 1572.721,
        "average": 1573.118
      },
      "rationale_metrics": {
        "rouge_l": 0.3829787234042553,
        "text_similarity": 0.8171603679656982,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase and the relation 'after', but the target timestamps are wildly incorrect (184.3\u2013190.1s vs. 1757.815\u20131762.821s) and the claim that the advice 'immediately follows' the anchor is false, so the timing is largely inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes that approaching a GP is about framing the conversation, when does she tell the viewer not to worry about being labeled a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1795.335,
        "end": 1798.383
      },
      "pred_interval": {
        "start": 250.4,
        "end": 253.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1544.935,
        "end": 1544.983,
        "average": 1544.9589999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.30158730158730157,
        "text_similarity": 0.6411538124084473,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target content and the 'after' relation and even reproduces the reassuring phrase, but it omits the anchor timestamp and gives incorrect target timestamps (should be ~1795.3\u20131798.4s), so the temporal localization is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker first says, 'Please don't worry about things like that', when does she next advise not to worry about being labelled as a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1827.66,
        "end": 1831.19
      },
      "pred_interval": {
        "start": 1940.0,
        "end": 1943.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 112.33999999999992,
        "end": 111.80999999999995,
        "average": 112.07499999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.5029937028884888,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timings (anchor 1938\u20131940s; target 1940\u20131943s) greatly contradict the reference times (anchor ~1787s; target ~1827\u20131831s) and incorrectly asserts the target follows immediately, including added details not in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks, 'What can I do to maintain healthy legs or feet so I don't get any problems?', when does she start listing actions like 'walk' and 'legs up'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1865.412,
        "end": 1883.383
      },
      "pred_interval": {
        "start": 1968.0,
        "end": 1970.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 102.58799999999997,
        "end": 86.61699999999996,
        "average": 94.60249999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.23762376237623764,
        "text_similarity": 0.609545111656189,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer captures the quoted actions ('walk... legs up') but the reported anchor and target timestamps are substantially incorrect (off by ~100+ seconds) and the target duration is unrealistically short, so it fails to match the key temporal facts."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks how much is in the GP curriculum, when does she say 'I don't know'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1983.7,
        "end": 1984.201
      },
      "pred_interval": {
        "start": 1972.5,
        "end": 1974.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.200000000000045,
        "end": 10.201000000000022,
        "average": 10.700500000000034
      },
      "rationale_metrics": {
        "rouge_l": 0.23684210526315788,
        "text_similarity": 0.6079587936401367,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the semantic relation right (the 'I don't know' immediately follows the question) but the timestamps are substantially incorrect (off by ~9\u201312 seconds and wrong duration), so it fails to match the provided ground-truth timing."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'I think it is something that Legs Matter can help with', when does she discuss Legs Matter influencing GP curriculums?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2004.063,
        "end": 2009.063
      },
      "pred_interval": {
        "start": 1982.0,
        "end": 1988.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.063000000000102,
        "end": 21.063000000000102,
        "average": 21.563000000000102
      },
      "rationale_metrics": {
        "rouge_l": 0.1758241758241758,
        "text_similarity": 0.6030677556991577,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and their temporal relation ('after'), but the provided timestamps are substantially different from the ground truth for both anchor and target, so the answer is factually inaccurate on the key timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks if seeing a nurse practitioner is appropriate, when does she state that nurse practitioners are 'extremely experienced clinicians'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2062.584,
        "end": 2066.851
      },
      "pred_interval": {
        "start": 2112.0,
        "end": 2115.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.41600000000017,
        "end": 48.14899999999989,
        "average": 48.78250000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.21176470588235294,
        "text_similarity": 0.5645791292190552,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the correct ordering (the target follows the question) and identifies the right utterances, but the provided timestamps are substantially off (\u224850s later) and do not match the precise anchor/target spans given in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I understand the issue of smartphones and taking pictures too\", when does she first ask \"is there somebody who can help you?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2174.0,
        "end": 2176.0
      },
      "pred_interval": {
        "start": 2148.0,
        "end": 2150.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.0,
        "end": 26.0,
        "average": 26.0
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.653994083404541,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the temporal relation right (target after anchor) but the timestamps are substantially incorrect (predicted 2130\u20132148 and 2148\u20132150 vs. ground truth 2165\u20132173 and 2174\u20132176), so it is factually wrong about the event times."
      }
    },
    {
      "question_id": "002",
      "question": "During the period when the speaker discusses the importance of planning phone calls to the GP, when does she ask, \"What am I feeling?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2197.721,
        "end": 2198.663
      },
      "pred_interval": {
        "start": 2181.0,
        "end": 2183.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.721000000000004,
        "end": 15.663000000000011,
        "average": 16.192000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.7131972908973694,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies a 'during' relationship and places events inside the broader anchor, but the timestamps are incorrect: the ground-truth target is at 2197.721\u20132198.663 (within anchor 2057.721\u20132207.721), whereas the prediction gives 2181.0\u20132183.0 for the target and a mismatched anchor span, so the key timing is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once Dr. Angelos finishes introducing Dr. Tolchin, when does Dr. Tolchin begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.128,
        "end": 109.393
      },
      "pred_interval": {
        "start": 100.7,
        "end": 101.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.427999999999997,
        "end": 8.192999999999998,
        "average": 6.3104999999999976
      },
      "rationale_metrics": {
        "rouge_l": 0.38461538461538464,
        "text_similarity": 0.8230301141738892,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the speaker transition and roughly matches E1's end, but it gives substantially incorrect start and end times for Dr. Tolchin (100.7\u2013101.2s predicted vs 105.128\u2013109.393s reference), contradicting the ground-truth timing."
      }
    },
    {
      "question_id": "002",
      "question": "After Dr. Angelos describes Dr. Tolchin's research on crisis standards of care, when does he describe his research on functional neurological disorders and epilepsy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.426,
        "end": 116.456
      },
      "pred_interval": {
        "start": 59.6,
        "end": 61.4
      },
      "iou": 0.029985007496251825,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.1739999999999995,
        "end": 55.056000000000004,
        "average": 29.115000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.7171764969825745,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the ordering (E2 follows E1) but the timestamps are substantially incorrect\u2014E1 is shifted and extended, and E2 is massively shorter and starts later than the reference\u2014so it omits and misstates key timing information."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating the second learning objective, when does he start explaining the third learning objective?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 181.0
      },
      "pred_interval": {
        "start": 174.14,
        "end": 175.14
      },
      "iou": 0.07142857142857142,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.139999999999986,
        "end": 5.860000000000014,
        "average": 6.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1797752808988764,
        "text_similarity": 0.42389795184135437,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction asserts a single, much later timestamp (174.14s) and immediate continuation at that same time, contradicting the correct times (16.4s end, 17.0s start) and omitting the 17.0\u201331.0s span; thus it is largely incorrect despite noting a continuation of objectives."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'Why conduct clinical ethics consultations?' is displayed, when does the speaker discuss moral distress among clinicians and staff?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.4,
        "end": 304.0
      },
      "pred_interval": {
        "start": 253.14,
        "end": 272.14
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.25999999999999,
        "end": 31.860000000000014,
        "average": 32.06
      },
      "rationale_metrics": {
        "rouge_l": 0.2765957446808511,
        "text_similarity": 0.7244088649749756,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps conflict with the reference: the correct slide spans 181.7\u2013307.6s and the discussion occurs 285.4\u2013304.0s, whereas the prediction gives entirely different intervals that do not match and misstate the temporal relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that clinical ethics consultations were helpful, when does he state that they were more likely to achieve consensus in clinical decisions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 350.2,
        "end": 357.0
      },
      "pred_interval": {
        "start": 342.0,
        "end": 354.0
      },
      "iou": 0.2533333333333341,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.199999999999989,
        "end": 3.0,
        "average": 5.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.3736263736263736,
        "text_similarity": 0.6737347841262817,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the 'after' relationship and the semantic sequence (helpfulness then consensus), but the timestamps for both E1 and E2 deviate substantially from the ground truth (E1 and E2 start/end times are incorrect)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of resource utilization, when does he specifically state that there was a reduced length of stay?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 438.9,
        "end": 450.3
      },
      "pred_interval": {
        "start": 387.0,
        "end": 392.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.89999999999998,
        "end": 58.30000000000001,
        "average": 55.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2616822429906542,
        "text_similarity": 0.6989406943321228,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly identifies the 'after' relationship, but the reported time spans are grossly inaccurate compared to the ground truth (predicted ~387\u2013392s vs actual anchor end 369.0s and target 438.9\u2013450.3s), so it fails to match the reference timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'to look at disparities', when does he begin to introduce Ellen Fox's team and their survey?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 493.5,
        "end": 499.0
      },
      "pred_interval": {
        "start": 418.0,
        "end": 423.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.5,
        "end": 76.0,
        "average": 75.75
      },
      "rationale_metrics": {
        "rouge_l": 0.34,
        "text_similarity": 0.7102351188659668,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the 'once_finished' relationship and sequence, but the reported timestamps for both the anchor and target differ substantially from the ground truth, so key factual details are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'hospitals with less than 400 beds', when does he mention 'little or no growth over that two decade period'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 527.809,
        "end": 530.91
      },
      "pred_interval": {
        "start": 634.43,
        "end": 639.35
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 106.62099999999998,
        "end": 108.44000000000005,
        "average": 107.53050000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.4545454545454545,
        "text_similarity": 0.8696805238723755,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that the target follows the anchor, but the timestamps are substantially wrong (off by ~108s) and the reported target span/duration does not match the reference, so the answer is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide titled 'Prior Healthcare System Ethics Committees' is fully displayed, when do the images of the six hospitals with their bed counts appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.7,
        "end": 552.0
      },
      "pred_interval": {
        "start": 594.94,
        "end": 607.61
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.24000000000001,
        "end": 55.610000000000014,
        "average": 49.42500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.22429906542056074,
        "text_similarity": 0.6896872520446777,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') but the timestamps for both the slide (E1) and the images (E2) are substantially incorrect and the predicted start/end times contradict the reference, so key factual timing details are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the number of ethics consults at Yale New Haven Hospital increased from 50 to 239, when does he describe this as 'approximately a five-fold increase in consult volume'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.7,
        "end": 624.7
      },
      "pred_interval": {
        "start": 703.44,
        "end": 707.32
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.74000000000001,
        "end": 82.62,
        "average": 81.68
      },
      "rationale_metrics": {
        "rouge_l": 0.35955056179775285,
        "text_similarity": 0.8588606715202332,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the order/relationship right (E2 occurs after E1) and matches the quoted phrases, but the timestamps are substantially incorrect compared to the ground truth, so it fails on key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially mentions the 'Community Bioethics Forum', when does he start describing its community members?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 887.216,
        "end": 905.918
      },
      "pred_interval": {
        "start": 954.2,
        "end": 957.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.98400000000004,
        "end": 51.182000000000016,
        "average": 59.08300000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.23157894736842105,
        "text_similarity": 0.8700299263000488,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the anchor phrase, the target content (description of community members), and the 'after' relation, but the provided timestamps are substantially incorrect and the target interval/duration does not match the ground truth, so the temporal alignment is factually wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that the primary focus of the Center for Clinical Ethics has been ethics education, when does he start listing 'Systemwide Ethics Forum and Newsletter'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1055.54,
        "end": 1069.28
      },
      "pred_interval": {
        "start": 1024.4,
        "end": 1030.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.139999999999873,
        "end": 38.57999999999993,
        "average": 34.8599999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2553191489361702,
        "text_similarity": 0.8646374940872192,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the relation and phrasing right but both event timestamps are substantially incorrect compared to the ground truth (E1 should be 938\u2013948s, E2 1055.54\u20131069.28s), so key factual details are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker lists 'ICU Walk Rounds', when does he mention 'HEC-C Certification'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1048.0,
        "end": 1052.0
      },
      "pred_interval": {
        "start": 1072.5,
        "end": 1079.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.5,
        "end": 27.700000000000045,
        "average": 26.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.850828230381012,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction identifies both the ICU rounds mention and the HEC-C certification and preserves the ordering, but it mislabels the anchor wording, gives substantially different timestamps/durations (offset by ~28s), and uses a vaguer relation ('after' vs 'next'), so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"ethics consultation services,\" when does he start talking about collecting feedback?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.8,
        "end": 1249.8
      },
      "pred_interval": {
        "start": 1255.0,
        "end": 1265.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.200000000000045,
        "end": 15.200000000000045,
        "average": 14.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.2588235294117647,
        "text_similarity": 0.6461894512176514,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the correct ordering (feedback is discussed immediately after the prior phrase) and even provides an end time, but the reported timestamps are significantly off (~16\u201317s later) compared to the reference, so the answer is factually inaccurate on key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that participant satisfaction is not the \"be-all and end-all,\" when does he say they have begun the survey process with clinicians?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.3,
        "end": 1282.8
      },
      "pred_interval": {
        "start": 1306.0,
        "end": 1313.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.700000000000045,
        "end": 30.200000000000045,
        "average": 28.950000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.33999999999999997,
        "text_similarity": 0.5970463156700134,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the target phrase and the immediate temporal relation (after/directly after), but the provided timestamps are substantially incorrect (~31s later than the ground truth), a significant factual mismatch."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes describing the first pie chart about helpful advice/guidance, when does the second pie chart about communication appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1367.5,
        "end": 1367.9
      },
      "pred_interval": {
        "start": 1313.0,
        "end": 1318.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.5,
        "end": 49.90000000000009,
        "average": 52.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.3655913978494624,
        "text_similarity": 0.6904114484786987,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer contradicts the ground truth times by tens of seconds for both events (1313\u20131318s vs 1356.0s and 1376.5s), so the temporal grounding is incorrect; while the relation ('immediately after' vs 'once_finished') is similar in intent, the factual timing is wrong, so the prediction is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he wants to turn to some of the organizational ethics consultation work, when does the slide showing the 'Organizational ethics consultations' table appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1472.0,
        "end": 1472.5
      },
      "pred_interval": {
        "start": 1424.0,
        "end": 1426.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.0,
        "end": 46.5,
        "average": 47.25
      },
      "rationale_metrics": {
        "rouge_l": 0.27184466019417475,
        "text_similarity": 0.6383645534515381,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives incorrect timestamps for both E1 and E2 and incorrectly states the slide appears 'at the same time' as the introduction; the ground truth shows the slide appears later (after the speaker's introduction), so the prediction is largely wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining that organizational ethics work is new to them, when do they state that it began during the COVID pandemic?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1469.5,
        "end": 1472.0
      },
      "pred_interval": {
        "start": 1440.0,
        "end": 1443.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.5,
        "end": 29.0,
        "average": 29.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2716049382716049,
        "text_similarity": 0.6921201944351196,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the consecutive relationship and quoted utterances, but the absolute timestamps are substantially incorrect (predicted ~1440\u20131443s vs correct 1469.3\u20131472.0s) and thus it fails to match key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the 'Organizational ethics consultations' table, when does the speaker mention the 'Blood products scarcity protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1510.0,
        "end": 1513.0
      },
      "pred_interval": {
        "start": 1471.0,
        "end": 1474.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 39.0,
        "average": 39.0
      },
      "rationale_metrics": {
        "rouge_l": 0.27848101265822783,
        "text_similarity": 0.5662637948989868,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct phrase but gives incorrect timings and temporal alignment\u2014it places both the table and the mention at ~1471\u20131474s, whereas the reference has the table 1474\u20131573s and the mention at 1510\u20131513s, so the temporal relation is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the 'sequential organ failure assessment or SOFA score', when does he begin to explain what it is?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1647.6,
        "end": 1697.0
      },
      "pred_interval": {
        "start": 1596.3,
        "end": 1601.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.299999999999955,
        "end": 95.79999999999995,
        "average": 73.54999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.25641025641025644,
        "text_similarity": 0.5814011096954346,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that an explanation follows the introduction, but the anchor and target timestamps are substantially different from the reference (off by ~25\u201350s) and the predicted target segment does not align with the ground-truth interval, so the timing is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that '70% of publicly available crisis standards of care used either the SOFA score or a modified version', when does he mention the SOFA score being used in Alaska?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1726.0,
        "end": 1733.0
      },
      "pred_interval": {
        "start": 1668.8,
        "end": 1675.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.200000000000045,
        "end": 58.0,
        "average": 57.60000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.27027027027027023,
        "text_similarity": 0.5761932134628296,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the correct semantic content and the 'after' relationship (the Alaska SOFA example follows the general statement), but both the anchor and target timestamps are incorrect compared to the ground truth, so it fails on the required temporal localization."
      }
    },
    {
      "question_id": "003",
      "question": "Once the 'SOFA Disparities' slide appears, when does the speaker begin discussing concerns about the score's accuracy and contributions to disparities?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1770.0,
        "end": 1776.606
      },
      "pred_interval": {
        "start": 1724.4,
        "end": 1731.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.59999999999991,
        "end": 45.605999999999995,
        "average": 45.60299999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2745098039215686,
        "text_similarity": 0.7426326274871826,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that the speaker immediately raises concerns about SOFA accuracy and disparities, but it gives substantially incorrect anchor and target timestamps (off by ~38 seconds), so key factual timing information is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that the center was able to test the triage protocol before it was used, when does he state that they developed a SOFA calculation system?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1799.553,
        "end": 1807.997
      },
      "pred_interval": {
        "start": 1773.6,
        "end": 1777.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.953000000000202,
        "end": 30.197000000000116,
        "average": 28.07500000000016
      },
      "rationale_metrics": {
        "rouge_l": 0.2888888888888889,
        "text_similarity": 0.8401725888252258,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the correct relative order and quotes the right utterances, but the timestamps are substantially incorrect (both anchor and target are ~25s earlier than the ground truth), so the temporal localization is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the retrospective cohort study, when does he detail the demographic breakdown of the patients?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1846.122,
        "end": 1858.077
      },
      "pred_interval": {
        "start": 1788.5,
        "end": 1803.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.62200000000007,
        "end": 54.577,
        "average": 56.099500000000035
      },
      "rationale_metrics": {
        "rouge_l": 0.21359223300970875,
        "text_similarity": 0.6932430267333984,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted E1 timing and the 'after' relationship roughly match, the predicted E2 timing is substantially earlier (1788.5\u20131803.5s) than the reference (1846.122\u20131858.077s), so the key temporal alignment is incorrect despite similar demographic content."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker highlights that non-Hispanic Black patients had greater odds of an elevated SOFA score, when does he state that no significant difference by race in mortality was found when controlling for other factors?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.642,
        "end": 1879.694
      },
      "pred_interval": {
        "start": 1828.2,
        "end": 1837.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.44200000000001,
        "end": 42.69399999999996,
        "average": 44.067999999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.27450980392156865,
        "text_similarity": 0.78053879737854,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly paraphrases the content and relative ordering ('after'), but the temporal boundaries are substantially incorrect (events placed ~40s earlier than the ground truth), so it fails to match the required timestamps."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the early small cohort out of Wuhan, China, when does he state that subsequent larger cohorts in the United States did not show such high accuracy rates?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.0,
        "end": 1966.5
      },
      "pred_interval": {
        "start": 2066.0,
        "end": 2072.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 107.0,
        "end": 105.5,
        "average": 106.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2745098039215686,
        "text_similarity": 0.8032042384147644,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the correct temporal relation (target follows anchor) but the timestamps are substantially misaligned with the ground truth (both events are shifted by ~100s and durations differ), so it fails to match the reference times."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'This graph here is a calibration curve', when does he explain that the diagonal line shows a perfectly calibrated predictor of mortality?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2014.0,
        "end": 2020.0
      },
      "pred_interval": {
        "start": 2105.0,
        "end": 2114.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 91.0,
        "end": 94.0,
        "average": 92.5
      },
      "rationale_metrics": {
        "rouge_l": 0.29357798165137616,
        "text_similarity": 0.8092246055603027,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly captures that the explanation follows the anchor (sequence), but the provided timestamps are substantially different from the reference (anchor/target times are misaligned by ~90+ seconds) and thus factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that SOFA predicted mortality with less accuracy than age in their own COVID cohort, when does he mention that SOFA predicted mortality with better accuracy than age in the pre-COVID eICU cohort?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2066.0,
        "end": 2069.0
      },
      "pred_interval": {
        "start": 2136.0,
        "end": 2142.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.0,
        "end": 73.0,
        "average": 71.5
      },
      "rationale_metrics": {
        "rouge_l": 0.24137931034482762,
        "text_similarity": 0.7361487746238708,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation correct (the mention occurs after the anchor) but the anchor and target timestamps are substantially incorrect compared to the ground truth, omitting the precise times given and thus failing key factual alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the Omicron surge increasing, when does he talk about working with the healthcare system's legal team?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2153.6,
        "end": 2174.93
      },
      "pred_interval": {
        "start": 2169.3,
        "end": 2173.0
      },
      "iou": 0.17346460384434276,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.700000000000273,
        "end": 1.9299999999998363,
        "average": 8.815000000000055
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.66963791847229,
        "llm_judge_score": 5,
        "llm_judge_justification": "The predicted answer correctly identifies the target event interval (E2) within the reference range and the temporal relation ('after'), but it mislocates the anchor event (E1) by ~36s and adds an unsupported audio-cue claim, so the alignment is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the policy was active until late February of 2022, when does the first 'Scope of protocol' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2194.0,
        "end": 2234.0
      },
      "pred_interval": {
        "start": 2211.0,
        "end": 2212.1
      },
      "iou": 0.027499999999997728,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.0,
        "end": 21.90000000000009,
        "average": 19.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.2921348314606742,
        "text_similarity": 0.7085089087486267,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly places the 'Scope of protocol' slide within the ground-truth interval, and the relative 'once_finished' relation matches, but the anchor event time is off by ~17 seconds (2209.2 vs 2192.0), so the absolute timing is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the second 'Scope of protocol' slide appears, when does the speaker mention 'renal replacement therapy'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2263.679,
        "end": 2254.733
      },
      "pred_interval": {
        "start": 2277.3,
        "end": 2280.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.621000000000095,
        "end": 25.966999999999643,
        "average": 19.79399999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.7774677276611328,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation ('after') but substantially mislabels the anchor/event times (E1 at 2274.3s vs correct 2230.0s, E2 at 2277.3s vs ~2254\u20132264s) and changes the anchor event, so it contradicts key timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that goals of care discussions significantly changed, when does the speaker mention that patients were more likely to choose limited life-sustaining interventions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2320.0,
        "end": 2327.0
      },
      "pred_interval": {
        "start": 2330.0,
        "end": 2340.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 13.0,
        "average": 11.5
      },
      "rationale_metrics": {
        "rouge_l": 0.15841584158415842,
        "text_similarity": 0.44168350100517273,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the target content and preserves the 'after' relation, but it misidentifies and mislocalizes the anchor event and shifts both timestamps ~15s from the ground truth, so key factual/time information is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states he wants to highlight some takeaway points, when does the first takeaway point appear on the screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "pred_interval": {
        "start": 2360.0,
        "end": 2365.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.0,
        "end": 35.0,
        "average": 35.0
      },
      "rationale_metrics": {
        "rouge_l": 0.17777777777777776,
        "text_similarity": 0.6536862850189209,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor utterance and the takeaway slide content and preserves the ordering, but both provided timestamps are significantly (~35 seconds) earlier than the ground-truth intervals, so the temporal labels are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I'll stop and take questions,\" when does an audience member begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2541.6,
        "end": 2544.0
      },
      "pred_interval": {
        "start": 2557.5,
        "end": 2559.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.900000000000091,
        "end": 15.099999999999909,
        "average": 15.5
      },
      "rationale_metrics": {
        "rouge_l": 0.32608695652173914,
        "text_similarity": 0.6499794721603394,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: the timestamps disagree substantially (predicted ~2557.5s vs. ground truth 2517.9s for E1 and predicted audience start at 2557.5s vs. ground truth 2541.6s), and it wrongly asserts the audience spoke immediately after the speaker rather than ~24s later; only the high-level 'after' relation is similar."
      }
    },
    {
      "question_id": "002",
      "question": "Once the audience member finishes complimenting the center, when does he ask a specific question about local hospital ethics committees?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2571.5,
        "end": 2580.5
      },
      "pred_interval": {
        "start": 2592.9,
        "end": 2601.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.40000000000009,
        "end": 21.0,
        "average": 21.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.3092783505154639,
        "text_similarity": 0.7406805157661438,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the events and the 'once_finished' relation and even quotes the question, but the timestamps are substantially wrong\u2014both E1 and E2 are shifted by about 27 seconds compared to the ground truth\u2014so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the audience member mentions the low numbers of ethics consultations, when does the speaker begin to answer the question?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2624.0,
        "end": 2634.8
      },
      "pred_interval": {
        "start": 2631.7,
        "end": 2632.7
      },
      "iou": 0.09259259259259103,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.699999999999818,
        "end": 2.100000000000364,
        "average": 4.900000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.27956989247311825,
        "text_similarity": 0.6214819550514221,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the direction ('after') but the reported timestamps for both E1 and E2 are substantially different from the ground truth (off by several seconds) and the speaker span is incorrectly shortened, so the prediction is largely temporally inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the listener asks about assessing the quality of care across the system, when does the speaker respond by calling it a 'great question'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.1,
        "end": 2745.7
      },
      "pred_interval": {
        "start": 2745.0,
        "end": 2755.0
      },
      "iou": 0.06422018348622131,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.900000000000091,
        "end": 9.300000000000182,
        "average": 5.100000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.4186046511627907,
        "text_similarity": 0.5965240597724915,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the speaker replies immediately after the listener with 'So that's a great question', but the timestamps are inaccurate (anchor shifted from 2739\u20132743 to 2744\u20132745, speaker start off by ~0.9s) and it adds an unwarranted long end time (2755.0), so it is factually imprecise."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions starting to survey clinicians for feedback, when does he mention planning to survey patients and families?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2807.8,
        "end": 2821.6
      },
      "pred_interval": {
        "start": 2780.0,
        "end": 2785.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.800000000000182,
        "end": 36.59999999999991,
        "average": 32.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.297029702970297,
        "text_similarity": 0.6060968637466431,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that E2 follows E1, but the timestamps are substantially incorrect and the predicted E2 window is too short and omits the key content about surveying 'patients and families'; it therefore hallucinates timing and omits crucial information."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that hospitals in the healthcare system can join together, when does he state that they will preferentially present cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2854.49,
        "end": 2856.13
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 2852.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.489999999999782,
        "end": 3.930000000000291,
        "average": 4.210000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.2549019607843137,
        "text_similarity": 0.7246668338775635,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relationship, but it gives incorrect and inconsistent timestamps (E2 is placed much earlier than the ground truth) and adds an irrelevant visual detail; key temporal facts are therefore wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces 'a third method of feedback', when does he describe it as 'formal needs assessments'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2877.53,
        "end": 2879.53
      },
      "pred_interval": {
        "start": 2871.8,
        "end": 2874.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.730000000000018,
        "end": 5.130000000000109,
        "average": 5.430000000000064
      },
      "rationale_metrics": {
        "rouge_l": 0.31683168316831684,
        "text_similarity": 0.7866258025169373,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the target follows the anchor and that the phrases are adjacent, but the timestamps are off by ~5\u20136 seconds compared to the reference and it adds an unsupported visual detail, so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'the overwhelming response was number one', when does he specify the first response as 'a lack of ethics education'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2901.56,
        "end": 2903.46
      },
      "pred_interval": {
        "start": 2905.2,
        "end": 2908.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.6399999999998727,
        "end": 4.940000000000055,
        "average": 4.289999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.38,
        "text_similarity": 0.7957659363746643,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the target follows the anchor and that the relation is immediate, but its timestamps conflict with the ground truth (anchor/target times are several seconds off) and it adds an unverified visual detail, so it is partially incorrect and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"The more medically complex cases tend to transfer,\" when does he start listing examples of such cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3044.3,
        "end": 3048.2
      },
      "pred_interval": {
        "start": 3051.3,
        "end": 3053.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 5.600000000000364,
        "average": 6.300000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.24444444444444444,
        "text_similarity": 0.6080585718154907,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures that the examples follow immediately after the anchor and correctly identifies example content, but the reported timestamps for both anchor and target are substantially different from the ground truth, so the key factual timing is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the questioner asks about the 'escalation of care policy', when does the slide titled 'Escalation of Care Protocol' appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3114.8,
        "end": 3117.8
      },
      "pred_interval": {
        "start": 3119.3,
        "end": 3122.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.5,
        "end": 4.199999999999818,
        "average": 4.349999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.7412072420120239,
        "llm_judge_score": 2,
        "llm_judge_justification": "While both answers agree the slide appears after the question, the predicted times are substantially different and inconsistent with the ground truth (misplaced by several seconds, extend past the stated video end, and contain internal timing contradictions), so it is largely factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions \"boarding 190 patients in the emergency department\", when does he discuss concerns about the level of care?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3154.983,
        "end": 3143.945
      },
      "pred_interval": {
        "start": 3165.5,
        "end": 3175.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.516999999999825,
        "end": 31.554999999999836,
        "average": 21.03599999999983
      },
      "rationale_metrics": {
        "rouge_l": 0.25000000000000006,
        "text_similarity": 0.7971755266189575,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target content and the 'after' relationship, but the provided timestamps are substantially shifted (~12 seconds later) and therefore contradict the ground-truth timing, making it largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker mentions 'in all 26 of those cases', when does he then talk about 'many more cases'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3214.9,
        "end": 3215.4
      },
      "pred_interval": {
        "start": 3213.92,
        "end": 3221.92
      },
      "iou": 0.0625,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.9800000000000182,
        "end": 6.519999999999982,
        "average": 3.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2978723404255319,
        "text_similarity": 0.4594728350639343,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase, the subsequent 'many more cases' phrase, and the 'after' relation, but the reported timestamps deviate substantially from the reference (notably E1 end and E2 end) and the predicted event durations are inconsistent with the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker states that the 'escalation of care protocol' was nice, when does he mention a 'SOFA-based protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3246.0,
        "end": 3249.0
      },
      "pred_interval": {
        "start": 3234.72,
        "end": 3237.46
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.2800000000002,
        "end": 11.539999999999964,
        "average": 11.410000000000082
      },
      "rationale_metrics": {
        "rouge_l": 0.23655913978494625,
        "text_similarity": 0.7342974543571472,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target phrases and the 'after' relation, but the time spans are inaccurate\u2014E1 is overly extended and E2 is placed ~13 seconds earlier than the ground truth, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the second speaker says 'SOFA is horrendous', when does he mention 'SOFA's AUC goes up'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3322.32,
        "end": 3324.71
      },
      "pred_interval": {
        "start": 3295.48,
        "end": 3298.64
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.840000000000146,
        "end": 26.070000000000164,
        "average": 26.455000000000155
      },
      "rationale_metrics": {
        "rouge_l": 0.35714285714285715,
        "text_similarity": 0.6931563019752502,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and their order, but the timestamps are substantially offset from the reference (\u224826.8s earlier) and the relation is over-specified as 'immediately after' versus the ground-truth 'after', so key temporal information is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the question about equity monitoring is asked, when does the speaker begin explaining the logging process for patient cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3401.583,
        "end": 3406.09
      },
      "pred_interval": {
        "start": 3400.2,
        "end": 3402.8
      },
      "iou": 0.206621392190158,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3830000000002656,
        "end": 3.2899999999999636,
        "average": 2.3365000000001146
      },
      "rationale_metrics": {
        "rouge_l": 0.2830188679245283,
        "text_similarity": 0.767194390296936,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct events and mentions logging for 26 patients and an 'after' relation, but the timestamps are substantially off (E1 given much earlier than the reference), E2 start time differs from the reference and no end time is provided, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the 'Escalation of Care Protocol', when does the 'Conscientious Practice Policy' slide appear on screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3429.8,
        "end": 3430.5
      },
      "pred_interval": {
        "start": 3409.6,
        "end": 3413.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.200000000000273,
        "end": 16.90000000000009,
        "average": 18.550000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.7828542590141296,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target events and the 'once_finished' relation, but the timestamps are substantially incorrect (E1 ~14.7s early, E2 ~20.2s early) and the interval between events is misrepresented (predicted ~0.3s vs actual ~5.8s), making it factually inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Conscientious Practice Policy' slide appears, when does the speaker mention tracking outcomes and looking back retrospectively for this policy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3444.0,
        "end": 3492.0
      },
      "pred_interval": {
        "start": 3455.2,
        "end": 3459.8
      },
      "iou": 0.09583333333334092,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.199999999999818,
        "end": 32.19999999999982,
        "average": 21.699999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.31683168316831684,
        "text_similarity": 0.7644993662834167,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the E2 interval (it falls within the reference window) and the temporal relation 'after', but the E1 anchor time is notably different (3409.6s vs. 3434.0s), a significant timing error. The extra audio/visual cues are harmless but do not compensate for the incorrect E1 timestamp."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions an increasing disparity over time, when does he discuss how they can provide support to all hospitals?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 707.399,
        "end": 742.972
      },
      "pred_interval": {
        "start": 705.7,
        "end": 716.0
      },
      "iou": 0.23076303927881558,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.6989999999999554,
        "end": 26.97199999999998,
        "average": 14.335499999999968
      },
      "rationale_metrics": {
        "rouge_l": 0.31932773109243695,
        "text_similarity": 0.8588142395019531,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the semantic relation (discussion of support follows the disparity comment) and the anchor phrase, but the timestamping is imprecise: the predicted anchor time is inside the correct anchor span yet the predicted target starts too early and ends much earlier than the ground truth, omitting most of the target interval."
      }
    },
    {
      "question_id": "002",
      "question": "While the organizational chart for the Center for Clinical Ethics is displayed, when does the speaker describe the Ethics Education program?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.177,
        "end": 786.763
      },
      "pred_interval": {
        "start": 736.0,
        "end": 746.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.17700000000002,
        "end": 40.763000000000034,
        "average": 36.97000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.23423423423423423,
        "text_similarity": 0.5763673782348633,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction wrongly reports all timestamps for the slide and the description (contradicting the ground truth), though it correctly asserts that the description occurs while the chart is visible; key factual timing details are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says he will go into depth on the programs, when does he first mention the Yale Interdisciplinary Center for Bioethics?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 837.605,
        "end": 845.26
      },
      "pred_interval": {
        "start": 781.0,
        "end": 787.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.60500000000002,
        "end": 58.25999999999999,
        "average": 57.432500000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.45762711864406785,
        "text_similarity": 0.6645243167877197,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') right, but it gives incorrect and inconsistent timestamps (both events at 781.0s while claiming one is after) and includes unsupported detail about listing order, so it fails to match the reference times and facts."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the title 'Systemwide Ethics Forum and Newsletter', when does he describe it as a hybrid meeting?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1070.5,
        "end": 1076.5
      },
      "pred_interval": {
        "start": 1130.18,
        "end": 1133.55
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.680000000000064,
        "end": 57.049999999999955,
        "average": 58.36500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3770491803278689,
        "text_similarity": 0.7387682199478149,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer correctly identifies the anchor (title) followed by the target (described as a hybrid in-person/online meeting) and labels the relation as 'after'; minor wording and timestamp differences do not affect semantic correctness."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining that they looked through the 26 specific patient cases individually, when does the slide transition to 'Scope of protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3425.8,
        "end": 3429.0
      },
      "pred_interval": {
        "start": 3418.5,
        "end": 3420.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.300000000000182,
        "end": 8.199999999999818,
        "average": 7.75
      },
      "rationale_metrics": {
        "rouge_l": 0.22500000000000003,
        "text_similarity": 0.5596901774406433,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted E1 time is close (\u22481s off) but the predicted E2 timing and transition are significantly wrong\u2014it claims an immediate slide change at 3419.0s, whereas the reference places 'Scope of protocol' at 3425.8s and transition at 3429.0s, so the prediction contradicts the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the 'Scope of protocol' slide finishes being displayed, when does the 'Conscientious Practice Policy' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3429.0,
        "end": 3519.5
      },
      "pred_interval": {
        "start": 3420.8,
        "end": 3423.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.199999999999818,
        "end": 96.5,
        "average": 52.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.7820461988449097,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the Conscientious Practice Policy slide appears immediately after the Scope of protocol slide ('once_finished'), but it gives substantially different timestamps (3420.8/3421.0 vs 3429.0) and omits the end time (3519.5s), while adding an unverified transition detail; thus it only partially matches the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes discussing the tracking of equity, socioeconomic status, and other demographic characteristics, when is the presentation window minimized?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3530.0,
        "end": 3531.0
      },
      "pred_interval": {
        "start": 3515.4,
        "end": 3517.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.599999999999909,
        "end": 13.300000000000182,
        "average": 13.950000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6548941135406494,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misaligns the key timestamps (3515.4/3515.7s vs correct 3508.5s and 3530.0\u20133531.0s) and incorrectly labels the relation as 'immediately after' rather than the correct later 'after' with a ~21.5s gap, indicating significant temporal and factual mismatch."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the audience will be on mute, when does he mention that the live event can be paused?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 38.524,
        "end": 43.729
      },
      "pred_interval": {
        "start": 38.8,
        "end": 41.9
      },
      "iou": 0.5955811719500484,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.27599999999999625,
        "end": 1.8290000000000006,
        "average": 1.0524999999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.17500000000000002,
        "text_similarity": 0.6114374995231628,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mislabels and timestamps the anchor event (mute) incorrectly\u2014placing it at ~37.8s instead of 33.102s\u2014and gives a different target span (ending 41.9s) and relation (same sentence) rather than the referenced 38.524s\u201343.729s with an 'after' relation; it partially captures the pause mention timing but is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses changing the speed of presentations and speakers, when does he advise on what to do if Wi-Fi or connection is lost?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 55.563,
        "end": 59.787
      },
      "pred_interval": {
        "start": 56.9,
        "end": 68.0
      },
      "iou": 0.2321299348717537,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3369999999999962,
        "end": 8.213000000000001,
        "average": 4.774999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1075268817204301,
        "text_similarity": 0.6392676830291748,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the 'after' relation and roughly captures the reconnection advice, but it misidentifies and mistimes E1 (should be mention of changing playback speed at 44.691s) and provides an incorrect anchor text/time, so key factual elements are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the presenter mentions Tom Gardner in the background, when does he mention Stephanie Fraser joining in place of Jane Preston?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.258,
        "end": 171.201
      },
      "pred_interval": {
        "start": 228.0,
        "end": 234.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.74199999999999,
        "end": 62.899,
        "average": 61.320499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.3220338983050847,
        "text_similarity": 0.8205791711807251,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target verbal mentions and the 'after' relation, but the provided timestamps are grossly incorrect (off by ~200s), so the temporal alignment is wrong and the answer is not acceptable."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male presenter finishes introducing Stephanie Fraser, when does Stephanie Fraser begin speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 223.86,
        "end": 224.8
      },
      "pred_interval": {
        "start": 234.1,
        "end": 234.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.23999999999998,
        "end": 10.0,
        "average": 10.11999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2105263157894737,
        "text_similarity": 0.4316340684890747,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates Stephanie speaks after the presenter and includes the phrase 'Good morning everybody', but the timestamps are off by ~11\u201312 seconds (234.1/234.8 vs 222.0/223.86) and it adds hallucinated dialogue and cues, making it largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker is discussing the recent research undertaken by the Neurological Alliance of Scotland, when does she state that 57% of respondents reported not being able to access a face-to-face appointment?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 433.0,
        "end": 434.9
      },
      "pred_interval": {
        "start": 126.1,
        "end": 131.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 306.9,
        "end": 303.7,
        "average": 305.29999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.19819819819819817,
        "text_similarity": 0.5269856452941895,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer misidentifies both anchor and target timings and reverses their order, contradicting the reference which places the 57% mention at ~433.0\u2013434.9s within the 383.3\u2013443.3s anchor interval."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that nearly two-thirds of respondents had not had a video appointment, when does she state that telephone appointments were the most common way to access care?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.8,
        "end": 452.9
      },
      "pred_interval": {
        "start": 137.3,
        "end": 138.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 310.5,
        "end": 314.5,
        "average": 312.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23913043478260868,
        "text_similarity": 0.7662668228149414,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer identifies the correct utterances and their temporal order (target after anchor) but the provided timestamps are substantially incorrect and do not match the ground-truth timing, so it fails on key factual alignment."
      }
    },
    {
      "question_id": "003",
      "question": "After the blue slide with the speaker's title disappears, when does the speaker begin to mention what factors clinicians should consider for appointment formats?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 479.3,
        "end": 480.3
      },
      "pred_interval": {
        "start": 216.0,
        "end": 217.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 263.3,
        "end": 263.3,
        "average": 263.3
      },
      "rationale_metrics": {
        "rouge_l": 0.44680851063829785,
        "text_similarity": 0.8315641283988953,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets only the temporal order right (target after anchor) but both absolute timestamps are wildly incorrect compared to the reference, omitting the key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stephanie finishes speaking and hands over to Mark, when does Mark begin to speak?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 606.5,
        "end": 607.0
      },
      "pred_interval": {
        "start": 690.0,
        "end": 691.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.5,
        "end": 84.0,
        "average": 83.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7169697284698486,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the ordering (Mark speaks after Stephanie) but the timestamps are substantially incorrect (off by ~95s) and the timing gap differs greatly from the reference; thus it is largely factually wrong despite the correct relation direction."
      }
    },
    {
      "question_id": "002",
      "question": "Once Mark finishes introducing Calum Duncan, when does Calum Duncan start speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 638.3,
        "end": 639.3
      },
      "pred_interval": {
        "start": 711.0,
        "end": 712.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.70000000000005,
        "end": 72.70000000000005,
        "average": 72.70000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.28125,
        "text_similarity": 0.6769064664840698,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the same events and that Calum speaks after Mark, but the timestamps disagree substantially with the reference and the relation label ('after' vs 'once_finished') is less specific; therefore it earns partial credit."
      }
    },
    {
      "question_id": "003",
      "question": "Once Calum Duncan says 'Next slide please', when does the second presentation slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 685.7,
        "end": 686.0
      },
      "pred_interval": {
        "start": 720.0,
        "end": 720.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.299999999999955,
        "end": 34.0,
        "average": 34.14999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.4727272727272728,
        "text_similarity": 0.7821460962295532,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the event order (second slide after Calum speaks) but the timestamps are wrong by ~35 seconds and the reference gives precise intervals while the prediction gives single times; the relation label also differs, so the answer is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 'near me is what we're going to focus on today', when does he describe it as 'internet-based'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 702.7,
        "end": 703.5
      },
      "pred_interval": {
        "start": 706.9,
        "end": 716.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.199999999999932,
        "end": 13.299999999999955,
        "average": 8.749999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.20454545454545453,
        "text_similarity": 0.6453396081924438,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the semantic relation ('after') and the content that 'Near Me' is internet-based, but the anchor and target timestamps are significantly incorrect (predicted ~690\u2013693s and ~706.9\u2013716.8s vs correct 699.8s and 702.7s), so it fails on key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states there were '330 consultations per week' before the pandemic, when does he mention it went up to '10,000'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 737.0,
        "end": 739.0
      },
      "pred_interval": {
        "start": 717.8,
        "end": 722.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.200000000000045,
        "end": 16.5,
        "average": 17.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.13793103448275862,
        "text_similarity": 0.5029205083847046,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly identifies the temporal relation as 'after', the provided timestamps for both anchor and target differ significantly from the ground-truth times, so the prediction is largely incorrect on the key factual element (when the events occur)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' for the first time, when does he point to the map on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.0,
        "end": 767.5
      },
      "pred_interval": {
        "start": 735.8,
        "end": 741.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.200000000000045,
        "end": 26.100000000000023,
        "average": 28.650000000000034
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7471411228179932,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misstates both timestamps and the temporal relation: it places the utterance and pointing ~20s earlier (735.3 and 735.8\u2013741.4) and claims the gesture is immediately after, whereas the ground truth has the utterance at 756.0 and the point at 767.0 (after). These discrepancies make the prediction factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'go back to the next slide', when does the slide titled 'Video consulting using near me via attend anywhere platform' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 874.0,
        "end": 874.1
      },
      "pred_interval": {
        "start": 885.76,
        "end": 888.74
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.759999999999991,
        "end": 14.639999999999986,
        "average": 13.199999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.2564102564102564,
        "text_similarity": 0.7909940481185913,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the correct events and their temporal relation ('after') and gives a visible time window, but the timestamps are off by ~11 seconds compared to the ground truth, so the timing is significantly incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that 'Stephanie Fraser has talked about' the survey, when does he then say 'Back to next slide, Mark, please'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 884.0
      },
      "pred_interval": {
        "start": 894.64,
        "end": 898.72
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.639999999999986,
        "end": 14.720000000000027,
        "average": 13.180000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.21176470588235294,
        "text_similarity": 0.6785710453987122,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the ground truth: it provides wrong timestamps (~894s vs ~882\u2013884s), swaps/mislabels the events, and asserts a 'simultaneous' relation whereas the reference states the target occurs after the anchor."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'Next slide, please' at the 42-second mark, when does the slide titled 'Clinician and patient experience - Scotland' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 913.0,
        "end": 913.1
      },
      "pred_interval": {
        "start": 906.62,
        "end": 908.12
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.3799999999999955,
        "end": 4.980000000000018,
        "average": 5.680000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.22535211267605634,
        "text_similarity": 0.7012459635734558,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the ground-truth timestamps: ground truth places the anchor at 912.0s and the slide at 913.0s, whereas the prediction places both around 906.62\u2013908.12s; although both note an 'immediately after' relationship, the timing is significantly incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "During the discussion of what works well with video calls, when does the speaker express finding it much easier to interact with groups on a video call than on the telephone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1053.0,
        "end": 1062.5
      },
      "pred_interval": {
        "start": 1071.0,
        "end": 1082.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.0,
        "end": 19.5,
        "average": 18.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2549019607843137,
        "text_similarity": 0.6281371712684631,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the quoted sentiment (ease interacting on video calls) but provides incorrect timestamps (E2 at 1071\u20131082s vs. gold 1053\u20131062.5s) and gives an imprecise E1 instead of the specified 1050.0s start, so the temporal alignment is wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions technical issues with patient bandwidth, when does he advise to choose patients correctly to avoid those difficulties?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1134.0,
        "end": 1135.5
      },
      "pred_interval": {
        "start": 1128.0,
        "end": 1136.0
      },
      "iou": 0.1875,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 0.5,
        "average": 3.25
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.7196581363677979,
        "llm_judge_score": 9,
        "llm_judge_justification": "Predicted answer correctly identifies the same problem statement, advisory remark, and the 'after' relation; time spans slightly differ (E1 shifted by ~2s and E2 expanded earlier), but the essential content and temporal ordering are preserved."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' to introduce the smart phone camera, when does he specifically point out his wife's iPhone on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1213.0,
        "end": 1215.0
      },
      "pred_interval": {
        "start": 1204.0,
        "end": 1209.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.0,
        "end": 6.0,
        "average": 7.5
      },
      "rationale_metrics": {
        "rouge_l": 0.37894736842105264,
        "text_similarity": 0.667698085308075,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies E1 at 1203.0s but gives a substantially incorrect time span for E2 (1204.0\u20131209.0s vs. the reference 1213.0\u20131215.0s), which contradicts the ground-truth temporal relation; extra visual detail does not compensate for the key timing error."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying 'Next slide please', when does the 'Sharing content' slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.574,
        "end": 1249.574
      },
      "pred_interval": {
        "start": 1241.3,
        "end": 1242.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.274000000000115,
        "end": 7.173999999999978,
        "average": 7.224000000000046
      },
      "rationale_metrics": {
        "rouge_l": 0.2978723404255319,
        "text_similarity": 0.7744593024253845,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target and gives a ~1s target duration, but the timestamps are factually incorrect (about 6 seconds earlier) and contradict the ground-truth times, so it does not match. "
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'You can share things', when does he point towards the screen showing the brain scan?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1252.25,
        "end": 1252.85
      },
      "pred_interval": {
        "start": 1258.5,
        "end": 1259.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.25,
        "end": 6.9500000000000455,
        "average": 6.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.32876712328767127,
        "text_similarity": 0.7348215579986572,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction references the correct events but the reported timestamps are substantially wrong and claim the pointing coincides with the speech, which contradicts the correct times; thus it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "003",
      "question": "During the discussion about poor picture quality, when does the speaker suggest clearing browser history?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1313.823,
        "end": 1315.286
      },
      "pred_interval": {
        "start": 1314.9,
        "end": 1316.9
      },
      "iou": 0.12544686382839373,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0769999999999982,
        "end": 1.6140000000000327,
        "average": 1.3455000000000155
      },
      "rationale_metrics": {
        "rouge_l": 0.5,
        "text_similarity": 0.8073025941848755,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the event and that the suggestion occurs during the discussion, but it omits the anchor's precise start time (1306.823s) and gives E2 timestamps shifted later (1314.9\u20131316.9s vs. 1313.823\u20131315.286s), so the timing is partially inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying \"Thank you very much for that\", when does he state he is handing over to Jane?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.837,
        "end": 1430.682
      },
      "pred_interval": {
        "start": 1418.4,
        "end": 1425.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.436999999999898,
        "end": 4.882000000000062,
        "average": 7.65949999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.7444289922714233,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same two events and correct ordering, but the timestamps are substantially (~9\u201310s) off and the relation label differs ('after' vs. 'once_finished'), so it fails to match the ground-truth temporal alignment. "
      }
    },
    {
      "question_id": "003",
      "question": "After the woman (Jane) describes the challenges of managing patients over the telephone, when does she mention that they had a pilot of 'Near Me' even prior to Covid?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1609.855,
        "end": 1624.692
      },
      "pred_interval": {
        "start": 1545.0,
        "end": 1553.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.85500000000002,
        "end": 71.19200000000001,
        "average": 68.02350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3410852713178295,
        "text_similarity": 0.7092163562774658,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer correctly identifies the speaker, the content (pilot of Near Me) and the 'after' relation, but the provided timestamps conflict significantly with the ground truth (off by ~60 seconds), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that using 'Near Me' felt quite adventurous, when does she state that its use became vital to their whole service?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1636.0,
        "end": 1643.0
      },
      "pred_interval": {
        "start": 1626.4,
        "end": 1631.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.599999999999909,
        "end": 11.099999999999909,
        "average": 10.349999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.35789473684210527,
        "text_similarity": 0.6709150075912476,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies the anchor utterance and gives incorrect timestamps for both events (and the relation/context is inconsistent); although it repeats the target phrase, the timing and anchor are wrong, so it fails to match the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes asking Mark to go back to the previous slide, when does she say 'Thank you'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1676.54,
        "end": 1678.02
      },
      "pred_interval": {
        "start": 1673.7,
        "end": 1675.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.839999999999918,
        "end": 2.8199999999999363,
        "average": 2.8299999999999272
      },
      "rationale_metrics": {
        "rouge_l": 0.345679012345679,
        "text_similarity": 0.7585268020629883,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor utterance and its time, but it places 'Thank you' much earlier (1673.7\u20131675.2s) than the reference span (1676.54\u20131678.02s) and thus contradicts the correct timing; the relation label also differs."
      }
    },
    {
      "question_id": "001",
      "question": "After the 'Training and preparation' slide appears, when does the speaker mention the 'Level 1' training?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1791.0,
        "end": 1791.5
      },
      "pred_interval": {
        "start": 1775.2,
        "end": 1777.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.799999999999955,
        "end": 14.0,
        "average": 14.899999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923078,
        "text_similarity": 0.6412229537963867,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives incorrect timestamps for both E1 and E2 and mislabels the relation as 'during' whereas the reference shows E2 occurs later (after) the slide; it contradicts the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing tele-swallowing partners as 'our eyes and our hands and our ears', when does she start talking about preparing the clinical room?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1897.0,
        "end": 1901.0
      },
      "pred_interval": {
        "start": 1810.8,
        "end": 1813.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 86.20000000000005,
        "end": 87.70000000000005,
        "average": 86.95000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.6182186603546143,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct events (the sentence and the 'preparing the clinical room' phrase) but the timestamps are substantially wrong (~84 seconds earlier) and internally inconsistent, and the relation label is only loosely equivalent; thus it fails on key temporal accuracy."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses tele-swallowing partners preparing the clinical room, when does she next talk about them providing reassurance to patients?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1906.0,
        "end": 1910.0
      },
      "pred_interval": {
        "start": 1827.1,
        "end": 1832.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.90000000000009,
        "end": 77.59999999999991,
        "average": 78.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2469135802469136,
        "text_similarity": 0.5592034459114075,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct entities and sequence notion (E1 then E2) and even the reassurance phrase, but the timestamps are substantially misaligned with the reference (off by ~74\u201380s) and the relation label ('after') is less precise than the required 'next', so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning emergency procedures in place onsite, when does the slide change to 'Technology/equipment'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1971.6,
        "end": 1972.0
      },
      "pred_interval": {
        "start": 1982.1,
        "end": 1986.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.5,
        "end": 14.799999999999955,
        "average": 12.649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.8568373918533325,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the order (slide follows the speaker) but the timestamps are substantially off (~20s later) and the relation label is less specific than the ground truth ('after' vs 'once_finished'), so it is largely incorrect. "
      }
    },
    {
      "question_id": "002",
      "question": "During the time the 'Technology/equipment' slide is displayed, when does the speaker discuss the need for a device with a webcam and microphone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2024.079,
        "end": 2026.579
      },
      "pred_interval": {
        "start": 2000.0,
        "end": 2003.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.07899999999995,
        "end": 23.278999999999996,
        "average": 23.678999999999974
      },
      "rationale_metrics": {
        "rouge_l": 0.29787234042553196,
        "text_similarity": 0.779918909072876,
        "llm_judge_score": 5,
        "llm_judge_justification": "The predicted answer correctly identifies the 'during' relationship (the spoken mention occurs while the slide is visible), but it omits the anchor's exact timestamps and gives incorrect E2 timestamps that differ substantially from the ground truth, so key factual timing details are not preserved."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the general category of 'certain resources' for teleswallow sessions, when does she mention 'appropriate diet and fluid consistencies'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.952,
        "end": 2061.952
      },
      "pred_interval": {
        "start": 2042.4,
        "end": 2044.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.552000000000135,
        "end": 17.15200000000027,
        "average": 16.852000000000203
      },
      "rationale_metrics": {
        "rouge_l": 0.3111111111111111,
        "text_similarity": 0.8079332113265991,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target content and that the target follows the anchor, but the provided timestamps are significantly incorrect (off by ~11\u201314 seconds) and do not match the reference, so the answer is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that remote swallowing assessments are not intended to fully replace face-to-face assessments, when does she mention that they are a very useful addition?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2159.677,
        "end": 2162.619
      },
      "pred_interval": {
        "start": 2212.0,
        "end": 2217.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.322999999999865,
        "end": 54.38099999999986,
        "average": 53.35199999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.380952380952381,
        "text_similarity": 0.71978759765625,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target utterances and their temporal relation ('immediately after'), but it gives substantially incorrect absolute timestamps (off by ~53 seconds) and adds an unsupported end time for E2, so the timing details are factually wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning gathering feedback from those who completed the training, when does she start talking about evaluating quantitative data?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2164.643,
        "end": 2186.427
      },
      "pred_interval": {
        "start": 2222.0,
        "end": 2228.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.35699999999997,
        "end": 41.572999999999865,
        "average": 49.46499999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.40404040404040403,
        "text_similarity": 0.745143473148346,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly shifts both timestamps (2222.0s vs 2185.427/2186.427s) and misrepresents the content by saying 'qualitative' instead of the correct 'quantitative' data; only the general 'immediately after' relation is preserved."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes her presentation by saying 'thank you very much for listening', when does the video visually transition to the male presenter?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2257.0,
        "end": 2258.0
      },
      "pred_interval": {
        "start": 2233.0,
        "end": 2234.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.0,
        "end": 24.0,
        "average": 24.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4523809523809524,
        "text_similarity": 0.8144111633300781,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the events and their immediate-after relationship, but both timestamps are significantly incorrect (off by 23 seconds), which contradicts key factual details in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that picking up cues is difficult, when does she start talking about 'points to consider' for virtual technology?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2491.8,
        "end": 2498.2
      },
      "pred_interval": {
        "start": 2500.0,
        "end": 2502.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.199999999999818,
        "end": 3.800000000000182,
        "average": 6.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3617021276595745,
        "text_similarity": 0.5731879472732544,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the temporal order (E2 after E1) but gives incorrect timestamps (E1 end differs slightly; E2 start is ~8.2s later than the reference) and labels the relation as 'after' rather than the immediate 'once_finished', contradicting the key timing detail."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions conducting a 'sprint audit' with patients, when does she state that 'most were very satisfied' with the virtual appointments?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2515.0,
        "end": 2516.0
      },
      "pred_interval": {
        "start": 2509.0,
        "end": 2512.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 4.0,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.49382716049382713,
        "text_similarity": 0.6306413412094116,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the same utterances and the 'after' relationship, but the timestamps are noticeably off (E1 predicted ~2497\u20132499s vs ground-truth 2509.5s; E2 predicted 2509.0s vs ground-truth 2515\u20132516s), so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that patients found virtual technology 'more acceptable', when does she say 'So moving on to the next slide'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2638.0,
        "end": 2639.3
      },
      "pred_interval": {
        "start": 2691.0,
        "end": 2692.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.0,
        "end": 52.69999999999982,
        "average": 52.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.4337349397590362,
        "text_similarity": 0.6021579504013062,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the general order (E2 occurs after E1) but the timestamps are substantially incorrect (~46\u201353s later than reference) and the relation label ('after') differs from the precise 'once_finished' relation; thus it fails on factual timing and relation accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing confidentiality, when does she begin to mention the subtlety of the therapeutic relationship?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2693.583,
        "end": 2697.126
      },
      "pred_interval": {
        "start": 2681.3,
        "end": 2682.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.282999999999902,
        "end": 14.326000000000022,
        "average": 13.304499999999962
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.7642640471458435,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction names the same events but gives timestamps that are significantly off (E1 ~7.3s early, E2 ~10.8s early) and incorrectly states the mention is 'immediately after'; it therefore fails to match the correct target span 2693.583\u20132697.126s."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'It all comes down to Wi-Fi', when does she state that 'delivery of remote therapy is very, very difficult'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.0,
        "end": 2729.0
      },
      "pred_interval": {
        "start": 2719.4,
        "end": 2720.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.599999999999909,
        "end": 8.400000000000091,
        "average": 8.0
      },
      "rationale_metrics": {
        "rouge_l": 0.47619047619047616,
        "text_similarity": 0.7901958227157593,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct utterances but the timestamps are substantially incorrect (off by several seconds) and the temporal relation is mischaracterized as 'immediately after' instead of occurring noticeably later; thus it fails on key factual timing and relation details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'So next slide', when does the slide visually change to 'Practical considerations'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2884.0,
        "end": 2884.2
      },
      "pred_interval": {
        "start": 3044.0,
        "end": 3047.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 160.0,
        "end": 162.80000000000018,
        "average": 161.4000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.47727272727272735,
        "text_similarity": 0.7249296307563782,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the immediate 'after' relationship and provides a start/end interval, but the absolute timestamps are significantly wrong (about 160s later than the reference), so it is factually incorrect on key details."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing 'Practical considerations', when does she first mention 'increasing reflective feedback'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2913.483,
        "end": 2916.268
      },
      "pred_interval": {
        "start": 3064.0,
        "end": 3070.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 150.51699999999983,
        "end": 153.73199999999997,
        "average": 152.1244999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.25000000000000006,
        "text_similarity": 0.6630889177322388,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives entirely different timestamps for both the start of 'Practical considerations' and the mention of 'increasing reflective feedback' (3047/3064s vs 2850/2913.483s) and even misstates their overlap, so it does not match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"for the patients\", when does the slide change to \"WHERE WE ARE NOW\"?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3067.769,
        "end": 3068.2
      },
      "pred_interval": {
        "start": 3036.2,
        "end": 3038.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.56899999999996,
        "end": 29.399999999999636,
        "average": 30.484499999999798
      },
      "rationale_metrics": {
        "rouge_l": 0.3516483516483517,
        "text_similarity": 0.6394408941268921,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the order (slide change follows the speaker) and cues, but the timestamps and intervals are substantially off (~31 seconds earlier) and the E2 visibility timing contradicts the ground truth, so the answer is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says \"open up for some discussion\", when does the discussion slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3163.435,
        "end": 3163.7
      },
      "pred_interval": {
        "start": 3065.3,
        "end": 3068.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 98.13499999999976,
        "end": 95.19999999999982,
        "average": 96.66749999999979
      },
      "rationale_metrics": {
        "rouge_l": 0.29213483146067415,
        "text_similarity": 0.5863021612167358,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the two events and that the slide follows the utterance, but the timestamps are substantially incorrect and it asserts an immediate transition contrary to the reference's precise timings, so it fails on factual accuracy and completeness."
      }
    },
    {
      "question_id": "001",
      "question": "After the first male speaker asks about attendees' experience with Near Me, when does the second male speaker begin talking about starting to use NearMe?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.9,
        "end": 3312.0
      },
      "pred_interval": {
        "start": 3288.4,
        "end": 3292.4
      },
      "iou": 0.09280742459396771,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.5,
        "end": 19.59999999999991,
        "average": 19.549999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.30927835051546393,
        "text_similarity": 0.6231682896614075,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies both events and the 'after' relation, but the provided timestamps differ substantially from the reference (each event is shifted by ~18\u201320 seconds), so the timing is factually inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second male speaker finishes stating the advantages and utility of NearMe, when does he mention supplementing normal activities?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.4,
        "end": 3293.32
      },
      "pred_interval": {
        "start": 3309.4,
        "end": 3314.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.0,
        "end": 21.079999999999927,
        "average": 21.039999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.2391304347826087,
        "text_similarity": 0.5382863283157349,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer correctly identifies the 'once_finished' relation and the sequence of events, but the provided timestamps significantly diverge from the ground truth (off by ~24s), so it is factually inaccurate on the key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "After the first man finishes reading Jenny's chat message, when does he ask the audience if they would find guidance helpful?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3411.0,
        "end": 3415.0
      },
      "pred_interval": {
        "start": 3437.0,
        "end": 3440.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.0,
        "end": 25.699999999999818,
        "average": 25.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.2474226804123712,
        "text_similarity": 0.6717827320098877,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the 'after' ordering but gives substantially different timestamps (off by ~29s) and mislocalizes the target span, so it is factually incorrect despite capturing the sequence."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first man finishes reading John Hogan's comment about clinical interviewing, when does he state he was quite skeptical?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3434.9,
        "end": 3437.7
      },
      "pred_interval": {
        "start": 3478.0,
        "end": 3481.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.09999999999991,
        "end": 43.80000000000018,
        "average": 43.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.35416666666666663,
        "text_similarity": 0.7331492304801941,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the reference by giving entirely different timestamps and a different relation ('immediately after' vs 'once_finished'), and it adds unsupported detail about uninterrupted audio; thus it fails to match the correct temporal span."
      }
    },
    {
      "question_id": "003",
      "question": "After the second woman mentions neuropsychology bringing out guidance, when is the next time a woman speaks about professional guidance?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3511.043,
        "end": 3528.447
      },
      "pred_interval": {
        "start": 3555.3,
        "end": 3558.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.25700000000006,
        "end": 30.452999999999975,
        "average": 37.35500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.8675249814987183,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly identifies both E1 and E2 time spans (off by large margins) and gives target spans that do not match the reference; it only preserves the vague 'after' ordering but fails on crucial timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 36 people joined the session, when does he talk about taking the next steps with Richard and the team?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3574.7,
        "end": 3576.5
      },
      "pred_interval": {
        "start": 3577.2,
        "end": 3587.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 10.5,
        "average": 6.5
      },
      "rationale_metrics": {
        "rouge_l": 0.29885057471264365,
        "text_similarity": 0.8185007572174072,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the anchor, the quoted target phrase, and the 'after' relationship, but the predicted target timing differs from the reference (starts ~2.5s later and ends much later), so the timing is partially incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker makes a plea to fill in the survey, when does he ask if listeners would like to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3592.9,
        "end": 3594.1
      },
      "pred_interval": {
        "start": 3593.6,
        "end": 3603.6
      },
      "iou": 0.04672897196261762,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.6999999999998181,
        "end": 9.5,
        "average": 5.099999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.3294117647058823,
        "text_similarity": 0.7681141495704651,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies both events and their 'after' relationship, but it gives an incorrect anchor timestamp (and no anchor interval), a slightly off target start, and omits the target end time, so the temporal details are inaccurate/incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes thanking everyone for joining the session today, when does he mention that the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3599.8,
        "end": 3603.2
      },
      "pred_interval": {
        "start": 3608.0,
        "end": 3615.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.199999999999818,
        "end": 11.800000000000182,
        "average": 10.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2926829268292683,
        "text_similarity": 0.8268274664878845,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and their causal relationship, but the provided timestamps are significantly offset from the ground truth and the target segment duration is incorrect, so it contains major factual errors."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'where did we start?', when does she mention considering moving to Near Me for patient contacts?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2332.719,
        "end": 2336.344
      },
      "pred_interval": {
        "start": 2387.0,
        "end": 2402.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.28099999999995,
        "end": 66.15599999999995,
        "average": 60.21849999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.24719101123595505,
        "text_similarity": 0.7364979982376099,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct utterances but the timestamps are substantially off (anchor and target shifted by ~55\u201370s and target end time is far from the ground truth), and the relationship is only described as 'after' rather than the precise 'direct follow-up', so the answer is largely incorrect. "
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says the pandemic came along, when does she mention adopting Near Me as their default for routine people?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2367.217,
        "end": 2412.045
      },
      "pred_interval": {
        "start": 2431.0,
        "end": 2448.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.7829999999999,
        "end": 35.95499999999993,
        "average": 49.868999999999915
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.7711224555969238,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target utterances and the 'after' relationship, but the provided start/end timestamps are substantially different from the ground truth, so the temporal spans are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the results of the focus groups for the qualitative study, when does she introduce the quotes from the participants?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2511.0,
        "end": 2512.0
      },
      "pred_interval": {
        "start": 2507.0,
        "end": 2510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 2.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.26415094339622647,
        "text_similarity": 0.7842296361923218,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the verbal cue introducing participant quotes and the 'after' relationship, but it misplaces the anchor timing (does not match the reference end at ~2469s) and the target timestamps are several seconds off from 2511\u20132512s, so the timing alignment is substantially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks to fill in the survey, when does he ask if listeners want to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3591.7,
        "end": 3595.8
      },
      "pred_interval": {
        "start": 3584.0,
        "end": 3592.0
      },
      "iou": 0.025423728813574346,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.699999999999818,
        "end": 3.800000000000182,
        "average": 5.75
      },
      "rationale_metrics": {
        "rouge_l": 0.32727272727272727,
        "text_similarity": 0.830962598323822,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the advisory-committee mention and the relative order (target after anchor), but it mislabels the anchor phrase and gives substantially incorrect timestamps for both events, omitting the actual 'plea to fill in the survey.'"
      }
    },
    {
      "question_id": "002",
      "question": "Before the speaker thanks the speakers for their expertise, when does he mention the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3599.9,
        "end": 3603.7
      },
      "pred_interval": {
        "start": 3595.0,
        "end": 3602.0
      },
      "iou": 0.24137931034482218,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.900000000000091,
        "end": 1.699999999999818,
        "average": 3.2999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.29411764705882354,
        "text_similarity": 0.8640783429145813,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction mislabels and splits the events, gives incorrect timestamps, and asserts the wrong temporal relationship; it contradicts the reference which places the combined recording/resources mention at 3599.9\u20133603.7 occurring before the thanks at 3604.0\u20133605.0."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker initially thanks the audience for joining, when does he deliver his final 'thank you very much' for the session?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3614.6,
        "end": 3615.4
      },
      "pred_interval": {
        "start": 3615.0,
        "end": 3617.0
      },
      "iou": 0.16666666666669824,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.40000000000009095,
        "end": 1.599999999999909,
        "average": 1.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4615384615384615,
        "text_similarity": 0.8506608009338379,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both thank-you utterances, their phrasing, and the 'after' relationship, but the anchor time is about 5.2s earlier than the reference and the target's end time is ~1.6s later, representing minor timing discrepancies."
      }
    },
    {
      "question_id": "001",
      "question": "After Mark introduces Dr. John Mckeown and Dr. Naomi Dow, when does he ask Dr. Dow to describe how they've been using Near Me?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.48,
        "end": 34.4
      },
      "pred_interval": {
        "start": 34.1,
        "end": 36.7
      },
      "iou": 0.05747126436781552,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.620000000000001,
        "end": 2.3000000000000043,
        "average": 2.4600000000000026
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.722975492477417,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the events and the 'after' relation, but both event timestamps are substantially off from the ground truth (E1 predicted ends at 34.0s vs 15.72s; E2 predicted starts at 34.1s vs 31.48s and ends later), so the temporal localization is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Dr. Naomi Dow finishes explaining how students take part in consultations, when does Mark ask Dr. Mckeown about the impact on the teaching team?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.96,
        "end": 124.4
      },
      "pred_interval": {
        "start": 73.6,
        "end": 74.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.36,
        "end": 49.5,
        "average": 47.43
      },
      "rationale_metrics": {
        "rouge_l": 0.37362637362637363,
        "text_similarity": 0.7729244828224182,
        "llm_judge_score": 1,
        "llm_judge_justification": "While the predicted answer correctly identifies the 'once_finished' relation, both event timestamps are substantially incorrect compared to the reference (predicted ~73.5\u201374.9s vs reference 117.60s and 118.96\u2013124.4s), so the prediction is factually wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker introduces the concept of emotions in the session, when does the female speaker first mention 'real patients'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.9,
        "end": 202.6
      },
      "pred_interval": {
        "start": 182.825,
        "end": 184.725
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.075000000000017,
        "end": 17.875,
        "average": 18.47500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.13207547169811318,
        "text_similarity": 0.586529016494751,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect on multiple counts: it misidentifies the anchor speaker (female vs male), gives substantially different timestamps for both events, and claims a 'during' relation whereas the correct relation is 'after'."
      }
    },
    {
      "question_id": "002",
      "question": "Once the interviewer finishes asking the question about comparing models, when does the female speaker finish explaining the advantages of 'Near Me' regarding real patients and capacity?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 198.7,
        "end": 306.9
      },
      "pred_interval": {
        "start": 188.5,
        "end": 192.075
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.199999999999989,
        "end": 114.82499999999999,
        "average": 62.51249999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1891891891891892,
        "text_similarity": 0.6975469589233398,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only matches the qualitative ordering (speaker speaks after the question) but gives incorrect timestamps for both events and wildly underestimates the duration of the female speaker's explanation, so it fails to match the correct answer's key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the man is speaking on screen, when does he mention 'Near Me'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 342.0,
        "end": 344.0
      },
      "pred_interval": {
        "start": 340.0,
        "end": 343.5
      },
      "iou": 0.375,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 0.5,
        "average": 1.25
      },
      "rationale_metrics": {
        "rouge_l": 0.16091954022988506,
        "text_similarity": 0.6685436964035034,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction largely disagrees with the reference: time spans are incorrect, the quoted speech differs (no 'Near Me'), and the relation is labeled 'after' instead of the correct 'during'. There is only minor temporal overlap, but key facts and the relation are wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying 'Thank you and goodbye', when do the 'NHS Scotland' and 'Near Me' logos appear with text links?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 348.5,
        "end": 352.0
      },
      "iou": 0.08695652173913043,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 8.0,
        "average": 5.25
      },
      "rationale_metrics": {
        "rouge_l": 0.303030303030303,
        "text_similarity": 0.7005590200424194,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies both events and the 'once_finished' relation correctly, but the timestamps are substantially off (E1 at 347s vs 350s; E2 at 348.5\u2013352s vs 351\u2013360s) and E2's duration is incorrect, so it is factually imprecise."
      }
    },
    {
      "question_id": "003",
      "question": "After the initial voiceover concludes with 'patient that day', when does the man on screen begin to say 'Thanks very much John and Amy'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 336.4,
        "end": 341.6
      },
      "pred_interval": {
        "start": 339.4,
        "end": 340.0
      },
      "iou": 0.11538461538461875,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 1.6000000000000227,
        "average": 2.3000000000000114
      },
      "rationale_metrics": {
        "rouge_l": 0.40860215053763443,
        "text_similarity": 0.7922263145446777,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the correct ordering (man speaks after the voiceover) but the provided timestamps are substantially different from the ground truth and the relation is mischaracterized as immediate ('once_finished'), so key factual timing information is incorrect."
      }
    }
  ]
}