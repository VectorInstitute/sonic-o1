{
  "topic_id": 1,
  "topic_name": "Patient-Doctor Consultations",
  "num_evaluated": 269,
  "aggregated_metrics": {
    "mean_iou": 0.2016161181668154,
    "std_iou": 0.2796408414944442,
    "median_iou": 0.02840909090909264,
    "R@0.3": {
      "recall": 0.26765799256505574,
      "count": 72,
      "total": 269
    },
    "R@0.5": {
      "recall": 0.18587360594795538,
      "count": 50,
      "total": 269
    },
    "R@0.7": {
      "recall": 0.10408921933085502,
      "count": 28,
      "total": 269
    },
    "mae": {
      "start_mean": 7.566360594795536,
      "end_mean": 3486.8729814126386,
      "average_mean": 1747.2196710037176
    },
    "rationale": {
      "rouge_l_mean": 0.29238135730468023,
      "rouge_l_std": 0.08536678405066815,
      "text_similarity_mean": 0.6654356305373202,
      "text_similarity_std": 0.14599353409903343,
      "llm_judge_score_mean": 5.044609665427509,
      "llm_judge_score_std": 2.560396609042105
    },
    "rationale_cider": 0.22397435132656698
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "After the speaker welcomes viewers and introduces himself as 'Karma Medic', when does he state that he is a 'final year medical student'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 35.0,
        "end": 36.62
      },
      "pred_interval": {
        "start": 28.5,
        "end": 30.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 6.119999999999997,
        "average": 6.309999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.4166666666666667,
        "text_similarity": 0.8085861206054688,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the statement content and that it follows the introduction, but the anchor and target timestamps are substantially incorrect (predicted at start and 28.5\u201330.5s vs. reference 3.54s and 35.00\u201336.62s), so the timing is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'Now with that lovely disclaimer out of the way, let's get right into it', when does the text 'before the history' appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.06,
        "end": 57.06
      },
      "pred_interval": {
        "start": 56.0,
        "end": 57.0
      },
      "iou": 0.8867924528301846,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.060000000000002274,
        "end": 0.060000000000002274,
        "average": 0.060000000000002274
      },
      "rationale_metrics": {
        "rouge_l": 0.34375,
        "text_similarity": 0.8188610076904297,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the immediate appearance and matches the target's timing closely (56.0s vs 56.06s and ~57.0s vs 57.06s); however it lists the anchor finishing ~0.5s earlier than the reference and adds an extra detail (red title card) not in the ground truth, so minor discrepancies remain."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'So before starting the history, there's generally two things that I try and keep in mind', when does he begin describing 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 206.36,
        "end": 207.36
      },
      "pred_interval": {
        "start": 206.0,
        "end": 210.0
      },
      "iou": 0.25,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.36000000000001364,
        "end": 2.6399999999999864,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.4383561643835617,
        "text_similarity": 0.8144007325172424,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target segments and the 'after' relationship, with only small timing shifts and an extended end time (210s vs ~207.36s) and an extra note about on-screen text not mentioned in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the acronym 'ICE', when does he explain what it stands for?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 155.7,
        "end": 158.7
      },
      "pred_interval": {
        "start": 158.0,
        "end": 161.0
      },
      "iou": 0.1320754716981108,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.3000000000000114,
        "end": 2.3000000000000114,
        "average": 2.3000000000000114
      },
      "rationale_metrics": {
        "rouge_l": 0.3421052631578947,
        "text_similarity": 0.6258746385574341,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the mention and the explanatory segment and preserves their temporal relation, but the reported timestamps differ by ~1\u20133 seconds from the reference, so it's largely correct but not exact."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the components of the WIPER acronym, when does he start elaborating on 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 212.0
      },
      "pred_interval": {
        "start": 208.0,
        "end": 215.0
      },
      "iou": 0.5,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 3.0,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.380952380952381,
        "text_similarity": 0.7222535610198975,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target events and their sequential relationship, but the timestamps are shifted by 1\u20133 seconds (E1: 207s vs 205s; E2: 208\u2013215s vs 207\u2013212s) and the relation label 'sequential' is a looser phrasing than 'once_finished'."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what brought the patient in, when does he explain what the 'history of presenting complaint' is about?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 346.0,
        "end": 351.0
      },
      "pred_interval": {
        "start": 347.5,
        "end": 360.5
      },
      "iou": 0.2413793103448276,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5,
        "end": 9.5,
        "average": 5.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2452830188679245,
        "text_similarity": 0.5456562042236328,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies E1 and that E2 occurs after it, with E1 timing closely matching; however E2's timing is inaccurate (starts ~1.5s late and extends significantly past the ground-truth end), so it partially but not perfectly aligns."
      }
    },
    {
      "question_id": "001",
      "question": "How long after the speaker says he'll put a picture of all possible questions does the \"REVIEW OF SYSTEMS\" checklist first appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 539.8,
        "end": 543.7
      },
      "pred_interval": {
        "start": 541.0,
        "end": 542.0
      },
      "iou": 0.25641025641025045,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2000000000000455,
        "end": 1.7000000000000455,
        "average": 1.4500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.2028985507246377,
        "text_similarity": 0.32525426149368286,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the checklist appears after the speaker, but the provided timestamps are substantially inaccurate and contradict the ground-truth times; it also omits the detail about when the checklist is fully visible."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is giving examples of systems review questions, when does he ask about \"tummy pain\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 565.74,
        "end": 566.422
      },
      "pred_interval": {
        "start": 571.2,
        "end": 572.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.460000000000036,
        "end": 5.77800000000002,
        "average": 5.619000000000028
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.369905948638916,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same event type but gives a substantially incorrect time window (571.2\u2013572.2s vs. 555.74\u2013556.42s) and adds an unsupported detail about following nausea/vomiting, so it is factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the \"JAM THREADS\" mnemonic, when does he say the name \"Sketchy Medical\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 696.0,
        "end": 699.531
      },
      "pred_interval": {
        "start": 702.8,
        "end": 704.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.7999999999999545,
        "end": 4.669000000000096,
        "average": 5.7345000000000255
      },
      "rationale_metrics": {
        "rouge_l": 0.3703703703703704,
        "text_similarity": 0.5697735548019409,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the relation that 'Sketchy Medical' occurs after 'JAM THREADS', but both timestamps are notably off from the reference (JAM: 638s vs 635s; Sketchy Medical: 702.8\u2013704.2s vs 696.0\u2013699.531s), so the timing is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker describes Sketchy Medical, when does he mention drugs' mechanism of action and side effects?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 701.0,
        "end": 703.982
      },
      "pred_interval": {
        "start": 705.0,
        "end": 708.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 4.018000000000029,
        "average": 4.0090000000000146
      },
      "rationale_metrics": {
        "rouge_l": 0.3508771929824562,
        "text_similarity": 0.6016778945922852,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives incorrect timestamps: the speaker actually begins around 697.49s (not ~701s) and mentions mechanism/side effects between 701.0\u2013703.982s, whereas the prediction shifts these to 705\u2013708s, contradicting the reference timing."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks a general question about family health, when does he suggest being specific about asthma, diabetes, and hypertension?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 742.914,
        "end": 745.914
      },
      "pred_interval": {
        "start": 746.0,
        "end": 750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0860000000000127,
        "end": 4.086000000000013,
        "average": 3.5860000000000127
      },
      "rationale_metrics": {
        "rouge_l": 0.14492753623188406,
        "text_similarity": 0.310583233833313,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the target occurs after the general family-health question and lists the same conditions, but it gives substantially different timing (746\u2013750s vs. the correct 742.914\u2013745.914s), so the temporal details are inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the importance of signposting, when does he ask if the patient uses any recreational drugs?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 811.123,
        "end": 812.664
      },
      "pred_interval": {
        "start": 815.0,
        "end": 817.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.8769999999999527,
        "end": 4.336000000000013,
        "average": 4.106499999999983
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.657507061958313,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives different timestamps that are several seconds later than the reference (806s vs ~800.9s for signposting, 815\u2013817s vs ~811.1\u2013812.7s for the question) and thus misaligns the events; it also fails to match the stated immediate follow relationship, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"concerns from ICE\", when does he start saying \"Just generally, if you're feeling stuck\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 880.187,
        "end": 883.471
      },
      "pred_interval": {
        "start": 884.0,
        "end": 885.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.812999999999988,
        "end": 2.129000000000019,
        "average": 2.9710000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.4415584415584415,
        "text_similarity": 0.6615244150161743,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the correct order (anchor then target) but the timestamps are substantially inaccurate\u2014the anchor is ~3.8s later and the target start ~3.8s later (target end ~2.1s later) than the ground truth\u2014so the temporal localization is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"golden rulebook\", when does he open both hands outwards in a gesture?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 895.8,
        "end": 897.5
      },
      "pred_interval": {
        "start": 900.2,
        "end": 901.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.400000000000091,
        "end": 4.2999999999999545,
        "average": 4.350000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.2564102564102564,
        "text_similarity": 0.6405322551727295,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same type of gesture occurring after the speech, but the anchor and target times are several seconds off from the ground truth and include extra/unfounded dialogue details; the large timing mismatch and hallucinated content make it largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying \"I hope you find this video useful\", when does he say \"Peace\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 910.148,
        "end": 910.609
      },
      "pred_interval": {
        "start": 914.0,
        "end": 914.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.8519999999999754,
        "end": 3.8909999999999627,
        "average": 3.871499999999969
      },
      "rationale_metrics": {
        "rouge_l": 0.3373493975903615,
        "text_similarity": 0.624423086643219,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the word 'Peace' but places both the anchor and the target several seconds later and adds an extra intervening sentence/gesture not present in the ground truth, so it fails the required temporal/alignment accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying he has an appointment at 10 am, when does the green text 'Sure, what's your name?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 6.1,
        "end": 8.2
      },
      "pred_interval": {
        "start": 6.0,
        "end": 9.0
      },
      "iou": 0.6999999999999998,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.09999999999999964,
        "end": 0.8000000000000007,
        "average": 0.4500000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.26506024096385544,
        "text_similarity": 0.7470679879188538,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relation (text appears immediately after the man finishes) and has only minor discrepancy in the anchor/end start times, but it overestimates the target's end time (9.0s vs correct 8.2s), so the target duration is inaccurately reported."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes stating his name, when does the green text 'Thank you, Lucas. Please take a seat...' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 11.9,
        "end": 19.0
      },
      "pred_interval": {
        "start": 10.0,
        "end": 19.0
      },
      "iou": 0.7888888888888889,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.9000000000000004,
        "end": 0.0,
        "average": 0.9500000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2465753424657534,
        "text_similarity": 0.5823714733123779,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction matches the target end time (19.0s) but misstates both the anchor end (10.0s vs 10.6s) and the target start (10.0s vs 11.9s), incorrectly claiming the text appears immediately rather than after the man finishes, so key timing and relational facts are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'How long is the wait?', when does the green text 'About 10 minutes. Would you like some water while you wait?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 22.1,
        "end": 25.3
      },
      "pred_interval": {
        "start": 20.0,
        "end": 26.0
      },
      "iou": 0.5333333333333332,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.1000000000000014,
        "end": 0.6999999999999993,
        "average": 1.4000000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.7614999413490295,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction misplaces the target's start time (claims 20.0s vs. correct 22.1s) and thus omits the described slight pause and 'after' relation; the other end times are only slightly off but the key temporal relation is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the video explains the 'we're a team' approach with animated graphics, when does the speaker appear at his desk looking at a computer?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 34.6,
        "end": 36.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.7
      },
      "iou": 0.4761904761904759,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3999999999999986,
        "end": 0.7000000000000028,
        "average": 0.5500000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.25742574257425743,
        "text_similarity": 0.7787912487983704,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the animated 'we're a team' segment followed by the speaker at his desk and matches the sequence and visual content, but its timestamps are slightly offset (E1 ends ~35.0s vs 34.6s and E2 is given as 35.0\u201336.7s versus the reference 34.0/34.6\u201336.0s) and includes an extra detail about scrubs that isn't in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker says 'take that extra bit of time to listen', when does the 'OK' hand gesture emoji appear?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 44.0,
        "end": 45.5
      },
      "pred_interval": {
        "start": 43.2,
        "end": 44.9
      },
      "iou": 0.3913043478260868,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7999999999999972,
        "end": 0.6000000000000014,
        "average": 0.6999999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.45,
        "text_similarity": 0.8610666990280151,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly matches the spoken phrase timing but misreports the emoji timing (saying it appears at 43.2s and ends at 44.9s vs. the reference 44.0\u201345.5s) and adds an unsupported scene-transition detail, so it is factually inaccurate on the key element."
      }
    },
    {
      "question_id": "001",
      "question": "After Nurse Kim mentions graduating as a registered nurse, when does she talk about working for many different pharmaceutical companies?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 43.0,
        "end": 50.475
      },
      "pred_interval": {
        "start": 41.0,
        "end": 51.0
      },
      "iou": 0.7475000000000002,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 2.0,
        "end": 0.5249999999999986,
        "average": 1.2624999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.2571428571428572,
        "text_similarity": 0.5963449478149414,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the order and approximate timing (E1 ~29s, E2 ~41\u201351s) and that E2 follows E1, but it misstates E2's start time (41.0s vs 43.0s), has a small end-time discrepancy, and hallucinate specific company names not present in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once Nurse Kim finishes describing her background as an 'incredible journey', when does she mention training side-by-side with Dr. Jugenberg for five years?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 149.87,
        "end": 153.25
      },
      "pred_interval": {
        "start": 148.0,
        "end": 153.0
      },
      "iou": 0.5961904761904753,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.8700000000000045,
        "end": 0.25,
        "average": 1.0600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.6287923455238342,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer captures the correct textual content and relation (once_finished) but the timestamps are substantially wrong (~148\u2013153s vs ground truth 108.275\u2013113.25s), so it fails the required temporal alignment."
      }
    },
    {
      "question_id": "001",
      "question": "While Nurse Kim explains options and possible outcomes, when does she begin examining the patient's stomach?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 157.5,
        "end": 160.5
      },
      "pred_interval": {
        "start": 159.1,
        "end": 170.4
      },
      "iou": 0.10852713178294612,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5999999999999943,
        "end": 9.900000000000006,
        "average": 5.75
      },
      "rationale_metrics": {
        "rouge_l": 0.17073170731707318,
        "text_similarity": 0.40098893642425537,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction partially overlaps the true interval but gives substantially different timings (159.1\u2013170.4s vs. the correct 157.5\u2013160.5s) and omits the anchor\u2019s explicit start time (156.8s), so it is inaccurate and adds unsupported end timing."
      }
    },
    {
      "question_id": "002",
      "question": "After Nurse Kim finishes discussing the benefits, risks, and possible complications of the procedure, when does she start talking about asymmetry?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 169.7,
        "end": 172.0
      },
      "pred_interval": {
        "start": 170.9,
        "end": 188.0
      },
      "iou": 0.06010928961748599,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.200000000000017,
        "end": 16.0,
        "average": 8.600000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.2197802197802198,
        "text_similarity": 0.5938235521316528,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction preserves the key relation (asymmetry discussion starts immediately after the risks/complications) and gives a very close start time (170.9s vs. 169.7s in reference); the slight ~1\u20131.5s timing discrepancy and the added end-time are minor and do not contradict the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once Nurse Kim finishes explaining that the one-hour consultation cannot provide everything you need to know, when does she mention that they are always available?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 201.5,
        "end": 203.71
      },
      "pred_interval": {
        "start": 202.3,
        "end": 207.2
      },
      "iou": 0.2473684210526315,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8000000000000114,
        "end": 3.4899999999999807,
        "average": 2.144999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.34003251791000366,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the immediate transition and meaning, but the reported anchor/start time is ~0.8s later than the reference (202.3s vs 201.5s) and it adds an end time not present in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces himself and the topic, when does the slide change to 'Objectives for today's lesson'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 24.379,
        "end": 24.5
      },
      "pred_interval": {
        "start": 23.0,
        "end": 25.0
      },
      "iou": 0.06049999999999933,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3790000000000013,
        "end": 0.5,
        "average": 0.9395000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.2592592592592593,
        "text_similarity": 0.5081123113632202,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately captures the end of the introduction (~15s) and the slide change (~23s), preserving the 'after' relation and closely matching the reference times."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the objectives for the lesson, when does the slide change to 'Brain storming time'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 46.529,
        "end": 47.0
      },
      "pred_interval": {
        "start": 47.0,
        "end": 49.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.47099999999999653,
        "end": 2.0,
        "average": 1.2354999999999983
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.66908198595047,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures both events and their order (slide change immediately after the speaker finishes) and the times are close to the reference, but it rounds times to whole seconds, causing a small (~0.47s) discrepancy for the slide change."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes defining communication as the successful passage of a message from one person to another, when does he start explaining how good communication manifests in medical practice by informing patients of their diagnosis?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 153.0,
        "end": 177.0
      },
      "pred_interval": {
        "start": 154.4,
        "end": 163.5
      },
      "iou": 0.37916666666666643,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.4000000000000057,
        "end": 13.5,
        "average": 7.450000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923078,
        "text_similarity": 0.6557069420814514,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the correct relation ('immediately after') and the start of the explanation theme, but the anchor and target timestamps are incorrect (anchor extended past 153.0s, target starts later at 154.4s and ends much earlier at 163.5s), omitting a substantial portion of the referenced target interval."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the 'Importance of communication' slide, when does he begin discussing that good doctor-patient communication has been linked to improved patient satisfaction?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 190.0,
        "end": 198.0
      },
      "pred_interval": {
        "start": 191.2,
        "end": 198.8
      },
      "iou": 0.772727272727273,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.1999999999999886,
        "end": 0.8000000000000114,
        "average": 1.0
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.6871370077133179,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target, their order, and the linked content (improved patient satisfaction); the reported times are close to the reference with minor offsets (~+0.5\u20131.2s) but no substantive contradiction or missing key elements."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker starts talking about how a lot of malpractice lawsuits have been documented, when does he explicitly advise being aware of communication's importance to avoid lawsuits?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 226.0,
        "end": 271.0
      },
      "pred_interval": {
        "start": 227.5,
        "end": 232.5
      },
      "iou": 0.1111111111111111,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5,
        "end": 38.5,
        "average": 20.0
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.7711485028266907,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted anchor and target timestamps fall within the correct intervals and the prediction accurately captures the explicit advice following the statement about malpractice lawsuits."
      }
    },
    {
      "question_id": "001",
      "question": "After the initial slide 'Communication is not just talking' is displayed, when does the speaker mention that physicians can improve health outcomes?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 339.28,
        "end": 346.0
      },
      "pred_interval": {
        "start": 341.0,
        "end": 347.0
      },
      "iou": 0.6476683937823812,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.7200000000000273,
        "end": 1.0,
        "average": 1.3600000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.37333333333333335,
        "text_similarity": 0.6235302686691284,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor at 330.0s and that the speaker's remark occurs after it; the predicted event times are very close to the reference (start ~1.7s later, end 1s later), a minor timing discrepancy."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide showing two images (bored girl vs. smiling doctor/patient), when does the speaker describe the first image as depicting a 'horribly bored' lady?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.8,
        "end": 359.0
      },
      "pred_interval": {
        "start": 355.0,
        "end": 360.0
      },
      "iou": 0.7692307692307709,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.19999999999998863,
        "end": 1.0,
        "average": 0.5999999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.3373493975903615,
        "text_similarity": 0.762628972530365,
        "llm_judge_score": 8,
        "llm_judge_justification": "The predicted answer's description timings closely match the reference (355.0s vs 354.8s start; 360.0s vs 359.0s end) but it omits the slide's end time and slightly misstates the slide start (349.0s vs 347.8s), so minor inaccuracies and one omitted key element."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker defines verbal communication as 'using spoken words', when is the next time they define non-verbal communication?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 428.87,
        "end": 433.596
      },
      "pred_interval": {
        "start": 431.0,
        "end": 436.0
      },
      "iou": 0.36409537166900496,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.1299999999999955,
        "end": 2.4039999999999964,
        "average": 2.266999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.5544725656509399,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states that the non\u2011verbal definition immediately follows the verbal one and accurately captures its meaning; the only issue is minor timing discrepancies of a few seconds for the start/end times. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the 'golden minute', when does he describe the patient's hypothetical response?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 613.818,
        "end": 630.0
      },
      "pred_interval": {
        "start": 614.5,
        "end": 626.5
      },
      "iou": 0.7415647015202069,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.6820000000000164,
        "end": 3.5,
        "average": 2.091000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.36538461538461536,
        "text_similarity": 0.8798331618309021,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction accurately identifies the target interval and content (patient's hypothetical response) closely matching the reference, but it mislocates the anchor: the 'golden minute' introduction is given ~37s earlier in the correct answer, so the anchor timestamp is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions 'Checking facts', when does he mention the next essential element of listening?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 641.157,
        "end": 642.461
      },
      "pred_interval": {
        "start": 645.5,
        "end": 647.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.342999999999961,
        "end": 4.538999999999987,
        "average": 4.440999999999974
      },
      "rationale_metrics": {
        "rouge_l": 0.325,
        "text_similarity": 0.891132116317749,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the next element as 'checking feelings' and preserves the order, but it misstates both timestamps (misplacing the 'Checking facts' anchor by ~28s and giving incorrect target timings/duration), so key factual timing details are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Before the speaker says 'So, for example, we have three main types of reflective listening', when does he explain what reflective listening involves?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 667.457,
        "end": 687.051
      },
      "pred_interval": {
        "start": 686.0,
        "end": 694.0
      },
      "iou": 0.0395961270391457,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.543000000000006,
        "end": 6.948999999999955,
        "average": 12.745999999999981
      },
      "rationale_metrics": {
        "rouge_l": 0.26190476190476186,
        "text_similarity": 0.8535233736038208,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly concludes the definition occurs before the examples, but it reverses the anchor/target labels and gives incorrect timestamps that contradict the reference, so the detailed temporal claims are inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the three main types of reflective listening, when does he start explaining the 'Repeating' example?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 710.0,
        "end": 737.0
      },
      "pred_interval": {
        "start": 714.0,
        "end": 717.0
      },
      "iou": 0.1111111111111111,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 20.0,
        "average": 12.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2903225806451613,
        "text_similarity": 0.5321177244186401,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the explanation occurs after the listing and gives an approximate start time close to the reference (714.0s vs 710.0s), but it omits the speaker's initial mention time (696.1s) and the explanation end time (737.0s), and has a small timing discrepancy."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the 'Repeating' example, when does he introduce 'Rephrasing'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 720.0,
        "end": 720.4
      },
      "pred_interval": {
        "start": 724.0,
        "end": 726.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 5.600000000000023,
        "average": 4.800000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.3943661971830986,
        "text_similarity": 0.7075346112251282,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the relation and paraphrase right but misstates key times: it claims the 'Repeating' example ends at 724.0s (correct is 698.0s) and shifts the 'Rephrasing' start to 724\u2013726s instead of 720.0s, so it contains significant factual timing errors."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing 'Reflection of feeling by showing empathy', when does the 'Non-verbal' slide appear?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 780.0,
        "end": 821.5
      },
      "pred_interval": {
        "start": 784.0,
        "end": 786.0
      },
      "iou": 0.04819277108433735,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 35.5,
        "average": 19.75
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5308279395103455,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the correct order/relation (slide appears after the empathy discussion) but both timestamps are off by several seconds (predicted 783.0s vs 778.5s and 784.0s vs 780.0s), so it's roughly correct but not precise."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises to smile, when does he mention checking for signs of pain?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.045,
        "end": 882.0
      },
      "pred_interval": {
        "start": 872.0,
        "end": 882.0
      },
      "iou": 0.8955000000000041,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.044999999999959,
        "end": 0.0,
        "average": 0.5224999999999795
      },
      "rationale_metrics": {
        "rouge_l": 0.26190476190476186,
        "text_similarity": 0.7376946210861206,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events and their content and matches the end time exactly; start times are slightly off by about 0.9\u20131.0 seconds but this is a minor timing discrepancy rather than a substantive error."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the cultural interpretations of folding arms, when does he advise to avoid folding arms?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 932.0,
        "end": 936009.0
      },
      "pred_interval": {
        "start": 937.0,
        "end": 941.0
      },
      "iou": 4.277722583273891e-06,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 935068.0,
        "average": 467536.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.7422357201576233,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the correct pieces of dialogue (cultural discussion and the advice), but the provided timestamps are significantly misaligned\u2014E1 is placed much later and E2 is shifted/extended past the ground truth, so the timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker instructs to introduce yourself to the patient, when does he advise to explain your role as a student or intern?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 985.0,
        "end": 990.853
      },
      "pred_interval": {
        "start": 990.0,
        "end": 994.0
      },
      "iou": 0.09477777777777242,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 3.147000000000048,
        "average": 4.073500000000024
      },
      "rationale_metrics": {
        "rouge_l": 0.3142857142857143,
        "text_similarity": 0.7125402688980103,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction identifies the correct events (introduce yourself; explain role as student/intern) but the timestamps are consistently shifted later by ~3\u20135 seconds versus the ground truth, so the temporal accuracy is poor."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"if you're in the hospital\", when does he refer to \"inpatient patients\"?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1059.6,
        "end": 1059.8
      },
      "pred_interval": {
        "start": 1060.0,
        "end": 1061.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.40000000000009095,
        "end": 1.7000000000000455,
        "average": 1.0500000000000682
      },
      "rationale_metrics": {
        "rouge_l": 0.07407407407407407,
        "text_similarity": 0.10331687331199646,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly locates the anchor (~1056.5s) and the target after it, but the predicted target window (1060.0\u20131061.5s) is slightly later than the reference (1059.6\u20131059.8s) and includes an unverified detail about stumbling."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining how to start a consultation, when does he give the example \"how can I help you today?\"",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1069.0,
        "end": 1070.0
      },
      "pred_interval": {
        "start": 1070.3,
        "end": 1072.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2999999999999545,
        "end": 2.0,
        "average": 1.6499999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.182961106300354,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the phrase is given as an example during the consultation start, but it omits the anchor interval and provides an incorrect/shifted timestamp (1070.3\u20131072.0 vs. 1069.0\u20131070.0) and adds unverified wording ('such as'), so it is only partially accurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes explaining the 'golden minute', when does he announce the end of the lecture?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1090.0,
        "end": 1094.0
      },
      "pred_interval": {
        "start": 1092.5,
        "end": 1095.5
      },
      "iou": 0.2727272727272727,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 1.5,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.14705882352941177,
        "text_similarity": 0.3722513020038605,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the order (anchor before the lecture-ending remark) and gives nearby timestamps, but the times are shifted ~2\u20132.5s later than the reference and the predicted end time extends 1.5s beyond the correct interval, so it is imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "While Raquel is talking about the hospital providing opportunities for nurses, when is she shown smiling and opening a package?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 2.0,
        "end": 4.5
      },
      "pred_interval": {
        "start": 2.0,
        "end": 5.0
      },
      "iou": 0.8333333333333334,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 0.5,
        "average": 0.25
      },
      "rationale_metrics": {
        "rouge_l": 0.32911392405063294,
        "text_similarity": 0.7576390504837036,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies that the smiling/opening-package visual (E2) occurs during Raquel's speech (E1) and matches the E2 start time; minor timing discrepancies (E1 start 0.00 vs 0.031s and E2 end 5.0s vs 4.5s) prevent a perfect score."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria finishes saying that new nurses will be nudged to become lifelong learners, when does Precious state that the teamwork is strong?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 14.321,
        "end": 16.486
      },
      "pred_interval": {
        "start": 14.0,
        "end": 16.0
      },
      "iou": 0.6753821399839098,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.32099999999999973,
        "end": 0.48600000000000065,
        "average": 0.4035000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.3582089552238806,
        "text_similarity": 0.7310975790023804,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction has the correct sequence and rough time window but the timestamps are inaccurate: E1 is off by ~1.3s and E2's start/end are ~0.32s and ~0.49s early, so it only partially matches the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After Reny states that the hospital does things up to a magnet level, when does Raquel say her values align with the hospital's values?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 42.854,
        "end": 50.692
      },
      "pred_interval": {
        "start": 43.0,
        "end": 46.0
      },
      "iou": 0.3827507017096198,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.1460000000000008,
        "end": 4.692,
        "average": 2.4190000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.20224719101123598,
        "text_similarity": 0.6743381023406982,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies Reny as the anchor and Raquel's turn starting near the reference, but the timestamps are imprecise (E1 end off by ~0.47s) and it significantly underestimates E2's duration\u2014omitting that Raquel's speech continues until ~50.69s and over the logo."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that healthcare in Siem Reap is not the best, when is the Royal Angkor International Hospital first shown on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 94.0,
        "end": 99.1
      },
      "pred_interval": {
        "start": 94.0,
        "end": 117.0
      },
      "iou": 0.22173913043478236,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.0,
        "end": 17.900000000000006,
        "average": 8.950000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3368421052631579,
        "text_similarity": 0.6498548984527588,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the visual start at 94.0s and roughly locates the prior speaker remark, but it omits the precise moment the speaker begins describing the hospital (99.100s) and slightly compresses the finishing time of the initial statement, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he begin describing the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 180.289,
        "end": 185.074
      },
      "pred_interval": {
        "start": 180.0,
        "end": 198.0
      },
      "iou": 0.2658333333333347,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.28899999999998727,
        "end": 12.925999999999988,
        "average": 6.6074999999999875
      },
      "rationale_metrics": {
        "rouge_l": 0.41904761904761906,
        "text_similarity": 0.8357691764831543,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the start of the Ly Sreyvyna II description (~180s), but it misstates the end time (198s vs 185.074s) and the Neak Tep finish time (~175s vs 165.611s), adding inaccurate details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he visited a clinic for chest congestion, when does he mention the Paschern Dental Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 209.8,
        "end": 211.4
      },
      "pred_interval": {
        "start": 238.0,
        "end": 256.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.19999999999999,
        "end": 44.599999999999994,
        "average": 36.39999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.205607476635514,
        "text_similarity": 0.8116121292114258,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the dental-clinic mention follows the chest-congestion remark, but its timestamps differ substantially from the ground truth (off by ~30\u201350s) and it invents extended segment boundaries, so it fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he introduce the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.0,
        "end": 184.8
      },
      "pred_interval": {
        "start": 184.0,
        "end": 202.0
      },
      "iou": 0.04444444444444508,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.0,
        "end": 17.19999999999999,
        "average": 8.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367344,
        "text_similarity": 0.7473281621932983,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the Neak Tep end (~182\u2013183s) and the Ly Sreyvyna II start (~184s), but it substantially misreports the clinic segment duration (predicts end at 202s vs ground truth 184.8s) and adds unsupported detail ('immediately after' and visual-change timing), so it is partially correct but contains significant incorrect/hallucinated timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker introduces the Cigna International Health Policy, when is the insurance quote form displayed with personal information?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 354.0,
        "end": 360.0
      },
      "iou": 0.6666666666666666,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 0.0,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.22448979591836732,
        "text_similarity": 0.7708057165145874,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the form is visible until 360s and that it follows the introduction, but it misreports timings (E1 start at 345s vs 350s, E2 start at 354s vs 351s) and omits E1's end time, causing timing and completeness errors."
      }
    },
    {
      "question_id": "002",
      "question": "After the voiceover states that the Cigna policy is \"fairly typical of policies of this type\", when does the Cigna website display the form for inputting personal details to get a quote?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 352.9,
        "end": 358.0
      },
      "pred_interval": {
        "start": 338.5,
        "end": 349.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.399999999999977,
        "end": 9.0,
        "average": 11.699999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.3255813953488372,
        "text_similarity": 0.6750984191894531,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the prediction preserves the ordering (the form appears after the anchor), the timestamps and durations are substantially incorrect relative to the reference (off by ~13\u201315s and different end times), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "003",
      "question": "After the voiceover mentions \"evacuation service, also part of Cigna plan\", when is the Global Rescue website displayed on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 384.0,
        "end": 431.0
      },
      "pred_interval": {
        "start": 369.0,
        "end": 450.0
      },
      "iou": 0.5802469135802469,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.0,
        "end": 19.0,
        "average": 17.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3146067415730337,
        "text_similarity": 0.7533268332481384,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction's timestamps conflict substantially with the reference (anchor 368s vs 379s, target 369s vs 384s, end 450s vs 431s) and adds an unsupported claim about cutting to 'nowcompare.com', so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the host concludes his introduction about the fight in modern healthcare, when does he introduce Sarah?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 19.4,
        "end": 22.0
      },
      "pred_interval": {
        "start": 19.0,
        "end": 24.0
      },
      "iou": 0.5200000000000002,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3999999999999986,
        "end": 2.0,
        "average": 1.1999999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.25581395348837205,
        "text_similarity": 0.5350226759910583,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the sequence and approximate timing of the host finishing (~18.0s) and introducing Sarah (~19s), but it misstates the end time of Sarah's introduction (saying ~24.0s vs the reference 22.0s) and adds unverified detail about the wording, so it's somewhat inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "While Sarah is introducing herself and her genetic condition, when does she mention having her very first surgery?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.08,
        "end": 108.8
      },
      "pred_interval": {
        "start": 106.0,
        "end": 112.0
      },
      "iou": 0.3535353535353531,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.9200000000000017,
        "end": 3.200000000000003,
        "average": 2.5600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.2631578947368421,
        "text_similarity": 0.5143873691558838,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the mention of the first surgery and that it occurs during her introduction, and the 106.0s start falls within the reference window (104.08\u2013108.08); however the predicted end time (112.0s) and slight start/end discrepancies differ from the precise reference times."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sarah finishes describing her role as a volunteer patient representative for a non-profit organization, when does the static image showing her behind a 'CHILDREN'S TUMOR FOUNDATION' table appear?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 185.0,
        "end": 190.0
      },
      "pred_interval": {
        "start": 161.1,
        "end": 166.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.900000000000006,
        "end": 23.900000000000006,
        "average": 23.900000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.796556830406189,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct events but the timings are substantially off: E1 is 4s later than the reference and E2 is ~24s earlier than the ground truth, contradicting the required temporal alignment (including the noted immediacy). These large timing discrepancies make the answer incorrect. "
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes explaining the purpose of the 'Shine a Light Walk' to raise money and awareness, when does the video clip showing children running at an outdoor event play?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 189.0,
        "end": 192.0
      },
      "pred_interval": {
        "start": 195.0,
        "end": 198.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 6.0,
        "average": 6.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2758620689655173,
        "text_similarity": 0.6503258943557739,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gives substantially different timestamps for both events (anchor at 195s vs 179s; target 195\u2013198s vs 189\u2013192s) and adds visual detail not in the reference, so it does not align with the correct timing and includes possible hallucination."
      }
    },
    {
      "question_id": "003",
      "question": "Once Steve asks if the 'Shine a Light Walk' goes throughout the world, when does Sarah begin to explain that the walks do not?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 253.2,
        "end": 258.88
      },
      "pred_interval": {
        "start": 260.0,
        "end": 264.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.800000000000011,
        "end": 5.1200000000000045,
        "average": 5.960000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962022,
        "text_similarity": 0.6699646711349487,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures Sarah's content (that the walks do not go throughout the world) but misreports the key timing: the anchor/response times are off by ~7 seconds and thus fail the required immediate-response alignment."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes asking Sarah what things in miscommunication can lead to delays or misdiagnosis, when does the woman start responding?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 362.48,
        "end": 365.44
      },
      "pred_interval": {
        "start": 368.1,
        "end": 371.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.6200000000000045,
        "end": 6.160000000000025,
        "average": 5.890000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.21505376344086022,
        "text_similarity": 0.513115406036377,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures that the woman begins speaking immediately after the man (i.e., 'once_finished'), but the provided timestamps do not match the reference times (they are shifted by several seconds), so the timing details are inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman gives the example of writing 'hyperthyroid instead of hypothyroid', when does the man respond with 'That that's pretty bad'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 389.2,
        "end": 432.5
      },
      "pred_interval": {
        "start": 395.1,
        "end": 396.5
      },
      "iou": 0.03233256351039208,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.900000000000034,
        "end": 36.0,
        "average": 20.950000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.5668210983276367,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the man responds after the woman, but it misidentifies the woman's example line and substantially misplaces both timestamps (off by ~6 seconds), so the timing and anchor are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the man says he tried researching miscommunication problems, when does he state his finding about thousands of preventable deaths?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 446.56,
        "end": 535.68
      },
      "pred_interval": {
        "start": 454.6,
        "end": 462.2
      },
      "iou": 0.08527827648114868,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.04000000000002,
        "end": 73.47999999999996,
        "average": 40.75999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.19565217391304346,
        "text_similarity": 0.4373425841331482,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the quoted content but gives substantially incorrect timestamps (placing both events around 454s) that contradict the reference timings (E1: 435.0\u2013440.6s, E2: 446.56\u2013451.68s) and the stated temporal separation, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks, \"What's in my budget to fix it?\", when does she start asking, \"How important is it to me to fix this issue?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 518.66,
        "end": 522.26
      },
      "pred_interval": {
        "start": 525.1,
        "end": 527.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.440000000000055,
        "end": 5.539999999999964,
        "average": 5.990000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.2564102564102564,
        "text_similarity": 0.7054997682571411,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and their temporal ordering (target after anchor), but the absolute timestamps and the target end time differ substantially (~6\u20137s offset) from the ground truth, so the answer is only partially accurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the man finishes saying, \"not continuing medical bills,\" when does he start asking, \"So, what does successful self-advocacy look like?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 643.04,
        "end": 646.32
      },
      "pred_interval": {
        "start": 649.5,
        "end": 651.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.460000000000036,
        "end": 5.4799999999999045,
        "average": 5.96999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.768196702003479,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the relationship ('after') but the timestamps are substantially different from the reference (anchor 647.0s vs 634.36s; target 649.5\u2013651.8s vs 643.04\u2013646.32s) and it adds an unsupported 'transition sentence', so it is factually inconsistent with the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining what a doctor's follow-up might entail, when does the woman start asking, \"Or will I actually be able to get into your office in two weeks?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 679.0,
        "end": 683.92
      },
      "pred_interval": {
        "start": 686.0,
        "end": 688.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 4.8799999999999955,
        "average": 5.939999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195122,
        "text_similarity": 0.81630539894104,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the event order and the quoted question, but the timestamps are substantially misaligned with the ground truth (off by several seconds for both anchor and target), so it is largely incorrect on the key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "Immediately after the woman asks if she should follow up if she is still experiencing symptoms, when does the man ask what if the symptoms go away?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.38,
        "end": 707.15
      },
      "pred_interval": {
        "start": 705.0,
        "end": 707.0
      },
      "iou": 0.257400257400258,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.6200000000000045,
        "end": 0.14999999999997726,
        "average": 2.884999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.3655913978494623,
        "text_similarity": 0.804207444190979,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction identifies the same two events and the 'immediately after' relation, but the timestamps are notably off (anchor extended to 704s and target shifted to 705s versus correct anchor ending at 698.78s and target starting at 699.38s), causing a temporal contradiction."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying to voice symptoms and concerns clearly, when does he give an example about shoulder pain?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 734.59,
        "end": 737.0
      },
      "pred_interval": {
        "start": 740.0,
        "end": 743.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.409999999999968,
        "end": 6.0,
        "average": 5.704999999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.2417582417582418,
        "text_similarity": 0.7729577422142029,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies an example about shoulder pain and that the target follows the anchor, but it gives substantially different timestamps and a different anchor utterance than the ground truth, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes warning not to try putting a hand in an electrical outlet, when does the woman agree and say not to try that?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 810.0,
        "end": 812.0
      },
      "pred_interval": {
        "start": 815.0,
        "end": 817.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 5.0,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.7954238653182983,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures that the woman immediately agrees, but it gives incorrect timestamps (808s vs 815s and 810\u2013812s vs 815\u2013817s) and misstates the temporal relation (claims slight overlap rather than the target immediately following), so key factual timing details are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes saying to assume benevolence of your doctor, when does the man begin to speak?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.9,
        "end": 879.1
      },
      "pred_interval": {
        "start": 885.0,
        "end": 888.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.100000000000023,
        "end": 8.899999999999977,
        "average": 7.5
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.6729588508605957,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly preserves the ordering (man speaks immediately after the woman), but the timestamps are substantially off (predicted ~885s vs correct 878.0s/878.9s) and it adds extra quoted content; thus the temporal accuracy is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks about trying non-surgical options first, when does the woman reply 'Yes'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 899.7,
        "end": 900.1
      },
      "pred_interval": {
        "start": 906.0,
        "end": 908.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.2999999999999545,
        "end": 7.899999999999977,
        "average": 7.099999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.41025641025641024,
        "text_similarity": 0.6548187732696533,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misreports the event times (placing both at ~906s/00:36 rel) rather than 899.5s\u2192899.7s as given, so the temporal alignment is incorrect; it only correctly captures that the woman replies immediately after the man, but the key timing facts are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the man concludes his statement about how to ask for another opinion, when does the woman respond that asking for another opinion is definitely valid?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 982.0,
        "end": 988.72
      },
      "pred_interval": {
        "start": 989.0,
        "end": 992.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 3.2799999999999727,
        "average": 5.139999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.4819277108433735,
        "text_similarity": 0.7135803699493408,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and the woman replying after the man, but the timestamps differ substantially from the reference (\u22487\u201312 seconds off and inconsistent absolute/relative mapping), so it is not fully accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the man suggests bringing someone along if you're not feeling safe, when does the woman agree that it's advisable?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1127.0,
        "end": 1130.0
      },
      "pred_interval": {
        "start": 1132.1,
        "end": 1133.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.099999999999909,
        "end": 3.599999999999909,
        "average": 4.349999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.26506024096385544,
        "text_similarity": 0.543062150478363,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the woman's verbal agreement ('Yeah. Definitely.') but misreports the timestamps: it places the man's suggestion much earlier (1062s vs 1120s) and the woman's agreement about 5s later (1132.1s vs 1127.0s), so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman talks about a doctor not trusting a patient's pain because they don't act like they're in pain, when does she give an example of a loved one vouching for the patient?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1167.68,
        "end": 1174.48
      },
      "pred_interval": {
        "start": 1167.9,
        "end": 1187.6
      },
      "iou": 0.33032128514056114,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.22000000000002728,
        "end": 13.11999999999989,
        "average": 6.669999999999959
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.5991088151931763,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the earlier segment and the start of the loved-one example (~1167.9s), but it incorrectly extends the example's end to 1187.6s (actual end 1174.48s) and thus includes extra/hallucinated content, so it's only a partial match."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks if it is legal to be given your own medical records, when does the woman confirm that it is?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1268.6,
        "end": 1270.7
      },
      "pred_interval": {
        "start": 1274.0,
        "end": 1276.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.400000000000091,
        "end": 5.2999999999999545,
        "average": 5.350000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.25000000000000006,
        "text_similarity": 0.6477713584899902,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that the woman's confirmation follows the man's question and even quotes her reply, but the provided timestamps are significantly later than the ground truth (off by ~5\u201310 seconds), so the timing is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman mentions that things have changed a lot with electronic medical records, when does the man state that bureaucracy reminds him of common barriers?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1333.0,
        "end": 1339.5
      },
      "pred_interval": {
        "start": 1338.0,
        "end": 1343.0
      },
      "iou": 0.15,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 3.5,
        "average": 4.25
      },
      "rationale_metrics": {
        "rouge_l": 0.19801980198019803,
        "text_similarity": 0.8206151723861694,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both anchor and target events and the 'after' relationship, but it has minor timing inaccuracies (E1 start/end and E2 end differ slightly from the ground truth) and omits the exact E1 end time."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks about common barriers and how to overcome them, when does the woman share her fear of ants?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.36,
        "end": 1383.7
      },
      "pred_interval": {
        "start": 1383.0,
        "end": 1402.0
      },
      "iou": 0.02840909090909264,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.6400000000001,
        "end": 18.299999999999955,
        "average": 11.970000000000027
      },
      "rationale_metrics": {
        "rouge_l": 0.22448979591836735,
        "text_similarity": 0.823279082775116,
        "llm_judge_score": 8,
        "llm_judge_justification": "The predicted answer correctly identifies the anchor and target events and the 'after' relationship, with start times close to the reference; however it extends the target end time beyond the ground truth and shows minor timing inconsistencies, so it is not a perfect match."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says to write things down on paper and give it to the doctor, when does he mention a doctor refusing to look at the paper?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1484.96,
        "end": 1490.0
      },
      "pred_interval": {
        "start": 1488.0,
        "end": 1494.5
      },
      "iou": 0.20964360587002176,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0399999999999636,
        "end": 4.5,
        "average": 3.769999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.3119266055045872,
        "text_similarity": 0.6750108003616333,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the target utterance content and roughly overlaps the target timing, but it mislocates the anchor (predicted ~1488s vs correct 1438.1\u20131441.28) and thus gets the relative timing/order wrong and shifts the target window slightly."
      }
    },
    {
      "question_id": "002",
      "question": "While the woman discusses prioritizing cognition, when does she state that she would rather be in pain than have her mental capacity harmed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1534.64,
        "end": 1542.24
      },
      "pred_interval": {
        "start": 1539.0,
        "end": 1545.5
      },
      "iou": 0.29834254143646766,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.3599999999999,
        "end": 3.259999999999991,
        "average": 3.8099999999999454
      },
      "rationale_metrics": {
        "rouge_l": 0.411764705882353,
        "text_similarity": 0.6579952239990234,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly identifies the same quote and context and largely matches the timing, but its reported time windows are slightly shifted later than the ground truth (minor temporal misalignment)."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'Nord, what is that?', when does the woman state what NORD stands for?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.4,
        "end": 1615.4
      },
      "pred_interval": {
        "start": 1619.0,
        "end": 1621.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.599999999999909,
        "end": 6.099999999999909,
        "average": 5.849999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.3132530120481927,
        "text_similarity": 0.5966132879257202,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the woman's reply content and that it follows the man's question, but the provided timestamps are about 5\u20136 seconds later than the ground truth, so the timing is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says 'I read that I need to start this at 30', when does she explain why she needs the doctor to order it?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1692.24,
        "end": 1711.28
      },
      "pred_interval": {
        "start": 1710.0,
        "end": 1712.5
      },
      "iou": 0.06317867719644488,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.75999999999999,
        "end": 1.2200000000000273,
        "average": 9.490000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.3963963963963964,
        "text_similarity": 0.5683414936065674,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the continuation where she asks the doctor to order it and gives reasonable timestamps, but the timing is slightly off\u2014placing the explicit line around 1710\u20131712.5s while the reference indicates the explanatory segment spans earlier up to 1711.28s, so it misses part of the earlier explanation."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman explains how to mirror a planned course of action, when does she suggest asking the doctor what they heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.0,
        "end": 1799.8
      },
      "pred_interval": {
        "start": 1802.0,
        "end": 1806.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 6.2000000000000455,
        "average": 5.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.18823529411764706,
        "text_similarity": 0.8443184494972229,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the target question follows the anchor after a brief explanation, but the annotated timestamps are substantially different and contradictory (anchor extended past the true end and the target is shifted later), so key factual timing details are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the man advises to 'just dig' and not use a medical dictionary, when does he ask if medical language can be 'dumbed down'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1836.56,
        "end": 1841.52
      },
      "pred_interval": {
        "start": 1841.0,
        "end": 1846.0
      },
      "iou": 0.05508474576270962,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.440000000000055,
        "end": 4.480000000000018,
        "average": 4.460000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.698386549949646,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly identifies a later ask-about 'dumbing down' but both anchor and target timestamps are several seconds off from the reference and the predicted target includes a hallucinated quote ('two master's degrees') not in the ground truth; thus it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks what to do when doctors look rushed, when does the woman describe slowing down and capturing their attention?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1965.6,
        "end": 1973.5
      },
      "pred_interval": {
        "start": 1972.0,
        "end": 1979.0
      },
      "iou": 0.11194029850746193,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.400000000000091,
        "end": 5.5,
        "average": 5.9500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.29473684210526313,
        "text_similarity": 0.733665943145752,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the event ordering and rough content but misaligns timestamps substantially (anchor off by ~17s; target start/end off by ~6s and ~5.5s respectively), so the temporal localization is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes suggesting a doctor might be having a bad day, when does the man humorously ask if doctors have bad days?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2002.5,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 2008.0,
        "end": 2012.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.5,
        "end": 8.0,
        "average": 6.75
      },
      "rationale_metrics": {
        "rouge_l": 0.27999999999999997,
        "text_similarity": 0.7175765633583069,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the man's line directly follows the woman's suggestion, but the timestamps are substantially off (predicted ~2008\u20132012s vs reference ~2001.5\u20132004.0s) and it introduces an extra utterance not present in the ground truth, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man introduces the 'five practical tips to advocate for yourself', when does the woman begin talking about writing down questions?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2195.28,
        "end": 2199.7
      },
      "pred_interval": {
        "start": 2201.2,
        "end": 2204.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.919999999999618,
        "end": 4.800000000000182,
        "average": 5.3599999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.17283950617283952,
        "text_similarity": 0.681704044342041,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor and the 'after' temporal relation and matches the quoted content, but the predicted target timestamp (2201.2\u20132204.5s) is slightly later than the reference window (2195.28\u20132199.7s), a minor temporal inaccuracy."
      }
    },
    {
      "question_id": "002",
      "question": "During the man's explanation about preparing beforehand, when does he demonstrate by pointing to his neck?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.0,
        "end": 2237.0
      },
      "pred_interval": {
        "start": 2241.0,
        "end": 2243.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 6.0,
        "average": 6.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24999999999999994,
        "text_similarity": 0.42248913645744324,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the neck-pointing gesture occurring during his explanation, but the timestamps are off by about 6 seconds (predicted 2241\u20132243s vs reference 2235\u20132237s) and it adds dialogue detail not present in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the man describes getting dizzy when walking up and down stairs, when does the woman mention repeating back what was heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2316.0,
        "end": 2317.0
      },
      "pred_interval": {
        "start": 2321.0,
        "end": 2324.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 7.0,
        "average": 6.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.7736994028091431,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction identifies the same events and the correct relation ('after') and even quotes the woman's line, but the temporal spans are noticeably offset and durations differ from the ground-truth timestamps, so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman expresses her inability to distract herself from the pain, when does the man advise her to be specific?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.7,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2374.0,
        "end": 2376.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.300000000000182,
        "end": 6.5,
        "average": 5.900000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.7212316393852234,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer gets the qualitative relation ('after') and the content of E2 right, but the event timestamps are substantially incorrect (E1 and E2 times are shifted and durations mismatched), so it fails to match the correct temporal alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says 'document everything', when does the woman affirm the advice and tell viewers to take notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2504.5,
        "end": 2506.0
      },
      "pred_interval": {
        "start": 2510.0,
        "end": 2514.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.5,
        "end": 8.0,
        "average": 6.75
      },
      "rationale_metrics": {
        "rouge_l": 0.42857142857142855,
        "text_similarity": 0.6246544122695923,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the man's utterance roughly correct but misstates and shifts the woman's timestamps by several seconds and invents an intervening question from the man; these timing and factual errors materially contradict the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes asking if one should ask permission before recording their doctor, when does the woman respond?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2531.6,
        "end": 2533.5
      },
      "pred_interval": {
        "start": 2537.0,
        "end": 2539.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.400000000000091,
        "end": 5.5,
        "average": 5.4500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.4355078339576721,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the woman's reply content and that she responds immediately, but the timestamps are significantly off (predicted ~2537\u20132539s vs. correct 2531.6\u20132533.5s), so the timing information is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman begins explaining the hope that doctors will focus more on patients with AI recording, when does she explain why she almost always checks her online appointment notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.0,
        "end": 2579.0
      },
      "pred_interval": {
        "start": 2572.0,
        "end": 2579.0
      },
      "iou": 0.5384615384615384,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 0.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.575046181678772,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction captures the correct content and reasoning about checking online notes, but the timestamps are somewhat off: E1 is given as ~2550s instead of 2556.7s and E2 is narrowed to 2572\u20132579s while the ground truth starts at 2566.0s, thus missing part of the true interval."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks if one should be assertive, when does he introduce the topic of emotional intelligence?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2701.0,
        "end": 2710.0
      },
      "pred_interval": {
        "start": 2704.0,
        "end": 2708.0
      },
      "iou": 0.4444444444444444,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 2.0,
        "average": 2.5
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367346,
        "text_similarity": 0.5537398457527161,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the sequence and that the emotional intelligence topic follows shortly, but it mislabels the anchor event time (2701s vs. 2696\u20132697s) and shifts the target event timing (2704\u20132708s vs. 2701\u20132710s), so the absolute timestamps do not match the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man says 'You wanna learn some breathing control', when does he start describing box breathing?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.0,
        "end": 2747.0
      },
      "pred_interval": {
        "start": 2746.0,
        "end": 2752.0
      },
      "iou": 0.08333333333333333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 5.0,
        "average": 5.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2376237623762376,
        "text_similarity": 0.649385929107666,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the order and content (box-breathing description) but the timestamps are substantially shifted (E1 and E2 are later) and it incorrectly states the description occurs immediately after E1, contradicting the reference timing and end times."
      }
    },
    {
      "question_id": "002",
      "question": "While the man is saying 'If you want, share your story in the comments', when is the 'COMMENT BELOW' graphic displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2924.0,
        "end": 2927.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 4.0,
        "average": 4.0
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619044,
        "text_similarity": 0.3173227310180664,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timings contradict the reference: it places both the speech and graphic several seconds later and does not match the correct overlap (graphic 2920.0\u20132923.0 continuously during the speech), thus omitting key temporal facts."
      }
    },
    {
      "question_id": "003",
      "question": "After the thumbs up icon appears on screen, when is the next graphic ('COMMENT BELOW') displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2924.0,
        "end": 2927.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 4.0,
        "average": 4.0
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.6827040314674377,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the relative ordering and the 'COMMENT BELOW' graphic as the next overlay, but the timestamps are consistently off by about 4 seconds (2866s vs 2862s and 2924\u20132927s vs 2920\u20132923s), so it is approximate rather than precise."
      }
    },
    {
      "question_id": "001",
      "question": "After Marissa Fourie introduces herself, when does she mention cross-cultural communication?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 34.2,
        "end": 36.5
      },
      "pred_interval": {
        "start": 34.6,
        "end": 36.6
      },
      "iou": 0.7916666666666665,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.3999999999999986,
        "end": 0.10000000000000142,
        "average": 0.25
      },
      "rationale_metrics": {
        "rouge_l": 0.32432432432432434,
        "text_similarity": 0.6508291959762573,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately identifies both events, preserves the temporal relation (E2 occurs after E1), and the timestamps closely match the reference (minor millisecond differences only)."
      }
    },
    {
      "question_id": "002",
      "question": "After mentioning cross-cultural communication, when does Marissa Fourie next mention personality-specific communication skills?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 37.0,
        "end": 39.0
      },
      "pred_interval": {
        "start": 37.0,
        "end": 39.7
      },
      "iou": 0.7407407407407399,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 0.7000000000000028,
        "average": 0.3500000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.4307692307692308,
        "text_similarity": 0.6573808193206787,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies that the 'personality-specific communication skills' mention begins at 37.0s and follows the cross-cultural mention, preserving the 'next' relation; minor timing discrepancies (E1 end given as 36.6s and E2 end 39.7s vs reference 39.0s) are small and do not change the core answer."
      }
    },
    {
      "question_id": "003",
      "question": "After encouraging viewers to join PhysioPlus, when does Marissa Fourie say 'See you there!'?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 62.9,
        "end": 63.7
      },
      "pred_interval": {
        "start": 102.6,
        "end": 103.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.699999999999996,
        "end": 40.0,
        "average": 39.849999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.37333333333333335,
        "text_similarity": 0.6289929747581482,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the invitation around 49s (matching E1) but gives a substantially incorrect time for 'See you there' (\u2248102.6\u2013103.7s vs. the reference 62.9\u201363.7s), so the key temporal information is wrong despite preserving the after relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes mentioning \"the dosage in each area\", when does the woman in blue gloves point to the glabella area of the patient's forehead?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 4.469,
        "end": 4.8
      },
      "pred_interval": {
        "start": 3.5,
        "end": 8.0
      },
      "iou": 0.07355555555555544,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.9690000000000003,
        "end": 3.2,
        "average": 2.0845000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.24390243902439024,
        "text_similarity": 0.6335679292678833,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same gesture but the timings and temporal relation are substantially wrong: E1 is placed at 3.5s (true 4.161s), E2 is incorrectly said to start simultaneously at 3.5s instead of at 4.469s and is overstated to 8.0s (true until 4.800s), reversing the correct 'after' relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the dosage for the brow lift, when does the woman in blue gloves point to the patient's upper lip?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 12.121,
        "end": 12.5
      },
      "pred_interval": {
        "start": 12.0,
        "end": 14.5
      },
      "iou": 0.15159999999999982,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.12100000000000044,
        "end": 2.0,
        "average": 1.0605000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2696629213483146,
        "text_similarity": 0.7105171084403992,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (E2 follows E1) and approximates the start times, but it misreports the end time of the pointer by ~2s and adds unsupported detail about finger movement (hallucination), so it is substantially inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the dosage for the lip flip, when does the text \"TIME TO INJECT!\" appear on screen?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 18.291,
        "end": 21.0
      },
      "pred_interval": {
        "start": 18.5,
        "end": 21.0
      },
      "iou": 0.9228497600590625,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.20899999999999963,
        "end": 0.0,
        "average": 0.10449999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.34567901234567905,
        "text_similarity": 0.6127559542655945,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both events and the 'once_finished' relation and the text's appearance lasting until the end; timestamps are very close to the reference (E1 ~0.67s early, E2 ~0.21s late). Minor timing discrepancies and an extraneous note about DAO/chin reduce precision but do not change the answer's substance."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host welcomes Rich, when does Rich begin his response?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 33.015,
        "end": 34.078
      },
      "pred_interval": {
        "start": 33.0,
        "end": 35.0
      },
      "iou": 0.5315000000000012,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.015000000000000568,
        "end": 0.921999999999997,
        "average": 0.4684999999999988
      },
      "rationale_metrics": {
        "rouge_l": 0.24615384615384617,
        "text_similarity": 0.8405055403709412,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction matches the reference closely\u2014both place the host utterance ~31.3s and Rich's reply immediately after ~33s\u2014so meaning is preserved; minor timing approximations (31.0s vs 31.333s, 33.0s vs 33.015s) and an extra end time (35.0s) warrant a small deduction."
      }
    },
    {
      "question_id": "002",
      "question": "While Rich is explaining how medicine may have let relationships with patients deteriorate, when does he say that scientific facts will protect us?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 89.0,
        "end": 93.76
      },
      "pred_interval": {
        "start": 129.0,
        "end": 134.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.0,
        "end": 40.239999999999995,
        "average": 40.12
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.4538857340812683,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are substantially incorrect\u2014the correct explanation begins at ~73.6s with the target phrase at 89.0\u201393.76s, whereas the prediction places them at ~115.0s and 129.0\u2013134.0s respectively, outside the true intervals. While the phrase content is identified, the timing is wrong, so the answer is nearly entirely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks what trust looks like in the future with intermediaries, when does Rich first discuss the stethoscope in relation to technology in medicine?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 112.0,
        "end": 113.0
      },
      "pred_interval": {
        "start": 152.0,
        "end": 200.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.0,
        "end": 87.0,
        "average": 63.5
      },
      "rationale_metrics": {
        "rouge_l": 0.32432432432432434,
        "text_similarity": 0.8202908635139465,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the sequence (stethoscope discussion occurs after the host's question) but gives substantially incorrect timestamps (~40\u201345s later) and adds an unfounded end time/host interjection, so the factual timing details are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the man in glasses finishes describing the giant TV screen in a new hospital exam room, when does the video show a patient interacting with a screen in a hospital bed?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 167.6,
        "end": 177.6
      },
      "pred_interval": {
        "start": 168.0,
        "end": 178.0
      },
      "iou": 0.923076923076922,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.4000000000000057,
        "end": 0.4000000000000057,
        "average": 0.4000000000000057
      },
      "rationale_metrics": {
        "rouge_l": 0.32989690721649484,
        "text_similarity": 0.8301138877868652,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the target clip, its ordering relative to the anchor, and has nearly matching start/end times, but it omits the exact anchor timestamp (152.8s) and has small timing offsets (~0.4s)."
      }
    },
    {
      "question_id": "002",
      "question": "While the interviewer asks if technology can bring doctors and patients closer together, when is he holding a small white 'Trust tv' card?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 178.0,
        "end": 183.5
      },
      "pred_interval": {
        "start": 179.0,
        "end": 185.0
      },
      "iou": 0.6428571428571429,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 1.5,
        "average": 1.25
      },
      "rationale_metrics": {
        "rouge_l": 0.18390804597701152,
        "text_similarity": 0.3907052278518677,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that the interviewer is holding the 'Trust tv' card during his question, but the timing is inaccurate (prediction states 179.0\u2013185.0s vs. the ground truth 178.0\u2013183.5s) and adds an unverified detail (left hand) while extending the shot beyond the anchor segment."
      }
    },
    {
      "question_id": "003",
      "question": "Once the interviewer thanks Rich and says viewers learned a lot, when does Rich respond 'It's really a pleasure'?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 210.3,
        "end": 212.1
      },
      "pred_interval": {
        "start": 211.0,
        "end": 212.0
      },
      "iou": 0.5555555555555608,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.6999999999999886,
        "end": 0.09999999999999432,
        "average": 0.3999999999999915
      },
      "rationale_metrics": {
        "rouge_l": 0.4772727272727273,
        "text_similarity": 0.8504321575164795,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies when Rich says 'It's really a pleasure' (211.0s vs 210.3s in the reference) and that it immediately follows the interviewer, but it misstates the anchor end time (210.8s vs 200.0s) and adds an unverified extra line ('Thanks for having me'), so it is mostly correct but includes errors and a hallucination."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions learning about 'patient rapport', when does he discuss charting and interacting with other healthcare providers?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 2.075,
        "end": 9.55
      },
      "pred_interval": {
        "start": 2.0,
        "end": 10.0
      },
      "iou": 0.9343750000000001,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.07500000000000018,
        "end": 0.4499999999999993,
        "average": 0.26249999999999973
      },
      "rationale_metrics": {
        "rouge_l": 0.2682926829268293,
        "text_similarity": 0.6930834054946899,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer matches the reference semantically and temporally: E1 and E2 time spans and content align (E2 immediately follows E1 and covers charting and healthcare providers), with only negligible timestamp rounding differences."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker talks about developing skills like putting an IV, when does he mention getting a patient discharged?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 15.42,
        "end": 24.583
      },
      "pred_interval": {
        "start": 15.0,
        "end": 19.0
      },
      "iou": 0.3735782114160493,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.41999999999999993,
        "end": 5.582999999999998,
        "average": 3.001499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2708333333333333,
        "text_similarity": 0.7965312600135803,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the anchor and the immediate follow-up target and matches the start times closely, but it underestimates the target's end time (ends ~5.6s early) and introduces an extra detail about medications not present in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Make their problem, your problem', when does he introduce the importance of self-care?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 45.009,
        "end": 48.396
      },
      "pred_interval": {
        "start": 45.0,
        "end": 48.0
      },
      "iou": 0.8807420494699644,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.009000000000000341,
        "end": 0.3960000000000008,
        "average": 0.20250000000000057
      },
      "rationale_metrics": {
        "rouge_l": 0.4943820224719101,
        "text_similarity": 0.7684515714645386,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both segments and that the self-care remark follows the prior point; E2 timing matches closely, but E1's end is understated (predicted ~00:41 vs reference 44.808s)."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker's introduction of herself, when does she mention specializing in wounds?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.605,
        "end": 26.329
      },
      "pred_interval": {
        "start": 25.0,
        "end": 26.8
      },
      "iou": 0.31680572109654365,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.3949999999999996,
        "end": 0.4710000000000001,
        "average": 1.4329999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2941176470588235,
        "text_similarity": 0.5197752714157104,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the self-introduction timing (~0:18) and the specialist remark around 0:25\u20130:26, matching the reference's window, but it slightly misstates the start time (omits the earlier 0:22.6 onset) and adds an extra role label ('tissue viability nurse') not present in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of 'getting the most out of your GP consultation', when does she mention that GP practices are getting a huge injection of funding?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.82,
        "end": 75.533
      },
      "pred_interval": {
        "start": 109.0,
        "end": 112.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.18000000000001,
        "end": 36.967,
        "average": 39.0735
      },
      "rationale_metrics": {
        "rouge_l": 0.2531645569620253,
        "text_similarity": 0.6873227953910828,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately identifies the introduction timing (around 1:01) and gives a funding interval (1:09\u20131:12.5) that falls within the reference range (67.82\u201375.53s), correctly noting it occurs after the introduction."
      }
    },
    {
      "question_id": "003",
      "question": "While the slide titled 'Appointments are precious' is on screen, when does the speaker mention that GP practices are moving back towards face-to-face appointments?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 123.0,
        "end": 129.0
      },
      "pred_interval": {
        "start": 204.5,
        "end": 209.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.5,
        "end": 80.0,
        "average": 80.75
      },
      "rationale_metrics": {
        "rouge_l": 0.425,
        "text_similarity": 0.8669825196266174,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction matches the reference: slide timing is effectively the same (1:40 \u2248 100.74s) and the speaker interval (2:04.5\u20132:09) falls within the correct 123.0\u2013129.0s range, with no added or missing facts."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that GP practices are very different places now, when does she begin listing the specific roles in a GP practice?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.0,
        "end": 204.0
      },
      "pred_interval": {
        "start": 178.0,
        "end": 186.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.0,
        "end": 18.0,
        "average": 21.5
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.6331995725631714,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the relative order and that the speaker lists GP roles, but it misplaces both event timestamps by ~25s and gives a different start phrasing, so it is factually inaccurate on the key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide displays the question 'Does it need to be a GP?', when does the speaker mention that paramedics work in primary care?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "pred_interval": {
        "start": 187.0,
        "end": 194.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.0,
        "end": 46.0,
        "average": 47.0
      },
      "rationale_metrics": {
        "rouge_l": 0.5194805194805195,
        "text_similarity": 0.7288122177124023,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the quoted remark but gives substantially incorrect timestamps for both the slide change and the speaker utterance (off by ~26s and ~48s), so it fails to match the ground-truth timing despite preserving the relative ordering."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker talks about paramedics working in primary care, when does she begin to explain the role of Advanced Clinical Practitioners?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 241.0,
        "end": 249.0
      },
      "pred_interval": {
        "start": 216.0,
        "end": 224.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.0,
        "end": 25.0,
        "average": 25.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2769230769230769,
        "text_similarity": 0.6861168146133423,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct segment type but gives timing that substantially contradicts the ground truth (216\u2013224s vs. 241.0s start), and it adds an unverified detail about ACPs; thus it fails to match the reference timings."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the problem of a wound on your foot, when does she strongly advise mentioning if you are diabetic?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 337.875,
        "end": 343.0
      },
      "pred_interval": {
        "start": 342.0,
        "end": 355.0
      },
      "iou": 0.058394160583941604,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.125,
        "end": 12.0,
        "average": 8.0625
      },
      "rationale_metrics": {
        "rouge_l": 0.2588235294117647,
        "text_similarity": 0.6146867275238037,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the advice immediately follows the problem introduction and the quoted phrasing, but the anchor and target timestamps are several seconds off from the reference and the predicted target end is unjustifiably extended, introducing inaccurate timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having a new wound on your leg, when does she suggest going to a local pharmacist for simple dressings?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 363.968,
        "end": 366.552
      },
      "pred_interval": {
        "start": 400.0,
        "end": 418.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.03199999999998,
        "end": 51.44799999999998,
        "average": 43.73999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2828282828282829,
        "text_similarity": 0.7694641351699829,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the content (pharmacist for simple dressings) and the 'after' relation, but the provided time stamps do not match the reference (E1 slightly offset and E2 is substantially different), so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker explains that a nurse's appointment is needed for long-standing wounds, when does she advise to clearly state how long the wound has been there?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 409.579,
        "end": 439.62
      },
      "pred_interval": {
        "start": 446.0,
        "end": 450.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.42099999999999,
        "end": 10.379999999999995,
        "average": 23.400499999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.23913043478260868,
        "text_similarity": 0.7919754981994629,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures that the advice immediately follows the nurse-appointment remark and reproduces the advice wording, but the provided timestamps differ substantially from the reference (E1/E2 start/end times are mismatched), so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if you feel more short of breath, when does she state that a GP or nurse practitioner might be needed the same day?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 522.783,
        "end": 525.113
      },
      "pred_interval": {
        "start": 525.1,
        "end": 530.6
      },
      "iou": 0.001663042087761755,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.3170000000000073,
        "end": 5.486999999999966,
        "average": 3.901999999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.19148936170212766,
        "text_similarity": 0.6081588268280029,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction partially matches\u2014both identify the anchor question and that the target comes after\u2014but the timestamps are notably off (E1 ~4s late; E2 start and especially end shifted later and extended to 530.6s vs reference 522.783\u2013525.113s) and the predicted utterance/timing do not align with the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to measure your ankle and calf, when does she give an example of a calf measurement that would 'perk up more interest'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.623,
        "end": 586.297
      },
      "pred_interval": {
        "start": 619.8,
        "end": 624.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.17699999999991,
        "end": 38.00299999999993,
        "average": 37.08999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.21686746987951805,
        "text_similarity": 0.6985986828804016,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction roughly matches the anchor timing but majorly mislocates the target (predicts 619.8\u2013624.3s vs correct 583.623\u2013586.297s), so the timing is inaccurate despite correctly stating the target occurs after the anchor."
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Photography', when does the speaker advise to 'expect to be asked for a photo'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 670.384,
        "end": 672.807
      },
      "pred_interval": {
        "start": 655.8,
        "end": 659.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.58400000000006,
        "end": 13.007000000000062,
        "average": 13.795500000000061
      },
      "rationale_metrics": {
        "rouge_l": 0.3294117647058824,
        "text_similarity": 0.8518354892730713,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the verbal content and the 'once the slide changes' relationship, but the timestamps are substantially wrong (E1 ~16s early; E2 start/end ~14s early) and thus do not match the reference intervals."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions some GP practices use video consultations, when does she state that a good quality photograph is better than a video?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.278,
        "end": 717.251
      },
      "pred_interval": {
        "start": 716.0,
        "end": 721.5
      },
      "iou": 0.17322071448351978,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.72199999999998,
        "end": 4.249000000000024,
        "average": 2.985500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.5173228979110718,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the first mention (around 710s) and the relation (photo stated after), but the timestamp for when the photograph is said to be better is inaccurately later (716\u2013721.5s) and does not match the correct 714.278s."
      }
    },
    {
      "question_id": "002",
      "question": "Once the slide changes to 'Photography tips', when does the speaker begin discussing taking a close-up and further-away picture?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 738.601,
        "end": 740.91
      },
      "pred_interval": {
        "start": 742.0,
        "end": 747.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.399000000000001,
        "end": 6.090000000000032,
        "average": 4.744500000000016
      },
      "rationale_metrics": {
        "rouge_l": 0.19672131147540986,
        "text_similarity": 0.41996127367019653,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the slide change occurring around 736\u2013737s and that the speaker speaks shortly after, but it inaccurately places the speaker's start at 742.0s (ground truth 738.601s) and invents an end time (747.0s), so the key timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide changes to 'General top tips- face to face appointments', when does the speaker advise to 'Go suitably dressed'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 860.136,
        "end": 860.846
      },
      "pred_interval": {
        "start": 864.0,
        "end": 870.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.8640000000000327,
        "end": 9.153999999999996,
        "average": 6.5090000000000146
      },
      "rationale_metrics": {
        "rouge_l": 0.2647058823529412,
        "text_similarity": 0.44816580414772034,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies that the slide change precedes the advice and gives timings very close to the reference (within ~3\u20134s); the only issues are minor timestamp discrepancies and an added end-time (870.0s) not specified in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises not to wear tight socks, trousers, or wellies, when does she suggest wearing something with quick access to lower limbs?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.0,
        "end": 877.5
      },
      "pred_interval": {
        "start": 877.0,
        "end": 883.0
      },
      "iou": 0.05,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 5.5,
        "average": 4.75
      },
      "rationale_metrics": {
        "rouge_l": 0.29268292682926833,
        "text_similarity": 0.6453975439071655,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction captures the correct relation and content (the suggestion follows the warning), but the timestamps are notably different from the ground truth\u2014E2 is reported as starting and ending several seconds later and E1's span differs\u2014so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes advising not to make chit-chat about the weather, when does she advise not to dodge the real problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 893.0,
        "end": 894.5
      },
      "pred_interval": {
        "start": 897.0,
        "end": 899.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 4.5,
        "average": 4.25
      },
      "rationale_metrics": {
        "rouge_l": 0.29729729729729726,
        "text_similarity": 0.7215455770492554,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events and that E2 follows E1, but the timestamps are significantly incorrect and the temporal relation ('immediately after') mischaracterizes the actual timing, so key factual details are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker advises to take a list of the medications you are actually taking, when does she advise against describing tablets by their appearance?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 948.0,
        "end": 969.0
      },
      "pred_interval": {
        "start": 952.0,
        "end": 955.0
      },
      "iou": 0.14285714285714285,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 14.0,
        "average": 9.0
      },
      "rationale_metrics": {
        "rouge_l": 0.32911392405063294,
        "text_similarity": 0.7537405490875244,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both events and their order (E2 after E1) and captures the core advice, but the timestamps are shifted later and E2's duration is significantly shorter than the ground truth, so the timing accuracy is imperfect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker advises speaking to the practice in advance about a relative, when does she explain the reason for this advance arrangement due to confidentiality?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1065.0,
        "end": 1095.0
      },
      "pred_interval": {
        "start": 1071.0,
        "end": 1090.0
      },
      "iou": 0.6333333333333333,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 5.0,
        "average": 5.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.37416213750839233,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the confidentiality explanation follows the advice and matches its content, but it misplaces both event timestamps (E1 shifted later and E2 starting and ending several seconds off), so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker suggests writing things down before an appointment to help structure what you say, when does she first ask 'How did it start?' regarding the leg problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1130.415,
        "end": 1131.738
      },
      "pred_interval": {
        "start": 1134.0,
        "end": 1136.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5850000000000364,
        "end": 4.261999999999944,
        "average": 3.92349999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2790697674418605,
        "text_similarity": 0.45258140563964844,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction markedly disagrees with the reference: the anchor event timing (1109\u20131113s) contradicts the correct end at 1130.0s, and the predicted question time (1134.0s) and narrative (return at 1127s) do not match the reference start at 1130.415s nor the 'once_finished' relation; only a loose proximity in time is present."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes advising to ask to be referred to a specialist service, when does she start introducing the referrals examples?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.105,
        "end": 1249.385
      },
      "pred_interval": {
        "start": 1251.4,
        "end": 1257.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.2950000000000728,
        "end": 8.115000000000009,
        "average": 5.705000000000041
      },
      "rationale_metrics": {
        "rouge_l": 0.13636363636363635,
        "text_similarity": 0.5073034763336182,
        "llm_judge_score": 3,
        "llm_judge_justification": "While the predicted answer correctly identifies the relation as 'after' and captures the E2 phrasing, it significantly misplaces both event timestamps (E1 predicted ~1248\u20131250.5s vs correct 1236.741s; E2 predicted 1251.4\u20131257.5s vs correct 1248.105\u20131249.385s), thus failing to match the key temporal facts."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that lymphoedema services can be patchy, when does she first advise writing to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.0,
        "end": 1378.0
      },
      "pred_interval": {
        "start": 1381.5,
        "end": 1383.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.5,
        "end": 5.5,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3291139240506329,
        "text_similarity": 0.7275108098983765,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the same events and the 'after' relation, but the timestamps are several seconds later and it appears to mark a later repetition of the MP-advice rather than the first instance, so it omits the key detail of the exact first occurrence."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions that a GP will assess new leg swelling for onward referral, when does she explain there are many different causes?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1429.846,
        "end": 1432.0
      },
      "pred_interval": {
        "start": 1420.8,
        "end": 1424.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.04600000000005,
        "end": 7.5,
        "average": 8.273000000000025
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.7470871210098267,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies both events and the 'after' relation and paraphrases the explanation, but the timestamps\u2014especially for E2\u2014are notably earlier than the reference, reducing temporal accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what information you could take with you, when does she suggest looking up the National Wound Care Strategy Lower Limb Recommendations?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1465.0,
        "end": 1469.5
      },
      "pred_interval": {
        "start": 1469.0,
        "end": 1473.0
      },
      "iou": 0.0625,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 3.5,
        "average": 3.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3218390804597701,
        "text_similarity": 0.7413026094436646,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both events, their content, and the 'after' relation, but the provided timestamps are a few seconds later than the ground truth (E1 ~2.8s late; E2 start ~4s late, end ~3.5s late)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions escalating concerns to the practice manager, when does she mention escalating concerns to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.6,
        "end": 1525.7
      },
      "pred_interval": {
        "start": 1528.0,
        "end": 1530.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.400000000000091,
        "end": 4.2999999999999545,
        "average": 4.350000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.32499999999999996,
        "text_similarity": 0.6945858597755432,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies both events and their ordering, but the provided timestamps differ from the reference by several seconds and the relation label ('after' vs 'next') is a looser match than the ground truth, so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'I'll stop sharing', when does she start reading the first question from a viewer?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1574.5,
        "end": 1578.5
      },
      "pred_interval": {
        "start": 1583.0,
        "end": 1598.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.5,
        "end": 19.5,
        "average": 14.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3655913978494624,
        "text_similarity": 0.7410968542098999,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction reasonably locates E1 (1570s is within the correct span) but E2 timing is substantially later than the ground truth and the relation is downgraded from 'once_finished' to generic 'after'; it also omits the brief immediate reading, so the overall match is weak."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially suggests the mum needs compression hosiery, when does she mention asking for an appointment with the nurse for stronger compression?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1654.942,
        "end": 1664.2
      },
      "pred_interval": {
        "start": 1662.2,
        "end": 1668.0
      },
      "iou": 0.1531628120692297,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.258000000000038,
        "end": 3.7999999999999545,
        "average": 5.528999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.375,
        "text_similarity": 0.8794130086898804,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor, target, and the 'after' relation and preserves the content, with only minor temporal offsets (a few seconds) in the start/end times compared to the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'That is such a good question', when does she state that self-diagnosis via the internet is never a good idea?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1757.815,
        "end": 1762.821
      },
      "pred_interval": {
        "start": 1761.5,
        "end": 1766.5
      },
      "iou": 0.15210132412204042,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.6849999999999454,
        "end": 3.6790000000000873,
        "average": 3.6820000000000164
      },
      "rationale_metrics": {
        "rouge_l": 0.5348837209302325,
        "text_similarity": 0.881263256072998,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase, the target statement, and the 'after' relation, but the timestamps are off by about 3\u20134 seconds and it includes an inconsistent video-time label, so it is not perfectly aligned with the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes that approaching a GP is about framing the conversation, when does she tell the viewer not to worry about being labeled a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1795.335,
        "end": 1798.383
      },
      "pred_interval": {
        "start": 1798.5,
        "end": 1800.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.1649999999999636,
        "end": 1.6169999999999618,
        "average": 2.3909999999999627
      },
      "rationale_metrics": {
        "rouge_l": 0.21568627450980393,
        "text_similarity": 0.7639501690864563,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the content and the 'after' relation and captures the 'No, no...' response, but the timestamps are notably off (anchor ~12s early) and the target timing is shifted/extended past 1800s contrary to the ground truth, so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker first says, 'Please don't worry about things like that', when does she next advise not to worry about being labelled as a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1827.66,
        "end": 1831.19
      },
      "pred_interval": {
        "start": 1831.44,
        "end": 1834.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.7799999999999727,
        "end": 3.4099999999998545,
        "average": 3.5949999999999136
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962025,
        "text_similarity": 0.6917032599449158,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction roughly locates the first utterance but gives an imprecise anchor time and incorrectly identifies the next instance: the correct E2 is 1827.66\u20131831.19s whereas the prediction states 1831.44\u20131834.6s, which does not match the reference interval."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks, 'What can I do to maintain healthy legs or feet so I don't get any problems?', when does she start listing actions like 'walk' and 'legs up'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1865.412,
        "end": 1883.383
      },
      "pred_interval": {
        "start": 1883.28,
        "end": 1886.88
      },
      "iou": 0.004797838643565545,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.867999999999938,
        "end": 3.497000000000071,
        "average": 10.682500000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.37647058823529417,
        "text_similarity": 0.7677988409996033,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted anchor time (1851s) matches the reference anchor, and the quoted actions are correct, but the predicted target start (1883.28s) is about 18s later than the correct target window (1865.412s\u20131883.383s), so the timing for when she begins listing the actions is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks how much is in the GP curriculum, when does she say 'I don't know'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1983.7,
        "end": 1984.201
      },
      "pred_interval": {
        "start": 1987.2,
        "end": 1988.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 3.8989999999998872,
        "average": 3.6994999999999436
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.6981489062309265,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target utterances and that the target immediately follows the anchor, but the provided timestamps are significantly shifted (~3.7\u20134s later) from the reference, so the timing information is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'I think it is something that Legs Matter can help with', when does she discuss Legs Matter influencing GP curriculums?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2004.063,
        "end": 2009.063
      },
      "pred_interval": {
        "start": 2007.4,
        "end": 2012.8
      },
      "iou": 0.190339933615662,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.336999999999989,
        "end": 3.7369999999998527,
        "average": 3.536999999999921
      },
      "rationale_metrics": {
        "rouge_l": 0.16438356164383558,
        "text_similarity": 0.6301378011703491,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the target occurs afterward and discusses GP curricula, but the time stamps are notably shifted (anchor ~0.6s late; target starts ~3.3s late and ends ~3.7s late) with only partial overlap, and it adds an extra interlude detail not in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks if seeing a nurse practitioner is appropriate, when does she state that nurse practitioners are 'extremely experienced clinicians'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2062.584,
        "end": 2066.851
      },
      "pred_interval": {
        "start": 2026.4,
        "end": 2030.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.18399999999974,
        "end": 36.85100000000011,
        "average": 36.51749999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.16901408450704225,
        "text_similarity": 0.5479481816291809,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the utterance content and its position as the immediate explanation, but the provided timestamps are substantially wrong (predicted ~2026\u20132030s vs correct ~2062.6\u20132066.9s) and the anchor time is also incorrect, so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I understand the issue of smartphones and taking pictures too\", when does she first ask \"is there somebody who can help you?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2174.0,
        "end": 2176.0
      },
      "pred_interval": {
        "start": 2177.5,
        "end": 2179.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 3.199999999999818,
        "average": 3.349999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.643244206905365,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events, the phrasing of the target question, and the 'after' relationship; the anchor time is within the reference window but the predicted target timestamps are a few seconds later than the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "During the period when the speaker discusses the importance of planning phone calls to the GP, when does she ask, \"What am I feeling?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2197.721,
        "end": 2198.663
      },
      "pred_interval": {
        "start": 2201.0,
        "end": 2202.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.2789999999999964,
        "end": 3.536999999999807,
        "average": 3.4079999999999018
      },
      "rationale_metrics": {
        "rouge_l": 0.06060606060606061,
        "text_similarity": 0.19765633344650269,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly places the question within the GP phone-call planning context (inside the anchor), but the reported timestamps are inaccurate: the reference has E2 at 2197.721\u20132198.663s, whereas the prediction gives 2201.0\u20132202.2s (several seconds later), so the timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once Dr. Angelos finishes introducing Dr. Tolchin, when does Dr. Tolchin begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.128,
        "end": 109.393
      },
      "pred_interval": {
        "start": 105.4,
        "end": 110.0
      },
      "iou": 0.8195812807881764,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.27200000000000557,
        "end": 0.6069999999999993,
        "average": 0.43950000000000244
      },
      "rationale_metrics": {
        "rouge_l": 0.3225806451612903,
        "text_similarity": 0.5497883558273315,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly indicates Tolchin begins shortly after Angelos and gives very close timestamps (101s vs 100.128s; 105.4s vs 105.128s). It slightly rounds Angelos's end time and omits Tolchin's end time, so not a perfect but a highly accurate match."
      }
    },
    {
      "question_id": "002",
      "question": "After Dr. Angelos describes Dr. Tolchin's research on crisis standards of care, when does he describe his research on functional neurological disorders and epilepsy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.426,
        "end": 116.456
      },
      "pred_interval": {
        "start": 55.3,
        "end": 76.5
      },
      "iou": 0.32824252730721426,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.1260000000000048,
        "end": 39.956,
        "average": 20.541000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.2531645569620253,
        "text_similarity": 0.39611849188804626,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the next topic (functional neurological disorders and epilepsy) and roughly the start time, but the end time is significantly underestimated (76.5s vs correct 116.456s), omitting a large portion of the described segment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating the second learning objective, when does he start explaining the third learning objective?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 181.0
      },
      "pred_interval": {
        "start": 157.9,
        "end": 178.8
      },
      "iou": 0.5108225108225114,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.099999999999994,
        "end": 2.1999999999999886,
        "average": 5.6499999999999915
      },
      "rationale_metrics": {
        "rouge_l": 0.17500000000000002,
        "text_similarity": 0.4965084493160248,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (E2 follows E1) but the reported timestamps and span (157.9s\u2013178.8s) greatly disagree with the ground-truth times (E1 16.4s; E2 17.0\u201331.0s), so the answer is largely incorrect on the key timing details."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'Why conduct clinical ethics consultations?' is displayed, when does the speaker discuss moral distress among clinicians and staff?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.4,
        "end": 304.0
      },
      "pred_interval": {
        "start": 215.5,
        "end": 237.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 69.89999999999998,
        "end": 66.19999999999999,
        "average": 68.04999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2558139534883721,
        "text_similarity": 0.6912204027175903,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the discussion occurs during the slide, but it gives substantially incorrect start/end times (215.5\u2013237.8s vs. the correct 285.4\u2013304.0s) and incorrectly claims the comment ends just before the slide change, so the temporal alignment is largely wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that clinical ethics consultations were helpful, when does he state that they were more likely to achieve consensus in clinical decisions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 350.2,
        "end": 357.0
      },
      "pred_interval": {
        "start": 353.0,
        "end": 361.0
      },
      "iou": 0.37037037037036996,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.8000000000000114,
        "end": 4.0,
        "average": 3.4000000000000057
      },
      "rationale_metrics": {
        "rouge_l": 0.271604938271605,
        "text_similarity": 0.4557919502258301,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the same statement and the 'after' relationship, but the timestamps are offset (predicted E1 ~334s vs correct end 337.0s; predicted E2 353.0\u2013361.0s vs correct 350.2\u2013357.0s), so content matches but timing is imprecise."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of resource utilization, when does he specifically state that there was a reduced length of stay?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 438.9,
        "end": 450.3
      },
      "pred_interval": {
        "start": 407.0,
        "end": 413.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.899999999999977,
        "end": 37.30000000000001,
        "average": 34.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2962962962962963,
        "text_similarity": 0.6797165870666504,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor at 369s and that the target occurs after it, but the target timestamps are substantially incorrect (predicted 407.0\u2013413.0s vs correct 438.9\u2013450.3s), so key factual timing is wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'to look at disparities', when does he begin to introduce Ellen Fox's team and their survey?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 493.5,
        "end": 499.0
      },
      "pred_interval": {
        "start": 458.0,
        "end": 465.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.5,
        "end": 34.0,
        "average": 34.75
      },
      "rationale_metrics": {
        "rouge_l": 0.33766233766233766,
        "text_similarity": 0.535443127155304,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the immediate transition and mentions Ellen Fox's team, but the timestamps are substantially incorrect and contradict the ground truth (predicted 458.0\u2013465.0s vs correct 393.0s and 493.5\u2013499.0s), so key factual elements are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'hospitals with less than 400 beds', when does he mention 'little or no growth over that two decade period'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 527.809,
        "end": 530.91
      },
      "pred_interval": {
        "start": 530.5,
        "end": 534.2
      },
      "iou": 0.06415271475511865,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.691000000000031,
        "end": 3.2900000000000773,
        "average": 2.990500000000054
      },
      "rationale_metrics": {
        "rouge_l": 0.4367816091954023,
        "text_similarity": 0.8800283670425415,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misplaces both the anchor and target by several seconds (anchor ends at ~530.5s vs 526.7s correct; target starts at 530.5s vs 527.809s correct and ends later), so although it notes immediate succession, the timestamps are substantially incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide titled 'Prior Healthcare System Ethics Committees' is fully displayed, when do the images of the six hospitals with their bed counts appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.7,
        "end": 552.0
      },
      "pred_interval": {
        "start": 553.0,
        "end": 607.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2999999999999545,
        "end": 55.0,
        "average": 28.149999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.30434782608695654,
        "text_similarity": 0.7665532827377319,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor (~536s) and that the target images appear after it; the E2 timing is slightly off (predicts 553.0s vs. 551.7\u2013552.0s) and includes an extra end-time not stated in the reference, but there is no contradiction."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the number of ethics consults at Yale New Haven Hospital increased from 50 to 239, when does he describe this as 'approximately a five-fold increase in consult volume'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.7,
        "end": 624.7
      },
      "pred_interval": {
        "start": 626.2,
        "end": 629.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 5.099999999999909,
        "average": 4.2999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.8318063020706177,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same anchor and target phrases and their immediate succession, but the timestamps are substantially shifted and do not match the ground truth intervals, so it is largely temporally incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially mentions the 'Community Bioethics Forum', when does he start describing its community members?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 887.216,
        "end": 905.918
      },
      "pred_interval": {
        "start": 890.3,
        "end": 911.5
      },
      "iou": 0.6431395157305245,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0839999999999463,
        "end": 5.581999999999994,
        "average": 4.33299999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.29545454545454547,
        "text_similarity": 0.8564481139183044,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the qualitative relation ('after') right but the timestamping is significantly off: the anchor is misplaced (should be 882.78\u2013885.11, predicted 888.0) and the target's start/end are shifted later than the ground truth (887.22\u2013905.92 vs 890.3\u2013911.5), and it adds quoted phrasing not supported by the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that the primary focus of the Center for Clinical Ethics has been ethics education, when does he start listing 'Systemwide Ethics Forum and Newsletter'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1055.54,
        "end": 1069.28
      },
      "pred_interval": {
        "start": 1042.3,
        "end": 1045.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.240000000000009,
        "end": 24.180000000000064,
        "average": 18.710000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.27956989247311825,
        "text_similarity": 0.8794898986816406,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted E1 aligns with the reference and the relation 'after' is preserved, but the predicted E2 timing (1042.3\u20131045.1s) is substantially different from the ground truth (1055.54\u20131069.28s) and introduces unsupported phrasing, so the target annotation is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker lists 'ICU Walk Rounds', when does he mention 'HEC-C Certification'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1048.0,
        "end": 1052.0
      },
      "pred_interval": {
        "start": 1056.4,
        "end": 1057.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.400000000000091,
        "end": 5.900000000000091,
        "average": 7.150000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.29629629629629634,
        "text_similarity": 0.8715449571609497,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction identifies the mention of 'HEC-C Certification' but gives incorrect anchor and target time offsets and a different relation; the anchor phrase, both time spans, and the relation do not match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"ethics consultation services,\" when does he start talking about collecting feedback?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.8,
        "end": 1249.8
      },
      "pred_interval": {
        "start": 1240.5,
        "end": 1252.5
      },
      "iou": 0.75,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.2999999999999545,
        "end": 2.7000000000000455,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.6713404655456543,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the transition to collecting feedback and preserves the temporal relation, but the reported times differ slightly from the reference (E1 off by ~1.3s, E2 off by ~0.3s) and includes an extra end timestamp not present in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that participant satisfaction is not the \"be-all and end-all,\" when does he say they have begun the survey process with clinicians?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.3,
        "end": 1282.8
      },
      "pred_interval": {
        "start": 1279.0,
        "end": 1284.0
      },
      "iou": 0.6666666666666534,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7000000000000455,
        "end": 1.2000000000000455,
        "average": 0.9500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.29629629629629634,
        "text_similarity": 0.5934826731681824,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the E2 sentence and its timing (about 1279s) and preserves the temporal relation, but it mislabels the E1 anchor time (saying ~1265s vs. the reference 1275.0s), a notable timing discrepancy."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes describing the first pie chart about helpful advice/guidance, when does the second pie chart about communication appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1367.5,
        "end": 1367.9
      },
      "pred_interval": {
        "start": 1357.2,
        "end": 1367.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.299999999999955,
        "end": 0.40000000000009095,
        "average": 5.350000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.35000000000000003,
        "text_similarity": 0.6636466979980469,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly approximates E1 (1357s vs 1356.0s) but gives a substantially incorrect time for E2 (starts at 1357.2s and ends 1367.5s versus the correct appearance at 1376.5s), thereby misrepresenting the event timing and relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he wants to turn to some of the organizational ethics consultation work, when does the slide showing the 'Organizational ethics consultations' table appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1472.0,
        "end": 1472.5
      },
      "pred_interval": {
        "start": 1466.4,
        "end": 1467.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.599999999999909,
        "end": 5.099999999999909,
        "average": 5.349999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.20454545454545456,
        "text_similarity": 0.376664400100708,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is semantically related but provides incorrect timestamps for both the speaker introduction (1410.0s vs correct ~1433.9\u20131437.8s) and the slide appearance (1466.4s vs correct ~1472.0\u20131472.5s), and includes unsupported extra detail about coinciding COVID remarks, so it does not match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining that organizational ethics work is new to them, when do they state that it began during the COVID pandemic?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1469.5,
        "end": 1472.0
      },
      "pred_interval": {
        "start": 1464.5,
        "end": 1467.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 4.5,
        "average": 4.75
      },
      "rationale_metrics": {
        "rouge_l": 0.28169014084507044,
        "text_similarity": 0.6085841655731201,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence and phrasing but gives substantially different timestamps (about 5 seconds earlier and different end time) than the reference, so the timing information is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the 'Organizational ethics consultations' table, when does the speaker mention the 'Blood products scarcity protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1510.0,
        "end": 1513.0
      },
      "pred_interval": {
        "start": 1508.4,
        "end": 1510.6
      },
      "iou": 0.13043478260867847,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.599999999999909,
        "end": 2.400000000000091,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2647058823529411,
        "text_similarity": 0.6654337644577026,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the mention and that it occurs while the table is visible, but the reported timestamps differ from the reference (predicted 1508.4\u20131510.6s vs. ground truth 1510.0\u20131513.0s), with only a brief overlap and an earlier end time."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the 'sequential organ failure assessment or SOFA score', when does he begin to explain what it is?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1647.6,
        "end": 1697.0
      },
      "pred_interval": {
        "start": 1650.5,
        "end": 1660.0
      },
      "iou": 0.19230769230769196,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.900000000000091,
        "end": 37.0,
        "average": 19.950000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.44196581840515137,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the start of a verbal definition and content (SOFA as a 25\u2011point scale over six organ systems), but it misplaces the anchor event (predicting ~1649s vs 1621\u20131629s) and substantially underestimates the explanation\u2019s duration/end time (predicts end ~1660s vs 1697s), so timestamps and completeness are notably inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that '70% of publicly available crisis standards of care used either the SOFA score or a modified version', when does he mention the SOFA score being used in Alaska?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1726.0,
        "end": 1733.0
      },
      "pred_interval": {
        "start": 1728.0,
        "end": 1737.0
      },
      "iou": 0.45454545454545453,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 4.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24390243902439027,
        "text_similarity": 0.40934163331985474,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted anchor timing is incorrect (\u22481718s vs correct 1705\u20131712s). The predicted target start is close but its end timing and added detail about allocating hemodialysis machines conflict with the reference and introduce likely hallucination."
      }
    },
    {
      "question_id": "003",
      "question": "Once the 'SOFA Disparities' slide appears, when does the speaker begin discussing concerns about the score's accuracy and contributions to disparities?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1770.0,
        "end": 1776.606
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1779.0
      },
      "iou": 0.7339999999999994,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 2.3940000000000055,
        "average": 1.1970000000000027
      },
      "rationale_metrics": {
        "rouge_l": 0.24,
        "text_similarity": 0.6230190396308899,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the target start time (1770.0s) and the speaker addressing concerns, but the anchor time is off by ~1s, the target end time is later than the reference (1779.0s vs 1776.606s), and it adds an unconfirmed detail about 'parallel development.'"
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that the center was able to test the triage protocol before it was used, when does he state that they developed a SOFA calculation system?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1799.553,
        "end": 1807.997
      },
      "pred_interval": {
        "start": 1799.5,
        "end": 1806.0
      },
      "iou": 0.7587383782511281,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.05300000000011096,
        "end": 1.997000000000071,
        "average": 1.025000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.37209302325581395,
        "text_similarity": 0.8554972410202026,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target ordering and gives start times nearly identical to the reference; minor discrepancies are the broader E1 range (1795\u20131798s vs precise 1795.5s) and a slightly early E2 end (1806.0s vs 1807.997s)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the retrospective cohort study, when does he detail the demographic breakdown of the patients?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1846.122,
        "end": 1858.077
      },
      "pred_interval": {
        "start": 1879.5,
        "end": 1891.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.37799999999993,
        "end": 33.423,
        "average": 33.400499999999965
      },
      "rationale_metrics": {
        "rouge_l": 0.21333333333333335,
        "text_similarity": 0.6311373710632324,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes demographics occur after the study introduction, but the timestamps are substantially off (predicted ~1879\u20131891s vs. true 1846\u20131858s) and it introduces a specific percentage that is not in the reference, so it is partially correct but factually inaccurate on key details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker highlights that non-Hispanic Black patients had greater odds of an elevated SOFA score, when does he state that no significant difference by race in mortality was found when controlling for other factors?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.642,
        "end": 1879.694
      },
      "pred_interval": {
        "start": 1904.5,
        "end": 1913.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.857999999999947,
        "end": 33.80600000000004,
        "average": 32.331999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2888888888888889,
        "text_similarity": 0.818823516368866,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the two findings (elevated SOFA odds for Black patients and no mortality difference when controlling for factors) but the provided timestamps are substantially offset from the reference (roughly 30\u201340s later), so the temporal locations are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the early small cohort out of Wuhan, China, when does he state that subsequent larger cohorts in the United States did not show such high accuracy rates?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.0,
        "end": 1966.5
      },
      "pred_interval": {
        "start": 1963.0,
        "end": 1970.0
      },
      "iou": 0.3181818181818182,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 3.5,
        "average": 3.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2637362637362637,
        "text_similarity": 0.8248275518417358,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly identifies the same anchor and target events and their 'after' relationship, but the target timestamps are slightly shifted later (start ~4s late and end ~3.5s late) compared to the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'This graph here is a calibration curve', when does he explain that the diagonal line shows a perfectly calibrated predictor of mortality?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2014.0,
        "end": 2020.0
      },
      "pred_interval": {
        "start": 2021.0,
        "end": 2027.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 7.0,
        "average": 7.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.7839120626449585,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the explanation follows the graph), but the reported event timestamps substantially differ from the reference (anchor timing is inconsistent and the target is shifted ~7s later), so the timing is not accurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that SOFA predicted mortality with less accuracy than age in their own COVID cohort, when does he mention that SOFA predicted mortality with better accuracy than age in the pre-COVID eICU cohort?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2066.0,
        "end": 2069.0
      },
      "pred_interval": {
        "start": 2063.0,
        "end": 2075.0
      },
      "iou": 0.25,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 6.0,
        "average": 4.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2826086956521739,
        "text_similarity": 0.7929031848907471,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer's time spans fully encompass the ground-truth intervals and correctly identifies the eICU/pre-COVID contrast and the temporal relationship ('after'); the phrasing differs slightly but is semantically equivalent."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the Omicron surge increasing, when does he talk about working with the healthcare system's legal team?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2153.6,
        "end": 2174.93
      },
      "pred_interval": {
        "start": 2159.0,
        "end": 2163.0
      },
      "iou": 0.18752930145335273,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.400000000000091,
        "end": 11.929999999999836,
        "average": 8.664999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.6417596340179443,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mis-times E1 by ~25s (2157s vs 2132s) and only partially captures E2 (2159\u20132163s vs correct 2153.6\u20132174.93s), truncating the legal-team segment\u2014overall largely misaligned."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the policy was active until late February of 2022, when does the first 'Scope of protocol' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2194.0,
        "end": 2234.0
      },
      "pred_interval": {
        "start": 2199.0,
        "end": 2230.0
      },
      "iou": 0.775,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 5.0,
        "end": 4.0,
        "average": 4.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.7295354604721069,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the correct sequence (speaker finishes then the 'Scope of protocol' slide appears) but the timestamps differ by several seconds (E1 off by ~7s; E2 start ~5s late and end ~4s early), so it's partially correct but not precisely aligned with the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the second 'Scope of protocol' slide appears, when does the speaker mention 'renal replacement therapy'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2263.679,
        "end": 2254.733
      },
      "pred_interval": {
        "start": 2263.0,
        "end": 2265.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.6790000000000873,
        "end": 10.266999999999825,
        "average": 5.472999999999956
      },
      "rationale_metrics": {
        "rouge_l": 0.358974358974359,
        "text_similarity": 0.8214412927627563,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies E1 and roughly the timing of E2's mention (around 2263s), but it incorrectly gives the event duration/end time (2265s) and does not align precisely with the reference interval (2254.733\u20132263.679s) and the judge's 3s offset, so timing is only approximately correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that goals of care discussions significantly changed, when does the speaker mention that patients were more likely to choose limited life-sustaining interventions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2320.0,
        "end": 2327.0
      },
      "pred_interval": {
        "start": 2320.5,
        "end": 2326.0
      },
      "iou": 0.7857142857142857,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.5,
        "end": 1.0,
        "average": 0.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3466666666666666,
        "text_similarity": 0.6700323224067688,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events and the 'after' relation, with timestamps closely matching the references; minor timing offsets (E1 given as a range and E2 start 0.5s later than reference) account for the small deduction."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states he wants to highlight some takeaway points, when does the first takeaway point appear on the screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "pred_interval": {
        "start": 2396.0,
        "end": 2412.0
      },
      "iou": 0.23529411764705882,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 12.0,
        "average": 6.5
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.7288101315498352,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the speaker cue (E1) with only a minor 1s start discrepancy, but it misstates the first takeaway timing: E2 is reported as 2396\u20132412s versus the ground truth 2395\u20132400s, a significant mismatch in start/end times and duration."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I'll stop and take questions,\" when does an audience member begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2541.6,
        "end": 2544.0
      },
      "pred_interval": {
        "start": 2543.0,
        "end": 2546.0
      },
      "iou": 0.22727272727272257,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.400000000000091,
        "end": 2.0,
        "average": 1.7000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.39473684210526316,
        "text_similarity": 0.6975051164627075,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the events, order ('after'), and gives timestamps very close to the reference (E1 ~1.1s later, E2 ~1.4s later); it omits the E2 end time and adds a brief quoted utterance, but does not contradict the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the audience member finishes complimenting the center, when does he ask a specific question about local hospital ethics committees?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2571.5,
        "end": 2580.5
      },
      "pred_interval": {
        "start": 2563.0,
        "end": 2568.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.5,
        "end": 12.5,
        "average": 10.5
      },
      "rationale_metrics": {
        "rouge_l": 0.273972602739726,
        "text_similarity": 0.6073230504989624,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly identifies the relation ('once_finished') and the events, but the timestamps are significantly off: E1 is 2.5s earlier than the reference and E2 is claimed to start immediately at 2563.0s versus the correct 2571.5s\u20132580.5s, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the audience member mentions the low numbers of ethics consultations, when does the speaker begin to answer the question?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2624.0,
        "end": 2634.8
      },
      "pred_interval": {
        "start": 2617.0,
        "end": 2620.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 14.800000000000182,
        "average": 10.900000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.2696629213483146,
        "text_similarity": 0.6074850559234619,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly labels the relation as 'after' but misidentifies both event times (E1 at 2617s vs correct 2621s; E2 start at 2617s vs correct 2624s), alters the anchor content, and omits the E2 end time, so it contradicts key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the listener asks about assessing the quality of care across the system, when does the speaker respond by calling it a 'great question'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.1,
        "end": 2745.7
      },
      "pred_interval": {
        "start": 2747.0,
        "end": 2749.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.900000000000091,
        "end": 3.300000000000182,
        "average": 3.1000000000001364
      },
      "rationale_metrics": {
        "rouge_l": 0.40540540540540543,
        "text_similarity": 0.7068292498588562,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the listener question and the speaker saying 'that's a great question', but the timestamps are several seconds off (E1 ends at 2743.0 vs predicted 2746.5; E2 at 2744.1 vs predicted 2747.0\u20132749.0), so the timing is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions starting to survey clinicians for feedback, when does he mention planning to survey patients and families?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2807.8,
        "end": 2821.6
      },
      "pred_interval": {
        "start": 2856.0,
        "end": 2863.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.19999999999982,
        "end": 41.90000000000009,
        "average": 45.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.33663366336633666,
        "text_similarity": 0.6383655071258545,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction accurately captures the content and sequence (clinicians then plans to survey patients/families), but the timestamp anchors are incorrect\u2014off by roughly 40\u201355 seconds\u2014so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that hospitals in the healthcare system can join together, when does he state that they will preferentially present cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2854.49,
        "end": 2856.13
      },
      "pred_interval": {
        "start": 2855.3,
        "end": 2858.0
      },
      "iou": 0.23646723646720103,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8100000000004002,
        "end": 1.8699999999998909,
        "average": 1.3400000000001455
      },
      "rationale_metrics": {
        "rouge_l": 0.2972972972972973,
        "text_similarity": 0.7660104632377625,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies both utterances and the relative order (target after anchor) and preserves key phrasing, but the timestamps are notably misaligned\u2014the anchor is extended into the ground-truth target interval and the target start/end are shifted later."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces 'a third method of feedback', when does he describe it as 'formal needs assessments'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2877.53,
        "end": 2879.53
      },
      "pred_interval": {
        "start": 2880.5,
        "end": 2883.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.9699999999998,
        "end": 3.4699999999998,
        "average": 3.2199999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.4507042253521127,
        "text_similarity": 0.8679519891738892,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly preserves the key relation that the target occurs after the anchor and captures the phrase, but the timestamp boundaries are shifted several seconds later and the end time/duration do not match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'the overwhelming response was number one', when does he specify the first response as 'a lack of ethics education'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2901.56,
        "end": 2903.46
      },
      "pred_interval": {
        "start": 2905.3,
        "end": 2907.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.7400000000002365,
        "end": 3.7399999999997817,
        "average": 3.740000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.4324324324324324,
        "text_similarity": 0.8988958597183228,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the ordering (the target follows the anchor), but the provided timestamps are off by about 3.8\u20135.0 seconds from the ground truth, so the temporal localization is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"The more medically complex cases tend to transfer,\" when does he start listing examples of such cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3044.3,
        "end": 3048.2
      },
      "pred_interval": {
        "start": 3044.0,
        "end": 3052.0
      },
      "iou": 0.4874999999999545,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3000000000001819,
        "end": 3.800000000000182,
        "average": 2.050000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.2941176470588235,
        "text_similarity": 0.2381536215543747,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the mention (~3039s) and the start of examples (~3044s), matching the reference start time, but it incorrectly extends the end of the example list to 3052s (reference ends ~3048.2s), adding extra timing detail that contradicts the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the questioner asks about the 'escalation of care policy', when does the slide titled 'Escalation of Care Protocol' appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3114.8,
        "end": 3117.8
      },
      "pred_interval": {
        "start": 3108.0,
        "end": 3240.0
      },
      "iou": 0.022727272727272728,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.800000000000182,
        "end": 122.19999999999982,
        "average": 64.5
      },
      "rationale_metrics": {
        "rouge_l": 0.34210526315789475,
        "text_similarity": 0.7152220606803894,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation right (the slide appears after the question), but the timestamps are substantially incorrect (predicts ~3098s and 3108s vs correct 3113.9\u20133114.8 for the question and slide), so it fails on factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions \"boarding 190 patients in the emergency department\", when does he discuss concerns about the level of care?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3154.983,
        "end": 3143.945
      },
      "pred_interval": {
        "start": 3148.0,
        "end": 3159.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.983000000000175,
        "end": 15.554999999999836,
        "average": 11.269000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.3013698630136986,
        "text_similarity": 0.6039080619812012,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the concern follows immediately after the boarding remark, but the timestamps are substantially off (reference anchor 3150.3\u20133153.3 and E2 ~3154.98 vs predicted anchor ending 3146 and E2 3148\u20133159.5) and it adds extra wording not specified in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker mentions 'in all 26 of those cases', when does he then talk about 'many more cases'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3214.9,
        "end": 3215.4
      },
      "pred_interval": {
        "start": 3220.0,
        "end": 3222.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.099999999999909,
        "end": 6.599999999999909,
        "average": 5.849999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.42666666666666664,
        "text_similarity": 0.6187906265258789,
        "llm_judge_score": 5,
        "llm_judge_justification": "The predicted answer correctly identifies the two events and their 'after' relation and captures the quoted phrases, but the provided timestamps are consistently off by about 4\u20137 seconds from the reference, so the timing is imprecise."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker states that the 'escalation of care protocol' was nice, when does he mention a 'SOFA-based protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3246.0,
        "end": 3249.0
      },
      "pred_interval": {
        "start": 3251.0,
        "end": 3253.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 4.0,
        "average": 4.5
      },
      "rationale_metrics": {
        "rouge_l": 0.28205128205128205,
        "text_similarity": 0.7596944570541382,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relation but misassigns and shifts the event timestamps (it places the escalation at ~3246s instead of 3231\u20133233s and the SOFA mention at ~3251\u20133253s instead of 3246\u20133249s), so the timing and alignment are largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the second speaker says 'SOFA is horrendous', when does he mention 'SOFA's AUC goes up'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3322.32,
        "end": 3324.71
      },
      "pred_interval": {
        "start": 3328.0,
        "end": 3330.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.679999999999836,
        "end": 5.289999999999964,
        "average": 5.4849999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.39506172839506176,
        "text_similarity": 0.7688323259353638,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and the 'after' relation, but the timestamps are substantially incorrect for both events (E1 predicted at 3307 vs 3320.32\u20133321.82; E2 predicted at 3328\u20133330 vs 3322.32\u20133324.71), so it fails on temporal accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "After the question about equity monitoring is asked, when does the speaker begin explaining the logging process for patient cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3401.583,
        "end": 3406.09
      },
      "pred_interval": {
        "start": 3401.5,
        "end": 3418.5
      },
      "iou": 0.2651176470588272,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.08300000000008367,
        "end": 12.409999999999854,
        "average": 6.246499999999969
      },
      "rationale_metrics": {
        "rouge_l": 0.2637362637362637,
        "text_similarity": 0.7026378512382507,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly approximates the speaker's start time (~3401.5s vs 3401.583s) but misstates the question time (3401.0s vs 3406.535s), the explanation end time (3418.5s vs 3406.090s), reverses the temporal relation, and adds unsupported details, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the 'Escalation of Care Protocol', when does the 'Conscientious Practice Policy' slide appear on screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3429.8,
        "end": 3430.5
      },
      "pred_interval": {
        "start": 3429.0,
        "end": 3432.0
      },
      "iou": 0.2333333333332727,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8000000000001819,
        "end": 1.5,
        "average": 1.150000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.45569620253164556,
        "text_similarity": 0.6859479546546936,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relation and closely matches the slide-appearance time (3429.0s vs 3429.8s), but the speaker-finish time is about 5s off and it introduces unverified/hallucinated details (intermediate clicks at 3426s/3427s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Conscientious Practice Policy' slide appears, when does the speaker mention tracking outcomes and looking back retrospectively for this policy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3444.0,
        "end": 3492.0
      },
      "pred_interval": {
        "start": 3442.0,
        "end": 3452.5
      },
      "iou": 0.17,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 39.5,
        "average": 20.75
      },
      "rationale_metrics": {
        "rouge_l": 0.31707317073170727,
        "text_similarity": 0.6934487819671631,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that the tracking/retrospective comment occurs after the slide and captures the quoted phrase, and its start time is close, but it misstates the slide time by 5s and significantly underestimates the end time (3452.5s vs 3492.0s), omitting a substantial portion of the annotated interval."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions an increasing disparity over time, when does he discuss how they can provide support to all hospitals?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 707.399,
        "end": 742.972
      },
      "pred_interval": {
        "start": 712.0,
        "end": 747.0
      },
      "iou": 0.7821014620842903,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 4.600999999999999,
        "end": 4.02800000000002,
        "average": 4.3145000000000095
      },
      "rationale_metrics": {
        "rouge_l": 0.18947368421052632,
        "text_similarity": 0.27830278873443604,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that the support-for-all-hospitals discussion immediately follows the disparity remark and captures the gist of content, but the timestamps are several seconds off (anchor start/end and target start/end differ from the reference) and it omits the anchor start time while adding specific quoted phrasing not present in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "While the organizational chart for the Center for Clinical Ethics is displayed, when does the speaker describe the Ethics Education program?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.177,
        "end": 786.763
      },
      "pred_interval": {
        "start": 775.0,
        "end": 785.0
      },
      "iou": 0.5686341407938128,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.822999999999979,
        "end": 1.7630000000000337,
        "average": 3.7930000000000064
      },
      "rationale_metrics": {
        "rouge_l": 0.32558139534883723,
        "text_similarity": 0.8004598617553711,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies that the Ethics Education description occurs during the organizational chart slide and gives a close time window (\u2248775\u2013785s) matching the reference (769.177\u2013786.763s); minor discrepancies exist in the slide start time and the description start/end seconds, and the prediction adds descriptive content not specified in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says he will go into depth on the programs, when does he first mention the Yale Interdisciplinary Center for Bioethics?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 837.605,
        "end": 845.26
      },
      "pred_interval": {
        "start": 842.0,
        "end": 850.0
      },
      "iou": 0.26300927793465073,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.394999999999982,
        "end": 4.740000000000009,
        "average": 4.5674999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.49523809523809526,
        "text_similarity": 0.8287959098815918,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase and that the Yale Interdisciplinary Center for Bioethics is mentioned after it, with timestamps close to the reference (minor discrepancies: anchor ~1s later and target end ~5s later), but no substantive contradiction or missing key facts."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the title 'Systemwide Ethics Forum and Newsletter', when does he describe it as a hybrid meeting?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1070.5,
        "end": 1076.5
      },
      "pred_interval": {
        "start": 1072.0,
        "end": 1076.5
      },
      "iou": 0.75,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.5,
        "end": 0.0,
        "average": 0.75
      },
      "rationale_metrics": {
        "rouge_l": 0.4772727272727273,
        "text_similarity": 0.5597013235092163,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly captures both events, their content, and the temporal relation (the hybrid description occurs after the title); minor timestamp offsets are negligible and noted as acceptable."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining that they looked through the 26 specific patient cases individually, when does the slide transition to 'Scope of protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3425.8,
        "end": 3429.0
      },
      "pred_interval": {
        "start": 3426.4,
        "end": 3427.7
      },
      "iou": 0.4062499999999378,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.599999999999909,
        "end": 1.300000000000182,
        "average": 0.9500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.6643968820571899,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the order and approximate times (E1 ~3418s, E2 begins ~3426s) and preserves the 'after' relation; however the predicted end/transition time (3427.7s) differs from the reference (3429.0s), a minor but notable timing discrepancy."
      }
    },
    {
      "question_id": "002",
      "question": "Once the 'Scope of protocol' slide finishes being displayed, when does the 'Conscientious Practice Policy' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3429.0,
        "end": 3519.5
      },
      "pred_interval": {
        "start": 3429.5,
        "end": 3520.0
      },
      "iou": 0.989010989010989,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.5,
        "end": 0.5,
        "average": 0.5
      },
      "rationale_metrics": {
        "rouge_l": 0.325,
        "text_similarity": 0.7716045379638672,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly matches the E2 timing but gives a different E1 end time and hallucinates an intermediate slide, contradicting the correct 'once_finished' immediate transition; small timing offsets aside, the added slide and relation error reduce correctness significantly."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes discussing the tracking of equity, socioeconomic status, and other demographic characteristics, when is the presentation window minimized?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3530.0,
        "end": 3531.0
      },
      "pred_interval": {
        "start": 3528.0,
        "end": 3529.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 2.0,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.20588235294117646,
        "text_similarity": 0.3728250563144684,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the high-level order (minimization occurs after discussion) but gives incorrect timestamps (3508.5 \u2192 ~3519 for end of discussion; 3530\u20133531 \u2192 3528 for minimization) and adds unsupported details (exiting full-screen/closing slides), so it is factually inaccurate on key elements."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the audience will be on mute, when does he mention that the live event can be paused?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 38.524,
        "end": 43.729
      },
      "pred_interval": {
        "start": 38.0,
        "end": 44.0
      },
      "iou": 0.8674999999999997,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.5240000000000009,
        "end": 0.2710000000000008,
        "average": 0.39750000000000085
      },
      "rationale_metrics": {
        "rouge_l": 0.1797752808988764,
        "text_similarity": 0.6574099659919739,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events, their 'after' relation, and gives target span close to the reference; however the anchor timestamp is about 1.9s later than the ground truth (minor temporal inaccuracy)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses changing the speed of presentations and speakers, when does he advise on what to do if Wi-Fi or connection is lost?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 55.563,
        "end": 59.787
      },
      "pred_interval": {
        "start": 55.0,
        "end": 105.0
      },
      "iou": 0.08447999999999993,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.5630000000000024,
        "end": 45.213,
        "average": 22.888
      },
      "rationale_metrics": {
        "rouge_l": 0.16822429906542055,
        "text_similarity": 0.7042595744132996,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target events, their order, and even quotes the advice about reconnecting; timing is very close though slightly offset (E1 ~4s late and target end extended by ~5s), so minor temporal inaccuracies prevent a perfect score."
      }
    },
    {
      "question_id": "001",
      "question": "After the presenter mentions Tom Gardner in the background, when does he mention Stephanie Fraser joining in place of Jane Preston?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.258,
        "end": 171.201
      },
      "pred_interval": {
        "start": 169.0,
        "end": 173.5
      },
      "iou": 0.41987790919496326,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7419999999999902,
        "end": 2.2990000000000066,
        "average": 1.5204999999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.3853211009174312,
        "text_similarity": 0.8307640552520752,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target utterances and the 'after' relation, but the provided timestamps are grossly misaligned with the ground truth (off by ~150s), so the temporal localization is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male presenter finishes introducing Stephanie Fraser, when does Stephanie Fraser begin speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 223.86,
        "end": 224.8
      },
      "pred_interval": {
        "start": 224.0,
        "end": 226.0
      },
      "iou": 0.3738317757009423,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.13999999999998636,
        "end": 1.1999999999999886,
        "average": 0.6699999999999875
      },
      "rationale_metrics": {
        "rouge_l": 0.3956043956043956,
        "text_similarity": 0.7786386013031006,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor end and target start times and the relation (equivalent to 'after'), with only minor timing (\u22481s) and wording differences for the anchor\u2014no factual contradictions or hallucinations."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker is discussing the recent research undertaken by the Neurological Alliance of Scotland, when does she state that 57% of respondents reported not being able to access a face-to-face appointment?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 433.0,
        "end": 434.9
      },
      "pred_interval": {
        "start": 436.0,
        "end": 446.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 11.100000000000023,
        "average": 7.050000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.16326530612244897,
        "text_similarity": 0.5297673344612122,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the quoted 57% statement and context, but it gives no precise anchor timing and its target interval (436.0\u2013446.0s) does not match the reference timing (433.0\u2013434.9s), so it misses the exact moment."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that nearly two-thirds of respondents had not had a video appointment, when does she state that telephone appointments were the most common way to access care?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.8,
        "end": 452.9
      },
      "pred_interval": {
        "start": 452.0,
        "end": 456.0
      },
      "iou": 0.10975609756097299,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.199999999999989,
        "end": 3.1000000000000227,
        "average": 3.6500000000000057
      },
      "rationale_metrics": {
        "rouge_l": 0.35,
        "text_similarity": 0.8339618444442749,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer quotes the correct line but gives substantially incorrect timestamps and claims the segments are adjacent; it misaligns E1/E2 by ~100s and has wrong start/end times for E2, so it is largely incorrect despite matching the content."
      }
    },
    {
      "question_id": "003",
      "question": "After the blue slide with the speaker's title disappears, when does the speaker begin to mention what factors clinicians should consider for appointment formats?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 479.3,
        "end": 480.3
      },
      "pred_interval": {
        "start": 530.0,
        "end": 537.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.69999999999999,
        "end": 56.69999999999999,
        "average": 53.69999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2391304347826087,
        "text_similarity": 0.7850109934806824,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction identifies an anchor and target but the timestamps are far off (E1 off by ~36.7s, E2 start off by ~50.7s) and the quoted utterance/interval does not match the reference, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stephanie finishes speaking and hands over to Mark, when does Mark begin to speak?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 606.5,
        "end": 607.0
      },
      "pred_interval": {
        "start": 609.0,
        "end": 612.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 5.0,
        "average": 3.75
      },
      "rationale_metrics": {
        "rouge_l": 0.25352112676056343,
        "text_similarity": 0.6417841911315918,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies Mark starting around the correct global time (~609s) and that he speaks after Stephanie, but it gives an incorrect/ambiguous timestamp for Stephanie (01:38 does not match the reference 593.7\u2013594.0s) and contains inconsistent times (01:39 vs 609.0s), so key timing information is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once Mark finishes introducing Calum Duncan, when does Calum Duncan start speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 638.3,
        "end": 639.3
      },
      "pred_interval": {
        "start": 640.0,
        "end": 643.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.7000000000000455,
        "end": 3.7000000000000455,
        "average": 2.7000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.18918918918918917,
        "text_similarity": 0.5281891822814941,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies Calum starting shortly after Mark and gives an E2 time close to the reference, but it misreports E1 (Mark's finish) with inconsistent/incorrect timestamps (02:09 vs 636.3\u2013636.6s) and provides conflicting time formats, so the match is only partial."
      }
    },
    {
      "question_id": "003",
      "question": "Once Calum Duncan says 'Next slide please', when does the second presentation slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 685.7,
        "end": 686.0
      },
      "pred_interval": {
        "start": 688.0,
        "end": 691.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.2999999999999545,
        "end": 5.0,
        "average": 3.6499999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.29850746268656714,
        "text_similarity": 0.5867975354194641,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the event ordering correct (slide appears after Calum speaks) and roughly the target slide timing, but the anchor time for Calum saying 'Next slide please' is grossly incorrect (02:57 vs 684.4\u2013685.2s) and the predicted E2 time slightly disagrees; it also adds an unsupported slide-title detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 'near me is what we're going to focus on today', when does he describe it as 'internet-based'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 702.7,
        "end": 703.5
      },
      "pred_interval": {
        "start": 704.5,
        "end": 706.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.7999999999999545,
        "end": 3.0,
        "average": 2.3999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.27027027027027023,
        "text_similarity": 0.6927087903022766,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase, the target description ('internet-based'), and the 'after' relation, but the timestamps are slightly off (E1 ~1.2s later and E2 ~1.8s later than the ground truth), so minor temporal inaccuracies reduce perfection."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states there were '330 consultations per week' before the pandemic, when does he mention it went up to '10,000'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 737.0,
        "end": 739.0
      },
      "pred_interval": {
        "start": 740.0,
        "end": 742.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 3.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2898550724637681,
        "text_similarity": 0.5993485450744629,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the same anchor utterance and the 'after' relation, but the predicted timestamps are rounded and E2 is about 3 seconds later than the reference interval, so the timing does not precisely match."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' for the first time, when does he point to the map on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.0,
        "end": 767.5
      },
      "pred_interval": {
        "start": 760.0,
        "end": 766.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 1.5,
        "average": 4.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2352941176470588,
        "text_similarity": 0.6364974975585938,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the relative ordering and mentions the map/Orkney, but it mislocates the anchor by ~7s (749s vs 756s) and importantly misidentifies the target action (mouse cursor movement from 760\u2013766s instead of the speaker visually pointing at 767s), so it is factually incorrect on key elements."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'go back to the next slide', when does the slide titled 'Video consulting using near me via attend anywhere platform' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 874.0,
        "end": 874.1
      },
      "pred_interval": {
        "start": 874.0,
        "end": 885.0
      },
      "iou": 0.009090909090911158,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.0,
        "end": 10.899999999999977,
        "average": 5.449999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619044,
        "text_similarity": 0.537479817867279,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states the slide appears at 874.0s (immediately after the instruction) but includes additional unsupported details about the speaker's reaction timing and the slide remaining until 885.0s, which are not present in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that 'Stephanie Fraser has talked about' the survey, when does he then say 'Back to next slide, Mark, please'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 884.0
      },
      "pred_interval": {
        "start": 884.0,
        "end": 886.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 2.0,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.19444444444444445,
        "text_similarity": 0.4377995431423187,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly places the target after the anchor but gives inconsistent/incorrect timings (mixing 00:14 with 884.0s) and incorrectly extends the target to ~886.0s, contradicting the reference end at 884.0s and adding an unwarranted slide-transition detail."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'Next slide, please' at the 42-second mark, when does the slide titled 'Clinician and patient experience - Scotland' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 913.0,
        "end": 913.1
      },
      "pred_interval": {
        "start": 914.0,
        "end": 973.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 59.89999999999998,
        "average": 30.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.18918918918918923,
        "text_similarity": 0.48827558755874634,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly identifies the slide appearance immediately after the instruction and is off by only 1 second (914.0s vs. 913.0s); the extra detail about how long it stays is additional but not contradictory."
      }
    },
    {
      "question_id": "001",
      "question": "During the discussion of what works well with video calls, when does the speaker express finding it much easier to interact with groups on a video call than on the telephone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1053.0,
        "end": 1062.5
      },
      "pred_interval": {
        "start": 1057.0,
        "end": 1065.0
      },
      "iou": 0.4583333333333333,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 2.5,
        "average": 3.25
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.32324928045272827,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction partially overlaps the correct interval (1053.0\u20131062.5) but starts 4s late and ends 2.5s late, and it omits the E1 marker at 1050.0s ('What works well'); therefore it is only partially correct on timing and relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions technical issues with patient bandwidth, when does he advise to choose patients correctly to avoid those difficulties?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1134.0,
        "end": 1135.5
      },
      "pred_interval": {
        "start": 1139.0,
        "end": 1145.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 9.5,
        "average": 7.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3846153846153847,
        "text_similarity": 0.6272033452987671,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the advice and the 'after' relation to the bandwidth issue, but the provided start/end timestamps are noticeably later than the ground truth (1139.0\u20131145.0s vs 1134.0\u20131135.5s), so temporal accuracy is lacking."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' to introduce the smart phone camera, when does he specifically point out his wife's iPhone on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1213.0,
        "end": 1215.0
      },
      "pred_interval": {
        "start": 1218.0,
        "end": 1220.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 5.0,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6398440003395081,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly preserves the event relation and identifies the same utterance, but the timestamps are off (E1 by ~2s and E2 by ~5s), so it only partially matches the reference timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying 'Next slide please', when does the 'Sharing content' slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.574,
        "end": 1249.574
      },
      "pred_interval": {
        "start": 1251.0,
        "end": 1252.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.425999999999931,
        "end": 2.425999999999931,
        "average": 2.425999999999931
      },
      "rationale_metrics": {
        "rouge_l": 0.3373493975903615,
        "text_similarity": 0.8092309236526489,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same events and order, but the timestamps are incorrect (predicted 1250.0s/1251.0s vs ground truth 1247.133\u20131248.173 and 1248.574s) and it misstates the timing gap (\u22480.4s actual vs 1.0s predicted), so it is factually inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'You can share things', when does he point towards the screen showing the brain scan?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1252.25,
        "end": 1252.85
      },
      "pred_interval": {
        "start": 1254.0,
        "end": 1256.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.75,
        "end": 3.150000000000091,
        "average": 2.4500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.29999999999999993,
        "text_similarity": 0.7403175830841064,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction recognizes a pointing gesture to the brain scan but the times are substantially off (anchor predicted ~1253s vs correct 1249.255s; target predicted 1254.0\u20131256.0 vs correct 1252.250\u20131252.850) and it adds an unsupported utterance ('So this is a scan'), so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "During the discussion about poor picture quality, when does the speaker suggest clearing browser history?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1313.823,
        "end": 1315.286
      },
      "pred_interval": {
        "start": 1316.0,
        "end": 1319.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.1769999999999072,
        "end": 3.713999999999942,
        "average": 2.9454999999999245
      },
      "rationale_metrics": {
        "rouge_l": 0.3733333333333333,
        "text_similarity": 0.8274735808372498,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the discussion and the suggested remedy ('clear browser history') but the timestamp annotations differ notably from the reference (anchor ~4.8s early and target ~2\u20133.7s late), so timing inaccuracies reduce the match."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying \"Thank you very much for that\", when does he state he is handing over to Jane?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.837,
        "end": 1430.682
      },
      "pred_interval": {
        "start": 1421.1,
        "end": 1423.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.73700000000008,
        "end": 7.481999999999971,
        "average": 7.6095000000000255
      },
      "rationale_metrics": {
        "rouge_l": 0.48648648648648646,
        "text_similarity": 0.727145791053772,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the utterances and order but the timestamps are substantially wrong (about 7\u20138 seconds earlier for both events) so it fails to match the key factual timing in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman (Jane) describes the challenges of managing patients over the telephone, when does she mention that they had a pilot of 'Near Me' even prior to Covid?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1609.855,
        "end": 1624.692
      },
      "pred_interval": {
        "start": 1612.3,
        "end": 1619.5
      },
      "iou": 0.4852733032284189,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.4449999999999363,
        "end": 5.192000000000007,
        "average": 3.818499999999972
      },
      "rationale_metrics": {
        "rouge_l": 0.3440860215053763,
        "text_similarity": 0.5718849897384644,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the E2 quote and relation (after) and gives an accurate E2 start time, but misplaces E1 substantially (~37s earlier than the reference), so timing alignment is imperfect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that using 'Near Me' felt quite adventurous, when does she state that its use became vital to their whole service?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1636.0,
        "end": 1643.0
      },
      "pred_interval": {
        "start": 1636.5,
        "end": 1640.5
      },
      "iou": 0.5714285714285714,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.5,
        "end": 2.5,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3703703703703703,
        "text_similarity": 0.7392404079437256,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the phrasing and roughly the start time of the 'vital' remark (~1636s) but misplaces the anchor event (E1) by ~7.7s and gives a target span (1636.5\u20131640.5s) that contradicts the correct span (1646.0\u20131653.0s), and it adds extraneous context."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes asking Mark to go back to the previous slide, when does she say 'Thank you'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1676.54,
        "end": 1678.02
      },
      "pred_interval": {
        "start": 1677.0,
        "end": 1678.0
      },
      "iou": 0.6756756756756673,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.4600000000000364,
        "end": 0.01999999999998181,
        "average": 0.2400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.7760498523712158,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the 'Thank you' target span (1677.0\u20131678.0s) and the post-correction relation, but it misplaces the anchor event (predicted ~1676s vs. reference 1673.4s), a nontrivial timing discrepancy."
      }
    },
    {
      "question_id": "001",
      "question": "After the 'Training and preparation' slide appears, when does the speaker mention the 'Level 1' training?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1791.0,
        "end": 1791.5
      },
      "pred_interval": {
        "start": 1796.0,
        "end": 1806.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 14.5,
        "average": 9.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2972972972972973,
        "text_similarity": 0.6458563804626465,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor slide and the 'after' relation, but the target timing is offset by ~5s (1796s vs 1791s) and includes an extended interval and extra detail not present in the reference, so it's partially but not fully accurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing tele-swallowing partners as 'our eyes and our hands and our ears', when does she start talking about preparing the clinical room?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1897.0,
        "end": 1901.0
      },
      "pred_interval": {
        "start": 1861.5,
        "end": 1867.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.5,
        "end": 34.0,
        "average": 34.75
      },
      "rationale_metrics": {
        "rouge_l": 0.29268292682926833,
        "text_similarity": 0.6912999153137207,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the two events and the 'once_finished' relation, but the timestamps are materially incorrect (E1 and E2 are ~34 seconds earlier than the ground truth and E2's span does not fall within the correct 1897.0\u20131901.0s window)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses tele-swallowing partners preparing the clinical room, when does she next talk about them providing reassurance to patients?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1906.0,
        "end": 1910.0
      },
      "pred_interval": {
        "start": 1867.5,
        "end": 1875.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.5,
        "end": 35.0,
        "average": 36.75
      },
      "rationale_metrics": {
        "rouge_l": 0.19999999999999998,
        "text_similarity": 0.698927640914917,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same two content events (preparing the room and providing reassurance) but the temporal spans are substantially different from the reference and the relation label ('after' vs 'next') is less precise; due to the large timestamp mismatch the answer is mostly incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning emergency procedures in place onsite, when does the slide change to 'Technology/equipment'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1971.6,
        "end": 1972.0
      },
      "pred_interval": {
        "start": 1970.6,
        "end": 1971.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 0.40000000000009095,
        "average": 0.7000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.34285714285714286,
        "text_similarity": 0.801353931427002,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the correct relation (slide change occurs after the emergency-procedures discussion) but both timestamps are notably inaccurate: the anchor end is ~2.9s later than the ground truth and the slide change time is ~1.0s earlier (and omits the correct 1971.6\u20131972.0 range). These substantive timing errors reduce correctness."
      }
    },
    {
      "question_id": "002",
      "question": "During the time the 'Technology/equipment' slide is displayed, when does the speaker discuss the need for a device with a webcam and microphone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2024.079,
        "end": 2026.579
      },
      "pred_interval": {
        "start": 2065.5,
        "end": 2069.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.42100000000005,
        "end": 42.42100000000005,
        "average": 41.92100000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.6964978575706482,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the mention occurs while the slide is displayed, but it gives substantially wrong timestamps (2065.5\u20132069.0 vs correct 2024.079\u20132026.579) and omits the slide end time, so the timing is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the general category of 'certain resources' for teleswallow sessions, when does she mention 'appropriate diet and fluid consistencies'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.952,
        "end": 2061.952
      },
      "pred_interval": {
        "start": 2108.3,
        "end": 2111.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.347999999999956,
        "end": 49.547999999999774,
        "average": 49.447999999999865
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.8054699301719666,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the relation (E2 follows the anchor) and identifies the mention, but the anchor and target timestamps are substantially offset from the ground truth, so the timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that remote swallowing assessments are not intended to fully replace face-to-face assessments, when does she mention that they are a very useful addition?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2159.677,
        "end": 2162.619
      },
      "pred_interval": {
        "start": 2161.0,
        "end": 2165.0
      },
      "iou": 0.30415179410110516,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3229999999998654,
        "end": 2.380999999999858,
        "average": 1.8519999999998618
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.7506827116012573,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction captures the sequence and content correctly and notes that the target immediately follows the anchor, but the reported timestamps differ slightly (predicted E1/E2 start times are ~1\u20132 seconds later than the reference), so it's not a perfect match."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning gathering feedback from those who completed the training, when does she start talking about evaluating quantitative data?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2164.643,
        "end": 2186.427
      },
      "pred_interval": {
        "start": 2172.0,
        "end": 2177.0
      },
      "iou": 0.22952625780389166,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.356999999999971,
        "end": 9.427000000000135,
        "average": 8.392000000000053
      },
      "rationale_metrics": {
        "rouge_l": 0.3820224719101123,
        "text_similarity": 0.712995171546936,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the remark about quantitative data immediately follows the feedback comment and even quotes the phrase, but the provided timestamps are significantly off from the reference (predicted ~2172\u20132177s vs correct 2185.427s/2186.427s), so the timing is factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes her presentation by saying 'thank you very much for listening', when does the video visually transition to the male presenter?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2257.0,
        "end": 2258.0
      },
      "pred_interval": {
        "start": 2260.0,
        "end": 2262.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 4.0,
        "average": 3.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3466666666666666,
        "text_similarity": 0.840809166431427,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates both timestamps (E1 at 2258s vs 2256s, E2 at 2260s vs 2257s), introduces a slide transition/delay instead of the immediate visual follow, and adds an unsupported name, so it contradicts key facts."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that picking up cues is difficult, when does she start talking about 'points to consider' for virtual technology?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2491.8,
        "end": 2498.2
      },
      "pred_interval": {
        "start": 2496.0,
        "end": 2503.0
      },
      "iou": 0.19642857142855838,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.199999999999818,
        "end": 4.800000000000182,
        "average": 4.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3564356435643564,
        "text_similarity": 0.5565057992935181,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the sequence and quoted phrases but the timestamps are significantly shifted (E1 and E2 start/end times differ by ~3\u20134s from the reference), so key factual timing information is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions conducting a 'sprint audit' with patients, when does she state that 'most were very satisfied' with the virtual appointments?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2515.0,
        "end": 2516.0
      },
      "pred_interval": {
        "start": 2519.0,
        "end": 2522.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 6.0,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4096385542168674,
        "text_similarity": 0.6343995928764343,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and their temporal relation (E2 after E1), but both timestamps are noticeably offset from the reference (E1 ~5.5s early; E2 ~3\u20136s late), so it is only partially accurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that patients found virtual technology 'more acceptable', when does she say 'So moving on to the next slide'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2638.0,
        "end": 2639.3
      },
      "pred_interval": {
        "start": 2603.0,
        "end": 2605.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.0,
        "end": 34.30000000000018,
        "average": 34.65000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.42105263157894735,
        "text_similarity": 0.5994884967803955,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the phrases and their ordering (E2 follows E1), but the timestamps are substantially incorrect (about 35 seconds earlier than the reference), so it does not align with the ground truth timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing confidentiality, when does she begin to mention the subtlety of the therapeutic relationship?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2693.583,
        "end": 2697.126
      },
      "pred_interval": {
        "start": 2697.0,
        "end": 2702.0
      },
      "iou": 0.01496970417015623,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.4169999999999163,
        "end": 4.873999999999796,
        "average": 4.145499999999856
      },
      "rationale_metrics": {
        "rouge_l": 0.1518987341772152,
        "text_similarity": 0.7222265005111694,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the sequence right (therapeutic relationship mentioned after confidentiality) but the reported anchor end and target start/end times differ substantially from the ground truth by several seconds, so the timing/spans do not align."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'It all comes down to Wi-Fi', when does she state that 'delivery of remote therapy is very, very difficult'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.0,
        "end": 2729.0
      },
      "pred_interval": {
        "start": 2730.0,
        "end": 2734.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 5.0,
        "average": 4.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4210526315789474,
        "text_similarity": 0.8544896245002747,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly preserves the temporal order (target occurs after the anchor) but the provided timestamps are substantially off (anchor 2722.041s vs 2726.0s; target 2727\u20132729s vs 2730\u20132734s) and it adds/changes phrasing, so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'So next slide', when does the slide visually change to 'Practical considerations'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2884.0,
        "end": 2884.2
      },
      "pred_interval": {
        "start": 2885.0,
        "end": 2886.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 1.800000000000182,
        "average": 1.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.36666666666666664,
        "text_similarity": 0.656806230545044,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction preserves the sequence and that the slide changes immediately after the cue, but the timestamps are off by ~1\u20132 seconds (speaker: 2884.8 vs 2883.0; slide: 2885.0 vs 2884.0) and it adds an extra previous-slide title not present in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing 'Practical considerations', when does she first mention 'increasing reflective feedback'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2913.483,
        "end": 2916.268
      },
      "pred_interval": {
        "start": 2915.5,
        "end": 2918.0
      },
      "iou": 0.17002435244632694,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0169999999998254,
        "end": 1.731999999999971,
        "average": 1.8744999999998981
      },
      "rationale_metrics": {
        "rouge_l": 0.3272727272727273,
        "text_similarity": 0.7900867462158203,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly locates the mention within the practical considerations discussion and gives a very close timestamp, but it omits the stated start time of the practical considerations segment (2850.0s) and differs slightly from the reference timestamp (2913.483s)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"for the patients\", when does the slide change to \"WHERE WE ARE NOW\"?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3067.769,
        "end": 3068.2
      },
      "pred_interval": {
        "start": 3067.0,
        "end": 3068.0
      },
      "iou": 0.1925000000002141,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7689999999997781,
        "end": 0.1999999999998181,
        "average": 0.4844999999997981
      },
      "rationale_metrics": {
        "rouge_l": 0.3888888888888889,
        "text_similarity": 0.6694483160972595,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction identifies the correct events and relation and E2 timing is close, but E1 is off by ~4.8 seconds (3062s vs 3066.769s), producing a materially inaccurate temporal alignment."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says \"open up for some discussion\", when does the discussion slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3163.435,
        "end": 3163.7
      },
      "pred_interval": {
        "start": 3123.0,
        "end": 3124.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.434999999999945,
        "end": 39.69999999999982,
        "average": 40.06749999999988
      },
      "rationale_metrics": {
        "rouge_l": 0.2898550724637681,
        "text_similarity": 0.6109205484390259,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets E1 timing approximately right and the 'after' relation, but it places E2 at 3123s instead of ~3163.435s (and omits the fully-visible timestamp), a major factual error about when the discussion slide appears."
      }
    },
    {
      "question_id": "001",
      "question": "After the first male speaker asks about attendees' experience with Near Me, when does the second male speaker begin talking about starting to use NearMe?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.9,
        "end": 3312.0
      },
      "pred_interval": {
        "start": 3273.0,
        "end": 3277.0
      },
      "iou": 0.09280742459396771,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.099999999999909,
        "end": 35.0,
        "average": 19.549999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.23809523809523808,
        "text_similarity": 0.5747754573822021,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the second speaker's turn about NearMe and the 'after' relation, and the E2 start is close to the reference (~4s difference) with the quoted phrase included; however, the E1 timing is given in a different (relative) format and there are minor timing inconsistencies with the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second male speaker finishes stating the advantages and utility of NearMe, when does he mention supplementing normal activities?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.4,
        "end": 3293.32
      },
      "pred_interval": {
        "start": 3293.0,
        "end": 3297.0
      },
      "iou": 0.037209302325600824,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.599999999999909,
        "end": 3.6799999999998363,
        "average": 4.139999999999873
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.5680540204048157,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the speakers, utterances, and that the second remark follows the first, but it gives inconsistent and incorrect timestamps (off by ~9\u201310s and claiming identical start/end times), contradicting the reference timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the first man finishes reading Jenny's chat message, when does he ask the audience if they would find guidance helpful?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3411.0,
        "end": 3415.0
      },
      "pred_interval": {
        "start": 3413.0,
        "end": 3419.0
      },
      "iou": 0.25,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 4.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24096385542168675,
        "text_similarity": 0.61041259765625,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction identifies both events and preserves the 'after' relation, but it misplaces E1 by ~4.4s (3412 vs 3407.6) and gives an E2 span (3413\u20133419) that only partially overlaps the correct target (3411\u20133415) and extends beyond it, so key timing details are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first man finishes reading John Hogan's comment about clinical interviewing, when does he state he was quite skeptical?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3434.9,
        "end": 3437.7
      },
      "pred_interval": {
        "start": 3439.0,
        "end": 3441.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.099999999999909,
        "end": 3.300000000000182,
        "average": 3.7000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.2391304347826087,
        "text_similarity": 0.6468648910522461,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the once_finished relation but the reported timestamps for both E1 and E2 are substantially off (\u2248+14s) and do not match the correct target span 3434.9\u20133437.7s, so the localization is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the second woman mentions neuropsychology bringing out guidance, when is the next time a woman speaks about professional guidance?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3511.043,
        "end": 3528.447
      },
      "pred_interval": {
        "start": 3514.0,
        "end": 3528.0
      },
      "iou": 0.8044127786715699,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 2.95699999999988,
        "end": 0.4470000000001164,
        "average": 1.7019999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.24000000000000005,
        "text_similarity": 0.768740713596344,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the next speaker and roughly matches the target span end and content, but it significantly misreports the anchor (E1) finish time (3508s vs 3422s) and slightly offsets the target start, so key timing details are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 36 people joined the session, when does he talk about taking the next steps with Richard and the team?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3574.7,
        "end": 3576.5
      },
      "pred_interval": {
        "start": 3576.5,
        "end": 3579.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.800000000000182,
        "end": 3.0,
        "average": 2.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.8150139451026917,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies both events, their order, and the anchor timing/content, but the target timestamp disagrees with the reference (predicted start/end are notably later than the ground truth)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker makes a plea to fill in the survey, when does he ask if listeners would like to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3592.9,
        "end": 3594.1
      },
      "pred_interval": {
        "start": 3593.0,
        "end": 3598.5
      },
      "iou": 0.19642857142855838,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.09999999999990905,
        "end": 4.400000000000091,
        "average": 2.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3764705882352941,
        "text_similarity": 0.8071860074996948,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the target's occurrence after the anchor and matches the target start time closely, but it misstates the anchor timing (3589.0 vs 3586.5\u20133588.0) and significantly overestimates the target end time (3598.5 vs 3594.1), introducing factual timing errors."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes thanking everyone for joining the session today, when does he mention that the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3599.8,
        "end": 3603.2
      },
      "pred_interval": {
        "start": 3602.5,
        "end": 3605.5
      },
      "iou": 0.12280701754383165,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.699999999999818,
        "end": 2.300000000000182,
        "average": 2.5
      },
      "rationale_metrics": {
        "rouge_l": 0.4285714285714286,
        "text_similarity": 0.8472215533256531,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the sequence and meaning (speaker thanks audience, then says the session will be recorded and resources provided) but the timecodes are shifted later by about 2.3\u20132.7 seconds and the quoted wording is slightly altered, so it is a partial but not exact match."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'where did we start?', when does she mention considering moving to Near Me for patient contacts?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2332.719,
        "end": 2336.344
      },
      "pred_interval": {
        "start": 2333.0,
        "end": 2337.0
      },
      "iou": 0.7811259051623665,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.28099999999994907,
        "end": 0.6559999999999491,
        "average": 0.46849999999994907
      },
      "rationale_metrics": {
        "rouge_l": 0.3684210526315789,
        "text_similarity": 0.7910867929458618,
        "llm_judge_score": 9,
        "llm_judge_justification": "Predicted anchor time matches exactly and target start/end times are very close to the reference (within ~0.3\u20130.7s); the predicted quote is correct. The only minor issue is the relationship labeled as 'after' rather than the more specific 'direct follow-up.'"
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says the pandemic came along, when does she mention adopting Near Me as their default for routine people?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2367.217,
        "end": 2412.045
      },
      "pred_interval": {
        "start": 2407.0,
        "end": 2412.0
      },
      "iou": 0.11153743196216656,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.7829999999999,
        "end": 0.04500000000007276,
        "average": 19.913999999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.8464353084564209,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the correct event and the 'after' relationship and even quotes the relevant phrase, but the target start time is substantially misaligned (~2407s vs correct 2367s) and the anchor timing is slightly off, so the temporal details are not accurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the results of the focus groups for the qualitative study, when does she introduce the quotes from the participants?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2511.0,
        "end": 2512.0
      },
      "pred_interval": {
        "start": 2431.0,
        "end": 2434.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.0,
        "end": 78.0,
        "average": 79.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4044943820224719,
        "text_similarity": 0.8213958144187927,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the verbal introduction of participant quotes but the timestamps are substantially off (predicted ~2431\u20132434s vs correct 2511\u20132512s and anchor end 2469s), making it factually incorrect on the key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks to fill in the survey, when does he ask if listeners want to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3591.7,
        "end": 3595.8
      },
      "pred_interval": {
        "start": 3592.5,
        "end": 3598.0
      },
      "iou": 0.5238095238095376,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8000000000001819,
        "end": 2.199999999999818,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.48214285714285715,
        "text_similarity": 0.868155300617218,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both anchor and target and their relative ordering ('after'), preserving the main meaning; however the timestamps differ slightly from the reference and the prediction adds minor extra phrasing/end time not present in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Before the speaker thanks the speakers for their expertise, when does he mention the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3599.9,
        "end": 3603.7
      },
      "pred_interval": {
        "start": 3602.5,
        "end": 3605.5
      },
      "iou": 0.2142857142856853,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.599999999999909,
        "end": 1.800000000000182,
        "average": 2.2000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.2608695652173913,
        "text_similarity": 0.881171703338623,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that the mention occurs before the thank-you (correct relative order) and gives a nearby time window, but it mislabels the events, provides inaccurate/overlapping timestamps compared to the reference, and shifts the anchor timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker initially thanks the audience for joining, when does he deliver his final 'thank you very much' for the session?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3614.6,
        "end": 3615.4
      },
      "pred_interval": {
        "start": 3616.5,
        "end": 3617.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.900000000000091,
        "end": 1.599999999999909,
        "average": 1.75
      },
      "rationale_metrics": {
        "rouge_l": 0.47706422018348627,
        "text_similarity": 0.8637603521347046,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase and the overall 'after' relationship, but the target timing is shifted by about 1\u20132 seconds from the ground truth and includes an unsupported detail about the video cutting, so it's not fully accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After Mark introduces Dr. John Mckeown and Dr. Naomi Dow, when does he ask Dr. Dow to describe how they've been using Near Me?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.48,
        "end": 34.4
      },
      "pred_interval": {
        "start": 31.5,
        "end": 35.5
      },
      "iou": 0.7213930348258704,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.019999999999999574,
        "end": 1.1000000000000014,
        "average": 0.5600000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.3243243243243243,
        "text_similarity": 0.7436825037002563,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the E2 question timing start (~31.5s) and the 'after' relation, but it significantly misstates E1 (anchor) ending time (31.0s vs the correct 15.72s) and slightly overestimates E2's end, so a key factual element is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Dr. Naomi Dow finishes explaining how students take part in consultations, when does Mark ask Dr. Mckeown about the impact on the teaching team?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.96,
        "end": 124.4
      },
      "pred_interval": {
        "start": 119.0,
        "end": 125.0
      },
      "iou": 0.8940397350993378,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.04000000000000625,
        "end": 0.5999999999999943,
        "average": 0.3200000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.34210526315789475,
        "text_similarity": 0.6636486053466797,
        "llm_judge_score": 10,
        "llm_judge_justification": "Predicted answer matches the reference semantically and temporally (timestamps differ by <1s) and preserves the 'once_finished' relation and content of the question, so it is effectively equivalent."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker introduces the concept of emotions in the session, when does the female speaker first mention 'real patients'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.9,
        "end": 202.6
      },
      "pred_interval": {
        "start": 203.0,
        "end": 204.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0999999999999943,
        "end": 1.9000000000000057,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.34567901234567905,
        "text_similarity": 0.7429955005645752,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies E1 and the 'after' relation and captures E2 as the first utterance of 'real patients', but the E2 timestamps are slightly off from the reference (about 1\u20132 seconds later and a longer end time), a minor temporal mismatch."
      }
    },
    {
      "question_id": "002",
      "question": "Once the interviewer finishes asking the question about comparing models, when does the female speaker finish explaining the advantages of 'Near Me' regarding real patients and capacity?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 198.7,
        "end": 306.9
      },
      "pred_interval": {
        "start": 199.0,
        "end": 267.0
      },
      "iou": 0.6284658040665435,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.30000000000001137,
        "end": 39.89999999999998,
        "average": 20.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.22471910112359553,
        "text_similarity": 0.5744110345840454,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the speaker, start time (approximately) and the topics ('real patients' and 'capacity'), but it misstates the interviewer's end time (198.0s vs 186.4s) and significantly underestimates the female speaker's finish time (267.0s vs 306.9s), so it is incomplete and partially inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the man is speaking on screen, when does he mention 'Near Me'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 342.0,
        "end": 344.0
      },
      "pred_interval": {
        "start": 346.5,
        "end": 347.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.5,
        "end": 3.0,
        "average": 3.75
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962022,
        "text_similarity": 0.47826045751571655,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the phrase occurs while the man is speaking, but both the speaker start time and the 'Near Me' timestamps conflict with the reference by several seconds and it adds an unsupported detail about subsequent wording, so it is largely temporally inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying 'Thank you and goodbye', when do the 'NHS Scotland' and 'Near Me' logos appear with text links?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 356.0,
        "end": 361.0
      },
      "iou": 0.4,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 1.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.25263157894736843,
        "text_similarity": 0.4590340256690979,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the logos appear immediately after the man finishes and remain until the segment end, but the provided timestamps (man at ~355.7s, logos 356.0\u2013361.0s) contradict the reference timings (350.0\u2013350.7s and 351.0\u2013360.0s), so it is factually inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the initial voiceover concludes with 'patient that day', when does the man on screen begin to say 'Thanks very much John and Amy'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 336.4,
        "end": 341.6
      },
      "pred_interval": {
        "start": 342.1,
        "end": 343.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.7000000000000455,
        "end": 2.1999999999999886,
        "average": 3.950000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.3023255813953489,
        "text_similarity": 0.7346088886260986,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the prediction preserves the order (E2 after E1), all provided timestamps contradict the ground truth by several seconds (E1 and E2 times are off by ~5\u20137s) and thus the timing information is largely incorrect."
      }
    }
  ]
}