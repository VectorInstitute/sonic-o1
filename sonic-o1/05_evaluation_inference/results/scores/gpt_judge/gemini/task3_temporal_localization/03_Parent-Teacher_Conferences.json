{
  "topic_id": 3,
  "topic_name": "Parent-Teacher Conferences",
  "num_evaluated": 548,
  "aggregated_metrics": {
    "mean_iou": 0.2253858097142175,
    "std_iou": 0.28680854414465773,
    "median_iou": 0.07296446334029966,
    "R@0.3": {
      "recall": 0.29927007299270075,
      "count": 164,
      "total": 548
    },
    "R@0.5": {
      "recall": 0.2062043795620438,
      "count": 113,
      "total": 548
    },
    "R@0.7": {
      "recall": 0.10766423357664233,
      "count": 59,
      "total": 548
    },
    "mae": {
      "start_mean": 11.230260948905096,
      "end_mean": 13.914812043795601,
      "average_mean": 12.572536496350349
    },
    "rationale": {
      "rouge_l_mean": 0.27788792973671245,
      "rouge_l_std": 0.08398475911888004,
      "text_similarity_mean": 0.6546616152092053,
      "text_similarity_std": 0.12166311213321802,
      "llm_judge_score_mean": 5.142335766423358,
      "llm_judge_score_std": 2.5669494698360475
    },
    "rationale_cider": 0.15069765103844188
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "Once the speaker states he used to be a teacher, when does he explain why he would be called upon to interpret?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 25.699,
        "end": 29.902
      },
      "pred_interval": {
        "start": 25.32,
        "end": 30.56
      },
      "iou": 0.8020992366412215,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.37900000000000134,
        "end": 0.6579999999999977,
        "average": 0.5184999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2790697674418604,
        "text_similarity": 0.6706633567810059,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the same utterances and semantic relation (E2 explains why he was called to interpret) with only minor timestamp discrepancies and a synonymous relation label ('after' vs 'once_finished'), so it largely matches the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker announces the opening poll, when does he start explaining how to format the name for the certificate?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 71.748,
        "end": 78.603
      },
      "pred_interval": {
        "start": 106.56,
        "end": 119.36
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.812,
        "end": 40.757000000000005,
        "average": 37.7845
      },
      "rationale_metrics": {
        "rouge_l": 0.21176470588235294,
        "text_similarity": 0.7395473718643188,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the opening poll timing (within the referenced interval) and the 'after' relation, but the predicted E2 times are substantially later than the ground-truth E2 (so the explanation segment is mislocalized), leading to an incorrect target span."
      }
    },
    {
      "question_id": "003",
      "question": "Next, after the speaker states that those who don't need a certificate can ignore the poll, when does he start explaining what to do if the pop-up doesn't appear?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 83.778,
        "end": 88.445
      },
      "pred_interval": {
        "start": 124.32,
        "end": 150.88
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.54199999999999,
        "end": 62.435,
        "average": 51.488499999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.17857142857142858,
        "text_similarity": 0.6602917313575745,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted E1 timestamp is close to the reference, but the predicted E2 timing is substantially incorrect (124.32\u2013150.88s vs correct 83.778\u201388.445s), which is a major factual mismatch; the relation label is essentially equivalent."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker mentions not leaving the webinar by 'X-ing out', when does he instruct to use the 'red button' to close out?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 172.8,
        "end": 174.7
      },
      "pred_interval": {
        "start": 174.0,
        "end": 177.0
      },
      "iou": 0.1666666666666644,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.1999999999999886,
        "end": 2.3000000000000114,
        "average": 1.75
      },
      "rationale_metrics": {
        "rouge_l": 0.24,
        "text_similarity": 0.7355688810348511,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target utterances and their temporal ordering ('after'), but the timestamp boundaries are inaccurate (anchor start/end misreported/omitted and target shifted later and extended), so it's only partially aligned with the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker says he will leave up the poll, when does he mention sharing links in the chat?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 193.9,
        "end": 195.4
      },
      "pred_interval": {
        "start": 196.0,
        "end": 199.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0999999999999943,
        "end": 3.5999999999999943,
        "average": 2.8499999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7661569118499756,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor event and the target mention and their temporal relationship ('after'), and the anchor time falls within the ground-truth interval; however, the predicted target start/end times are shifted later by ~2\u20133 seconds and the duration is overstated compared to the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the male speaker discusses the second link, a webinar called 'Translation for Teachers', when does he introduce the third link for the Refugee Services of Texas charity?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 231.5,
        "end": 236.0
      },
      "pred_interval": {
        "start": 233.0,
        "end": 239.0
      },
      "iou": 0.4,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5,
        "end": 3.0,
        "average": 2.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2702702702702703,
        "text_similarity": 0.7754938006401062,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the target link and that it comes after the anchor, and gives an approximately similar start time for E2, but it significantly misstates the anchor interval (232.0s vs 213.5\u2013218.5s) and shifts/extends the E2 interval (233.0\u2013239.0s vs 231.5\u2013236.0s), so the timestamps are not accurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once Graciela finishes asking the participants to unmute and then mute themselves, when does she say \"Perfect\"?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 380.807,
        "end": 381.3
      },
      "pred_interval": {
        "start": 384.0,
        "end": 385.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.1929999999999836,
        "end": 3.6999999999999886,
        "average": 3.446499999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.2941176470588235,
        "text_similarity": 0.5245728492736816,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the sequence (she says 'Perfect' after participants comply) but is temporally inaccurate: it mislabels the anchor event timing (gives a begin time 368s vs the correct finish at 374.2s) and places 'Perfect' at 384s rather than ~380.8\u2013381.3s."
      }
    },
    {
      "question_id": "002",
      "question": "Once Graciela finishes explaining how questions will be handled, when does she mention the glossary of terms?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 425.281,
        "end": 429.266
      },
      "pred_interval": {
        "start": 429.0,
        "end": 432.0
      },
      "iou": 0.039589224586995056,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.718999999999994,
        "end": 2.7339999999999804,
        "average": 3.2264999999999873
      },
      "rationale_metrics": {
        "rouge_l": 0.30434782608695654,
        "text_similarity": 0.6205859184265137,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly preserves the sequence and the quoted phrase, but the timestamps are noticeably shifted (predicts ~428s end vs 425.058s, and places the glossary at 429\u2013432s rather than 425.281\u2013429.266s), so the timing information is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the modes of interpretation used in educational settings, when does the slide transition to 'Educational Settings'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 560.8,
        "end": 560.9
      },
      "pred_interval": {
        "start": 547.0,
        "end": 549.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.799999999999955,
        "end": 11.899999999999977,
        "average": 12.849999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.2077922077922078,
        "text_similarity": 0.6861040592193604,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the ground truth timing: it places E2 much earlier (547\u2013549s) overlapping the anchor and not at the actual 560.8\u2013560.9s, so the temporal relation and times are largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker defines an educational setting, when does she list the types of institutions that can be included?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 575.0,
        "end": 585.8
      },
      "pred_interval": {
        "start": 583.0,
        "end": 592.0
      },
      "iou": 0.1647058823529385,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.0,
        "end": 6.2000000000000455,
        "average": 7.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.24615384615384614,
        "text_similarity": 0.5522885322570801,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same two events but the timestamps are substantially shifted (definition ends much later and the listing starts/ends later), so it contradicts the ground-truth timing and the claim that the listing immediately follows the definition."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining where interpreters are mostly called, when does the slide change to an image with a diploma and US flag?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 628.0,
        "end": 628.1
      },
      "pred_interval": {
        "start": 631.0,
        "end": 633.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 4.899999999999977,
        "average": 3.9499999999999886
      },
      "rationale_metrics": {
        "rouge_l": 0.2696629213483146,
        "text_similarity": 0.7848132848739624,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction recognizes the slide change occurs immediately after the explanation, but it gives substantially incorrect timestamps and an inconsistent duration (631.0\u2013633.0s) compared to the ground truth (E1 ends 627.0s; E2 at 628.0\u2013628.1s), so it is largely factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the mandatory schooling age in the United States, when do they state the mandatory schooling age in Mexico?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 749.416,
        "end": 751.6
      },
      "pred_interval": {
        "start": 753.0,
        "end": 756.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5839999999999463,
        "end": 4.399999999999977,
        "average": 3.991999999999962
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195122,
        "text_similarity": 0.8126338124275208,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relative relation that the Mexico event follows immediately after the US event, but it misstates the absolute timestamps (off by ~4\u20135s) and extends the intervals, and it adds specific ages not given in the ground truth, so it does not match the reference closely."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker describes the grades for middle school or junior high in the United States, when do they describe the equivalent 'secundaria' grades in Mexico?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 804.2,
        "end": 809.5
      },
      "pred_interval": {
        "start": 808.0,
        "end": 814.0
      },
      "iou": 0.15306122448979662,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.7999999999999545,
        "end": 4.5,
        "average": 4.149999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.8661346435546875,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the ordering (E2 occurs immediately after E1) and the grade labels, but the reported timestamps are substantially offset from the ground truth (both start and end times mismatch by several seconds), so it is not temporally accurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning the number of public schools in the U.S. in 2021, when does she state the average number of students per public school?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.167,
        "end": 877.377
      },
      "pred_interval": {
        "start": 876.5,
        "end": 881.3
      },
      "iou": 0.10783228820852832,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.33299999999997,
        "end": 3.923000000000002,
        "average": 3.627999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.25316455696202533,
        "text_similarity": 0.7149070501327515,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the quoted phrases and the 'once finished' relation, but the temporal boundaries are significantly offset (predicted E1/E2 start and end times are ~3.3s later than the ground truth), so the timestamps do not match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states the total allocation for K-12 schools, when does she mention the average amount per student?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 920.147,
        "end": 925.432
      },
      "pred_interval": {
        "start": 924.0,
        "end": 929.5
      },
      "iou": 0.15310595530845972,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.852999999999952,
        "end": 4.067999999999984,
        "average": 3.9604999999999677
      },
      "rationale_metrics": {
        "rouge_l": 0.27499999999999997,
        "text_similarity": 0.6779171228408813,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the average-per-student figure (~$12,600) follows the total-allocation statement, but it misstates both event timestamps (shifting them later) and erroneously inserts a '$12,000' value, so key temporal and factual details are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning 'disciplinary meetings', when does she mention 'classroom instruction'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1191.5,
        "end": 1192.5
      },
      "pred_interval": {
        "start": 1192.6,
        "end": 1194.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.099999999999909,
        "end": 1.7000000000000455,
        "average": 1.3999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.26229508196721313,
        "text_similarity": 0.633822500705719,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the order/relation (disciplinary meetings then classroom instruction) but the timestamps conflict with the reference: it shifts the end/start times by about 1.0\u20131.1 seconds and extends the classroom interval to 1194.2s instead of 1192.5s, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker is listing the participants of ARD Meetings, when does she specifically mention the 'District Representative'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1240.5,
        "end": 1245.0
      },
      "pred_interval": {
        "start": 1242.6,
        "end": 1244.6
      },
      "iou": 0.4444444444444444,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.099999999999909,
        "end": 0.40000000000009095,
        "average": 1.25
      },
      "rationale_metrics": {
        "rouge_l": 0.20000000000000004,
        "text_similarity": 0.5361722707748413,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted timing (1242.6\u20131244.6s) falls within the reference interval (1240.5\u20131245.0s) and correctly indicates the phrase is spoken during the participants list, matching the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes listing the participants of an ARD meeting, when does she begin discussing the purpose of the meeting?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1249.5,
        "end": 1252.8
      },
      "pred_interval": {
        "start": 1250.6,
        "end": 1331.0
      },
      "iou": 0.026993865030675405,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.099999999999909,
        "end": 78.20000000000005,
        "average": 39.64999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195122,
        "text_similarity": 0.5062737464904785,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the immediate transition to the 'Purpose' topic, but the timestamps do not match the ground truth (predicted listing end/start and especially the end time at 1331.0s conflict with the reference 1248.0\u20131252.8s) and it adds unsupported extended content, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker asks about the reasons for an ARD meeting, when does she state the first reason?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1294.4,
        "end": 1296.1
      },
      "pred_interval": {
        "start": 1335.5,
        "end": 1347.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.09999999999991,
        "end": 50.90000000000009,
        "average": 46.0
      },
      "rationale_metrics": {
        "rouge_l": 0.1875,
        "text_similarity": 0.47626858949661255,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the first reason's wording but gives timestamps that are ~40 seconds later than the ground truth, so the temporal information is factually incorrect and misaligned."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks about the different purposes of the ARD meeting, when does she start listing the initial purposes?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1445.358,
        "end": 1450.41
      },
      "pred_interval": {
        "start": 1447.0,
        "end": 1453.0
      },
      "iou": 0.4462182674692565,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.6420000000000528,
        "end": 2.589999999999918,
        "average": 2.1159999999999854
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666669,
        "text_similarity": 0.5850186347961426,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that the listing occurs after the question and matches the listed items, but it misstates/omits the exact E1 start and gives E1/E2 timestamps that are several seconds later than the reference, and it extends E2 beyond the correct end time."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide fully displays the 'Review Assessment' section, when does the speaker specifically mention the 'full individual evaluation'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.092,
        "end": 1432.125
      },
      "pred_interval": {
        "start": 1481.0,
        "end": 1484.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.9079999999999,
        "end": 51.875,
        "average": 52.39149999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.375,
        "text_similarity": 0.7172791957855225,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the events and that the speaker says 'full individual evaluation' after the slide, but the provided timestamps are significantly off (by ~46\u201356 seconds) from the ground truth, so the timing is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing parental input, when does the text for 'Review PLAAFP' appear on the slide?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1531.58,
        "end": 1532.59
      },
      "pred_interval": {
        "start": 1530.0,
        "end": 1532.0
      },
      "iou": 0.16216216216219537,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5799999999999272,
        "end": 0.5899999999999181,
        "average": 1.0849999999999227
      },
      "rationale_metrics": {
        "rouge_l": 0.3283582089552239,
        "text_similarity": 0.561843991279602,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction preserves the event order (E2 after E1) but the timestamps are noticeably off (both E1 and E2 ~1.5s earlier than the ground truth) and it omits the detail that the text is fully visible by 1532.59s, so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions being 'completely clueless' about the ARD meetings, when does she state that the terminology was 'so scary'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1602.75,
        "end": 1607.38
      },
      "pred_interval": {
        "start": 1607.0,
        "end": 1608.8
      },
      "iou": 0.06280991735539042,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.25,
        "end": 1.4199999999998454,
        "average": 2.8349999999999227
      },
      "rationale_metrics": {
        "rouge_l": 0.24390243902439024,
        "text_similarity": 0.6120325326919556,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and the 'after' relation, but the provided timestamps/spans are wildly incorrect/inconsistent with the reference, so it fails key temporal accuracy requirements."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker states 'I am an interpreter', when does she recount the other interpreter responding 'I have to interpret'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1656.82,
        "end": 1658.744
      },
      "pred_interval": {
        "start": 1659.0,
        "end": 1661.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.1800000000000637,
        "end": 2.7560000000000855,
        "average": 2.4680000000000746
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.6564180850982666,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction identifies the correct anchor and target events and the 'immediately following' relation, but the provided timestamps are shifted by ~1\u20133 seconds from the ground-truth intervals, so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker reviews the IEP goals and objectives, when does she begin to review accommodations?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1758.266,
        "end": 1760.028
      },
      "pred_interval": {
        "start": 1761.0,
        "end": 1764.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.7339999999999236,
        "end": 3.97199999999998,
        "average": 3.352999999999952
      },
      "rationale_metrics": {
        "rouge_l": 0.24657534246575344,
        "text_similarity": 0.6808325052261353,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after'), but the reported timestamps are noticeably off from the reference (anchor ~2.1s late, target start ~2.7s late and end ~4.0s late), so it fails to match the precise times given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes discussing the previous assessment, when does she mention the proposal of the STAAR assessment?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1783.7,
        "end": 1791.4
      },
      "pred_interval": {
        "start": 1788.16,
        "end": 1795.12
      },
      "iou": 0.28371278458844595,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.460000000000036,
        "end": 3.7199999999998,
        "average": 4.089999999999918
      },
      "rationale_metrics": {
        "rouge_l": 0.2564102564102564,
        "text_similarity": 0.6617682576179504,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relation (E2 starts immediately after E1) but the timestamps are substantially shifted (E1/E2 times differ by ~4\u20137s from the ground truth) and it adds unsupported details about content, so it is not accurately aligned."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker concludes the topic of district-wide assessments and accommodations, when does she introduce the least restrictive environment?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1810.5,
        "end": 1815.2
      },
      "pred_interval": {
        "start": 1814.53,
        "end": 1818.52
      },
      "iou": 0.08354114713217883,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.029999999999973,
        "end": 3.3199999999999363,
        "average": 3.6749999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.4691358024691358,
        "text_similarity": 0.7505279779434204,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the same utterance and relation (introducing the least restrictive environment after the district-wide assessments), but the timestamp boundaries are shifted by ~3\u20134 seconds for both anchor and target and the end time differs, so it is not temporally accurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing the potential harmful effects of an instruction setting, when does she question if the benefits outweigh the harm?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1854.7,
        "end": 1857.3
      },
      "pred_interval": {
        "start": 1887.55,
        "end": 1891.56
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.84999999999991,
        "end": 34.25999999999999,
        "average": 33.55499999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.4146341463414634,
        "text_similarity": 0.7501295804977417,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the quoted question and correct relation (E2 follows E1), but the provided timestamps are substantially off from the reference (\u224835\u201340s difference), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says she will send glossaries to Marco, when does she introduce disciplinary action meetings?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1969.3,
        "end": 1975.0
      },
      "pred_interval": {
        "start": 1970.0,
        "end": 1979.0
      },
      "iou": 0.5154639175257708,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7000000000000455,
        "end": 4.0,
        "average": 2.3500000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.6318730115890503,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that the introduction of disciplinary meetings occurs after the glossaries, but the timestamps are notably shifted (E1 end is ~3\u20134s late and E2 start/end are ~1\u20134s later than the reference) and the predicted end time for E2 extends beyond the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining when disciplinary actions happen, when does the slide transition to 'Potential disciplinary outcomes'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2006.4,
        "end": 2007.1
      },
      "pred_interval": {
        "start": 2009.0,
        "end": 2012.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.599999999999909,
        "end": 4.900000000000091,
        "average": 3.75
      },
      "rationale_metrics": {
        "rouge_l": 0.379746835443038,
        "text_similarity": 0.7342450618743896,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the ordering (slide follows speaker) but the timestamps are off by ~2\u20133 seconds from the reference and it adds unverified details (code of conduct, speaker acknowledgment) while omitting the precise settle time, so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what skills are needed to interpret in an educational setting, when does she define the interpreter's role?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2161.0,
        "end": 2168.0
      },
      "pred_interval": {
        "start": 2161.0,
        "end": 2168.0
      },
      "iou": 1.0,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 0.0,
        "average": 0.0
      },
      "rationale_metrics": {
        "rouge_l": 0.28205128205128205,
        "text_similarity": 0.5215618014335632,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly locates the definition (2161\u20132168s) and places the question just prior (\u22482154s), preserving the 'after' relation; it omits the question's explicit end time (2159s) but otherwise matches semantically. "
      }
    },
    {
      "question_id": "003",
      "question": "During the discussion about accuracy and completeness, when does the speaker give the specific advice to 'say what was said'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2175.0,
        "end": 2184.0
      },
      "pred_interval": {
        "start": 2237.0,
        "end": 2239.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.0,
        "end": 55.0,
        "average": 58.5
      },
      "rationale_metrics": {
        "rouge_l": 0.21212121212121213,
        "text_similarity": 0.5053541660308838,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the advice phrase and context but gives substantially different timestamps (2223s/2237\u20132239s) than the reference (2163\u20132184s with advice 2175\u20132184s), so the timing is incorrect and the answer fails to match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker stops sharing the slides, when does the video switch to the gallery view of the participants?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2465.33,
        "end": 2475.337
      },
      "pred_interval": {
        "start": 2465.0,
        "end": 2467.0
      },
      "iou": 0.1615555770533109,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.32999999999992724,
        "end": 8.336999999999989,
        "average": 4.333499999999958
      },
      "rationale_metrics": {
        "rouge_l": 0.3111111111111111,
        "text_similarity": 0.6844171285629272,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events and their timestamps (within ~0.5s) and the switch to gallery view; it omits the later completion timestamp (2475.337s) and phrases the relation as 'immediately after' instead of 'once_finished'."
      }
    },
    {
      "question_id": "002",
      "question": "After the 'Simultaneous Interpreting' slide is displayed, when does the speaker mention ARD meetings as a use case?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2409.449,
        "end": 2418.605
      },
      "pred_interval": {
        "start": 2410.0,
        "end": 2412.0
      },
      "iou": 0.21843599825251322,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.5509999999999309,
        "end": 6.605000000000018,
        "average": 3.5779999999999745
      },
      "rationale_metrics": {
        "rouge_l": 0.26865671641791045,
        "text_similarity": 0.7348774671554565,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies both events and the spoken phrase, and E2's start time is close to the reference, but E1's timestamp is off by ~15 seconds and the prediction omits E2's end time, so it is incomplete/partially inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker asks if everyone is still awake, when does she begin to explain the practice method?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2490.175,
        "end": 2497.855
      },
      "pred_interval": {
        "start": 2479.0,
        "end": 2485.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.175000000000182,
        "end": 12.855000000000018,
        "average": 12.0150000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.24175824175824176,
        "text_similarity": 0.6406164169311523,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the 'Are we still awake?' utterance (timing close to reference) and keeps the 'after' relation, but it places the practice-method explanation ~11s earlier than the ground truth and introduces specific logistical details (addressing the moderator, group-size change) not supported by the reference, so the target event timing and content are inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states that everyone at home will be interpreting, when does she ask if everyone is good with the plan?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2513.9,
        "end": 2515.1
      },
      "pred_interval": {
        "start": 2515.0,
        "end": 2518.0
      },
      "iou": 0.024390243902417383,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.099999999999909,
        "end": 2.900000000000091,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24,
        "text_similarity": 0.520899772644043,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly locates the question around 2515s, but it significantly misaligns the explanation span (E1 is shifted later by several seconds) and extends/augments E2 with extra dialogue not in the reference; overall timestamps and added content are inconsistent with the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks to discuss a classroom concern about Peter, when does she describe Peter as a sweet boy who enjoys stacking blocks?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2558.467,
        "end": 2564.21
      },
      "pred_interval": {
        "start": 2560.0,
        "end": 2569.0
      },
      "iou": 0.3996961929175046,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5329999999999018,
        "end": 4.789999999999964,
        "average": 3.1614999999999327
      },
      "rationale_metrics": {
        "rouge_l": 0.2941176470588235,
        "text_similarity": 0.6450914740562439,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the events, order, and quoted content, but the time intervals are slightly shifted (notably E2 ends ~4.8s later than the reference), so it\u2019s largely accurate with minor timestamp discrepancies."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions Peter may benefit from special education services, when does she discuss the social worker's assessment and concerns at home?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2595.389,
        "end": 2610.228
      },
      "pred_interval": {
        "start": 2597.0,
        "end": 2612.0
      },
      "iou": 0.7963397748480021,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.6109999999998763,
        "end": 1.7719999999999345,
        "average": 1.6914999999999054
      },
      "rationale_metrics": {
        "rouge_l": 0.30357142857142855,
        "text_similarity": 0.7281321287155151,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted timings closely match the reference intervals and correctly indicate that the social worker assessment (E2) follows the mention of special education (E1); differences are minor and do not affect correctness."
      }
    },
    {
      "question_id": "001",
      "question": "During the main speaker's instructions for showing thumbs up, sideways, or down, when do multiple participants start showing their reactions?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2731.0,
        "end": 2736.0
      },
      "pred_interval": {
        "start": 2733.0,
        "end": 2745.0
      },
      "iou": 0.21428571428571427,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 9.0,
        "average": 5.5
      },
      "rationale_metrics": {
        "rouge_l": 0.27499999999999997,
        "text_similarity": 0.7026629447937012,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that participants react during the speaker's instructions, but it misstates both event timings and durations (E1 start/end and E2 start and end are shifted later and the reaction window is greatly extended), so it is only a partial, inaccurate match."
      }
    },
    {
      "question_id": "002",
      "question": "After the main speaker asks Marco if he has anything to say, when does Marco start talking about the link he shared?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2760.32,
        "end": 2763.065
      },
      "pred_interval": {
        "start": 2761.0,
        "end": 2808.0
      },
      "iou": 0.043309563758390554,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.6799999999998363,
        "end": 44.934999999999945,
        "average": 22.80749999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324323,
        "text_similarity": 0.5633186101913452,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies Marco starting to talk about the link around 2761s (close to 2760.320s), but it misstates the anchor end time and greatly overextends Marco's speaking duration (claiming continuation to 2808s), which contradicts the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Okay' to transition, when does she start talking about questions related to a child's behavior for a rating scale?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2838.512,
        "end": 2846.226
      },
      "pred_interval": {
        "start": 2835.0,
        "end": 2847.0
      },
      "iou": 0.6428333333333285,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.512000000000171,
        "end": 0.7739999999998872,
        "average": 2.143000000000029
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195125,
        "text_similarity": 0.6880170106887817,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction identifies the same two events but the timestamps are notably off (E1 by ~2.3s and E2 by ~3.5s) and it incorrectly asserts an immediate topic start, whereas the reference indicates a gap before the new topic begins. These timing inaccuracies reduce correctness though the general events are matched."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes instructing to write 'DK' if the answer is unknown, when does she start reading the first child-related question?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2867.07,
        "end": 2872.84
      },
      "pred_interval": {
        "start": 2870.5,
        "end": 2877.2
      },
      "iou": 0.23099703849952866,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.4299999999998363,
        "end": 4.359999999999673,
        "average": 3.8949999999997544
      },
      "rationale_metrics": {
        "rouge_l": 0.29508196721311475,
        "text_similarity": 0.4221653938293457,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the event order ('after') and provides start/end times, but the timestamps materially differ from the reference (anchor ~8s late, target start/end ~3\u20134s late), so it's only partially accurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'My child often argues with adults', when does she start reading the next child-related question?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2888.82,
        "end": 2892.66
      },
      "pred_interval": {
        "start": 2892.0,
        "end": 2897.2
      },
      "iou": 0.07875894988065414,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.1799999999998363,
        "end": 4.539999999999964,
        "average": 3.8599999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.4385386109352112,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction identifies the same anchor and next question and correctly states the temporal relation ('after'), but the reported timestamps are several seconds later than the ground truth (anchor ~+3.2s, target start ~+3.2s, target end ~+4.5s), which reduces accuracy."
      }
    },
    {
      "question_id": "003",
      "question": "After the video screen changes to a black view displaying names, when does the speaker read the question about the child blurring out answers?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2930.0,
        "end": 2934.78
      },
      "pred_interval": {
        "start": 2975.5,
        "end": 2981.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.5,
        "end": 46.41999999999962,
        "average": 45.95999999999981
      },
      "rationale_metrics": {
        "rouge_l": 0.27027027027027023,
        "text_similarity": 0.49591371417045593,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the relationship ('after') and event types, but the timestamps are significantly incorrect (off by ~48 seconds and with mismatched event durations), so it does not match the reference answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker describes a child having difficulty waiting for their turn, when does she describe a child being constantly on the go?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3036.8,
        "end": 3044.7
      },
      "pred_interval": {
        "start": 3041.0,
        "end": 3049.0
      },
      "iou": 0.3032786885245798,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.199999999999818,
        "end": 4.300000000000182,
        "average": 4.25
      },
      "rationale_metrics": {
        "rouge_l": 0.23157894736842105,
        "text_similarity": 0.6805238723754883,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target utterances but the timestamps are noticeably shifted (anchor ~+2s/ +1s, target starts ~+4s and ends ~+4s) and it labels the relation merely as 'after' rather than the correct 'immediately follows', so it only partially matches."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing a child being often forgetful in daily activities, when does she ask the audience how they did?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3099.8,
        "end": 3101.4
      },
      "pred_interval": {
        "start": 3103.0,
        "end": 3106.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.199999999999818,
        "end": 4.599999999999909,
        "average": 3.8999999999998636
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.6776950359344482,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the target question follows the anchor, but the reported timestamps are substantially offset from the ground truth (anchor end and target start differ by several seconds), and the target duration/end times are also incorrect, so the answer is not sufficiently accurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks about the remaining time, when does Marco start responding?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3134.1,
        "end": 3139.2
      },
      "pred_interval": {
        "start": 3138.0,
        "end": 3144.0
      },
      "iou": 0.12121212121210173,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.900000000000091,
        "end": 4.800000000000182,
        "average": 4.350000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.23404255319148937,
        "text_similarity": 0.6657357811927795,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that Marco's reply follows the question, but the timestamps are substantially off (predicted start 3138.0s vs correct 3134.1s and differing end times), and it adds verbatim speech not present in the reference; thus it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "Once Frank finishes asking if the 504 plan is inside the subject of special education, when does the woman in green confirm that it is?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3235.829,
        "end": 3239.914
      },
      "pred_interval": {
        "start": 3240.8,
        "end": 3245.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.971000000000004,
        "end": 5.585999999999785,
        "average": 5.2784999999998945
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413793,
        "text_similarity": 0.6223236918449402,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that the woman immediately confirms the 504 plan and quotes her line, but the event timestamps are off by ~5\u20136 seconds (both start and end) and the end-time is extended, so timing accuracy is lacking though the relation is semantically similar."
      }
    },
    {
      "question_id": "002",
      "question": "Once Frank finishes stating that he thinks 504 is federal language, when does another woman ask for confirmation?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.61,
        "end": 3269.733
      },
      "pred_interval": {
        "start": 3273.0,
        "end": 3274.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.389999999999873,
        "end": 4.766999999999825,
        "average": 4.578499999999849
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962022,
        "text_similarity": 0.5797303915023804,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two events and that the woman asks for confirmation shortly after Frank, but the reported timestamps differ by ~4 seconds from the reference and the relation is labeled 'after' rather than the specific 'once_finished'; additionally the predicted answer adds an unreferenced detail ('woman in green')."
      }
    },
    {
      "question_id": "003",
      "question": "Once Jesse Thompson finishes asking how interpreters can stand up for themselves, when does the woman in green explain what interpreters have control over?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3361.672,
        "end": 3367.782
      },
      "pred_interval": {
        "start": 3326.8,
        "end": 3333.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.871999999999844,
        "end": 34.28200000000015,
        "average": 34.577
      },
      "rationale_metrics": {
        "rouge_l": 0.30303030303030304,
        "text_similarity": 0.6105859279632568,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer captures the content and the immediate/once_finished relation, but all three timestamps are off by ~34 seconds (outside the allowed tolerance), so the timing is incorrect despite correct semantic content."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying she doesn't like being 'used' as an interpreter, when does she begin explaining what she needs for a successful encounter?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3404.5,
        "end": 3411.6
      },
      "pred_interval": {
        "start": 3405.5,
        "end": 3425.0
      },
      "iou": 0.29756097560975164,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 13.400000000000091,
        "average": 7.2000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.20618556701030927,
        "text_similarity": 0.5574514865875244,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the target follows the anchor and that the speaker begins explaining needs immediately after, but the timestamps are substantially off (anchor/target start times differ by ~1\u20135s and the predicted end time far exceeds the reference) and it introduces extra/unverified detail, so it is only a partial match."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that rules can be set ahead of time for pre-sessions, when does she explain what raising a hand means?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3433.1,
        "end": 3436.5
      },
      "pred_interval": {
        "start": 3431.0,
        "end": 3447.0
      },
      "iou": 0.21250000000000568,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.099999999999909,
        "end": 10.5,
        "average": 6.2999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.25287356321839083,
        "text_similarity": 0.7439572811126709,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the target follows, and captures the target's content, but its timing is off (target start ~2s early and end extended ~10s beyond the reference), adding an inaccurate extended conclusion."
      }
    },
    {
      "question_id": "003",
      "question": "Once the female speaker replies 'Yes' to the question about doing work on Zoom, when does she explain how consecutive interpreting works on Zoom?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3471.0,
        "end": 3493.0
      },
      "pred_interval": {
        "start": 3479.0,
        "end": 3494.0
      },
      "iou": 0.6086956521739131,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.0,
        "end": 1.0,
        "average": 4.5
      },
      "rationale_metrics": {
        "rouge_l": 0.26804123711340205,
        "text_similarity": 0.7250016927719116,
        "llm_judge_score": 7,
        "llm_judge_justification": "The anchor timing is correct and the predicted target overlaps and correctly describes the consecutive interpreting content, but it omits the earlier portion of the explanation (starts ~8s later than reference) and has a slight end-time discrepancy, so it is not fully complete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"And then you as the interpreter will go into that room as well,\" when does she explain what the attendees can hear?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3584.889,
        "end": 3595.545
      },
      "pred_interval": {
        "start": 3589.0,
        "end": 3597.0
      },
      "iou": 0.540417801998195,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.110999999999876,
        "end": 1.4549999999999272,
        "average": 2.7829999999999018
      },
      "rationale_metrics": {
        "rouge_l": 0.36893203883495146,
        "text_similarity": 0.7476065158843994,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase, the explanatory content, and that the explanation occurs after the instruction (matches 'once_finished'), but the timestamps are slightly offset (E1 ~1s later, E2 begins ~4s later and ends later than the reference), so timing precision is imperfect."
      }
    },
    {
      "question_id": "002",
      "question": "After Martha Rosenbaum mentions that schools receive a lot of funding from the government, when does she ask how to change the use of teachers as translators?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3629.646,
        "end": 3632.125
      },
      "pred_interval": {
        "start": 3634.0,
        "end": 3641.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.3539999999998145,
        "end": 8.875,
        "average": 6.614499999999907
      },
      "rationale_metrics": {
        "rouge_l": 0.20512820512820512,
        "text_similarity": 0.6778501272201538,
        "llm_judge_score": 4,
        "llm_judge_justification": "The anchor interval is reasonably close to the ground truth, and the relation 'after' matches, but the target interval is substantially later and much longer than the reference (and includes extra quoted wording), so the prediction is not temporally precise or fully faithful."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker first mentions \"Executive Order 13166,\" when does she expand on its details, including its signing by President Clinton?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3669.853,
        "end": 3689.291
      },
      "pred_interval": {
        "start": 3672.0,
        "end": 3684.0
      },
      "iou": 0.6173474637308333,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.1469999999999345,
        "end": 5.291000000000167,
        "average": 3.719000000000051
      },
      "rationale_metrics": {
        "rouge_l": 0.27659574468085113,
        "text_similarity": 0.7728849053382874,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the initial mention and the elaboration (including Clinton signing) with reasonably close timestamps, but it shifts the start/end times slightly and labels the relation as simply 'after' rather than the immediate 'once_finished' described in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that organizations receiving federal funds must provide meaningful language access, when does she suggest starting those conversations?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3762.0,
        "end": 3764.7
      },
      "pred_interval": {
        "start": 3764.5,
        "end": 3767.0
      },
      "iou": 0.03999999999996362,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 2.300000000000182,
        "average": 2.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.2077922077922078,
        "text_similarity": 0.6566726565361023,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the relation (target immediately follows anchor and includes the quoted phrase) but the timestamps are noticeably off (predicted ~3764.5\u20133767.0s vs. correct 3762.0\u20133764.7s), so it is factually inaccurate on key timing details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male speaker jokes about Google Translate replacing human interpreters, when does Maria E. Mendoza respond with 'Exactly!'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3789.6,
        "end": 3790.5
      },
      "pred_interval": {
        "start": 3791.6,
        "end": 3792.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 2.300000000000182,
        "average": 2.150000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.30303030303030304,
        "text_similarity": 0.6519395112991333,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the immediate-following relation but the provided timestamps are off by about 5\u20136 seconds and durations differ from the reference, so the answer is temporally incorrect despite correct sequence."
      }
    },
    {
      "question_id": "003",
      "question": "Once Susanna finishes asking if the Zoom environment for interpreting school meetings is common in other states, when does Maria E. Mendoza begin to respond?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3933.2,
        "end": 3934.2
      },
      "pred_interval": {
        "start": 3903.5,
        "end": 3908.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.699999999999818,
        "end": 26.199999999999818,
        "average": 27.949999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.666102945804596,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies Maria E. Mendoza as the responder and reasonably paraphrases her opening phrase, but the anchor/target timestamps are substantially off (~20 seconds earlier) and thus do not match the reference timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once Maria E. Mendosa finishes saying people are getting more comfortable with in-person meetings, when does the next speaker begin to add her point?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3956.6,
        "end": 3957.8
      },
      "pred_interval": {
        "start": 3960.0,
        "end": 3963.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.400000000000091,
        "end": 5.199999999999818,
        "average": 4.2999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.2926829268292683,
        "text_similarity": 0.6383405327796936,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the speakers, the phrase ('I just wanted to add one thing') and that the next speaker begins about one second after Maria, matching the reference; only minor timestamp rounding/precision differences exist. "
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria E. Mendosa interrupts to say 'This is gonna help you feel better', when does she start talking about her conversation with a school district client?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 4002.0,
        "end": 4007.6
      },
      "pred_interval": {
        "start": 4005.0,
        "end": 4011.0
      },
      "iou": 0.28888888888887876,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 3.400000000000091,
        "average": 3.2000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.38636363636363635,
        "text_similarity": 0.47931134700775146,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately conveys that E2 starts immediately after E1 and gives an equivalent ~6-second span for the same utterance (01:15\u201301:21), so it matches the reference despite using a different timestamp format."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks to hear from Alejandra Mendez, when does Alejandra Mendez start speaking?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 4096.7,
        "end": 4098.5
      },
      "pred_interval": {
        "start": 4098.0,
        "end": 4102.0
      },
      "iou": 0.0943396226415062,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.300000000000182,
        "end": 3.5,
        "average": 2.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.21875,
        "text_similarity": 0.6632061004638672,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies that Alejandra begins after a short pause and pins the start near 4098s (02:48), which is very close to the reference start at 4096.7s; however it has a small timestamp/conversion inconsistency and is off by about 1\u20132 seconds."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says that the meetings are emotionally exhausting, when does Maria ask if the volume of meetings for Spanish-speaking families has increased?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4154.13,
        "end": 4166.78
      },
      "pred_interval": {
        "start": 4158.0,
        "end": 4171.0
      },
      "iou": 0.5204505038529817,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.869999999999891,
        "end": 4.220000000000255,
        "average": 4.045000000000073
      },
      "rationale_metrics": {
        "rouge_l": 0.1951219512195122,
        "text_similarity": 0.5955899357795715,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target, preserves their ordering and the content of Maria's question; the timestamps are slightly shifted (anchor ~2\u20134s late, target ~4s late and ends a few seconds later) but are otherwise accurate and within reasonable tolerance."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that there is more parent participation because it is easier, when does she mention a teacher requesting an in-person interpreter for initial ARD meetings?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4232.2,
        "end": 4238.0
      },
      "pred_interval": {
        "start": 4194.0,
        "end": 4203.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.19999999999982,
        "end": 35.0,
        "average": 36.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.6867191791534424,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer roughly locates the anchor correctly, but the target timestamp is significantly earlier (~4194\u20134203s vs correct 4232.2\u20134238.0s) and thus fails the key relation that the target follows the anchor; this timing/order error is a major mismatch."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host says, 'let's do one more question from Jesse,' when does Jesse begin asking about teachers interpreting?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4340.45,
        "end": 4347.8
      },
      "pred_interval": {
        "start": 4349.0,
        "end": 4352.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.550000000000182,
        "end": 4.199999999999818,
        "average": 6.375
      },
      "rationale_metrics": {
        "rouge_l": 0.17142857142857143,
        "text_similarity": 0.5862532258033752,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly locates the host prompt (around 4335s) but places Jesse's start notably later (4349\u20134352s) than the reference (~4340.45s) and introduces an explicit quoted phrasing not stated in the ground truth, so it is partially inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once Jesse finishes asking about legal liability for teachers interpreting, when does Maria state there isn't a government push for certification?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4367.0,
        "end": 4370.11
      },
      "pred_interval": {
        "start": 4371.0,
        "end": 4375.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 4.890000000000327,
        "average": 4.445000000000164
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.5859992504119873,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly reports Maria's statement content, but the timestamps are shifted (Maria given at 4371\u20134375s vs. reference ~4367s) and Jesse's question timing (E1) is mislocated, so timing accuracy is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After Maria instructs to Google 'Executive Order 13166', when does she mention the CLASs standards for healthcare organizations?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4461.82,
        "end": 4474.23
      },
      "pred_interval": {
        "start": 4468.0,
        "end": 4472.0
      },
      "iou": 0.3223207091055638,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.180000000000291,
        "end": 2.2299999999995634,
        "average": 4.204999999999927
      },
      "rationale_metrics": {
        "rouge_l": 0.24657534246575344,
        "text_similarity": 0.604727029800415,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events and their timings close to the reference; however, E2 is reported to start ~6s later and end ~2s earlier than the ground truth, slightly underestimating its full span."
      }
    },
    {
      "question_id": "001",
      "question": "After Maria E. Mendoza explains Executive Order 13166, when does Jon Thompson ask about the regulation's enforcement mechanisms?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4470.0,
        "end": 4612.51
      },
      "gt_interval": {
        "start": 4479.38,
        "end": 4496.58
      },
      "pred_interval": {
        "start": 4479.64,
        "end": 4497.44
      },
      "iou": 0.9379844961240353,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.2600000000002183,
        "end": 0.8599999999996726,
        "average": 0.5599999999999454
      },
      "rationale_metrics": {
        "rouge_l": 0.3181818181818182,
        "text_similarity": 0.7336478233337402,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies that Jon asks about enforcement and labels the relation 'after', with target timestamps close to the reference; however the anchor end time is off by ~2s and is misleadingly described as the 'very beginning' of the clip, so there are minor timing/inaccuracy issues."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria E. Mendoza finishes stating her uncertainty about the executive order's trickle-down effect to individual schools, when does she mention the federal government's right to withdraw funds?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4470.0,
        "end": 4612.51
      },
      "gt_interval": {
        "start": 4508.48,
        "end": 4516.58
      },
      "pred_interval": {
        "start": 4508.8,
        "end": 4515.36
      },
      "iou": 0.8098765432097773,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.32000000000061846,
        "end": 1.2200000000002547,
        "average": 0.7700000000004366
      },
      "rationale_metrics": {
        "rouge_l": 0.33707865168539325,
        "text_similarity": 0.7430869340896606,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the 'once_finished' relation and the content about the federal government's right to withdraw funds, but the reported timestamps differ from the reference by about 0.3\u20131.4 seconds and there is a minor transcription error ('fund funds')."
      }
    },
    {
      "question_id": "003",
      "question": "Once Maria E. Mendoza finishes giving the healthcare example of funding withdrawal for lack of interpreters, when does she state that 'there are very strict laws'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4470.0,
        "end": 4612.51
      },
      "gt_interval": {
        "start": 4552.98,
        "end": 4555.18
      },
      "pred_interval": {
        "start": 4553.4,
        "end": 4556.24
      },
      "iou": 0.5460122699388146,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.42000000000007276,
        "end": 1.0599999999994907,
        "average": 0.7399999999997817
      },
      "rationale_metrics": {
        "rouge_l": 0.35000000000000003,
        "text_similarity": 0.6832677125930786,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the same utterances and the 'once_finished' relation and preserves the quoted phrase, but the provided timestamps differ slightly (anchor end and target end off by ~1s), so it's mostly correct but not exact."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that what's most important is helping her kid understand their experience, when does she explain that we often center the other person instead of our kid?",
      "video_id": "Z6o8S8JDg00",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 44.150000000000006
      },
      "gt_interval": {
        "start": 10.281,
        "end": 17.954
      },
      "pred_interval": {
        "start": 10.0,
        "end": 17.0
      },
      "iou": 0.8447322102086999,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.2810000000000006,
        "end": 0.9540000000000006,
        "average": 0.6175000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.24719101123595508,
        "text_similarity": 0.5740727186203003,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target utterances, their order (after), and contains matching quoted content; the provided timestamps slightly differ from the reference but substantially overlap, so only minor timing imprecision is present."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker asks 'Could we do this course together?', when does she say 'That would just be great. You don't have to agree with anything. I think that would be great.'?",
      "video_id": "Z6o8S8JDg00",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 44.150000000000006
      },
      "gt_interval": {
        "start": 25.207,
        "end": 27.812
      },
      "pred_interval": {
        "start": 25.0,
        "end": 28.0
      },
      "iou": 0.8683333333333335,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.20700000000000074,
        "end": 0.18799999999999883,
        "average": 0.1974999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3235294117647059,
        "text_similarity": 0.5906338095664978,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately matches the anchor and target utterances and their temporal ordering, with only minor rounding differences in timestamps that do not affect the 'once_finished' relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces herself as April Rehrig, when does the text 'IEPs' appear on screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 44.229,
        "end": 45.479
      },
      "pred_interval": {
        "start": 43.4,
        "end": 45.1
      },
      "iou": 0.4189514189514199,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8290000000000006,
        "end": 0.3789999999999978,
        "average": 0.6039999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.28169014084507044,
        "text_similarity": 0.6867787837982178,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the ordering and approximate durations (text appears after the introduction and disappears around 45s), but key timestamps are off by ~0.8s for the intro start and the text onset compared to the reference, and it adds an unverified spatial/graphic detail not present in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker explains that Section 504 is a civil rights statute, when does the text 'Civil Rights Statute' appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.493,
        "end": 71.953
      },
      "pred_interval": {
        "start": 108.4,
        "end": 111.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.90700000000001,
        "end": 39.346999999999994,
        "average": 40.127
      },
      "rationale_metrics": {
        "rouge_l": 0.417910447761194,
        "text_similarity": 0.7986359596252441,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives completely different timestamps (\u2248104\u2013111s) than the reference (\u224864.5\u201371.95s), so the timing is incorrect; while it preserves the 'during' relation, the factual timestamps contradict the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions '504 meetings with five tips', when does she explain what to do before the meeting?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 26.541,
        "end": 33.582
      },
      "pred_interval": {
        "start": 26.3,
        "end": 28.5
      },
      "iou": 0.26901950013732484,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.24099999999999966,
        "end": 5.082000000000001,
        "average": 2.6615
      },
      "rationale_metrics": {
        "rouge_l": 0.3488372093023256,
        "text_similarity": 0.5982168316841125,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the explanation starting shortly after the phrase, with a close start time, but it misreports the phrase end time, gives a much earlier end time (omitting the remainder of the explanation through 33.582s) and omits the 'how to advocate' content, and adds possibly unsupported on-screen text."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"This is a problem because pro tip\", when does the \"Pro-Tip\" visual with a thumbs-up icon appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 177.7,
        "end": 179.0
      },
      "pred_interval": {
        "start": 243.2,
        "end": 246.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.5,
        "end": 67.1,
        "average": 66.3
      },
      "rationale_metrics": {
        "rouge_l": 0.10752688172043012,
        "text_similarity": 0.44886544346809387,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the 'Pro-Tip' thumbs-up visual, but the reported timings and relation to the anchor speech are substantially incorrect (predicted ~241.5\u2013246.1s vs. correct 174.337\u2013179s) and contradict the reference's immediate appearance and shorter duration."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"Now it's time to talk about tip two\", when does the text \"Parent Letter of Attachment\" appear on screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 234.0,
        "end": 236.0
      },
      "pred_interval": {
        "start": 299.8,
        "end": 304.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.80000000000001,
        "end": 68.19999999999999,
        "average": 67.0
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.5379248857498169,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timings differ substantially from the reference (\u2248296\u2013304s vs. 228\u2013236s) and it misstates the temporal relation (claims coincidence), so it contradicts the ground truth despite mentioning an anchor/text sequence."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says it's time to jump into the second part of what they will talk about, when do the animated files appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 357.05,
        "end": 358.05
      },
      "pred_interval": {
        "start": 362.0,
        "end": 365.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.949999999999989,
        "end": 6.949999999999989,
        "average": 5.949999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.11428571428571428,
        "text_similarity": 0.4643442630767822,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the relative order (animated files occur after the anchor), but the timestamps are several seconds off (speaker end and animation start/end differ substantially) and it adds an unverified utterance, so it is largely factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "During the speaker's question 'What is inside a 504 plan?', when do the question mark graphics appear and disappear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.5,
        "end": 457.0
      },
      "pred_interval": {
        "start": 412.0,
        "end": 417.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.5,
        "end": 40.0,
        "average": 37.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2631578947368421,
        "text_similarity": 0.6466341018676758,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps contradict the reference: the question actually occurs at 447.05\u2013451.76s (not 411.0s) and the graphics appear around 447.5s and disappear by ~457.0s (not 412.0\u2013417.0s), so the prediction is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'now it's time to dive into tip four', when does the large golden number '4' graphic appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 442.05,
        "end": 444.05
      },
      "pred_interval": {
        "start": 447.0,
        "end": 453.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.949999999999989,
        "end": 8.949999999999989,
        "average": 6.949999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.2608695652173913,
        "text_similarity": 0.49884581565856934,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the graphic appears immediately after the speech, but it gives incorrect timestamps (shifted ~5s later) and adds unsupported details about fading and surrounding text, contradicting the reference timing and completeness."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning the Parent Report, when does she start explaining what a Parent Report is?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 521.0,
        "end": 526.5
      },
      "pred_interval": {
        "start": 521.0,
        "end": 528.0
      },
      "iou": 0.7857142857142857,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 1.5,
        "average": 0.75
      },
      "rationale_metrics": {
        "rouge_l": 0.15555555555555553,
        "text_similarity": 0.1222924143075943,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies that the explanation begins after the anchor and correctly pins the start at ~521s, but it misstates the anchor end (~520s vs 518.6s) and the target end (528s vs 526.5s) and adds extra quoted content not present in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "During the speaker's explanation about getting her free guide, when does the visual graphic of the guide appear on the screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 579.8,
        "end": 584.0
      },
      "pred_interval": {
        "start": 580.0,
        "end": 585.0
      },
      "iou": 0.7692307692307625,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.20000000000004547,
        "end": 1.0,
        "average": 0.6000000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.15,
        "text_similarity": 0.42335963249206543,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly notes the graphic appears during the speaker's line and gives an accurate appearance time (~579.8s vs 580s), but it misstated the disappearance time (585s vs 584.0s) and adds unsupported details (replaced by text and specific left-side placement)."
      }
    },
    {
      "question_id": "003",
      "question": "During the speaker's introduction of \"The Ultimate 504 Guide\", when does the cover image for the guide appear on screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 690.0,
        "end": 829.166
      },
      "gt_interval": {
        "start": 738.5,
        "end": 741.0
      },
      "pred_interval": {
        "start": 741.0,
        "end": 744.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 3.0,
        "average": 2.75
      },
      "rationale_metrics": {
        "rouge_l": 0.25999999999999995,
        "text_similarity": 0.5637310743331909,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction partly captures that the image appears while the speaker names the guide, but its onset (741.0s vs correct 738.5s) and offset (744.0s vs correct 741.0s) are significantly inaccurate and it introduces a hallucinatory cut to b-roll, contradicting the reference timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once Bobbi finishes reading the admission details from the tablet, when does her sustained ecstatic reaction begin?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 102.7,
        "end": 131.0
      },
      "pred_interval": {
        "start": 103.0,
        "end": 134.0
      },
      "iou": 0.8945686900958467,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.29999999999999716,
        "end": 3.0,
        "average": 1.6499999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.672421932220459,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction captures the sequence and approximate timings (E1 ~102s, E2 starting just after with a 'Woo!' and sustained screams), but it slightly misstates the start/end timestamps (102.7s->103s is close, but end 131s->134s is off) and adds specific vocalizations ('Let's go!' laughing) not mentioned in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the daughter mentions Berkeley, when does she explain why she probably won't get in?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 175.1,
        "end": 180.0
      },
      "pred_interval": {
        "start": 178.0,
        "end": 182.0
      },
      "iou": 0.2898550724637679,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.9000000000000057,
        "end": 2.0,
        "average": 2.450000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3611111111111111,
        "text_similarity": 0.7826045751571655,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies both events and their 'after' relation, but the timestamps are shifted and it omits the actual E2 start utterance ('I'm really probably not gonna get in'), quoting a later clause instead, so it is incomplete and moderately inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the mother asks how scouting works, when does the daughter start explaining her basketball options?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 191.5,
        "end": 195.9
      },
      "pred_interval": {
        "start": 191.0,
        "end": 195.0
      },
      "iou": 0.7142857142857134,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.5,
        "end": 0.9000000000000057,
        "average": 0.7000000000000028
      },
      "rationale_metrics": {
        "rouge_l": 0.3448275862068966,
        "text_similarity": 0.6132299304008484,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the relation ('once_finished'), the content of the daughter's explanation, and nearly the same timestamps with only minor small offsets (<1s) in start/end times, so it is essentially accurate."
      }
    },
    {
      "question_id": "003",
      "question": "While the daughter says she is weighing her options and is not sure yet, when does the mother appear in the frame, leaning on the bed?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 252.3,
        "end": 256.5
      },
      "pred_interval": {
        "start": 252.0,
        "end": 255.0
      },
      "iou": 0.5999999999999974,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.30000000000001137,
        "end": 1.5,
        "average": 0.9000000000000057
      },
      "rationale_metrics": {
        "rouge_l": 0.25974025974025977,
        "text_similarity": 0.7616103887557983,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the mother's appearance timing (~252s) and that she is leaning on the bed, and approximates the daughter's context start (~244s); it omits the precise end times and the explicit 'during' relation and adds an unsupported 'jump cut' detail."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman on the right says she didn't go to Howard, when does she mention where she did go?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 365.0,
        "end": 368.0
      },
      "pred_interval": {
        "start": 370.0,
        "end": 373.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 5.199999999999989,
        "average": 5.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.7985036373138428,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the sequence (she names an alternative after saying she didn't go to Howard), but the timestamps are notably off by several seconds compared to the reference and it introduces a specific university name not present in the ground truth, indicating inaccuracy/hallucination."
      }
    },
    {
      "question_id": "002",
      "question": "After the daughter laughs, when does she state that she has many options for college?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 423.0,
        "end": 428.5
      },
      "pred_interval": {
        "start": 427.5,
        "end": 429.5
      },
      "iou": 0.15384615384615385,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.5,
        "end": 1.0,
        "average": 2.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3235294117647059,
        "text_similarity": 0.7017214298248291,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction substantially misaligns the timestamps\u2014placing the laugh ~24s later and claiming the speech immediately follows\u2014creating a major temporal contradiction with the ground truth, despite correctly identifying the quoted line."
      }
    },
    {
      "question_id": "001",
      "question": "After the mother asks if every college has sororities and fraternities, when does the daughter state that not every school has Greek life?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 538.294,
        "end": 539.697
      },
      "pred_interval": {
        "start": 541.12,
        "end": 543.28
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.826000000000022,
        "end": 3.58299999999997,
        "average": 3.204499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.7002798318862915,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events, their dialogue content, and the 'after' relation; the only issue is minor timestamp discrepancies (predicted times are ~2\u20133.6 seconds later than the ground truth)."
      }
    },
    {
      "question_id": "002",
      "question": "After the mother says her one regret in life is not joining a sorority, when does she mention her AP at school is a 'die hard AKA'?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 587.969,
        "end": 592.336
      },
      "pred_interval": {
        "start": 590.6,
        "end": 594.4
      },
      "iou": 0.26994246617944484,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.630999999999972,
        "end": 2.0639999999999645,
        "average": 2.347499999999968
      },
      "rationale_metrics": {
        "rouge_l": 0.3058823529411765,
        "text_similarity": 0.7965419292449951,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relation and roughly locates E2, but it gives a substantially incorrect start time for E1 (and omits its end), slightly mis-times E2's end, and mislabels E1, so timing/details are only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the girl on the right asks if she did Columbia, when does the girl on the left respond?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 703.8,
        "end": 704.0
      },
      "pred_interval": {
        "start": 704.0,
        "end": 705.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.20000000000004547,
        "end": 1.0,
        "average": 0.6000000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.32432432432432434,
        "text_similarity": 0.6695578694343567,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly matches the anchor timing (703s vs 702.6\u2013703.3s) but gives an incorrect/contradictory timing for the response: it shifts the target start to 704.0s and vastly overestimates its duration (ending ~705.0s) versus the ground truth 703.8\u2013704.0s, so key temporal details are wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the girl on the left states the acceptance rate, when does she start explaining what scattergrams are?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.6,
        "end": 781.7
      },
      "pred_interval": {
        "start": 769.0,
        "end": 786.0
      },
      "iou": 0.6902173913043511,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3999999999999773,
        "end": 4.2999999999999545,
        "average": 2.849999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.3130434782608696,
        "text_similarity": 0.750572681427002,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies that the scattergram explanation follows the acceptance-rate remark and even quotes the introduction, but the reported start/end times are off by several seconds (E1 ~1.5s early, E2 starts ~1.4s late and ends ~4.3s late) and it adds/shifted detail about the axes and video timestamps that don't match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman on the right says \"That Sydney wasn't feeling well\", when does she say \"He's doing well\"?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 917.7,
        "end": 918.6
      },
      "pred_interval": {
        "start": 922.2,
        "end": 923.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.5,
        "end": 5.199999999999932,
        "average": 4.849999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.2278481012658228,
        "text_similarity": 0.6772327423095703,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the anchor/target ordering and that the target follows immediately (once_finished), but the absolute timestamps are off by ~5 seconds and the reported durations for E2 differ from the ground truth, so it does not precisely align."
      }
    },
    {
      "question_id": "003",
      "question": "Once the woman on the right says \"And then Sydney will be next\", when does the woman on the left start talking about the college application process?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 988.4,
        "end": 992.1
      },
      "pred_interval": {
        "start": 994.5,
        "end": 998.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.100000000000023,
        "end": 6.399999999999977,
        "average": 6.25
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.6539939045906067,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer's timestamps are substantially off (E1/E2 shifted by ~6\u20138+ seconds and durations incorrect) and do not match the precise anchor/target timing given in the ground truth, so it fails to correctly locate the utterances despite preserving the general sequence."
      }
    },
    {
      "question_id": "001",
      "question": "Once the girl on the left finishes listing application platforms, when does she say \"Just word of advice, just start\"?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1086.0,
        "end": 1089.5
      },
      "pred_interval": {
        "start": 1089.5,
        "end": 1092.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 2.5,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3055555555555556,
        "text_similarity": 0.5186039805412292,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the relation (the target phrase occurs after the listing) but the timestamps are noticeably off\u2014the anchor end is given as 1085.0s vs ~1089s predicted and the target start/end are shifted ~3\u20134s later than the reference, so timing accuracy is lacking."
      }
    },
    {
      "question_id": "002",
      "question": "Once the girl on the right asks \"what type of law?\", when does the girl on the left reply saying she'd probably go into civil law?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1119.5,
        "end": 1120.9
      },
      "pred_interval": {
        "start": 1122.0,
        "end": 1125.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 4.599999999999909,
        "average": 3.5499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.2716049382716049,
        "text_similarity": 0.5073279738426208,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the question, the reply text, and the immediate (once_finished) relation, but the provided timestamps deviate noticeably from the ground truth, so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the mother says \"a small school too\", when does the daughter stretch her arms up?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.741,
        "end": 1242.0
      },
      "pred_interval": {
        "start": 1243.0,
        "end": 1249.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.2590000000000146,
        "end": 7.0,
        "average": 4.629500000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.1379310344827586,
        "text_similarity": 0.45715782046318054,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the coarse relation (after) and that the daughter stretches, but it misstates the anchor and event timestamps by several seconds and invents extra motion details (right-arm, behind-head, yawning) and an incorrect end time, so it is largely factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the mother is explaining how teachers can adjust grades, when does the daughter adjust her body position?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.0,
        "end": 1281.0
      },
      "pred_interval": {
        "start": 1278.0,
        "end": 1281.0
      },
      "iou": 1.0,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 0.0,
        "average": 0.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195122,
        "text_similarity": 0.3988081216812134,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the daughter adjusting from 1278.0s to 1281.0s and preserves the 'during' relation with the mother's explanation; it only slightly misstates the mother's end time (1283.0s vs 1280.017s) and adds minor descriptive detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks her daughter what she was doing, when does the daughter respond 'You was yelling her name'?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1410.0,
        "end": 1455.304
      },
      "gt_interval": {
        "start": 1423.817,
        "end": 1429.817
      },
      "pred_interval": {
        "start": 1424.6,
        "end": 1426.1
      },
      "iou": 0.25,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7829999999999018,
        "end": 3.7170000000000982,
        "average": 2.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.5687665939331055,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relation but the timestamps differ substantially: the anchor and target starts are ~0.8\u20131.5s later than the reference and the predicted target end (1426.1s) is ~3.7s earlier than the correct end (1429.817s), so the temporal alignment and duration are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the daughter finishes saying 'The front door', when does the woman on the right begin responding and laughing?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1410.0,
        "end": 1455.304
      },
      "gt_interval": {
        "start": 1428.184,
        "end": 1432.184
      },
      "pred_interval": {
        "start": 1428.2,
        "end": 1431.5
      },
      "iou": 0.8249999999999886,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.016000000000076398,
        "end": 0.6839999999999691,
        "average": 0.35000000000002274
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.675205647945404,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the 'once_finished' relation and timing (woman responds immediately after the daughter), with only minor timestamp discrepancies (~0.4\u20130.7s) and a slight difference in the reported end time and an extra quoted phrase; no substantive contradiction or omission."
      }
    },
    {
      "question_id": "001",
      "question": "After Susan asks the audience to click on the subscribe button, when does she mention that talks will happen every two weeks?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 23.621,
        "end": 26.608
      },
      "pred_interval": {
        "start": 22.36,
        "end": 25.1
      },
      "iou": 0.34816384180791016,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2609999999999992,
        "end": 1.5079999999999991,
        "average": 1.3844999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.1951219512195122,
        "text_similarity": 0.8156004548072815,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly identifies both events, the quoted line, and the 'after' relationship; the anchor timing is within the reference span, while the target timestamps are slightly earlier than the ground truth by about 1\u20131.5s but remain semantically accurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once Susan introduces Nick Prollins, when does Nick greet Susan?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 83.186,
        "end": 83.986
      },
      "pred_interval": {
        "start": 123.2,
        "end": 124.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.013999999999996,
        "end": 40.513999999999996,
        "average": 40.263999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.4000000000000001,
        "text_similarity": 0.8896868824958801,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the greeting occurs after the introduction, but the anchor and target timestamps differ substantially from the ground truth and the predicted quoted utterance is unsupported, so the answer is factually incorrect on key details."
      }
    },
    {
      "question_id": "002",
      "question": "After the man states he had a class of 40 grade six boys, when does the woman touch her face in surprise?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 195.0,
        "end": 197.51
      },
      "pred_interval": {
        "start": 200.0,
        "end": 206.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 8.490000000000009,
        "average": 6.7450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.25882352941176473,
        "text_similarity": 0.45293128490448,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the correct temporal relation (woman's touch occurs after the man\u2019s statement) but the reported timestamps differ substantially from the ground truth (off by ~4\u20139 seconds), so the timing is not accurately matched."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man mentions the Reggio Emilia approach, when does the woman interject 'Not at all'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 271.17,
        "end": 272.771
      },
      "pred_interval": {
        "start": 276.0,
        "end": 278.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.829999999999984,
        "end": 5.228999999999985,
        "average": 5.0294999999999845
      },
      "rationale_metrics": {
        "rouge_l": 0.34210526315789475,
        "text_similarity": 0.5265783071517944,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted locates the man's mention close to the ground truth but the woman's interjection timing is off by about 5 seconds (starts at 276s vs 271.17s), contradicting the 'immediately after' relation and adding an unwarranted repetition, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says he learned mostly about behavior management, when does the woman state that everyone needs classroom management tips?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.3,
        "end": 356.5
      },
      "pred_interval": {
        "start": 359.0,
        "end": 362.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.699999999999989,
        "end": 5.5,
        "average": 5.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.40540540540540543,
        "text_similarity": 0.6083489656448364,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the same utterance/content for both events, but the reported timestamps are several seconds later than the ground truth (\u22484\u20136s off) and it adds an unsupported detail about emphasis, so it is only partially accurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying they are digressing, when does the woman state that it is connected to what they will talk about?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 392.9,
        "end": 395.5
      },
      "pred_interval": {
        "start": 398.0,
        "end": 400.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.100000000000023,
        "end": 4.5,
        "average": 4.800000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.4044943820224719,
        "text_similarity": 0.6070971488952637,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly reproduces the quoted dialogue but gives substantially incorrect timestamps for both events (off by ~6\u20137 seconds), failing to match the reference temporal annotations."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman asks about the relationship between families and schools, when does the man describe his previous role at a bilingual school?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 460.0,
        "end": 468.923
      },
      "pred_interval": {
        "start": 461.0,
        "end": 474.0
      },
      "iou": 0.5659285714285716,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 5.076999999999998,
        "average": 3.038499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.339622641509434,
        "text_similarity": 0.5263819694519043,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the man beginning to describe his role as Head of Primary around 460\u2013461s, but it misstates the anchor event (E1) timing by ~15s and extends E2 by ~5s beyond the reference; it also adds extraneous details (e.g., 'amazing', location) not present in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes asking about the common denominators in the parent-teacher relationship, when does the man say it's a 'really great question'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.804,
        "end": 584.905
      },
      "pred_interval": {
        "start": 79.0,
        "end": 81.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 504.804,
        "end": 503.905,
        "average": 504.3545
      },
      "rationale_metrics": {
        "rouge_l": 0.39999999999999997,
        "text_similarity": 0.628054141998291,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the sequence (woman finishes then man says 'Really great question') but the provided timestamps are drastically incorrect compared to the ground truth (off by ~500s) and the E2 end time also mismatches, so the answer is largely factually wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes explaining that there was an initial impression among groups that their problems were unique, when does he start describing what they were actually saying?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 610.142,
        "end": 620.738
      },
      "pred_interval": {
        "start": 128.0,
        "end": 135.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 482.14200000000005,
        "end": 485.23800000000006,
        "average": 483.69000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2891566265060241,
        "text_similarity": 0.5895646810531616,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer preserves the sequence and quoted content (E2 starts after E1), but the timestamps are substantially inconsistent with the reference (large time discrepancies/likely different timebase) and therefore not precise or correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the man talks about parents wanting their children to succeed academically, when does he mention that many parents are unsure how to support their child?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.2,
        "end": 724.5
      },
      "pred_interval": {
        "start": 715.0,
        "end": 732.0
      },
      "iou": 0.5337078651685407,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7999999999999545,
        "end": 7.5,
        "average": 4.149999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.18947368421052632,
        "text_similarity": 0.7377229928970337,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the anchor and the target start and even quotes the relevant phrase, with only minor start-time shifts; however it significantly over-extends the target end time (732.0s vs 724.5s), including extra unrelated content, so the timing is imprecise."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes asking what 'the best' means in the context of raising a child, when does the man explain that it looks different in different contexts?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 762.4,
        "end": 767.8
      },
      "pred_interval": {
        "start": 766.0,
        "end": 770.0
      },
      "iou": 0.2368421052631512,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.6000000000000227,
        "end": 2.2000000000000455,
        "average": 2.900000000000034
      },
      "rationale_metrics": {
        "rouge_l": 0.273972602739726,
        "text_similarity": 0.6348674297332764,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction captures the content and that the man responds immediately, but the event timestamps are offset from the ground truth (start +3.6s, end +2.2s), so it's partially but not perfectly aligned."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman describes a picture of a parent and infant looking at each other, when does she demonstrate with her phone a shift in parental focus?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 822.7,
        "end": 825.8
      },
      "pred_interval": {
        "start": 827.0,
        "end": 833.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.2999999999999545,
        "end": 7.2000000000000455,
        "average": 5.75
      },
      "rationale_metrics": {
        "rouge_l": 0.32558139534883723,
        "text_similarity": 0.7509307861328125,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the demonstration (the 'instead of this is this' phone gesture) but the timestamps are substantially off\u2014E1 end is ~29.6s later and E2\u2019s start/end are several seconds later than the ground truth\u2014so the timing is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the man states he doesn't have children himself, when does he explain how he has spent his career working with children and families?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.7,
        "end": 880.4
      },
      "pred_interval": {
        "start": 879.0,
        "end": 885.0
      },
      "iou": 0.2222222222222202,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.2999999999999545,
        "end": 4.600000000000023,
        "average": 2.4499999999999886
      },
      "rationale_metrics": {
        "rouge_l": 0.5681818181818182,
        "text_similarity": 0.884903073310852,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the quoted phrases and the 'after' relationship, but the anchor timing is off by several seconds and the target end time is substantially overestimated compared to the reference, so temporal alignment is only partially accurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the man asks 'Tell me what matters to you?', when does the woman ask if he asks this question to parents and teachers?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 902.9,
        "end": 909.0
      },
      "pred_interval": {
        "start": 907.0,
        "end": 913.0
      },
      "iou": 0.19801980198019759,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.100000000000023,
        "end": 4.0,
        "average": 4.050000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.5154639175257731,
        "text_similarity": 0.839015007019043,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the utterances and the 'after' relationship, but the anchor and target time spans are significantly shifted and durations mismatched compared to the ground truth, so the temporal details are inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the woman says she has been on a 'triangle' of experiences, when does she list her roles as a parent, teacher, and tutor?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1003.2,
        "end": 1017.677
      },
      "pred_interval": {
        "start": 1009.0,
        "end": 1023.0
      },
      "iou": 0.4382323232323253,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.7999999999999545,
        "end": 5.322999999999979,
        "average": 5.561499999999967
      },
      "rationale_metrics": {
        "rouge_l": 0.43396226415094347,
        "text_similarity": 0.8056445121765137,
        "llm_judge_score": 7,
        "llm_judge_justification": "The predicted answer correctly captures the content (the woman listing parent, teacher, tutor) and the 'once_finished' relation, but the anchor and target timestamps are offset by several seconds (E1 ~+5\u20137s, E2 start/end ~+5s), so the timing is imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "Once the male speaker finishes saying 'Really great strategy, really great strategy', when does he begin talking about clarifying something?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1101.703,
        "end": 1108.353
      },
      "pred_interval": {
        "start": 1111.5,
        "end": 1114.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.797000000000025,
        "end": 6.1469999999999345,
        "average": 7.97199999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.13793103448275862,
        "text_similarity": 0.5362430810928345,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer contradicts the reference on key timing details (anchor/target times differ by ~5\u201310s) and adds a hesitation/false start not present in the ground truth, so it does not match the correct sequence."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker describes most parents wanting their children and teachers to thrive, when does he start talking about the 1%?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1146.304,
        "end": 1154.554
      },
      "pred_interval": {
        "start": 1151.5,
        "end": 1160.0
      },
      "iou": 0.22298481308411994,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.195999999999913,
        "end": 5.445999999999913,
        "average": 5.320999999999913
      },
      "rationale_metrics": {
        "rouge_l": 0.12195121951219513,
        "text_similarity": 0.39743590354919434,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the target occurs after the anchor, but the timestamps substantially disagree with the reference (anchor end off by ~29s and target boundaries off by ~5\u20136s), so the answer is factually misaligned with the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'who trains us to deal with these situations?', when does the woman respond 'No one'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1256.9,
        "end": 1257.3
      },
      "pred_interval": {
        "start": 1261.0,
        "end": 1263.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.099999999999909,
        "end": 5.7000000000000455,
        "average": 4.899999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.2978723404255319,
        "text_similarity": 0.680883526802063,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction captures that the woman replies immediately after the man's question, but the timestamps are off by about 4\u20136 seconds and the relation is labeled 'after' rather than the more specific 'once_finished', so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes describing demanding parents, when does the woman say she's 'starting to break out in hives'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1302.8,
        "end": 1306.5
      },
      "pred_interval": {
        "start": 1308.0,
        "end": 1311.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.2000000000000455,
        "end": 4.5,
        "average": 4.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.35514018691588783,
        "text_similarity": 0.6803976893424988,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the woman's line and that it follows the man's remark, but it mislocates both events by several seconds, labels the relation as the weaker 'after' instead of the immediate 'once_finished', and gives a different anchor phrasing\u2014so it's a partial but not precise match."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman says she would love to know more about that, when does the man state that the ABCD trust model is not specifically for schools or parents?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1423.0,
        "end": 1434.135
      },
      "pred_interval": {
        "start": 1429.0,
        "end": 1439.0
      },
      "iou": 0.32093749999999943,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 4.865000000000009,
        "average": 5.4325000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.7137196063995361,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') but the timestamps are several seconds off from the ground truth (anchor 1421.11s vs predicted ~1426s; target 1423\u20131434.135s vs predicted 1429\u20131439s), so the timing details are inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "When is the next time the man introduces a letter of the ABCD trust model after he explains 'A is for ability'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1543.182,
        "end": 1544.983
      },
      "pred_interval": {
        "start": 1548.0,
        "end": 1551.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.817999999999984,
        "end": 6.517000000000053,
        "average": 5.667500000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.3764705882352941,
        "text_similarity": 0.7286087274551392,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the sequential relation (B follows A) but gives significantly different and incorrect timestamps for both anchor and target and adds specific phrasing ('believability') not asserted in the correct answer, so it is not factually aligned."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes inviting teachers to move beyond the 'us against them' mindset, when does he introduce the idea of 'family engagement'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1496.349,
        "end": 1501.218
      },
      "pred_interval": {
        "start": 1503.0,
        "end": 1507.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.651000000000067,
        "end": 5.781999999999925,
        "average": 6.216499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.18823529411764706,
        "text_similarity": 0.7706726789474487,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequencing (the family engagement idea follows the invitation), but the reported timestamps are substantially inaccurate and do not match the reference event boundaries, so key factual timing details are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man states 'believability', when does he ask if you will do what you say you're going to do?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1659.124,
        "end": 1661.589
      },
      "pred_interval": {
        "start": 1663.0,
        "end": 1666.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.8759999999999764,
        "end": 4.411000000000058,
        "average": 4.143500000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.5675675675675675,
        "text_similarity": 0.7523906230926514,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the two events and the 'after' relation, but the provided timestamps are several seconds later than the reference (off by ~4\u20135s), so timing accuracy is lacking though the semantic relation is preserved."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman asks for an example, when does the man describe the advice 'under promise and over deliver'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1691.205,
        "end": 1694.03
      },
      "pred_interval": {
        "start": 1696.0,
        "end": 1699.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.795000000000073,
        "end": 4.970000000000027,
        "average": 4.88250000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.3835616438356164,
        "text_similarity": 0.7491992115974426,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies both events and their temporal relation ('after'), but the provided timestamps are several seconds later than the ground truth for both E1 (~+2.4s) and E2 (~+2.8\u2013+5s), so it is mostly correct but not precisely aligned."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining why schools might not always follow through on promises, when does the woman summarize the advice as 'under promise and over deliver'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1742.844,
        "end": 1747.709
      },
      "pred_interval": {
        "start": 1749.0,
        "end": 1752.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.155999999999949,
        "end": 4.29099999999994,
        "average": 5.2234999999999445
      },
      "rationale_metrics": {
        "rouge_l": 0.25974025974025977,
        "text_similarity": 0.706641435623169,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the semantic relation ('after') and the woman's quote, but the absolute timestamps are substantially off (predicted E1/E2 around 1747\u20131752s versus correct E1 end ~1732s and E2 1742.844\u20131747.709s), so the timing is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker asks about initiatives, when does he ask if they have parent representative councils?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1820.1,
        "end": 1826.2
      },
      "pred_interval": {
        "start": 1826.3,
        "end": 1831.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.2000000000000455,
        "end": 4.7999999999999545,
        "average": 5.5
      },
      "rationale_metrics": {
        "rouge_l": 0.18390804597701152,
        "text_similarity": 0.6660588979721069,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction matches the semantic sequence (general initiatives question followed by the parent-representative question) but the timestamps are substantially incorrect\u2014the predicted anchor and target occur ~6\u20137s later and the predicted target extends well beyond the ground-truth interval\u2014so the timing is not accurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker says the reading breakfast was 'such a cool thing', when does the female speaker react with wide eyes?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1848.0,
        "end": 1849.0
      },
      "pred_interval": {
        "start": 1854.2,
        "end": 1856.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.2000000000000455,
        "end": 7.0,
        "average": 6.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.7173455357551575,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that her wide-eyed reaction follows his remark and its nature, but the anchor and target timestamps and durations are significantly off (~6\u20137 seconds) compared to the reference, so the timing facts are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the female speaker mentions the connection with character strengths, when does she give examples of these strengths?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1957.0,
        "end": 1963.8
      },
      "pred_interval": {
        "start": 1960.0,
        "end": 1969.0
      },
      "iou": 0.3166666666666629,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 5.2000000000000455,
        "average": 4.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.29999999999999993,
        "text_similarity": 0.6343960165977478,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor mention and that the target examples occur after it, and it captures the example content, but the reported timestamps are notably shifted (anchor ~2\u20134s late and target start/end several seconds off/extended), so it only partially matches the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the female speaker talks about opportunities for 'loose ties communications between school staff and families', when does the male speaker agree?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2008.0,
        "end": 2009.5
      },
      "pred_interval": {
        "start": 2012.0,
        "end": 2016.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 6.5,
        "average": 5.25
      },
      "rationale_metrics": {
        "rouge_l": 0.30434782608695654,
        "text_similarity": 0.7852520942687988,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the male speaker agrees immediately after the female and captures the verbal agreement, but the provided timestamps are substantially off (predicted ~2012\u20132016s vs. correct 2008.0\u20132009.5s) and it extends the target much longer than referenced."
      }
    },
    {
      "question_id": "003",
      "question": "After the female speaker introduces 'dependability', when does the male speaker explain it as 'being consistent'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2050.0,
        "end": 2054.5
      },
      "pred_interval": {
        "start": 2056.0,
        "end": 2060.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 5.5,
        "average": 5.75
      },
      "rationale_metrics": {
        "rouge_l": 0.29473684210526313,
        "text_similarity": 0.8284846544265747,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the male explanation occurs after the female introduction, but the anchor and target timestamps are significantly off from the reference and the quoted sentence/times appear inaccurate/hallucinated, so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks 'what do I believe?', when does he state that having a school that has done the thinking makes a teacher feel more supported?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2142.885,
        "end": 2150.675
      },
      "pred_interval": {
        "start": 2148.0,
        "end": 2155.0
      },
      "iou": 0.22080066033844242,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.114999999999782,
        "end": 4.324999999999818,
        "average": 4.7199999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.19512195121951217,
        "text_similarity": 0.662171483039856,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction captures the correct content and the 'after' relation, but the reported timestamps are consistently ~4\u20136 seconds later than the ground-truth intervals, so the timing is notably inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says she can do her part but asks about the parents' part, when does the man explicitly state they are not talking about a wall regarding boundaries?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2228.336,
        "end": 2229.739
      },
      "pred_interval": {
        "start": 2232.5,
        "end": 2235.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.164000000000215,
        "end": 5.760999999999967,
        "average": 4.962500000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.3125,
        "text_similarity": 0.7819101214408875,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the 'after' relation but misattributes who says 'not talking about a wall' and gives significantly different timestamps for both E1 and E2 (E1 ~2216 vs correct 2203.7\u20132213.7; E2 ~2232.5\u20132235.5 vs correct 2228.336\u20132229.739), so it is factually and temporally inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes saying he got schooled on something he didn't realize, when does he explain his naive assumption about WhatsApp?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2246.965,
        "end": 2299.733
      },
      "pred_interval": {
        "start": 2256.0,
        "end": 2268.0
      },
      "iou": 0.2274105518496057,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.034999999999854,
        "end": 31.733000000000175,
        "average": 20.384000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.28260869565217395,
        "text_similarity": 0.7758213877677917,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the sequence/relationship (after/once_finished) but the timestamp estimates deviate substantially from the reference\u2014E1 is several seconds off and E2's start and especially end times are significantly shifted/shortened, so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes describing the participant's WhatsApp call from a mother during her holiday, when does he state that this behavior must stop?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2339.8,
        "end": 2341.0
      },
      "pred_interval": {
        "start": 2345.0,
        "end": 2347.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.199999999999818,
        "end": 6.0,
        "average": 5.599999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.2162162162162162,
        "text_similarity": 0.8186018466949463,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the utterance 'This has to stop,' but both event timestamps are noticeably shifted (E2 is ~4\u20136s late) and it fails to preserve the immediate-follow relation between anchor and target specified in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks if anyone else would be treated like that in any other industry, when does the woman reply 'No'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2381.0,
        "end": 2381.3
      },
      "pred_interval": {
        "start": 2385.0,
        "end": 2386.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 4.699999999999818,
        "average": 4.349999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.19718309859154928,
        "text_similarity": 0.8164087533950806,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the immediate audible 'No' reply following the question, but the provided timestamp (2385s) is offset by about 4 seconds from the reference (2381.0\u20132381.3s), so the timing is imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes talking about the school's duty to create boundaries, when does he suggest working towards positive change?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.2,
        "end": 2575.5
      },
      "pred_interval": {
        "start": 2577.5,
        "end": 2580.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.300000000000182,
        "end": 4.699999999999818,
        "average": 8.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2278481012658228,
        "text_similarity": 0.610979437828064,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the suggestion occurs after the duty statement, but it misstates both E1/E2 timestamps, isolates a brief phrase rather than the immediate complete thought, and places E2 much later than the reference, so timing and completeness are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman says 'That's right', when does she start talking about teachers having problems with school leadership regarding boundaries?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2600.5,
        "end": 2606.0
      },
      "pred_interval": {
        "start": 2605.8,
        "end": 2611.8
      },
      "iou": 0.017699115044231405,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.300000000000182,
        "end": 5.800000000000182,
        "average": 5.550000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.6962224245071411,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the utterance content and that E2 follows E1, but the timestamps are substantially off (E1 ~4s late; E2 start/end ~5s late and extended), so it is factually imprecise relative to the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'What's in and what's out for me?', when is the next time he asks 'What are my red lines?'",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2697.043,
        "end": 2698.184
      },
      "pred_interval": {
        "start": 2698.1,
        "end": 2699.8
      },
      "iou": 0.030467899891289632,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.056999999999789,
        "end": 1.6159999999999854,
        "average": 1.3364999999998872
      },
      "rationale_metrics": {
        "rouge_l": 0.4523809523809524,
        "text_similarity": 0.7009031772613525,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the subsequent question and gives a close timestamp for E2 and the correct ordering, but it misplaces E1 by a large margin (predicted ~2696s vs reference ~2793\u20132795s), so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker talks about reflecting on professional boundaries, when does he ask about boundaries around communication with parents and colleagues?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2677.99,
        "end": 2692.02
      },
      "pred_interval": {
        "start": 2687.0,
        "end": 2697.0
      },
      "iou": 0.26407154129405175,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.010000000000218,
        "end": 4.980000000000018,
        "average": 6.995000000000118
      },
      "rationale_metrics": {
        "rouge_l": 0.2888888888888889,
        "text_similarity": 0.548991858959198,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target events, their relative order, and even quotes the target question, but it omits the anchor end time and shifts the target timestamps later (start ~9s later, end ~5s later) compared to the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker asks if teachers are okay with answering WhatsApp messages from colleagues after school hours, when does he ask if they are comfortable sharing their personal mobile number with a parent?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.77,
        "end": 2736.23
      },
      "pred_interval": {
        "start": 2733.0,
        "end": 2742.0
      },
      "iou": 0.22698524244553858,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.230000000000018,
        "end": 5.769999999999982,
        "average": 5.5
      },
      "rationale_metrics": {
        "rouge_l": 0.24657534246575344,
        "text_similarity": 0.6596395969390869,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both segments and the question content with start times that fall within the ground-truth windows, but it omits an interval for E1 and gives an E2 end time that extends beyond the referenced end (2736.23s), so timestamps are slightly inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the female speaker talks about being clear about boundaries and communicating them with 'whole heart', when does the male speaker discuss the comfort derived from setting clear boundaries?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2840.24,
        "end": 2850.66
      },
      "pred_interval": {
        "start": 2835.0,
        "end": 2850.0
      },
      "iou": 0.6232439335887809,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.239999999999782,
        "end": 0.6599999999998545,
        "average": 2.949999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.22807017543859648,
        "text_similarity": 0.7501938343048096,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the same exchange and quotes the male speaker, with end times nearly matching, but it misplaces the anchor/target boundaries slightly\u2014placing the male turn before the female finishes\u2014so timing is modestly off."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says, 'I want this to be practical', when does he say, 'You have no idea'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2960.516,
        "end": 2964.8
      },
      "pred_interval": {
        "start": 2966.36,
        "end": 2968.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.844000000000051,
        "end": 3.399999999999636,
        "average": 4.621999999999844
      },
      "rationale_metrics": {
        "rouge_l": 0.18461538461538463,
        "text_similarity": 0.7791863083839417,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the phrases and that the target occurs after the anchor, but the provided timestamps are noticeably off from the ground truth (anchor ~3.9s late; target ~5.8s late)."
      }
    },
    {
      "question_id": "002",
      "question": "After the man asks, 'Tell me what matters to you right now', when does the woman make a thumbs-up gesture?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 3024.99,
        "end": 3026.99
      },
      "pred_interval": {
        "start": 3029.6,
        "end": 3031.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.610000000000127,
        "end": 4.210000000000036,
        "average": 4.410000000000082
      },
      "rationale_metrics": {
        "rouge_l": 0.29850746268656714,
        "text_similarity": 0.7928347587585449,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction identifies the correct events and their ordering (target after anchor), but the timestamp boundaries are noticeably inaccurate: the predicted anchor is ~2\u20133s later and the predicted target ~4.6s later than the reference intervals."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes saying, 'Thank you for sharing that information with me', when does he immediately advise to 'take note of that teacher'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 3046.646,
        "end": 3049.969
      },
      "pred_interval": {
        "start": 3054.2,
        "end": 3056.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.553999999999633,
        "end": 6.030999999999949,
        "average": 6.792499999999791
      },
      "rationale_metrics": {
        "rouge_l": 0.2571428571428572,
        "text_similarity": 0.7249301075935364,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are substantially off for both anchor (3031s vs 3047.2s) and target (3054.2\u20133056.0s vs 3046.646\u20133049.969s) and it incorrectly states the target does not immediately follow the anchor, contradicting the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes suggesting to invite families to propose solutions, when does the woman react with a wide-eyed expression?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3069.0,
        "end": 3070.0
      },
      "pred_interval": {
        "start": 3044.8,
        "end": 3047.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.199999999999818,
        "end": 22.800000000000182,
        "average": 23.5
      },
      "rationale_metrics": {
        "rouge_l": 0.30952380952380953,
        "text_similarity": 0.7541681528091431,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor and immediate wide-eyed reaction sequence, but the timestamps are substantially off (~24s earlier) and the predicted duration/extra nod detail do not match the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes warning against creating a 'cycle of learned helplessness', when does he ask how they would approach the problem?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3136.766,
        "end": 3138.327
      },
      "pred_interval": {
        "start": 3151.6,
        "end": 3153.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.833999999999833,
        "end": 15.172999999999774,
        "average": 15.003499999999804
      },
      "rationale_metrics": {
        "rouge_l": 0.23376623376623376,
        "text_similarity": 0.7777292728424072,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the target immediately follows the anchor, but the provided absolute timestamps differ substantially (~16s) from the ground truth and it introduces an unsupported closing phrase, so the timing and wording are largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman first states that the advice is about 'a way of being', when does she re-emphasize that 'This is about a way of being'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3178.623,
        "end": 3181.496
      },
      "pred_interval": {
        "start": 3233.5,
        "end": 3236.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.87699999999995,
        "end": 54.503999999999905,
        "average": 54.69049999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.17204301075268816,
        "text_similarity": 0.664921760559082,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the re-emphasis occurs after the initial statement and matches the quoted phrasing, but the supplied timestamps are substantially off (about 60s later) compared with the reference, so the answer is factually inaccurate on key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman suggests to 'crack a window open', when does she ask 'what would happen if?'",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3213.0,
        "end": 3217.0
      },
      "pred_interval": {
        "start": 3216.0,
        "end": 3218.0
      },
      "iou": 0.2,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 1.0,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.36111111111111116,
        "text_similarity": 0.78155916929245,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor time and the temporal relation ('after'); the predicted E2 start (3216.0s) differs from the reference start (3213.0s) by 3s but still falls within the referenced E2 interval (3213.0\u20133217.0s), so it is essentially correct with a minor timing discrepancy."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman asks for the name of the course, when does she state the name herself?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3391.0,
        "end": 3393.0
      },
      "pred_interval": {
        "start": 3394.0,
        "end": 3396.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 3.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.273972602739726,
        "text_similarity": 0.7911099791526794,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the same utterances and the 'after' relationship, but the timestamps are inaccurate (E1 placed at 3386.0s vs 3380.0\u20133383.0s and E2 at 3394.0s vs 3391.0\u20133393.0s), so it receives partial credit."
      }
    },
    {
      "question_id": "001",
      "question": "After the man confirms 'building bridges', when does the woman ask him about traveling?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3390.0,
        "end": 3482.7169999999996
      },
      "gt_interval": {
        "start": 3401.076,
        "end": 3404.512
      },
      "pred_interval": {
        "start": 3403.5,
        "end": 3409.2
      },
      "iou": 0.1245691777449774,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.423999999999978,
        "end": 4.687999999999647,
        "average": 3.5559999999998126
      },
      "rationale_metrics": {
        "rouge_l": 0.28205128205128205,
        "text_similarity": 0.6450271606445312,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the 'after' relation and identifies the 'but you do travel' inquiry, but the event timestamps are noticeably shifted (E1 ~6\u20138s late; E2 starts ~2.4s late and ends ~4.7s late) and the prediction adds an extra preceding phrase not present in the reference, so it is only partially accurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says his website is on the screen, when does he mention having other tips and resources?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3390.0,
        "end": 3482.7169999999996
      },
      "gt_interval": {
        "start": 3425.376,
        "end": 3431.514
      },
      "pred_interval": {
        "start": 3429.0,
        "end": 3432.5
      },
      "iou": 0.35289163391355916,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.6239999999997963,
        "end": 0.9859999999998763,
        "average": 2.3049999999998363
      },
      "rationale_metrics": {
        "rouge_l": 0.28125,
        "text_similarity": 0.6422934532165527,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the sequence and even quotes the line about tips/resources, preserving the relation (E2 after E1), but the timestamp for E1 is off by ~5.6s and E2 start/end times differ from the reference by ~3.6s and ~1s respectively, so timings are imprecise."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman asks viewers to click the subscribe button, when does she mention inviting Nick back?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3390.0,
        "end": 3482.7169999999996
      },
      "gt_interval": {
        "start": 3471.07,
        "end": 3474.532
      },
      "pred_interval": {
        "start": 3476.0,
        "end": 3479.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.929999999999836,
        "end": 4.967999999999847,
        "average": 4.948999999999842
      },
      "rationale_metrics": {
        "rouge_l": 0.29850746268656714,
        "text_similarity": 0.7407742738723755,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the correct ordering and content (she invites Nick back after the subscribe prompt) but the timestamps are significantly off\u2014E1 and E2 are shifted later and do not match the ground-truth start/end times or intervals."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker explains that she will show what to do before, during, and after parent-teacher conferences with five tips, when does the '5' graphic appear on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.258,
        "end": 37.358
      },
      "pred_interval": {
        "start": 31.0,
        "end": 33.0
      },
      "iou": 0.27398553004089365,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.2579999999999991,
        "end": 4.357999999999997,
        "average": 2.307999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.25581395348837205,
        "text_similarity": 0.777252197265625,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction roughly captures the graphic's start (31.0s vs 31.258s) but gives an incorrect end time (33.0s vs 37.358s) and misstates the speaker/anchor timing (23.0s vs 29.8\u201331.9s), so it is partially correct but misses key timing details."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker introduces herself as a special education advocate, when do the visual overlays 'IEPs' and '504 Plans' appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 47.954,
        "end": 51.274
      },
      "pred_interval": {
        "start": 48.0,
        "end": 51.0
      },
      "iou": 0.9036144578313252,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.045999999999999375,
        "end": 0.2740000000000009,
        "average": 0.16000000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.2784810126582279,
        "text_similarity": 0.7310469150543213,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction roughly matches the onset timing but omits the precise end of the speaker's introduction and misstates the overlays' timing \u2014 it claims 'IEPs' and '504 Plans' appear staggered at 48.0s and 49.0s, whereas the reference shows them appearing together at ~47.954s and disappearing at ~51.274s; end-time differences are also slightly off."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what one needs to do to prepare to help their child, when does the 'How Do You Prepare?' graphic appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 192.8,
        "end": 195.0
      },
      "pred_interval": {
        "start": 192.4,
        "end": 196.5
      },
      "iou": 0.5365853658536565,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.4000000000000057,
        "end": 1.5,
        "average": 0.9500000000000028
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.516170859336853,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the speaker question and the graphic appearance with only minor timestamp discrepancies (graphic start 0.4s early and end 1.5s late) and omits an explicit note that the graphic occurs after the anchor speech ends, though that is implied."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker mentions her guide 'The Ten Keys to Communication', when is the guide's cover displayed on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 238.0,
        "end": 242.0
      },
      "pred_interval": {
        "start": 237.8,
        "end": 241.5
      },
      "iou": 0.8333333333333356,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.19999999999998863,
        "end": 0.5,
        "average": 0.3499999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.17073170731707316,
        "text_similarity": 0.5224948525428772,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately identifies the cover's on-screen interval (237.8\u2013241.5s) which closely matches the reference (238.0\u2013242.0s) and correctly states it appears during the speaker's mention; differences are negligible."
      }
    },
    {
      "question_id": "003",
      "question": "During the speaker's introduction of 'tip two', when does the 'Tip 2' graphic appear on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 294.0,
        "end": 298.0
      },
      "pred_interval": {
        "start": 294.9,
        "end": 296.2
      },
      "iou": 0.32500000000000284,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8999999999999773,
        "end": 1.8000000000000114,
        "average": 1.3499999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.6921539902687073,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly matches the graphic's onset (~294s) but gives a later speaker cue time and an earlier disappearance (296.2s vs 298.0s), and introduces a replacement graphic not mentioned in the reference, so it partially aligns but is factually inconsistent on key timing/details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what the difference is between IEP and 504 plans, when does the graphic with the number '10' appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 380.8,
        "end": 383.86
      },
      "pred_interval": {
        "start": 381.8,
        "end": 384.2
      },
      "iou": 0.6058823529411812,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 0.339999999999975,
        "average": 0.6699999999999875
      },
      "rationale_metrics": {
        "rouge_l": 0.37333333333333335,
        "text_similarity": 0.5063201189041138,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target events and their temporal order, with only small timing offsets (anchor ~1\u20132s early, target start ~1s late, end ~0.3s late) and an extra unverified detail about her saying 'ten differences.'"
      }
    },
    {
      "question_id": "002",
      "question": "After the text overlay 'Academic Adjustments' appears, when does the text overlay 'Accommodations' appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 450.722,
        "end": 451.722
      },
      "pred_interval": {
        "start": 449.2,
        "end": 451.0
      },
      "iou": 0.11022997620936596,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5219999999999914,
        "end": 0.72199999999998,
        "average": 1.1219999999999857
      },
      "rationale_metrics": {
        "rouge_l": 0.4411764705882353,
        "text_similarity": 0.6778216361999512,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the ordering right (Accommodations appears after Academic Adjustments) and gives approximate times, but the timestamps are notably off (~1.5s), it omits the disappearance time for Academic Adjustments, and adds an unsupported detail about screen position."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker describes where children might be struggling by listing areas, when do icons representing different areas of need appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 455.722,
        "end": 460.135
      },
      "pred_interval": {
        "start": 454.2,
        "end": 459.5
      },
      "iou": 0.6365627632687478,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5219999999999914,
        "end": 0.6349999999999909,
        "average": 1.0784999999999911
      },
      "rationale_metrics": {
        "rouge_l": 0.2926829268292683,
        "text_similarity": 0.4608386754989624,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies both events and that the icons appear during the speaker's description, but the reported timestamps deviate from the ground truth by about 1\u20132 seconds and the speech end time is omitted, so the timing is not accurately matched."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces question two, when does she first ask what the teacher is doing to support the child?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 516.831,
        "end": 519.018
      },
      "pred_interval": {
        "start": 516.5,
        "end": 521.5
      },
      "iou": 0.43740000000000234,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3310000000000173,
        "end": 2.481999999999971,
        "average": 1.406499999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2524271844660194,
        "text_similarity": 0.4589272141456604,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the main relationship (the target follows the anchor and includes the question phrase) but has notable timing errors and a small contradiction: the anchor/target boundaries differ by several tenths to ~2.5s (target end) and it omits the slight overlap present in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "During the discussion about the Meeting Toolkit, when does the speaker highlight how it provides clarity on accommodations versus modifications?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 609.57,
        "end": 615.0
      },
      "pred_interval": {
        "start": 612.5,
        "end": 618.0
      },
      "iou": 0.29655990510083213,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.92999999999995,
        "end": 3.0,
        "average": 2.964999999999975
      },
      "rationale_metrics": {
        "rouge_l": 0.23655913978494625,
        "text_similarity": 0.6120941638946533,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the content of the E2 utterance but the timings are inaccurate: E1 is given as 601s vs the correct 609.5s, and E2 should be 609.0\u2013615.0s while the prediction gives 612.5\u2013618.0s (only partial overlap and extends beyond the true interval). It also adds an unverified visual detail (checklist)."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker talking about implementing new supports and services and wanting to follow up, when does the 'Follow Up' graphic appear on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 690.0,
        "end": 887.283
      },
      "gt_interval": {
        "start": 707.435,
        "end": 710.155
      },
      "pred_interval": {
        "start": 708.0,
        "end": 712.0
      },
      "iou": 0.47207009857611104,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.5650000000000546,
        "end": 1.8450000000000273,
        "average": 1.205000000000041
      },
      "rationale_metrics": {
        "rouge_l": 0.13513513513513514,
        "text_similarity": 0.3752739429473877,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the graphic appearing during the speaker's remark and gives an onset very close to the ground truth (708.0s vs 707.435s), but the predicted disappearance time is inaccurate (712.0s vs 710.155s), extending the graphic about 1.8s too long."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker clarifies her listener's 'action plan', when does she mention checking out her video 'How To Get An IEP'?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 690.0,
        "end": 887.283
      },
      "gt_interval": {
        "start": 745.788,
        "end": 748.198
      },
      "pred_interval": {
        "start": 743.0,
        "end": 748.0
      },
      "iou": 0.42554828780300075,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.788000000000011,
        "end": 0.19799999999997908,
        "average": 1.492999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.4473684210526316,
        "text_similarity": 0.7008023262023926,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the events, order, and title and matches the end time closely, but it misreports the start of the video mention (743.0s vs the reference 745.788s), a minor temporal inaccuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once Margaret finishes introducing herself, when does she introduce her husband Marco and sister Mary?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 9.58,
        "end": 12.102
      },
      "pred_interval": {
        "start": 9.0,
        "end": 12.0
      },
      "iou": 0.7801418439716311,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.5800000000000001,
        "end": 0.10200000000000031,
        "average": 0.3410000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2318840579710145,
        "text_similarity": 0.6837071776390076,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures that the family introduction immediately follows her self-introduction and the E2 timing matches closely; the only minor issue is the E1 start time (~00:07) which is about 1\u20131.5s earlier than the reference (8.099s)."
      }
    },
    {
      "question_id": "002",
      "question": "After Margaret states they are speaking to primary and secondary teachers specifically, when does she say that the information can more broadly benefit students?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 50.9,
        "end": 55.67
      },
      "pred_interval": {
        "start": 53.0,
        "end": 57.0
      },
      "iou": 0.43770491803278705,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.1000000000000014,
        "end": 1.3299999999999983,
        "average": 1.7149999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.22784810126582275,
        "text_similarity": 0.6378961205482483,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the semantic relation (E2 occurs after E1 and expresses broader benefit to students) and roughly matches the timestamps; minor discrepancies in the exact start/end times for E2 account for a small deduction."
      }
    },
    {
      "question_id": "003",
      "question": "After Margaret tells interpreters and translators to email them for a certificate of attendance, when does she state that they are not producing certificates?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.787,
        "end": 114.451
      },
      "pred_interval": {
        "start": 146.0,
        "end": 150.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.212999999999994,
        "end": 35.54900000000001,
        "average": 37.881
      },
      "rationale_metrics": {
        "rouge_l": 0.2535211267605634,
        "text_similarity": 0.7067176103591919,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately captures the timing and content: the anchor and target time ranges align closely with the reference (within rounding), the quoted line matches, and it correctly identifies the relationship as 'after'."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker touches on budgets and administrators, when does she mention pursuing things career-wise?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 172.462
      },
      "pred_interval": {
        "start": 167.0,
        "end": 171.0
      },
      "iou": 0.7323324789454427,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 1.461999999999989,
        "average": 0.7309999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.2926829268292683,
        "text_similarity": 0.5816552042961121,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted timestamps and relation match the reference (E1 within 153.844\u2013157.929s, E2 within 167\u2013172.462s) and correctly state the relation as 'after', so it accurately reflects the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After Marco says they are all 'language geeks', when does he describe his experience teaching in a bilingual program on the Mexican border?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 278.303,
        "end": 309.735
      },
      "pred_interval": {
        "start": 251.0,
        "end": 265.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.302999999999997,
        "end": 44.735000000000014,
        "average": 36.019000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.32941176470588235,
        "text_similarity": 0.7313681840896606,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction roughly identifies the anchor utterance but with a small timestamp offset; it also captures the correct content for the bilingual-teaching segment but places E2 much earlier (251\u2013265s vs. 278.303\u2013309.735s), a significant timing error that makes the alignment incorrect despite preserving the 'after' relation."
      }
    },
    {
      "question_id": "003",
      "question": "After Marco describes his experience of having to translate English handouts into Spanish, when does Margaret share a similar experience with campus newsletters?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 331.826,
        "end": 355.983
      },
      "pred_interval": {
        "start": 345.0,
        "end": 359.0
      },
      "iou": 0.4041731066460592,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.173999999999978,
        "end": 3.016999999999996,
        "average": 8.095499999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.18666666666666668,
        "text_similarity": 0.6846403479576111,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the same events and the 'after' relation, but the reported timestamps deviate substantially from the reference (E1 ~13s late, E2 ~13s late at start and ~3s late at end) and includes an extra detail not present in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions working on the campus newsletter all week for a Friday release, when does she describe being asked to translate it on Thursday afternoon?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.383,
        "end": 355.983
      },
      "pred_interval": {
        "start": 355.0,
        "end": 359.0
      },
      "iou": 0.21290881524799657,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.6170000000000186,
        "end": 3.016999999999996,
        "average": 1.8170000000000073
      },
      "rationale_metrics": {
        "rouge_l": 0.21666666666666667,
        "text_similarity": 0.5456991791725159,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the sequence and content (anchor then immediate request) and has only minor start-time offsets, but it overextends the target segment by ~3s and includes the subsequent interjection, causing a notable timing/segmentation mismatch with the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker finishes her point about being asked to translate due to bilingualism, when does the second speaker (Mary Lamb) introduce herself?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 413.696,
        "end": 416.456
      },
      "pred_interval": {
        "start": 416.0,
        "end": 424.0
      },
      "iou": 0.04425465838509496,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.3039999999999736,
        "end": 7.543999999999983,
        "average": 4.923999999999978
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.5855433344841003,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies Mary Lamb introducing herself, but the timestamps are notably later and the predicted end time extends well beyond the reference; it also adds extra utterances not present in the ground truth, so timing and completeness are inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"We want to just touch on some terminology that we will be using today\", when does she start to clarify \"Translation versus interpretation\"?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 613.706,
        "end": 627.331
      },
      "pred_interval": {
        "start": 606.5,
        "end": 683.0
      },
      "iou": 0.1781045751633987,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.206000000000017,
        "end": 55.66899999999998,
        "average": 31.4375
      },
      "rationale_metrics": {
        "rouge_l": 0.2115384615384615,
        "text_similarity": 0.6733992695808411,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the qualitative relation ('after') right but the timestamps are substantially off: E1 is ~2.8s early, E2 starts ~7s earlier and ends ~55s later than the reference, effectively hallucinating an extended clarification and missing the correct end time."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker defines 'language access', when does she start talking about 'LEP'?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 705.6,
        "end": 710.0
      },
      "pred_interval": {
        "start": 709.2,
        "end": 714.8
      },
      "iou": 0.08695652173912613,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.6000000000000227,
        "end": 4.7999999999999545,
        "average": 4.199999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.28260869565217395,
        "text_similarity": 0.7300392389297485,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that discussion of LEP follows the language-access definition and even provides a quoted start, but the reported timestamps differ noticeably from the reference (E1 off by ~9s, E2 start/end off by several seconds), so timing accuracy is only moderate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker clarifies that they are 'not talking about politics today', when does she explain that language comes with 'cultural and emotional baggage'?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 757.048,
        "end": 780.333
      },
      "pred_interval": {
        "start": 764.5,
        "end": 771.2
      },
      "iou": 0.2877388876959439,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.451999999999998,
        "end": 9.132999999999925,
        "average": 8.292499999999961
      },
      "rationale_metrics": {
        "rouge_l": 0.3106796116504854,
        "text_similarity": 0.7339197397232056,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the quoted phrase and places E2 within the correct interval, but the timestamps are slightly shifted (E1 ~7s late and E2 ends ~9s earlier) so timing is not exact though the semantic match is good."
      }
    },
    {
      "question_id": "003",
      "question": "Once the male voice finishes inviting participants to the chat, when does the female voice add to the chat invitation?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 822.133,
        "end": 827.458
      },
      "pred_interval": {
        "start": 826.4,
        "end": 832.3
      },
      "iou": 0.10406216189633141,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.266999999999939,
        "end": 4.8419999999999845,
        "average": 4.554499999999962
      },
      "rationale_metrics": {
        "rouge_l": 0.3296703296703297,
        "text_similarity": 0.7370182871818542,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the female adds immediately after the male, but the timestamps are off by ~4\u20135 seconds (predicted 826.4\u2013832.3s vs. reference 822.133\u2013827.458s) and it includes quoted content not specified in the reference, so it is temporally and factually misaligned."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker explains 'back translating' through DeepL, when does she say they will show an example?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 938.629,
        "end": 940.511
      },
      "pred_interval": {
        "start": 944.2,
        "end": 946.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.571000000000026,
        "end": 5.88900000000001,
        "average": 5.730000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.09999999999999999,
        "text_similarity": 0.25818103551864624,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct utterance but the timestamps are off by about 5\u20136 seconds (both the end of the explanation and the start/end of the example utterance), so the anchor/target intervals and temporal alignment do not match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker points out that 'UIL Academics' was not translated by Google Translate, when does she explain the cultural meaning of 'a letter' in the US context?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 979.009,
        "end": 1035.774
      },
      "pred_interval": {
        "start": 983.7,
        "end": 1000.8
      },
      "iou": 0.30124196247687746,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.691000000000031,
        "end": 34.97399999999993,
        "average": 19.832499999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.12280701754385964,
        "text_similarity": 0.17562979459762573,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the back-translation discussion and locates the cultural explanation within the E2 segment, but the timestamps are slightly off (anchor given as ~966s vs 970\u2013973s) and the predicted end time (1000.8s) is earlier than the reference target end (1035.774s)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker discusses 'a letter referring to a letter jacket', when does she suggest changing the vocabulary for accurate translation?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1107.0,
        "end": 1150.0
      },
      "pred_interval": {
        "start": 1101.5,
        "end": 1110.0
      },
      "iou": 0.061855670103092786,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.5,
        "end": 40.0,
        "average": 22.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3409090909090909,
        "text_similarity": 0.7194720506668091,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor and the 'after' relation and captures a similar utterance, but its target timing is significantly earlier and much shorter than the ground truth (1107.0\u20131150.0s), omitting the full span of the speaker's completed thought."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that Google Translate and DeepL are almost identical and accurate for the student handbook, when does she highlight a minor difference in DeepL's translation?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1151.0,
        "end": 1161.0
      },
      "pred_interval": {
        "start": 1150.0,
        "end": 1162.0
      },
      "iou": 0.8333333333333334,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.0,
        "end": 1.0,
        "average": 1.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.5866519808769226,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer aligns closely with the reference: anchor and target intervals and the described content match, with only 1\u20132 second rounding differences, and the temporal relation ('after') is preserved."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining why AI machine translations struggle with literary texts, when does she provide the first example of a mistranslated Russian literary text?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1200.0,
        "end": 1204.0
      },
      "pred_interval": {
        "start": 1200.5,
        "end": 1205.0
      },
      "iou": 0.7,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.5,
        "end": 1.0,
        "average": 0.75
      },
      "rationale_metrics": {
        "rouge_l": 0.5,
        "text_similarity": 0.6880031824111938,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction matches the reference closely\u2014anchor end and target start/end times are within ~0.5\u20131s and the relation (first example after finish) is preserved; minor discrepancies include a small timing offset and an extra detail about 'teenage slang' not mentioned in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the Spanish-speaking father begins his first statement, when does the interpreter finish translating it to English?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1467.348,
        "end": 1510.677
      },
      "pred_interval": {
        "start": 1466.5,
        "end": 1471.5
      },
      "iou": 0.09398555809584291,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8479999999999563,
        "end": 39.17699999999991,
        "average": 20.012499999999932
      },
      "rationale_metrics": {
        "rouge_l": 0.2597402597402597,
        "text_similarity": 0.789504885673523,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer gets the temporal relation ('after') right and roughly locates the events, the timestamps are substantially inaccurate\u2014especially the interpreter's end time (1471.5s vs. correct 1510.677s) and the father's end time\u2014omitting the long translation and correction, so it fails on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the lecturer asks what's hard about consecutive interpretation, when does the interpreter finish explaining her challenges?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1509.179,
        "end": 1519.19
      },
      "pred_interval": {
        "start": 1511.0,
        "end": 1522.0
      },
      "iou": 0.6387957257624296,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.8209999999999127,
        "end": 2.8099999999999454,
        "average": 2.315499999999929
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324323,
        "text_similarity": 0.7185337543487549,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction roughly identifies that the interpreter finishes after the lecturer's question, but it gives incorrect and notably later timestamps for both events (off by ~1\u20133 s) and labels the relation as 'after' instead of the specified 'once_finished', so it is only a partial, imprecise match."
      }
    },
    {
      "question_id": "003",
      "question": "After the lecturer introduces sight translation, when does the interpreter begin reading the handwritten note aloud?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1556.54,
        "end": 1558.452
      },
      "pred_interval": {
        "start": 1560.0,
        "end": 1562.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.4600000000000364,
        "end": 3.548000000000002,
        "average": 3.504000000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.24691358024691357,
        "text_similarity": 0.7272703051567078,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relation (E2 occurs after E1) and that the interpreter reads aloud, but the timestamps are noticeably inaccurate (E1 start ~7.6s early; E2 start/end ~3.5s late) and it adds a quoted phrase not present in the reference, so it is partially incorrect and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the main presenter mentions a side exercise on the next slide, when does he begin discussing the importance of preparation for interpreting?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1615.359,
        "end": 1621.799
      },
      "pred_interval": {
        "start": 1618.5,
        "end": 1633.5
      },
      "iou": 0.18185326056997764,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.1410000000000764,
        "end": 11.701000000000022,
        "average": 7.421000000000049
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.7842860221862793,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly locates the anchor near 1615s and that the target follows, but its target start/end times (1618.5s\u20131633.5s) substantially disagree with the ground-truth window (1615.359s\u20131621.799s) and it introduces an explicit quote and extra details not supported by the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the main presenter describes an interpreter as a 'traffic cop', when does he describe the typical reactions people have to being instructed by an interpreter?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1703.019,
        "end": 1712.776
      },
      "pred_interval": {
        "start": 1706.5,
        "end": 1716.5
      },
      "iou": 0.46554409910244565,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.4809999999999945,
        "end": 3.7239999999999327,
        "average": 3.6024999999999636
      },
      "rationale_metrics": {
        "rouge_l": 0.28,
        "text_similarity": 0.7647681832313538,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor, the target content and their order, and paraphrases the reactions; only minor timestamp discrepancies (a few seconds) and slight differences in endpoints reduce perfect alignment."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says he will see if the AI can understand him, when does he start speaking in Russian?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1813.0,
        "end": 1829.8
      },
      "pred_interval": {
        "start": 1816.5,
        "end": 1835.5
      },
      "iou": 0.5911111111111091,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 5.7000000000000455,
        "average": 4.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619052,
        "text_similarity": 0.5465956926345825,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the order (Russian follows the English utterance) but the timestamps are several seconds off for both E1 and E2 and E2's end is overstated, so it does not match the ground-truth timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker describes training attorneys and judges about simultaneous interpretation, when does he explain the purpose of this for non-bilingual people?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.703,
        "end": 1964.21
      },
      "pred_interval": {
        "start": 1964.0,
        "end": 1969.0
      },
      "iou": 0.022587931590839605,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.2970000000000255,
        "end": 4.789999999999964,
        "average": 4.5434999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.175,
        "text_similarity": 0.5323362350463867,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies both events, their content, and that E2 occurs after E1, but the timestamps are notably shifted (E1 slightly later and E2 moved and extended several seconds beyond the ground-truth interval), so the timing accuracy is lacking."
      }
    },
    {
      "question_id": "003",
      "question": "Once the interpreter finishes speaking the text, when does the speaker ask the audience to evaluate the message transmission?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2033.24,
        "end": 2039.185
      },
      "pred_interval": {
        "start": 2112.0,
        "end": 2118.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.75999999999999,
        "end": 78.81500000000005,
        "average": 78.78750000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818185,
        "text_similarity": 0.4300886392593384,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the sequence right (interpreter finishes then speaker asks for evaluation) but the provided time intervals are substantially off (~80\u201390s later) and do not overlap the ground-truth windows, so it fails on precise temporal alignment and correctness."
      }
    },
    {
      "question_id": "001",
      "question": "After the female speaker says it's hard to hear over the sound of her own voice, when does the male speaker comment about being distracted by reading?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2146.342,
        "end": 2148.204
      },
      "pred_interval": {
        "start": 2146.5,
        "end": 2151.5
      },
      "iou": 0.33036060488565544,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.15799999999990177,
        "end": 3.2959999999998217,
        "average": 1.7269999999998618
      },
      "rationale_metrics": {
        "rouge_l": 0.1935483870967742,
        "text_similarity": 0.7138271331787109,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the ordering and roughly the male's turn start, but it misstates the female utterance end (2146.5s vs correct 2140.8s) and the male turn end (2151.5s vs 2148.204s), so the timestamps and durations are inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Interpreting' slide, when does the female speaker state that teaching and interpreting are two different jobs?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2219.994,
        "end": 2241.697
      },
      "pred_interval": {
        "start": 2238.5,
        "end": 2241.0
      },
      "iou": 0.11519144818688674,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.505999999999858,
        "end": 0.6970000000001164,
        "average": 9.601499999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.20512820512820512,
        "text_similarity": 0.6816772222518921,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only partially matches (both say the phrase occurs while the slide is on), but it misidentifies the speaker (male vs female) and gives incorrect times for both the slide end (2244s vs 2259.84s) and the utterance (2238.5\u20132241.0s vs 2219.994\u20132241.697s), so it is largely inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the male speaker explains that doing the interpretation exercise makes people more willing to speak slowly and make pauses, what is the next action he suggests?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2169.782,
        "end": 2173.68
      },
      "pred_interval": {
        "start": 2169.5,
        "end": 2172.0
      },
      "iou": 0.5306220095693622,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.2820000000001528,
        "end": 1.6799999999998363,
        "average": 0.9809999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307692,
        "text_similarity": 0.6875841617584229,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the next item is giving written information and occurs immediately after, with timestamps roughly aligned; however it omits the alternate item (hiring an interpreter) listed in the reference and gives a slightly different end timestamp for the target."
      }
    },
    {
      "question_id": "001",
      "question": "Once the other speaker states that translating 100 pages would take longer than a weekend, when does the main speaker agree and say it would probably take a month?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2348.812,
        "end": 2349.894
      },
      "pred_interval": {
        "start": 2350.5,
        "end": 2352.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.6880000000001019,
        "end": 2.606000000000222,
        "average": 2.147000000000162
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.5581049919128418,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction preserves the speaker identities, sequence, and that the main speaker immediately follows saying 'Probably take a month,' but the reported timestamps are off by ~1.9\u20132.6 seconds from the ground truth, so it's imprecise on timing."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the hourly rates for interpreters, when does he mention there is often a two-hour minimum?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2378.997,
        "end": 2380.078
      },
      "pred_interval": {
        "start": 2421.5,
        "end": 2424.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.503000000000156,
        "end": 43.922000000000025,
        "average": 43.21250000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.6426382064819336,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer captures that the two-hour minimum is mentioned but gives substantially incorrect timestamps (2421.5\u20132424.0s vs reference 2378.997\u20132380.078s) and does not provide the precise E1 end time, so it is largely misaligned with the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions being aware of the difference between freelancers and agencies, when does he explain that most translators and interpreters are freelancers who work for agencies?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2403.56,
        "end": 2407.963
      },
      "pred_interval": {
        "start": 2446.5,
        "end": 2451.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.940000000000055,
        "end": 43.03699999999981,
        "average": 42.98849999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.3477514088153839,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relation that E2 immediately follows E1 and gives a similar short duration, but the absolute timestamps are substantially off (~43s later) and thus factually inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions working for an agency, when does she mention working as a freelancer?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2686.2,
        "end": 2687.5
      },
      "pred_interval": {
        "start": 2688.2,
        "end": 2690.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 2.900000000000091,
        "average": 2.4500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.3835616438356164,
        "text_similarity": 0.7213847637176514,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the freelancer mention follows, but the target timestamps are offset by ~2\u20133 seconds from the ground truth and the timing/ordering detail (immediately after) is inaccurate, so it is only a partial match."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'we can dare to dream', when does Marco start talking about his Spanish interpreting skills?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2733.4,
        "end": 2738.4
      },
      "pred_interval": {
        "start": 2776.2,
        "end": 2790.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.79999999999973,
        "end": 51.79999999999973,
        "average": 47.29999999999973
      },
      "rationale_metrics": {
        "rouge_l": 0.2972972972972973,
        "text_similarity": 0.6710071563720703,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gets the speaker-order/transition right (immediate 'once_finished') but all timestamps are incorrect and it adds content about Marco's teaching that is not in the reference, so it largely fails to match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After Marco describes how teaching Spanish improved his interpreting skills, when does the speaker (Margaret) share her similar experience about teaching young children?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2749.5,
        "end": 2752.9
      },
      "pred_interval": {
        "start": 2790.5,
        "end": 2818.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.0,
        "end": 65.09999999999991,
        "average": 53.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.7861433029174805,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that Margaret speaks after Marco and shares a similar experience, but it gives substantially incorrect timestamps and an inaccurate duration (hallucinated timing), contradicting the key factual elements of the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the female speaker finishes listing language populations like Vietnamese, German, and French, when does she mention Arabic?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2857.835,
        "end": 2858.836
      },
      "pred_interval": {
        "start": 2860.0,
        "end": 2862.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.1649999999999636,
        "end": 3.1640000000002146,
        "average": 2.664500000000089
      },
      "rationale_metrics": {
        "rouge_l": 0.17647058823529413,
        "text_similarity": 0.7300355434417725,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('immediately after') but the anchor/target timestamps are substantially wrong and it adds unsupported dialogue details, so it is largely factually inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male speaker asks if an agency can provide a price for an interpreter scenario, when does he state that it's not a trade secret?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2915.411,
        "end": 2918.755
      },
      "pred_interval": {
        "start": 2921.0,
        "end": 2922.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.588999999999942,
        "end": 3.744999999999891,
        "average": 4.666999999999916
      },
      "rationale_metrics": {
        "rouge_l": 0.1714285714285714,
        "text_similarity": 0.7332767248153687,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamps and temporal relation are incorrect: it places the anchor and target several seconds later than the ground truth and labels the relation as merely 'after' instead of 'immediately follows.' This misaligns key factual timing details despite correctly identifying that the target follows the question."
      }
    },
    {
      "question_id": "003",
      "question": "After the male speaker invites participants to unmute and ask questions, when does he mention that an email with a video link will be sent next week?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2969.806,
        "end": 2975.771
      },
      "pred_interval": {
        "start": 2973.5,
        "end": 2978.5
      },
      "iou": 0.2612146307798707,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.69399999999996,
        "end": 2.7289999999998145,
        "average": 3.2114999999998872
      },
      "rationale_metrics": {
        "rouge_l": 0.19780219780219782,
        "text_similarity": 0.6961488723754883,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the events, their order, and approximate times/content, but has small timing inaccuracies (anchor given as a single time rather than the full span; target start is later than the reference and the predicted end extends beyond the true end) and adds an extra detail about stopping screen share not present in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman on the top left panel says \"I would go to that school as a starting point\", how long does she continue explaining the process of approaching a school?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3031.4,
        "end": 3049.5
      },
      "pred_interval": {
        "start": 3038.0,
        "end": 3058.0
      },
      "iou": 0.4323308270676707,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.599999999999909,
        "end": 8.5,
        "average": 7.5499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.16494845360824745,
        "text_similarity": 0.45981526374816895,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly identifies the start and end of the explanation and gives a close relative duration (~20s) compared to the reference duration (18.1s), with only a small timing discrepancy of ~1\u20132 seconds."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man on the top left panel finishes mentioning PTA meetings or board meetings, when does the woman on the top left panel start talking about who they want to know?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3059.8,
        "end": 3062.05
      },
      "pred_interval": {
        "start": 3064.0,
        "end": 3076.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.199999999999818,
        "end": 13.949999999999818,
        "average": 9.074999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.10752688172043011,
        "text_similarity": 0.24637813866138458,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly reports that the woman speaks immediately after the man and utters the target line ('they will want to know who you are'), but it gives imprecise/converted timestamps and adds extra details about driver's license/background checks and a longer duration that are not specified in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man on the top left panel finishes explaining how to use YouTube videos for practice, when does the woman on the top left panel begin mentioning volunteering through church connections?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3110.298,
        "end": 3113.563
      },
      "pred_interval": {
        "start": 3114.0,
        "end": 3126.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.7020000000002256,
        "end": 12.436999999999898,
        "average": 8.069500000000062
      },
      "rationale_metrics": {
        "rouge_l": 0.125,
        "text_similarity": 0.15523430705070496,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the woman immediately follows and mentions volunteering, but the reported timing (01:24\u201301:36) substantially disagrees with the reference start/end (3110.298s\u20133113.563s) and adds unverified details, so the answer is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes asking her main question about recommendations for remote interpreting in educational settings, when does the man (Jesse Thompson) ask if she'll be working directly for the school or an agency?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3259.94,
        "end": 3264.367
      },
      "pred_interval": {
        "start": 3265.1,
        "end": 3268.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.1599999999998545,
        "end": 4.432999999999993,
        "average": 4.796499999999924
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5101133584976196,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the order (man asks after the woman) and the content of the question, but the reported timestamps are substantially off (woman ~10s late; man's question start/end several seconds later than the ground truth) and the predicted spans do not match the correct intervals."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman says 'That's a great point' for the second time, when does she state that she will be persistent?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3384.717,
        "end": 3386.626
      },
      "pred_interval": {
        "start": 3390.6,
        "end": 3392.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.882999999999811,
        "end": 5.673999999999978,
        "average": 5.7784999999998945
      },
      "rationale_metrics": {
        "rouge_l": 0.3428571428571428,
        "text_similarity": 0.5897216200828552,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the overall 'after' relation but misidentifies the timing of the second \"That's a great point\" and the \"I will be persistent\" utterance by several seconds and adds unverified intervening content, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions she has been doing IEP meetings since January, when does she state that 80% of them were virtual?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3419.487,
        "end": 3423.472
      },
      "pred_interval": {
        "start": 3421.2,
        "end": 3424.0
      },
      "iou": 0.503434522490678,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.712999999999738,
        "end": 0.5279999999997926,
        "average": 1.1204999999997654
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7878334522247314,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted timestamps align closely with the reference (anchor within the anchor interval, target start within the target interval and end only ~0.5s off) and correctly labels the temporal relation as 'after', with no factual contradictions."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker describes IEPs as not straightforward, when does another person define an IEP as an individualized education plan under special education?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3472.184,
        "end": 3478.875
      },
      "pred_interval": {
        "start": 3474.1,
        "end": 3479.2
      },
      "iou": 0.6805872291904715,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.9159999999997126,
        "end": 0.3249999999998181,
        "average": 1.1204999999997654
      },
      "rationale_metrics": {
        "rouge_l": 0.21505376344086022,
        "text_similarity": 0.6472306251525879,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the speakers' content and the general sequential relation, but the timestamps differ (anchor given as a single 3468.0s rather than the 3463.757\u20133472.184s interval) and the target start (3474.1s) does not match the correct immediate-following start at 3472.184s, so immediacy is not preserved."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions that agencies don't get the information, when does she give examples like a brief summary or an IP packet?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3616.2,
        "end": 3624.0
      },
      "pred_interval": {
        "start": 3616.4,
        "end": 3622.1
      },
      "iou": 0.7307692307691904,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.20000000000027285,
        "end": 1.900000000000091,
        "average": 1.050000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.24175824175824176,
        "text_similarity": 0.6222741603851318,
        "llm_judge_score": 8,
        "llm_judge_justification": "The predicted answer correctly captures the events, their order, and the examples, with relationship matching; minor timestamp discrepancies (E1 ~2.5s off and E2 end ~1.9s early) justify a small deduction."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says that doing the budget is the hardest part, when does she mention 'numbers, the dates, and all this'?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3631.3,
        "end": 3633.3
      },
      "pred_interval": {
        "start": 3631.0,
        "end": 3633.5
      },
      "iou": 0.8,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.3000000000001819,
        "end": 0.1999999999998181,
        "average": 0.25
      },
      "rationale_metrics": {
        "rouge_l": 0.37209302325581395,
        "text_similarity": 0.685596227645874,
        "llm_judge_score": 7,
        "llm_judge_justification": "The predicted answer correctly identifies both events and their ordering (E2 occurs shortly after E1) and E2's timings are close, but E1's timestamp is off by several seconds compared to the reference, so it's not fully accurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker suggests asking people to share their screen, when does she suggest asking them to scroll as they read?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3669.7,
        "end": 3672.2
      },
      "pred_interval": {
        "start": 3668.0,
        "end": 3671.0
      },
      "iou": 0.3095238095238662,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.699999999999818,
        "end": 1.199999999999818,
        "average": 1.449999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.34408602150537637,
        "text_similarity": 0.579838752746582,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both suggestions and their sequential relation, and the timestamps are very close to the reference (within ~0.9\u20131.7s); minor issues are the slightly earlier times and omission of E1's end boundary. "
      }
    },
    {
      "question_id": "001",
      "question": "After the first female speaker asks about inquiring with the school for contacts with various specialists for special education IEPs, when does the second female speaker state that it's a great idea for background information?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3750.0,
        "end": 3853.87
      },
      "gt_interval": {
        "start": 3772.54,
        "end": 3777.487
      },
      "pred_interval": {
        "start": 3774.6,
        "end": 3780.0
      },
      "iou": 0.38699731903487355,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0599999999999454,
        "end": 2.51299999999992,
        "average": 2.2864999999999327
      },
      "rationale_metrics": {
        "rouge_l": 0.38775510204081637,
        "text_similarity": 0.8636555075645447,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the second speaker and the gist of her line, but the timestamps are significantly off and the relation is misstated as 'immediate succession' rather than the simple 'after' with a gap; thus it fails on key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second female speaker finishes asking what professionals usually talk about, when does she ask about the terminologies they use?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3750.0,
        "end": 3853.87
      },
      "gt_interval": {
        "start": 3782.973,
        "end": 3786.917
      },
      "pred_interval": {
        "start": 3785.6,
        "end": 3789.5
      },
      "iou": 0.2017772330320206,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.6269999999999527,
        "end": 2.5830000000000837,
        "average": 2.605000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367344,
        "text_similarity": 0.6251818537712097,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the sequential relation and the follow-up question content, but the timestamps are significantly off (by ~2.6s for start/end times) and the event durations do not match the reference, so it is not an accurate temporal alignment."
      }
    },
    {
      "question_id": "003",
      "question": "Once the male speaker finishes saying that interpreters are friendly and help each other, when does the second female speaker explain that it's because it's a small community?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3750.0,
        "end": 3853.87
      },
      "gt_interval": {
        "start": 3843.755,
        "end": 3850.083
      },
      "pred_interval": {
        "start": 3845.6,
        "end": 3850.5
      },
      "iou": 0.664640474425537,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.8449999999998,
        "end": 0.4169999999999163,
        "average": 1.1309999999998581
      },
      "rationale_metrics": {
        "rouge_l": 0.25263157894736843,
        "text_similarity": 0.6885092258453369,
        "llm_judge_score": 8,
        "llm_judge_justification": "The predicted answer correctly captures the speakers, dialogue content, and the immediate-successor relation, but the provided timestamps for both the anchor end and target start are ~1.8s later than the ground truth, a modest but relevant timing discrepancy."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker introduces the topic of a parent letter, when does she mention that emotional language is fraught with danger for AI?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1264.183,
        "end": 1268.577
      },
      "pred_interval": {
        "start": 1265.0,
        "end": 1269.0
      },
      "iou": 0.7425783682790104,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.8170000000000073,
        "end": 0.4230000000000018,
        "average": 0.6200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.7938663959503174,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer correctly identifies both events, captures the quoted phrasing, and gives timestamps within about 1 second of the reference, preserving the 'after' relation with no substantive errors."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker reads the ambiguous phrase 'I would have raised my hand on her child', when does she begin questioning its meaning?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1297.182,
        "end": 1306.16
      },
      "pred_interval": {
        "start": 1299.0,
        "end": 1307.0
      },
      "iou": 0.7292727643104597,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.8179999999999836,
        "end": 0.8399999999999181,
        "average": 1.3289999999999509
      },
      "rationale_metrics": {
        "rouge_l": 0.25581395348837205,
        "text_similarity": 0.5162501335144043,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both events, their semantic content, and that E2 follows E1, but the timestamps are slightly shifted (E1 ~0.8s later and E2 start ~1.8s later, end ~0.8s later) compared to the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes saying that something 'doesn't make a lot of sense', when does the second speaker say 'Over to me?'",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1340.99,
        "end": 1341.351
      },
      "pred_interval": {
        "start": 1342.0,
        "end": 1343.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.009999999999991,
        "end": 1.6489999999998872,
        "average": 1.329499999999939
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.661340594291687,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the first speaker's utterance timing roughly, but the second speaker's start/end times are ~1\u20132s later than the reference and the added 'slide transition/brief pause' contradicts the documented direct once_finished transition and introduces unsupported detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what she is talking about, when does she begin to explain it?",
      "video_id": "y9bwM3YYMd0",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 23.383
      },
      "gt_interval": {
        "start": 1.974,
        "end": 5.3
      },
      "pred_interval": {
        "start": 1.3,
        "end": 5.5
      },
      "iou": 0.7919047619047618,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.6739999999999999,
        "end": 0.20000000000000018,
        "average": 0.43700000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.3111111111111111,
        "text_similarity": 0.5861462950706482,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly matches the anchor timing but places the target start much earlier (1.3s vs 1.974s) and shortens/ends the explanation around 5.5s, whereas the ground truth indicates a later start and a continued target event (up to 10.989s); key temporal details are therefore incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to document evidence and justify a request, when does she mention that 'all of this can be documented in writing'?",
      "video_id": "y9bwM3YYMd0",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 23.383
      },
      "gt_interval": {
        "start": 11.189,
        "end": 14.2
      },
      "pred_interval": {
        "start": 11.0,
        "end": 13.5
      },
      "iou": 0.7221875000000001,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.18900000000000006,
        "end": 0.6999999999999993,
        "average": 0.4444999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2891566265060241,
        "text_similarity": 0.6354231834411621,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target and captures the complete spoken phrase; the provided timestamps are slightly offset from the reference (E1 ~0.5s early, E2 ~0.7s early) but still align closely and contain the full phrase."
      }
    },
    {
      "question_id": "003",
      "question": "While Anna explains how to add parent collaboration, when does the presenter click the wrench icon in the top right corner of the screen?",
      "video_id": "9su8PwUYUhQ",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 176.283
      },
      "gt_interval": {
        "start": 2.313,
        "end": 2.317
      },
      "pred_interval": {
        "start": 151.5,
        "end": 152.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 149.187,
        "end": 150.183,
        "average": 149.685
      },
      "rationale_metrics": {
        "rouge_l": 0.2947368421052632,
        "text_similarity": 0.7870020866394043,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly describes clicking the wrench and opening Class Settings during the explanation, but the timestamps are wildly incorrect (predicted ~151s vs correct ~2.3s) and thus misaligns key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After the male student in the plaid shirt says that they were 'invalidated', when does he mention 'mental health'?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 10.6,
        "end": 11.8
      },
      "pred_interval": {
        "start": 9.5,
        "end": 11.5
      },
      "iou": 0.391304347826087,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0999999999999996,
        "end": 0.3000000000000007,
        "average": 0.7000000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413796,
        "text_similarity": 0.7033972144126892,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events, the semantic content, and that the target occurs after the anchor; timestamps are very close (E1 exact, E2 start is ~1.1s earlier than reference) so only a minor timing discrepancy exists."
      }
    },
    {
      "question_id": "002",
      "question": "After the female student in the black coat talks about 'basic respect', when does the female student in the purple hoodie question why a first-grader incident is being brought up?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 59.8,
        "end": 64.7
      },
      "pred_interval": {
        "start": 52.5,
        "end": 106.5
      },
      "iou": 0.09074074074074084,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.299999999999997,
        "end": 41.8,
        "average": 24.549999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.20183486238532108,
        "text_similarity": 0.66033935546875,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the speakers, relative order, and content roughly right, but the timestamps are substantially off (anchor predicted ~52s vs correct 30.8\u201336.5s; target start/end times are misaligned), and it adds specific timing details that contradict the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the female student in the black hijab asserts that she 'did put a conclusion', when does the female student in the white hoodie explain the 'trauma-informed approach'?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.0,
        "end": 123.6
      },
      "pred_interval": {
        "start": 199.0,
        "end": 204.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.0,
        "end": 80.4,
        "average": 80.7
      },
      "rationale_metrics": {
        "rouge_l": 0.1894736842105263,
        "text_similarity": 0.7019835114479065,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately matches the reference timings and order: the anchor (~78s) falls within the correct anchor interval and the target start/end (119s\u2013124s) closely match 118.0s\u2013123.6s, with the target occurring after the anchor."
      }
    },
    {
      "question_id": "001",
      "question": "After the first student finishes speaking about seeing their point of view, when does the man in the black vest and backpack start speaking?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 180.8,
        "end": 184.6
      },
      "pred_interval": {
        "start": 188.0,
        "end": 191.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.199999999999989,
        "end": 6.400000000000006,
        "average": 6.799999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.3636363636363637,
        "text_similarity": 0.5853322148323059,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the ordering (man speaks after the student) but the timestamps are substantially off (E1: 32.0s vs 179.0s; E2 start: 188.0s vs 180.8s; E2 end: 191.0s vs 184.6s) and adds unsupported detail about the reporter; therefore it is largely incorrect. "
      }
    },
    {
      "question_id": "001",
      "question": "After the girl in the purple hoodie finishes her statement, when does the man with the microphone ask if anyone else wants to speak?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 330.0,
        "end": 384.801
      },
      "gt_interval": {
        "start": 335.3,
        "end": 337.5
      },
      "pred_interval": {
        "start": 339.8,
        "end": 342.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.5,
        "end": 5.0,
        "average": 4.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3448275862068966,
        "text_similarity": 0.6337177753448486,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction preserves the correct temporal relation (the man speaks after the girl) and even captures the utterance, but the provided timestamps are offset by ~5 seconds from the ground truth and the start/end times do not match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the girl in the grey hoodie finishes her explanation about introverts, when does the male student in the blue jacket start speaking?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 330.0,
        "end": 384.801
      },
      "gt_interval": {
        "start": 363.5,
        "end": 372.7
      },
      "pred_interval": {
        "start": 367.8,
        "end": 377.3
      },
      "iou": 0.355072463768114,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.300000000000011,
        "end": 4.600000000000023,
        "average": 4.450000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.29411764705882354,
        "text_similarity": 0.5767642259597778,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the correct temporal relation and gives timestamps roughly consistent with the reference, but the times are shifted by several seconds and the answer adds unsupported/details (interjection, laughter, quoted dialogue) not present in the ground truth, so it is partially inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man with the microphone asks the 'brother' if he wants to say anything, when does the man in the black vest respond?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 330.0,
        "end": 384.801
      },
      "gt_interval": {
        "start": 378.0,
        "end": 383.6
      },
      "pred_interval": {
        "start": 381.0,
        "end": 384.8
      },
      "iou": 0.3823529411764733,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 1.1999999999999886,
        "average": 2.0999999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.2298850574712644,
        "text_similarity": 0.5932611227035522,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the relation (immediate response) and even the respondent's utterance, but the reported timestamps are noticeably offset from the ground truth (anchor ~3.2s later and target start ~3.0s later), so it is semantically correct but temporally imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states that the cat comes in whenever it's showtime, when does she ask 'How do you know?'",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 58.579,
        "end": 60.615
      },
      "pred_interval": {
        "start": 60.0,
        "end": 62.0
      },
      "iou": 0.17977199649225434,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.4209999999999994,
        "end": 1.384999999999998,
        "average": 1.4029999999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.841334879398346,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly captures the anchor start but extends E1 too late and shifts E2 about 1.4s later (predicts 60.0\u201362.0 vs correct 58.579\u201360.615), only overlapping briefly; timings for the target are therefore inaccurate and not a close match."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'We are going live', when does she welcome the friends?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.063,
        "end": 104.724
      },
      "pred_interval": {
        "start": 104.5,
        "end": 106.5
      },
      "iou": 0.09191629052113418,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.4369999999999976,
        "end": 1.7759999999999962,
        "average": 1.106499999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.23880597014925373,
        "text_similarity": 0.85611891746521,
        "llm_judge_score": 6,
        "llm_judge_justification": "The anchor timing is effectively matched, and the predicted target start is close, but the prediction hallucinates an extra 'Welcome' at 102.0s and incorrectly extends the 'Welcome friends' end time to 106.5s instead of ~104.724s, so it is only partially accurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the Summer Stride Tuesday Night Author Series, when does she mention that it's summertime for adults?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 198.433,
        "end": 202.298
      },
      "pred_interval": {
        "start": 201.0,
        "end": 203.5
      },
      "iou": 0.2561673574106967,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5670000000000073,
        "end": 1.2019999999999982,
        "average": 1.8845000000000027
      },
      "rationale_metrics": {
        "rouge_l": 0.3380281690140845,
        "text_similarity": 0.8181533813476562,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both anchor and target events and the quoted phrase, with timestamps closely matching the reference; only minor discrepancies in the exact start/end times (predicted end ~1.2s later) prevent a perfect score."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the 'Summer Stride Tuesday Night Author Series', when does she describe the Summer Stride reading challenge for adults?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.9,
        "end": 254.0
      },
      "pred_interval": {
        "start": 205.0,
        "end": 218.0
      },
      "iou": 0.2594810379241517,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0999999999999943,
        "end": 36.0,
        "average": 18.549999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.7997835874557495,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor, the start of E2, and the temporal relation ('after') and captures the main content, but it substantially underestimates E2's end time (218.0s vs 254.0s), omitting a significant portion of the described segment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"And it's really fun.\", when does she mention Malaka Garib doing a zine?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 342.37,
        "end": 345.33
      },
      "pred_interval": {
        "start": 344.0,
        "end": 346.0
      },
      "iou": 0.36639118457299885,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.6299999999999955,
        "end": 0.6700000000000159,
        "average": 1.1500000000000057
      },
      "rationale_metrics": {
        "rouge_l": 0.3513513513513513,
        "text_similarity": 0.6499282121658325,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target events, and the temporal relation 'after'; the predicted anchor timestamp matches closely and the target interval is slightly shifted (~1.6s later start, ~0.7s later end) but preserves the correct ordering and content."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces Rhodessa Jones, when is the next time she says \"So please come check that out.\"?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 388.074,
        "end": 389.334
      },
      "pred_interval": {
        "start": 388.0,
        "end": 390.0
      },
      "iou": 0.6299999999999955,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.07400000000001228,
        "end": 0.6659999999999968,
        "average": 0.37000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.2985074626865672,
        "text_similarity": 0.7622324228286743,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and next target and their temporal relationship ('after'); timestamps are very close to the reference with only minor timing discrepancies (start/end differences under ~0.7s)."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela mentions that any question is open for the chat, when does she hold up the physical copy of 'The Overly Honest Teacher'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 563.7,
        "end": 567.0
      },
      "pred_interval": {
        "start": 565.0,
        "end": 569.0
      },
      "iou": 0.377358490566041,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2999999999999545,
        "end": 2.0,
        "average": 1.6499999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.23999999999999996,
        "text_similarity": 0.651504635810852,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target and their relative order; the anchor time aligns closely and the target start is within ~1.3s of the reference, with only a minor ~2s discrepancy on the end time."
      }
    },
    {
      "question_id": "002",
      "question": "Once Angela finishes saying she will turn it over to Meredith, when does Meredith begin speaking?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 590.0,
        "end": 594.0
      },
      "pred_interval": {
        "start": 592.0,
        "end": 596.0
      },
      "iou": 0.3333333333333333,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 2.0,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.1764705882352941,
        "text_similarity": 0.483506977558136,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the speakers and that Meredith speaks after Angela, but the timestamps are inaccurate (off by ~1\u20132s), it wrongly introduces a gap between speeches, and it extends Meredith's duration, contradicting the correct 'immediately follows' relation."
      }
    },
    {
      "question_id": "003",
      "question": "After Meredith introduces herself as the author, when does she start talking about what everyone has gone through in the last 18 months regarding education?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 625.0,
        "end": 679.0
      },
      "pred_interval": {
        "start": 629.0,
        "end": 643.0
      },
      "iou": 0.25925925925925924,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 36.0,
        "average": 20.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.6144782304763794,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor\u2192target order and gives a target start (629s) very close to the reference (625s), and the predicted target lies within the reference window; minor timing offsets exist (anchor given as 604s vs 597\u2013602.5s, and the predicted target ends earlier than the full reference range)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the main topic slide, when does the first specific point, 'Consistency', appear on screen?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 727.0,
        "end": 727.9
      },
      "pred_interval": {
        "start": 728.0,
        "end": 731.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 3.1000000000000227,
        "average": 2.0500000000000114
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.5313928723335266,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly identifies the 'Consistency' onset (about 1s later than the reference) but omits the precise E1 times and gives an incorrect, much later end time tied to the next graphic, contradicting the reference settle time of 727.9s."
      }
    },
    {
      "question_id": "002",
      "question": "After the last point, 'Autonomy', appears on screen, when does the speaker begin to talk about her past teaching experience and starting the year with the definition of autonomy?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 749.5,
        "end": 751.9
      },
      "pred_interval": {
        "start": 738.0,
        "end": 754.0
      },
      "iou": 0.14999999999999858,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.5,
        "end": 2.1000000000000227,
        "average": 6.800000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.339622641509434,
        "text_similarity": 0.5982460975646973,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly approximates E1 but significantly misidentifies E2's start time (738.0s vs the ground-truth 749.5s) and adds incorrect content about middle-school teaching, failing to match key temporal and factual details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker uses the example of traffic lights to explain consistency, when does she give the example of microwave popcorn instructions?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 822.0,
        "end": 831.0
      },
      "pred_interval": {
        "start": 823.0,
        "end": 832.0
      },
      "iou": 0.8,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.0,
        "end": 1.0,
        "average": 1.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2272727272727273,
        "text_similarity": 0.5862622261047363,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the microwave popcorn example immediately after the traffic-light segment and provides start/end times that are essentially one second later than the reference; it omits the traffic-light start time but otherwise matches semantically and factually."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions setting meal times as important, when does she elaborate on discussing meals further during the evening?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 891.0
      },
      "pred_interval": {
        "start": 886.0,
        "end": 890.0
      },
      "iou": 0.5,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 1.0,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4269662921348315,
        "text_similarity": 0.7049379348754883,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the same utterances and that the elaboration follows, but the timestamps are slightly shifted (anchor time is ~2\u20133s off and its end is omitted) and the target boundaries differ modestly from the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide lists 'Daily schedule of classes', 'Set meal times', etc., when does the speaker elaborate on students crashing and burning due to lack of food?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 900.2,
        "end": 911.0
      },
      "pred_interval": {
        "start": 906.0,
        "end": 910.0
      },
      "iou": 0.3703703703703719,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.7999999999999545,
        "end": 1.0,
        "average": 3.3999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.3097759485244751,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the speaker's remark and that it occurs while the slide is shown, but the timestamps differ from the reference (starts at 906.0s vs 900.2s, ends ~910.0s vs 911.0s), it omits the quoted ending 'bodies are running on empty', and it slightly reframes the content as stressing 'importance of food' rather than the negative outcome due to lack of food."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that all listed things can be implemented at home, when does the slide update to reveal the 'Having a schedule and routine at home mimics...' text?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 964.9,
        "end": 965.0
      },
      "pred_interval": {
        "start": 1008.0,
        "end": 1010.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.10000000000002,
        "end": 45.0,
        "average": 44.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.6783155798912048,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (E2 follows E1) but has substantially incorrect timestamps, an incorrect completion duration, and adds an unsupported slide title\u2014so it is largely factually wrong despite the correct ordering."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes talking about morning hygiene routines, when does she start talking about knowing the time to leave the house?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1059.9,
        "end": 1067.9
      },
      "pred_interval": {
        "start": 1061.0,
        "end": 1069.0
      },
      "iou": 0.7582417582417759,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.099999999999909,
        "end": 1.099999999999909,
        "average": 1.099999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.1518987341772152,
        "text_similarity": 0.6846121549606323,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the transition and content, with start/end times and wording that align closely to the reference; minor timing offsets (~1.1s) and a slight difference in the anchor phrasing justify a small deduction."
      }
    },
    {
      "question_id": "002",
      "question": "While the 'After school' list of activities is displayed, when does the speaker mention 'making time for dinner'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1104.2,
        "end": 1107.0
      },
      "pred_interval": {
        "start": 1106.0,
        "end": 1109.0
      },
      "iou": 0.2083333333333353,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.7999999999999545,
        "end": 2.0,
        "average": 1.8999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.3037974683544304,
        "text_similarity": 0.7729901075363159,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the 'making time for dinner' utterance within the 'After school' period and its timing is close (~1106s vs 1104.2\u20131107.0s), but it omits the precise E1 start/end timestamps given in the reference and gives a slightly later end time for E2, so key temporal details are missing/inexact."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes being consistent, when does she mention that parents might sometimes feel like 'the heavy'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1140.4,
        "end": 1145.7
      },
      "pred_interval": {
        "start": 1142.0,
        "end": 1148.0
      },
      "iou": 0.4868421052631697,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.599999999999909,
        "end": 2.2999999999999545,
        "average": 1.9499999999999318
      },
      "rationale_metrics": {
        "rouge_l": 0.16091954022988508,
        "text_similarity": 0.6632887125015259,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target segmentation and the quoted line about feeling like 'the heavy,' but its timestamps are consistently ~1.5\u20133s later than the reference\u2014minor timing discrepancies rather than semantic errors."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes discussing how consistency helps with sibling rivalry, when is the 'ACCOUNTABILITY' slide fully displayed?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1246.0,
        "end": 1247.5
      },
      "pred_interval": {
        "start": 1246.0,
        "end": 1253.0
      },
      "iou": 0.21428571428571427,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.0,
        "end": 5.5,
        "average": 2.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.6434258222579956,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the slide appearing at 1246.0s but misstates the anchor (1245.0s vs correct 1241.0s) and wrongly extends the slide display to 1253.0s (contradicting the correct end around 1247.5s), adding unfounded detail."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker emphasizes the importance of repeatedly stressing accountability, when does the second panel describing accountability appear on the slide?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1285.7,
        "end": 1286.2
      },
      "pred_interval": {
        "start": 1286.0,
        "end": 1300.0
      },
      "iou": 0.01398601398601721,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.2999999999999545,
        "end": 13.799999999999955,
        "average": 7.0499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.3142857142857143,
        "text_similarity": 0.6256174445152283,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events and the temporal relation (E2 after E1) and closely matches the event start times (E1 ~1275s vs 1272s, E2 ~1286s vs 1285.7s); minor timing offsets and the extra end-time for E2 (1300s) are deviations but not contradictory."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that accountability is the baseline foundation for a school community, when does she mention 'due dates for homework assignments'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1329.7,
        "end": 1331.9
      },
      "pred_interval": {
        "start": 1333.0,
        "end": 1336.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.2999999999999545,
        "end": 4.099999999999909,
        "average": 3.699999999999932
      },
      "rationale_metrics": {
        "rouge_l": 0.3582089552238805,
        "text_similarity": 0.578632116317749,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor (accountability) and the temporal relation (E2 after E1), and E1's interval overlaps the ground truth, but the E2 time window is significantly later than the reference and does not overlap the true span, so the answer is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"If there's one thing you take away to put in your toolbox tonight, I hope it is this\", when does she explain what students had to write if they said something negative?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1442.41,
        "end": 1454.99
      },
      "pred_interval": {
        "start": 1443.5,
        "end": 1446.5
      },
      "iou": 0.23847376788553398,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0899999999999181,
        "end": 8.490000000000009,
        "average": 4.789999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.17204301075268816,
        "text_similarity": 0.575964093208313,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that the explanation (students had to write 25 positive adjectives) occurs after the anchor and matches the E2 content and approximate start, but the anchor timestamp is significantly off (1421s vs 1434.03s) and the predicted E2 window is much shorter than the ground-truth full explanation (ends at 1454.99s), so it's a partial match."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes talking about reminding themselves of positive thoughts, when does she introduce the topic of 'Restorative practice when community has been broken'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1486.37,
        "end": 1488.95
      },
      "pred_interval": {
        "start": 1517.5,
        "end": 1521.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.13000000000011,
        "end": 32.549999999999955,
        "average": 31.840000000000032
      },
      "rationale_metrics": {
        "rouge_l": 0.34408602150537637,
        "text_similarity": 0.6788455247879028,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the same transition and topic (reminding self \u2192 'Restorative practice...') and preserves the relation, but the timestamps are substantially off (\u224830\u201340s later) and the end time/duration do not match the reference."
      }
    },
    {
      "question_id": "003",
      "question": "While the green slide titled \"Holding everyone accountable for their own choices and responsibilities\" is displayed, when does the speaker give the example of parents getting a dog for their kids?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1524.93,
        "end": 1577.73
      },
      "pred_interval": {
        "start": 1556.5,
        "end": 1610.0
      },
      "iou": 0.24955918655225148,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.569999999999936,
        "end": 32.26999999999998,
        "average": 31.91999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.2365591397849462,
        "text_similarity": 0.4804883599281311,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the dog example occurs during the green slide, but it misstates the slide title and gives substantially different start/end times (each ~30s later than the reference) and omits the slide's correct end time, so key factual timing and label details are inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states 'You must be your student's parent first', when does she say that 'you can't always say 'yes' and give in to whatever they want'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1694.8,
        "end": 1697.5
      },
      "pred_interval": {
        "start": 1759.0,
        "end": 1762.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.20000000000005,
        "end": 65.0,
        "average": 64.60000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1941747572815534,
        "text_similarity": 0.6202553510665894,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target events and their relative order, but the provided timestamps are substantially shifted from the reference (well beyond typical tolerance), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states that 'we have to equip them with their ability to be able to overcome obstacles', when does she explain what saying 'no' does?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1785.657,
        "end": 1788.202
      },
      "pred_interval": {
        "start": 1787.8,
        "end": 1795.0
      },
      "iou": 0.04302686503264909,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.143000000000029,
        "end": 6.798000000000002,
        "average": 4.4705000000000155
      },
      "rationale_metrics": {
        "rouge_l": 0.17204301075268816,
        "text_similarity": 0.6675570607185364,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer correctly identifies the anchor phrase and approximate anchor time, but the target timing and duration are incorrect and extend well beyond the ground truth, altering the temporal relationship (not immediate) and adding extra content; therefore it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to 'help and not hinder their development', when does she suggest brainstorming for an essay instead of writing it for them?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1881.94,
        "end": 1883.282
      },
      "pred_interval": {
        "start": 1883.2,
        "end": 1886.5
      },
      "iou": 0.017982456140324767,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.259999999999991,
        "end": 3.2180000000000746,
        "average": 2.2390000000000327
      },
      "rationale_metrics": {
        "rouge_l": 0.2816901408450704,
        "text_similarity": 0.6704534888267517,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and the 'after' relationship, but gives imprecise timing: it omits the anchor end, shifts the target start later than the reference, and erroneously extends the target end beyond the ground-truth interval, adding unsupported content."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide transitions to 'Collaboration Form Two', when does the speaker say that teachers want to work with parents and guardians?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1934.726,
        "end": 1943.0
      },
      "pred_interval": {
        "start": 1939.5,
        "end": 1945.5
      },
      "iou": 0.3248561351401556,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.773999999999887,
        "end": 2.5,
        "average": 3.6369999999999436
      },
      "rationale_metrics": {
        "rouge_l": 0.24,
        "text_similarity": 0.7225050330162048,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the target occurs after it, but it misstates the target speech timing substantially (predicted start ~1939.5s vs reference 1934.726s, predicted end 1945.5s vs reference 1943s) and adds quoted phrasing\u2014so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"It is so important so that we can get a hold of you when we need to be able to talk,\" when do the bullet points on the slide disappear?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2163.0,
        "end": 2163.5
      },
      "pred_interval": {
        "start": 2134.3,
        "end": 2135.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.699999999999818,
        "end": 28.5,
        "average": 28.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.21568627450980393,
        "text_similarity": 0.7409495115280151,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation right ('immediately after') but the reported timestamps are significantly incorrect (about 28 seconds earlier) and do not match the reference start/end times, so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker describes a harmonious journey with unicorns and rainbows, when does she say, \"It's not always going to be perfect. And there's going to be times where we are going to continue to butt heads\"?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2176.5,
        "end": 2181.0
      },
      "pred_interval": {
        "start": 2149.1,
        "end": 2154.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.40000000000009,
        "end": 26.5,
        "average": 26.950000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.3116883116883117,
        "text_similarity": 0.6844409704208374,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the relation/right-to-follow and quotes the phrase, but the anchor and target timestamps are significantly incorrect (off by ~27.5s and end times mismatch), so it fails on key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker suggests saying, \"I don't think this is going the way that either of us intended,\" when does she suggest scheduling time later in the week for a phone call?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2219.5,
        "end": 2226.5
      },
      "pred_interval": {
        "start": 2252.2,
        "end": 2258.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.69999999999982,
        "end": 31.5,
        "average": 32.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413793,
        "text_similarity": 0.6794281601905823,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the order and that the target follows immediately after the anchor, but the provided timestamps differ substantially from the ground truth (2252s vs 2219.5s) and the event durations/boundaries do not match, making it factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that most classrooms will have a homework board, when does she suggest that students should come to school equipped with a planner?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2495.0,
        "end": 2500.0
      },
      "pred_interval": {
        "start": 2495.5,
        "end": 2500.5
      },
      "iou": 0.8181818181818182,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.5,
        "end": 0.5,
        "average": 0.5
      },
      "rationale_metrics": {
        "rouge_l": 0.4489795918367347,
        "text_similarity": 0.7248352766036987,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the target phrase and that it follows the anchor, and the target timings are close, but the anchor timestamp is notably off (predicted ~2494s vs correct 2490.5\u20132491.2), causing a temporal misalignment."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker suggests having accessible snacks that can be accessed independently at home, when does she mention tasking students with making their own lunch or breakfast?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2538.8,
        "end": 2542.8
      },
      "pred_interval": {
        "start": 2541.0,
        "end": 2545.5
      },
      "iou": 0.26865671641794486,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.199999999999818,
        "end": 2.699999999999818,
        "average": 2.449999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.43902439024390244,
        "text_similarity": 0.6357041597366333,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the anchor and the target content, and the target start falls within the reference span, but the predicted end time is later than the ground truth and it adds extra phrasing ('or portions thereof') not present in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker suggests having students set out their clothes the night before, when does she mention that these actions will help ease up on hectic morning routines?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2604.5,
        "end": 2608.0
      },
      "pred_interval": {
        "start": 2604.5,
        "end": 2608.5
      },
      "iou": 0.875,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 0.5,
        "average": 0.25
      },
      "rationale_metrics": {
        "rouge_l": 0.45,
        "text_similarity": 0.7667601704597473,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer matches the reference semantically and the timestamps align closely (anchor within the correct interval, target start identical and end off by only 0.5s), with no contradictions or omitted key details."
      }
    },
    {
      "question_id": "001",
      "question": "After Meredith asks Angela if there are any questions, when does Angela respond about pushing her buttons?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2698.0,
        "end": 2701.0
      },
      "pred_interval": {
        "start": 2702.8,
        "end": 2707.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.800000000000182,
        "end": 6.0,
        "average": 5.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.26829268292682923,
        "text_similarity": 0.7063513994216919,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the relation ('after') and the content of Angela's reply right, but the event timestamps are substantially off (E1 and E2 times differ by several seconds from the ground truth), so it is factually inaccurate on the key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "Once Angela finishes her question about kindergartener and eighth grader interactions on cell phones, when does Meredith begin to answer?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2771.5,
        "end": 2773.5
      },
      "pred_interval": {
        "start": 2816.2,
        "end": 2820.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.69999999999982,
        "end": 46.5,
        "average": 45.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.2558139534883721,
        "text_similarity": 0.6042250394821167,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the 'once_finished' relation, but the timestamps are substantially incorrect (2816.2s vs correct ~2770.5\u20132771.5s) and it wrongly asserts immediate simultaneous timing, contradicting the one-second gap in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After Meredith encourages parents to follow their students on social media, when does she explain how to approach conversations offline?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2717.3,
        "end": 2729.9
      },
      "pred_interval": {
        "start": 2873.5,
        "end": 2880.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 156.19999999999982,
        "end": 150.0999999999999,
        "average": 153.14999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.2830188679245283,
        "text_similarity": 0.7086769342422485,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the content and the 'after' relation (encouraging follow then advising to take conversations offline with honesty), but the timestamps are substantially off (~150\u2013160 seconds later) compared to the ground truth, so it only partially matches."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker talks about establishing very baseline questions to begin with around social media with kids, when does she mention having family meetings around responsibility?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2893.0,
        "end": 2896.0
      },
      "pred_interval": {
        "start": 2896.5,
        "end": 2901.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 5.0,
        "average": 4.25
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818185,
        "text_similarity": 0.6061363220214844,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and preserves that the target occurs after it, but it misstates the target timestamps (shifting them later to ~2896.5\u20132901s instead of 2893\u20132896s) and adds an inaccurate interval."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having to change how you talk in terms of voice projection for different age groups in the classroom, when does she advise being careful about the words you're choosing to use?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2921.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2923.0,
        "end": 2927.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 4.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.19753086419753085,
        "text_similarity": 0.6783230900764465,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target content and even quotes the target line, but the timestamps for E2 are inaccurate (predicted 2923.0\u20132927.0 vs gold 2921.0\u20132923.0), while E1 timing is acceptably close."
      }
    },
    {
      "question_id": "001",
      "question": "After Meredith discusses students possibly feeling social anxiety and insecurity when re-entering school, when does she suggest getting them together with friends and classmates ahead of time?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3092.1,
        "end": 3098.5
      },
      "pred_interval": {
        "start": 3092.2,
        "end": 3098.5
      },
      "iou": 0.9843750000000144,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.09999999999990905,
        "end": 0.0,
        "average": 0.049999999999954525
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.7383373975753784,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly locates E2 and the relation (immediately after/once finished) but substantially misplaces E1\u2019s end time (predicting ~3092.2s vs the correct ~3077.7s), so the anchor timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After Angela praises the 'breakfast idea', when does Meredith add that candles don't have to just be for birthdays?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3150.324,
        "end": 3153.068
      },
      "pred_interval": {
        "start": 3150.0,
        "end": 3153.2
      },
      "iou": 0.8575000000000931,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.3240000000000691,
        "end": 0.1319999999996071,
        "average": 0.2279999999998381
      },
      "rationale_metrics": {
        "rouge_l": 0.3421052631578948,
        "text_similarity": 0.7727458477020264,
        "llm_judge_score": 7,
        "llm_judge_justification": "The predicted answer correctly identifies the two events and gives times very close to the reference, but it slightly shifts E1 later and E2 earlier and incorrectly characterizes the relation as 'immediately after' despite a ~2s gap in the reference, so the temporal relation is overstated."
      }
    },
    {
      "question_id": "001",
      "question": "After Meredith Esau states that social and emotional learning doesn't have to exist in its own silo, when does she talk about teachers weaving social-emotional learning into debate?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3227.397,
        "end": 3232.508
      },
      "pred_interval": {
        "start": 3229.0,
        "end": 3235.0
      },
      "iou": 0.4613968170458741,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.6030000000000655,
        "end": 2.492000000000189,
        "average": 2.0475000000001273
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454545,
        "text_similarity": 0.6346874833106995,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events and their 'after' relation, with only minor timing discrepancies (within ~0.6\u20132.5s) and a small extension of the end boundary; no factual contradiction or hallucination affecting meaning."
      }
    },
    {
      "question_id": "002",
      "question": "During Meredith Esau's explanation about enabling students to see their unique talents, when does she mention students wanting to code instead of playing football?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3269.041,
        "end": 3312.931
      },
      "pred_interval": {
        "start": 3311.0,
        "end": 3316.0
      },
      "iou": 0.04112097787431689,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.95899999999983,
        "end": 3.06899999999996,
        "average": 22.513999999999896
      },
      "rationale_metrics": {
        "rouge_l": 0.2156862745098039,
        "text_similarity": 0.6442201137542725,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the football vs. coding example and its placement within the explanation, but the timestamps are substantially off (~3307\u20133316s vs ~3261\u20133269s) and the relation is ambiguously labeled 'after/during' instead of clearly 'during'."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela finishes asking about parents in conflict regarding screen time, when does Meredith start her response by saying \"Absolutely\"?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3400.93,
        "end": 3402.12
      },
      "pred_interval": {
        "start": 3401.4,
        "end": 3402.4
      },
      "iou": 0.489795918367126,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.47000000000025466,
        "end": 0.2800000000002001,
        "average": 0.3750000000002274
      },
      "rationale_metrics": {
        "rouge_l": 0.38095238095238093,
        "text_similarity": 0.5926103591918945,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction preserves the correct temporal relation and captures that Meredith says 'Absolutely' immediately after Angela, with only small, acceptable offsets in the reported timestamps (\u22480.5\u20130.8s later than the reference)."
      }
    },
    {
      "question_id": "002",
      "question": "After Meredith states that you should \"never put your student in the middle\", when does she suggest helping them develop their own sense of compromise?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3462.72,
        "end": 3469.49
      },
      "pred_interval": {
        "start": 3462.5,
        "end": 3466.0
      },
      "iou": 0.4692417739628473,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.2199999999997999,
        "end": 3.4899999999997817,
        "average": 1.8549999999997908
      },
      "rationale_metrics": {
        "rouge_l": 0.32500000000000007,
        "text_similarity": 0.6212202310562134,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately matches the anchor and target timings (E1 ~3448s within the referenced range; E2 3462.5\u20133466.0s falls within the correct span) and preserves the 'after' relationship, with only minor acceptable timestamp rounding differences."
      }
    },
    {
      "question_id": "003",
      "question": "After Angela lists several places where Meredith's book is available, when does she specifically mention Green Apple Books?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3556.06,
        "end": 3559.12
      },
      "pred_interval": {
        "start": 3557.4,
        "end": 3559.1
      },
      "iou": 0.5555555555555061,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3400000000001455,
        "end": 0.01999999999998181,
        "average": 0.6800000000000637
      },
      "rationale_metrics": {
        "rouge_l": 0.30985915492957744,
        "text_similarity": 0.6226716041564941,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately captures both events and their temporal order, with event time ranges closely matching the reference and correctly indicating that the Green Apple Books mention occurs later."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela asks if librarians buy digital books, when does Anissa confirm they do?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3595.925,
        "end": 3600.567
      },
      "pred_interval": {
        "start": 3599.0,
        "end": 3603.0
      },
      "iou": 0.22148409893993606,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.074999999999818,
        "end": 2.4329999999999927,
        "average": 2.7539999999999054
      },
      "rationale_metrics": {
        "rouge_l": 0.23999999999999996,
        "text_similarity": 0.6398877501487732,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that Anissa confirms immediately after Angela, but the timestamps differ substantially (predicted ~3599s vs. reference ~3595.9s start) and the answer adds quoted dialog not present in the ground truth, so it is only a partial, imprecise match."
      }
    },
    {
      "question_id": "002",
      "question": "Once Anissa finishes asking Angela if she wants to take the YouTube viewer's question, when does Angela say 'Sure, yeah'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3617.561,
        "end": 3621.102
      },
      "pred_interval": {
        "start": 3621.0,
        "end": 3623.0
      },
      "iou": 0.018753447324850993,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.438999999999851,
        "end": 1.8980000000001382,
        "average": 2.6684999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.46874999999999994,
        "text_similarity": 0.8064948916435242,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that Angela responds immediately after Anissa, but the provided timestamps are noticeably off (Anissa end shifted from 3617.061s to 3621s and Angela's start/end also shifted by ~3\u20134s), so the temporal localization is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After Meredith begins answering the question about schools helping children cope with COVID deaths, when does Angela next speak?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3720.052,
        "end": 3723.137
      },
      "pred_interval": {
        "start": 3724.0,
        "end": 3730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.9479999999998654,
        "end": 6.862999999999829,
        "average": 5.405499999999847
      },
      "rationale_metrics": {
        "rouge_l": 0.4615384615384615,
        "text_similarity": 0.8593306541442871,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the speaker order and Angela's phrase right, but the timestamps are substantially incorrect (Meredith start is ~39s early and end times/more precise Angela timings are off by several seconds), and it omits the correct end times, so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela finishes stating that they need to pick one more winner who will get a digital code, when does she clarify that it's an actual digital ebook?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3778.3,
        "end": 3780.3
      },
      "pred_interval": {
        "start": 3777.5,
        "end": 3781.0
      },
      "iou": 0.5714285714285714,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8000000000001819,
        "end": 0.6999999999998181,
        "average": 0.75
      },
      "rationale_metrics": {
        "rouge_l": 0.38532110091743116,
        "text_similarity": 0.6331137418746948,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately captures both events and their relation, with timestamps closely matching the reference within acceptable tolerance and correct wording of the clarification, so it is a precise semantic and temporal match."
      }
    },
    {
      "question_id": "002",
      "question": "Once Angela finishes stating her intention to put her email in the chat, when do her fingers come into view as she appears to type?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3833.5,
        "end": 3840.4
      },
      "pred_interval": {
        "start": 3834.0,
        "end": 3844.0
      },
      "iou": 0.6095238095238182,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.5,
        "end": 3.599999999999909,
        "average": 2.0499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.3518518518518519,
        "text_similarity": 0.6620936393737793,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction preserves the correct sequence and relation and gives times close to the reference (E1 ~+1s, E2 start ~+0.5s), but it extends E2's end by several seconds and adds details about obscuring the camera and pulling hands back not specified in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman at the bottom finishes describing the usefulness of the book for specific tips, when does she start reading the quote about teaching children?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3930.0,
        "end": 3989.9829999999997
      },
      "gt_interval": {
        "start": 3945.123,
        "end": 3950.606
      },
      "pred_interval": {
        "start": 3949.0,
        "end": 3954.0
      },
      "iou": 0.18091697645603588,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.8769999999999527,
        "end": 3.393999999999778,
        "average": 3.6354999999998654
      },
      "rationale_metrics": {
        "rouge_l": 0.24999999999999994,
        "text_similarity": 0.532444417476654,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer gets the temporal relation correct ('after') but the event timestamps deviate substantially from the reference (E1 ~6s later; E2 start ~4s later and end ~3.4s later), so the timing details are inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman on the left says 'Sounds like a great way to leave it', when is the next time she speaks to thank the community?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3930.0,
        "end": 3989.9829999999997
      },
      "gt_interval": {
        "start": 3979.368,
        "end": 3982.382
      },
      "pred_interval": {
        "start": 3982.5,
        "end": 3988.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.132000000000062,
        "end": 6.117999999999938,
        "average": 4.625
      },
      "rationale_metrics": {
        "rouge_l": 0.2077922077922078,
        "text_similarity": 0.5042433738708496,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that E2 thanks the community, but the timestamps are substantially off (E1 and E2 shifted later by ~2+ seconds and E2's end time is overstated) and the relation is labeled 'after' rather than the immediate 'next'; it also adds extra/unsupported dialog details. These factual and timing discrepancies reduce the match significantly."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'we want to be your allies', when does she talk about parents and teachers wanting the best for the kids?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1953.971,
        "end": 1964.847
      },
      "pred_interval": {
        "start": 1958.0,
        "end": 1967.0
      },
      "iou": 0.5255199938598497,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.028999999999996,
        "end": 2.15300000000002,
        "average": 3.091000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.40860215053763443,
        "text_similarity": 0.6679103374481201,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events and their temporal relation (E2 after E1) and matches the correct time windows closely; minor timing offsets (E2 start ~4s late and end ~2s late, and E1 given only as relative 00:05) account for the small deduction."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes discussing the scaffolding teachers have in place, when does she mention bringing students to meetings?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.427,
        "end": 2061.512
      },
      "pred_interval": {
        "start": 2062.0,
        "end": 2066.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5729999999998654,
        "end": 4.487999999999829,
        "average": 4.030499999999847
      },
      "rationale_metrics": {
        "rouge_l": 0.25490196078431376,
        "text_similarity": 0.6989178657531738,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the quoted line and the causal relation but the timestamps are significantly off and the anchor end-time is contradicted; it also adds an unsupported detail about the 'at-home environment.'"
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes her parents attending a parent-teacher conference without her, when does she explain how her presence could have helped?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2110.911,
        "end": 2135.889
      },
      "pred_interval": {
        "start": 2115.0,
        "end": 2133.0
      },
      "iou": 0.7206341580590901,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 4.088999999999942,
        "end": 2.8890000000001237,
        "average": 3.4890000000000327
      },
      "rationale_metrics": {
        "rouge_l": 0.23214285714285712,
        "text_similarity": 0.6542195081710815,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies E1 and E2, their relation (after), and the content of E2, with only minor timing offsets of a few seconds compared to the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining how collaborating with parents increases involvement on a holistic level in the academic environment, when does she start talking about identifying unique talents and abilities?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2340.0,
        "end": 2348.835
      },
      "pred_interval": {
        "start": 2346.0,
        "end": 2353.0
      },
      "iou": 0.2180769230769259,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 4.164999999999964,
        "average": 5.082499999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.6324361562728882,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the immediate 'after' relationship and the content transition, but the provided timestamps differ noticeably from the reference (start/end times ~4\u20135 seconds later and a longer target duration), so key factual timing details are inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says it's our duty to instill independence, resilience, and self-reliance in students, when does she state that 'autonomy is action when we...'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2407.49,
        "end": 2412.5
      },
      "pred_interval": {
        "start": 2411.0,
        "end": 2417.0
      },
      "iou": 0.15772870662460206,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5100000000002183,
        "end": 4.5,
        "average": 4.005000000000109
      },
      "rationale_metrics": {
        "rouge_l": 0.2417582417582418,
        "text_similarity": 0.6548330783843994,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relationship and quotes the trigger phrase, but the anchor and target timestamps deviate substantially from the reference and the predicted target duration adds extra content not present in the ground truth, indicating inaccurate alignment and some hallucination."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions students experiencing a gamut of emotions within a calendar day, when does she begin discussing their ability to be allies and advocates for others?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2429.86,
        "end": 2438.809
      },
      "pred_interval": {
        "start": 2435.0,
        "end": 2443.0
      },
      "iou": 0.2898782343988001,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.139999999999873,
        "end": 4.1909999999998035,
        "average": 4.665499999999838
      },
      "rationale_metrics": {
        "rouge_l": 0.20930232558139536,
        "text_similarity": 0.7302155494689941,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the successive content and the 'after' relationship, but the timestamp estimates are consistently about 4\u20136 seconds later than the reference, so it's not fully time-accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating that this is 'practice dialogue number one', when does the English speaker (teacher) begin her first segment?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 81.412,
        "end": 86.516
      },
      "pred_interval": {
        "start": 121.0,
        "end": 127.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.587999999999994,
        "end": 40.483999999999995,
        "average": 40.035999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.1917808219178082,
        "text_similarity": 0.3871566355228424,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly identifies the anchor at ~28s and the teacher segment starting at ~81s and ending ~86.5s (given as 01:21\u201301:27), preserving the 'after' relation; only minor rounding differences exist."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes reading the English segment for Segment 5, when does she start reading the Telugu segment for Segment 6?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 150.0,
        "end": 233.917
      },
      "gt_interval": {
        "start": 158.981,
        "end": 170.016
      },
      "pred_interval": {
        "start": 158.8,
        "end": 171.5
      },
      "iou": 0.8688976377952761,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.18099999999998317,
        "end": 1.4840000000000089,
        "average": 0.832499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.1951219512195122,
        "text_similarity": 0.6641050577163696,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction captures the sequence (English ends, a beep/chime, then Telugu begins) and the Telugu start time is close, but the English finish time and Telugu end time deviate by ~1.7s and ~1.5s from the reference, so timings are inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes reading the English segment for Segment 7, when does she start reading the Telugu segment for Segment 8?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 150.0,
        "end": 233.917
      },
      "gt_interval": {
        "start": 187.957,
        "end": 202.515
      },
      "pred_interval": {
        "start": 187.3,
        "end": 203.0
      },
      "iou": 0.9272611464968155,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.6569999999999823,
        "end": 0.48500000000001364,
        "average": 0.570999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.6180793642997742,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the sequence (English ends, a beep/chime, then Telugu begins) and gives times close to the reference, but the start and end times differ by about 0.6s and 0.5s respectively from the ground truth, so it's largely accurate with minor timing discrepancies."
      }
    },
    {
      "question_id": "003",
      "question": "While the 'Thank You!' screen is displayed, when does the speaker begin her concluding remarks about the dialogue?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 150.0,
        "end": 233.917
      },
      "gt_interval": {
        "start": 209.544,
        "end": 233.917
      },
      "pred_interval": {
        "start": 208.5,
        "end": 233.9
      },
      "iou": 0.9582562851634729,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.0440000000000111,
        "end": 0.016999999999995907,
        "average": 0.5305000000000035
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.4787469506263733,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states that the concluding remarks occur during the 'Thank You!' screen and gives end time accurately, but both start timestamps are slightly off by about 1\u20132 seconds compared to the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the introductory speaker says, 'And I will turn it over to you,' when does Megan start speaking her introductory remarks?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 88.123,
        "end": 97.103
      },
      "pred_interval": {
        "start": 88.0,
        "end": 97.0
      },
      "iou": 0.975173019883555,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.12300000000000466,
        "end": 0.10299999999999443,
        "average": 0.11299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195122,
        "text_similarity": 0.6443618535995483,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies Megan's opening phrase and approximates the E2 end time, but it misplaces E1 (saying ~88.0s vs the reference ~85.54s) and wrongly characterizes the timing as 'immediate' rather than the short 'after' gap before E2 at 88.123s."
      }
    },
    {
      "question_id": "002",
      "question": "After Megan displays the 'Pandemic Parenting Principles' slide, when does she first mention graduating from Fairfield in 2010?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 101.112,
        "end": 102.697
      },
      "pred_interval": {
        "start": 101.0,
        "end": 104.0
      },
      "iou": 0.528333333333336,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.11199999999999477,
        "end": 1.3029999999999973,
        "average": 0.707499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.208955223880597,
        "text_similarity": 0.7464770078659058,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies and time-ranges Megan's graduation mention (E2) and the 'after' relationship, but misstates the slide appearance (E1) as ~96s instead of the correct 91.23\u201393.47s, a minor timestamp error."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions she got her master's in early childhood from BC, when does she start talking about teaching in Newton and Wellesley?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.6,
        "end": 174.5
      },
      "pred_interval": {
        "start": 231.0,
        "end": 235.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.400000000000006,
        "end": 60.5,
        "average": 61.45
      },
      "rationale_metrics": {
        "rouge_l": 0.17777777777777776,
        "text_similarity": 0.46331503987312317,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes that E2 follows immediately after E1 and even quotes the line, but the timestamps are substantially different and it adds an unsupported looping claim, so the answer contradicts the ground-truth timing information."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is talking about the Jesuit ideals instilled during her time at Fairfield, when does she mention the ability to reflect on where she was and wanted to go?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 352.0,
        "end": 355.5
      },
      "pred_interval": {
        "start": 338.0,
        "end": 341.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 14.5,
        "average": 14.25
      },
      "rationale_metrics": {
        "rouge_l": 0.17391304347826086,
        "text_similarity": 0.6006563305854797,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer references the correct phrase but gives timestamps that contradict the ground truth by ~65s and incorrect segment boundaries (ends at video end), so it is essentially wrong about the location and duration of the target segment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions offering strategies to help motivate your child, when does she introduce the topic of handwriting?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 351.8,
        "end": 361.0
      },
      "pred_interval": {
        "start": 346.0,
        "end": 356.0
      },
      "iou": 0.27999999999999925,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.800000000000011,
        "end": 5.0,
        "average": 5.400000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.30357142857142855,
        "text_similarity": 0.507922887802124,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events and their content, and preserves the temporal relation (after); the provided timestamps are slightly earlier by ~5\u20136 seconds than the reference but are within a reasonable tolerance and do not change the meaning."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide displays '2-5 minutes of handwriting practice adds up!', when does the speaker explain the importance of modeling numbers for children?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 396.0,
        "end": 413.0
      },
      "pred_interval": {
        "start": 431.5,
        "end": 438.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.5,
        "end": 25.0,
        "average": 30.25
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.6121479272842407,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the content (speaker modeling numbers) but misstates both event timings and their relation: the reference places the slide at 348\u2013414s and the explanation at 396\u2013413s (during the slide), whereas the prediction shifts both to ~423\u2013438s, so it fails the core temporal alignment."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes talking about using magnetic letters for word building, when does she start discussing ordering numbers?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 455.216,
        "end": 464.045
      },
      "pred_interval": {
        "start": 529.5,
        "end": 540.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.28399999999999,
        "end": 75.95499999999998,
        "average": 75.11949999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2448979591836735,
        "text_similarity": 0.5973266363143921,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gets the ordering (E2 after E1) but the timestamps are substantially different from the ground truth and include unverified extra details, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker describes the specific elements a child included on their glowfish poster, when does she start to explain the general benefits of using big poster boards?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 532.8,
        "end": 542.0
      },
      "pred_interval": {
        "start": 536.0,
        "end": 551.0
      },
      "iou": 0.32967032967032883,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.2000000000000455,
        "end": 9.0,
        "average": 6.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.15789473684210525,
        "text_similarity": 0.45029765367507935,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures that the general-benefits explanation begins immediately after the glowfish-poster description and accurately summarizes the content; only minor discrepancies in the reported timestamps (a few seconds) prevent a perfect match."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes showing the second poster example about the solar system, when does she explicitly list the general benefits of posters?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 576.835,
        "end": 593.004
      },
      "pred_interval": {
        "start": 574.0,
        "end": 585.0
      },
      "iou": 0.42964639023363266,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.8350000000000364,
        "end": 8.004000000000019,
        "average": 5.419500000000028
      },
      "rationale_metrics": {
        "rouge_l": 0.29545454545454547,
        "text_similarity": 0.7006201148033142,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the end of the solar-system example and the subsequent explicit listing of poster benefits and even the listed items; only a minor temporal discrepancy exists (predicted E2 starts ~2.8s earlier and ends earlier than the reference)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker makes a general statement about children hesitating to write about things they can't draw, when does she provide a personal example of her nephew?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 672.0,
        "end": 690.0
      },
      "pred_interval": {
        "start": 653.0,
        "end": 658.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.0,
        "end": 32.0,
        "average": 25.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2376237623762376,
        "text_similarity": 0.5903531312942505,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the nephew example but the timestamps and sequence do not match the reference\u2014the predicted E1/E2 timings are substantially earlier and not the direct follow-up described in the correct answer, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions a 'how-to drawing type book', when does she explain that drawing is a big piece of practice in addition to writing?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.375,
        "end": 704.155
      },
      "pred_interval": {
        "start": 698.0,
        "end": 706.0
      },
      "iou": 0.5974999999999966,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.375,
        "end": 1.8450000000000273,
        "average": 1.6100000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.3838383838383838,
        "text_similarity": 0.6925960779190063,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both events, their content, and the 'after' relation, but the timestamps are slightly off (E1 ~1.7s late; E2 starts ~1.4s early and ends ~1.8s late), so it's not an exact match."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker transitions to the 'MAKE YOUR OWN MATH GAMES' slide, when does she specifically describe making green and pink number cards?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 744.49,
        "end": 748.575
      },
      "pred_interval": {
        "start": 747.0,
        "end": 751.0
      },
      "iou": 0.24193548387097508,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.509999999999991,
        "end": 2.4249999999999545,
        "average": 2.4674999999999727
      },
      "rationale_metrics": {
        "rouge_l": 0.54,
        "text_similarity": 0.7172919511795044,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly identifies the slide, quotes the speaker, and the temporal relation ('after')\u2014only minor timing offsets (~1\u20132.5s) from the reference occur, which do not change the meaning."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that a collection of 'just right' books is key to helping children learn to read, when does she show an example of a Scholastic reader?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 911.4,
        "end": 915.0
      },
      "pred_interval": {
        "start": 911.0,
        "end": 915.0
      },
      "iou": 0.9000000000000057,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.39999999999997726,
        "end": 0.0,
        "average": 0.19999999999998863
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424246,
        "text_similarity": 0.4363449215888977,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately matches the reference timing and relation: it identifies the 'just right' mention around 890s and the Scholastic reader shown from about 911\u2013915s, correctly indicating the latter occurs after the former and preserving the key details."
      }
    },
    {
      "question_id": "002",
      "question": "During the explanation of the '5 Finger Test', when does the speaker describe what constitutes a 'just right' book?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 986.5,
        "end": 970.0
      },
      "pred_interval": {
        "start": 987.0,
        "end": 991.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.5,
        "end": 21.0,
        "average": 10.75
      },
      "rationale_metrics": {
        "rouge_l": 0.22680412371134023,
        "text_similarity": 0.7362226247787476,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies and timestamps the 'just right' definition around 986\u2013987s (giving 987\u2013991s) and even quotes the phrasing; the only minor issue is a small discrepancy in the claimed start time of the overall explanation (964s vs 974s)."
      }
    },
    {
      "question_id": "001",
      "question": "While the images of the cardboard clocks are displayed, when does the speaker mention a child drawing a puppy on one of them?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1058.2,
        "end": 1060.95
      },
      "pred_interval": {
        "start": 1062.0,
        "end": 1067.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.7999999999999545,
        "end": 6.0499999999999545,
        "average": 4.9249999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307691,
        "text_similarity": 0.488119512796402,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the puppy mention and quotes the line, but its timing is several seconds late (predicts ~1062\u20131067s vs the ground truth 1058.2\u20131060.95s), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the 'Weekend News' template is shown on the screen, when does the speaker say that kids would be excited to share their news?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1131.3,
        "end": 1138.0
      },
      "pred_interval": {
        "start": 1136.0,
        "end": 1139.0
      },
      "iou": 0.2597402597402582,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.7000000000000455,
        "end": 1.0,
        "average": 2.8500000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.2105263157894737,
        "text_similarity": 0.5320755243301392,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the utterance during the 'Weekend News' visual and matches the quoted phrase; the temporal window largely overlaps the ground truth but is slightly shifted later (predicted ~1136\u20131139s vs ground truth 1131.3\u20131138.0s)."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the 'Hide & Go Seek' sight word game, when does she start explaining the 'Memory' sight word game?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1204.2,
        "end": 1205.5
      },
      "pred_interval": {
        "start": 1192.0,
        "end": 1202.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.200000000000045,
        "end": 3.5,
        "average": 7.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.17777777777777776,
        "text_similarity": 0.5600919723510742,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction locates the Memory explanation in the same general time window but gives incorrect timestamps and math (predicts start at ~1192s vs. the correct 1204.2s and end ~1202s vs. 1205.5s), so it is only loosely correct and not precise."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes recommending non-fiction books if the home collection is mostly storybooks, when does she start talking about having visuals to practice multiplication?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1250.14,
        "end": 1251.01
      },
      "pred_interval": {
        "start": 1249.0,
        "end": 1269.0
      },
      "iou": 0.04349999999999454,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.1400000000001,
        "end": 17.99000000000001,
        "average": 9.565000000000055
      },
      "rationale_metrics": {
        "rouge_l": 0.2708333333333333,
        "text_similarity": 0.766295313835144,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction roughly locates the anchor and nearly captures the start of the multiplication segment, but it misplaces both timestamps (E1 off by ~2.5s, E2 by ~1s) and critically extends the target end far beyond the correct end (1251.01s \u2192 1269s), adding unrelated content; therefore the overall timing alignment is poor."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes explaining that dry erase boards help with handwriting consistency, when does she start talking about having math tools for exploration?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1322.321,
        "end": 1324.997
      },
      "pred_interval": {
        "start": 1325.0,
        "end": 1365.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.6790000000000873,
        "end": 40.00299999999993,
        "average": 21.341000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.26506024096385544,
        "text_similarity": 0.8007151484489441,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly identifies the topics but has significant and inconsistent timing errors (E1/E2 off by several seconds and E2 end grossly overextended to 1365s) and even mixes timestamp formats, so it does not match the reference timings. The content also appears to rely on slide-change cues not present in the ground truth, leading to an incorrect segmentation."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes mentioning having sharpened pencils around for home setup, when does she display and introduce the word wall for visual reinforcement?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1425.637,
        "end": 1450.0
      },
      "pred_interval": {
        "start": 1427.0,
        "end": 1440.0
      },
      "iou": 0.5335960267618918,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3630000000000564,
        "end": 10.0,
        "average": 5.681500000000028
      },
      "rationale_metrics": {
        "rouge_l": 0.2365591397849462,
        "text_similarity": 0.6727697849273682,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor mention of sharpened pencils and the subsequent introduction/display of the word wall, but the timestamps are notably off (E1 and E2 start/end times differ by several seconds) and it shortens the segment end (1440s vs 1450s), so timing accuracy is only partial."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions having an alphabet chart or number line for easy accessibility, when does she introduce the word wall?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1425.2,
        "end": 1427.5
      },
      "pred_interval": {
        "start": 1426.5,
        "end": 1431.0
      },
      "iou": 0.17241379310344962,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2999999999999545,
        "end": 3.5,
        "average": 2.3999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.30379746835443044,
        "text_similarity": 0.7618749141693115,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the target occurs after it, and the reported start time is close to the reference; however the predicted end time is ~3.5s later than the ground truth, so the temporal boundaries are slightly off."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker suggests parents type the words for a book while the child illustrates, when does she suggest having the child practice typing?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1506.0,
        "end": 1508.0
      },
      "pred_interval": {
        "start": 1507.0,
        "end": 1511.0
      },
      "iou": 0.2,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 3.0,
        "average": 2.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3023255813953488,
        "text_similarity": 0.6984397768974304,
        "llm_judge_score": 6,
        "llm_judge_justification": "The predicted answer correctly identifies the successive suggestion (child practicing typing) and quotes the phrase, but the provided timestamps differ from the ground truth (E1/E2 start and end times are off by several seconds), so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that games help build skills, when does she mention 'problem solving'?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1617.701,
        "end": 1618.281
      },
      "pred_interval": {
        "start": 1618.8,
        "end": 1620.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0989999999999327,
        "end": 2.0190000000000055,
        "average": 1.558999999999969
      },
      "rationale_metrics": {
        "rouge_l": 0.4225352112676056,
        "text_similarity": 0.8280539512634277,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target events and the 'after' relation, but the reported timestamps are off by about 1\u20132 seconds from the reference, so timing accuracy is imperfect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker compares reading less than a minute a day to 20 minutes a day, when does she state that 1.8 million words are exposed per year?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1683.016,
        "end": 1684.426
      },
      "pred_interval": {
        "start": 1684.5,
        "end": 1686.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.4839999999999236,
        "end": 1.7740000000001146,
        "average": 1.629000000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.5274725274725274,
        "text_similarity": 0.8680461049079895,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target utterances and the 'after' relationship; timings are slightly later than the reference (anchor ~0.45s later; target start ~1.48s and end ~1.77s later) but contain no substantive errors or hallucinations."
      }
    },
    {
      "question_id": "001",
      "question": "Once the 'Q&A' slide is displayed, when does the slide asking 'COVID and religious education?' appear?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.8,
        "end": 1803.9
      },
      "pred_interval": {
        "start": 1796.5,
        "end": 1803.5
      },
      "iou": 0.770270270270267,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.2999999999999545,
        "end": 0.40000000000009095,
        "average": 0.8500000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.3571428571428571,
        "text_similarity": 0.7611020803451538,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction locates both slides near the correct times but gives different timestamps (E1 at 1789.0s with no end vs correct 1787.5\u20131797.8s; E2 at 1796.5s vs correct 1797.8s) and implies E2 appears before E1 finishes, contradicting the 'once_finished' relation; the end time also differs, so it is partially correct but factually inconsistent."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker concludes her statement about music being important for religious education, when does she start talking about children learning about saints?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1840.4,
        "end": 1844.9
      },
      "pred_interval": {
        "start": 1846.5,
        "end": 1850.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.099999999999909,
        "end": 5.099999999999909,
        "average": 5.599999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.3488372093023256,
        "text_similarity": 0.6969573497772217,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the correct order (E1 before E2) and paraphrases the saint-related line, but the reported start/end timestamps are several seconds later than the ground truth and thus factually inaccurate for precise temporal labeling."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes asking how schools can assist with the transition to in-person learning, when does the slide listing 'clear expectations' appear?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1879.3,
        "end": 1940.0
      },
      "pred_interval": {
        "start": 1881.5,
        "end": 1914.0
      },
      "iou": 0.5354200988467871,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.2000000000000455,
        "end": 26.0,
        "average": 14.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.22784810126582278,
        "text_similarity": 0.584735631942749,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly locates the slide's appearance roughly (within ~2s) but misstates the anchor/end times: the anchor (E1) end is far off (~96s) and the slide's end time differs by ~26s, so key temporal facts are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks, 'How to ensure children are not being distracted by non-school work when online?', when does she start listing tips?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.342,
        "end": 1963.495
      },
      "pred_interval": {
        "start": 1963.0,
        "end": 1999.0
      },
      "iou": 0.012481718694838169,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.6579999999999018,
        "end": 35.50500000000011,
        "average": 19.581500000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2391304347826087,
        "text_similarity": 0.7329429388046265,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the tips come after the question, but it misstates both anchor and target timestamps (anchor window overlaps and ends later than the ground truth; target start and end are significantly delayed and extended) and adds extraneous details, so it does not match the precise timing or content."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes giving tips on staying on task, when does she offer to answer questions?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1997.897,
        "end": 2003.182
      },
      "pred_interval": {
        "start": 2003.0,
        "end": 2006.0
      },
      "iou": 0.022460816981366767,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.1030000000000655,
        "end": 2.8179999999999836,
        "average": 3.9605000000000246
      },
      "rationale_metrics": {
        "rouge_l": 0.3516483516483516,
        "text_similarity": 0.6636376976966858,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the offer to answer questions and the quoted phrase, but the provided timestamps significantly deviate from the reference (both E1 and E2 are several seconds off) and do not match the reported immediate follow-up timing, so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the host says 'Great. I have two more. Thank you for that.', when does she ask the question about kindergarten?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2083.534,
        "end": 2093.534
      },
      "pred_interval": {
        "start": 2086.0,
        "end": 2097.0
      },
      "iou": 0.5594831427298503,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.4659999999998945,
        "end": 3.4659999999998945,
        "average": 2.9659999999998945
      },
      "rationale_metrics": {
        "rouge_l": 0.35443037974683544,
        "text_similarity": 0.7240493297576904,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the kindergarten question follows next and matches the content, but the provided timestamps are several seconds later than the reference (E1 ~0.4s off, E2 start ~2.5s late and end ~3.5s late), so the timing is not fully accurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the female speaker on the right finishes asking the question about the emotional side of entering a new grade, when does the female speaker on the left begin to respond?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2297.683
      },
      "gt_interval": {
        "start": 2181.936,
        "end": 2182.54
      },
      "pred_interval": {
        "start": 2182.0,
        "end": 2188.0
      },
      "iou": 0.08905013192611756,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.06399999999985084,
        "end": 5.460000000000036,
        "average": 2.7619999999999436
      },
      "rationale_metrics": {
        "rouge_l": 0.3170731707317073,
        "text_similarity": 0.7378493547439575,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that the left speaker begins responding after the right speaker finishes, but the provided timestamps are notably off (E1 ~2182.0s vs 2179.574s; E2 start ~2182.5s vs 2181.936s) and it omits the detailed completion timing for the target utterance, so it is only partially accurate."
      }
    },
    {
      "question_id": "002",
      "question": "When is the next time the female speaker on the left mentions a way students are socializing online after she describes a student's weekly Zoom calls?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2297.683
      },
      "gt_interval": {
        "start": 2204.249,
        "end": 2210.952
      },
      "pred_interval": {
        "start": 2206.0,
        "end": 2212.0
      },
      "iou": 0.6388853051219321,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.7510000000002037,
        "end": 1.0479999999997744,
        "average": 1.399499999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.2278481012658228,
        "text_similarity": 0.6630622744560242,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the next mention (the online newspaper) and preserves the anchor/target relation and content; its timestamps are approximate and slightly off by a few seconds compared to the reference, but no key facts are omitted or contradicted."
      }
    },
    {
      "question_id": "003",
      "question": "After the female speaker on the left finishes talking about an online newspaper, when does she begin to introduce the 'Outschool' platform?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2297.683
      },
      "gt_interval": {
        "start": 2227.882,
        "end": 2232.043
      },
      "pred_interval": {
        "start": 2228.0,
        "end": 2234.0
      },
      "iou": 0.6608368747957112,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.11799999999993815,
        "end": 1.95699999999988,
        "average": 1.037499999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.16,
        "text_similarity": 0.6628387570381165,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the sequence and the start of the 'Outschool' mention with timings very close to the reference and preserves the relation (after), but it omits the precise end time of E2 and has minor timing offsets."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'Number four', when does the text 'Parents don't get trained' appear on screen?",
      "video_id": "J-upF-lwWvg",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 46.400000000000006
      },
      "gt_interval": {
        "start": 2.02,
        "end": 3.73
      },
      "pred_interval": {
        "start": 1.3,
        "end": 3.2
      },
      "iou": 0.48559670781893016,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.72,
        "end": 0.5299999999999998,
        "average": 0.6249999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.4615384615384615,
        "text_similarity": 0.794581949710846,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly implies the text appears after the cue but has incorrect timings and extra/unfounded detail: the anchor is at 0.58s (not 0.00) and the text runs 2.02\u20133.73s (not split/starting at 1.3s and ending at 3.2s)."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'communicating at the IEP table', when does she continue her explanation about parents at the IEP table?",
      "video_id": "J-upF-lwWvg",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 46.400000000000006
      },
      "gt_interval": {
        "start": 9.85,
        "end": 12.35
      },
      "pred_interval": {
        "start": 9.5,
        "end": 21.8
      },
      "iou": 0.2032520325203252,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.34999999999999964,
        "end": 9.450000000000001,
        "average": 4.9
      },
      "rationale_metrics": {
        "rouge_l": 0.4444444444444445,
        "text_similarity": 0.748836874961853,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the relation and approximate E1/E2 start times (minor offsets), but it significantly misstates E2's end time (21.8s vs 12.35s) and introduces unfounded extended content, making it substantially inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'And number five', when does the text 'you don't have the playbook' appear?",
      "video_id": "J-upF-lwWvg",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 46.400000000000006
      },
      "gt_interval": {
        "start": 24.8,
        "end": 26.0
      },
      "pred_interval": {
        "start": 24.3,
        "end": 26.0
      },
      "iou": 0.7058823529411763,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.5,
        "end": 0.0,
        "average": 0.25
      },
      "rationale_metrics": {
        "rouge_l": 0.49411764705882355,
        "text_similarity": 0.7433841824531555,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the relation (after) and the end time (26.0s), and gives a plausible timeline, but the anchor time is off (~0.7\u20131.7s late) and the predicted E2 start splits the phrase and begins earlier (24.3s) than the reference (24.8s), so timing details are not fully aligned."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions they have three presentations, when does she introduce the first presenter, Khadija Mohamed?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 40.767,
        "end": 45.473
      },
      "pred_interval": {
        "start": 41.5,
        "end": 46.5
      },
      "iou": 0.6930054072911218,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.732999999999997,
        "end": 1.027000000000001,
        "average": 0.879999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324326,
        "text_similarity": 0.6648193597793579,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted timestamps align closely with the reference ranges (26.5s within 25.934\u201327.658s; 41.5\u201346.5s overlaps the 40.767\u201345.473s window) and correctly states the relation 'after' without introducing contradictions."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions revealing the hidden curriculum, when does the slide change to display 'Teaching Scotland's Future'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.8,
        "end": 202.8
      },
      "pred_interval": {
        "start": 202.0,
        "end": 203.0
      },
      "iou": 0.6666666666666825,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.19999999999998863,
        "end": 0.19999999999998863,
        "average": 0.19999999999998863
      },
      "rationale_metrics": {
        "rouge_l": 0.11940298507462688,
        "text_similarity": 0.33416324853897095,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the slide change occurring around 202s and that it follows the anchor, but it misstates the anchor timing (saying ~174s vs the correct 166.5\u2013169.8s) and omits the precise start/end windows given in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing teacher educators, when does a blue speech bubble with the question 'Is the team all right?' appear on the screen?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 245.5,
        "end": 258.7
      },
      "pred_interval": {
        "start": 247.0,
        "end": 249.0
      },
      "iou": 0.15151515151515166,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5,
        "end": 9.699999999999989,
        "average": 5.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.12658227848101267,
        "text_similarity": 0.5209946632385254,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the discussion time (\u2248236s) and the bubble appearing around 247\u2013248s, which closely matches the reference (245.5s); however it omits the bubble disappearance time and the precise anchor start/end span noted in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing the challenges faced by collectivist teachers, when does she state the research question about how minority ethnic teachers use their cultural, religious, and linguistic skills?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 390.6,
        "end": 394.78
      },
      "pred_interval": {
        "start": 394.0,
        "end": 399.0
      },
      "iou": 0.09285714285713986,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.3999999999999773,
        "end": 4.220000000000027,
        "average": 3.8100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.27272727272727276,
        "text_similarity": 0.6313092708587646,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the correct events and question wording, but the timestamps differ substantially (E1: predicted 386.0s vs correct 390.5s; E2: predicted 394.0\u2013399.0s vs correct 390.6\u2013394.78s) and it fails to reflect that E2 starts immediately after E1, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker quotes Ladson-Billings about Critical Race Theory, when does she explain what Critical Race Theory helps to do?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 420.0,
        "end": 427.3
      },
      "pred_interval": {
        "start": 427.0,
        "end": 433.0
      },
      "iou": 0.023076923076923953,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 5.699999999999989,
        "average": 6.349999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2716049382716049,
        "text_similarity": 0.5921096801757812,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that E2 explains CRT's purpose immediately after the quote, but the provided timestamps are significantly off (E2 starts ~7s later and ends ~5.7s later than the ground truth), so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the 'racial microaggression framework', when does she mention the time period 'the early 1970s to the 1990s'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 517.1,
        "end": 519.1
      },
      "pred_interval": {
        "start": 519.5,
        "end": 523.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.3999999999999773,
        "end": 4.399999999999977,
        "average": 3.3999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.34146341463414637,
        "text_similarity": 0.7452249526977539,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly identifies both events and that the 'early 1970s to the 1990s' mention occurs after the 'racial microaggression framework' mention; only minor timestamp offsets exist, which do not change the relative relation."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker shares discussions from her study, when does the first speech bubble graphic appear on the 'Cultural and Linguistic experiences' slide?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 574.2,
        "end": 574.9
      },
      "pred_interval": {
        "start": 603.5,
        "end": 631.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.299999999999955,
        "end": 56.60000000000002,
        "average": 42.94999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.19753086419753088,
        "text_similarity": 0.5506993532180786,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps contradict the reference by roughly 30s (correct first bubble ~574.2s vs predicted 603.5s) and thus fails to match the key timing; it also omits the speaker-start time given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions a teacher in Edinburgh trying to talk about the slave trade issue with her class, when does the speaker state that the discussion 'went terribly wrong'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 721.0,
        "end": 722.451
      },
      "pred_interval": {
        "start": 727.4,
        "end": 729.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.399999999999977,
        "end": 6.749000000000024,
        "average": 6.5745000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.345679012345679,
        "text_similarity": 0.6599300503730774,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events and their ordering, but the timestamps are substantially off from the ground truth (predicted ~727\u2013729s vs. correct E1 708\u2013719s and E2 721\u2013722s), so it is temporally inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the teacher asks Muslim children to draw an image of what they think God looks like, when does the speaker describe the Muslim kids just sitting there and staring?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 746.761,
        "end": 793.029
      },
      "pred_interval": {
        "start": 762.6,
        "end": 765.8
      },
      "iou": 0.06916227198063304,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.839000000000055,
        "end": 27.229000000000042,
        "average": 21.53400000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.3658536585365854,
        "text_similarity": 0.7143797874450684,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted E2 time (762.6\u2013765.8s) falls inside the correct E2 interval, so it partially identifies when the speaker describes the kids, but it gives an incorrect E1 anchor (762.5s vs 742.417\u2013746.162s), drastically underestimates E2's duration, and misaligns the event relation; therefore only a partial match."
      }
    },
    {
      "question_id": "001",
      "question": "After the teacher asks what's happening in Burma, when do the children ask why it's not in the news?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 897.0,
        "end": 899.8
      },
      "pred_interval": {
        "start": 894.2,
        "end": 897.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.7999999999999545,
        "end": 2.7999999999999545,
        "average": 2.7999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.2285714285714286,
        "text_similarity": 0.5491490364074707,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the sequence (children ask after the teacher) but misstates timings and some content: the students' interval (894.2\u2013897.0s) is ~2.8s early compared to the reference (897.0\u2013899.8s), and the teacher utterance is described differently, so the localization and phrasing are inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "During the 'Using a microaggression framework' slide, when does the speaker list the instances of lessons that negate, nullify, exclude, or marginalize?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 950.0,
        "end": 951.0
      },
      "pred_interval": {
        "start": 947.8,
        "end": 954.5
      },
      "iou": 0.14925373134328257,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.2000000000000455,
        "end": 3.5,
        "average": 2.8500000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.36923076923076925,
        "text_similarity": 0.6294171810150146,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the listing occurs during the slide, but its timestamp range (947.8\u2013954.5s) does not match the precise reference (950\u2013951s) and it adds extra phrasing ('further marginalize our students of color'), so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stella finishes inviting Jacqueline to introduce herself, when does Jacqueline begin speaking?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1145.3,
        "end": 1146.2
      },
      "pred_interval": {
        "start": 1151.0,
        "end": 1154.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.7000000000000455,
        "end": 7.7999999999999545,
        "average": 6.75
      },
      "rationale_metrics": {
        "rouge_l": 0.40579710144927533,
        "text_similarity": 0.8293533325195312,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures that Jacqueline begins speaking immediately after Stella and even quotes the utterance, but it gives incorrect absolute timestamps (1151.0s vs. reference 1145.0s/1145.3s), so it fails to match the key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "After Khadija finishes her presentation and apology, when does Stella begin thanking her?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1119.9,
        "end": 1121.2
      },
      "pred_interval": {
        "start": 1126.0,
        "end": 1129.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.099999999999909,
        "end": 7.7999999999999545,
        "average": 6.949999999999932
      },
      "rationale_metrics": {
        "rouge_l": 0.23809523809523808,
        "text_similarity": 0.7281444668769836,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction preserves the event order and approximate pause (~6s) between Khadija and Stella, but the absolute timestamps are off by ~5\u20136s and it omits the end timestamp for Stella (1121.2s), so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After Jacqueline says, 'Let me just see if I can share these slides with you', when does her presentation's title slide appear in full screen?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1177.8,
        "end": 1182.0
      },
      "pred_interval": {
        "start": 1178.0,
        "end": 1181.0
      },
      "iou": 0.7142857142857065,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.20000000000004547,
        "end": 1.0,
        "average": 0.6000000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.27083333333333337,
        "text_similarity": 0.7433189153671265,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both events and the 'after' relation and matches E2's timing closely, but E1 is ~3.3s off and the prediction omits that the title slide remained until 1182.0s as Jacqueline begins speaking over it."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes talking about how students of color were feeling left out at the secondary school, when does she transition to the slide about 'Race in Scotland'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1260.0,
        "end": 1269.32
      },
      "pred_interval": {
        "start": 1261.0,
        "end": 1267.0
      },
      "iou": 0.6437768240343391,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 2.3199999999999363,
        "average": 1.6599999999999682
      },
      "rationale_metrics": {
        "rouge_l": 0.39080459770114945,
        "text_similarity": 0.789085865020752,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the same events and their causal relation, and the slide change timing is close, but the timestamps differ (E1 ~1.5s late, E2 slide ~1s late) and the predicted speaker introduction (1266s) disagrees with the reference timing and omits the speaker's end time (1269.32s)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that only 40% of Scottish people surveyed agreed that immigrants make Scotland a better place, when does she mention the number of hate crimes reported in Scotland?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1312.001,
        "end": 1323.455
      },
      "pred_interval": {
        "start": 1325.0,
        "end": 1328.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.999000000000024,
        "end": 4.545000000000073,
        "average": 8.772000000000048
      },
      "rationale_metrics": {
        "rouge_l": 0.23809523809523814,
        "text_similarity": 0.6149930953979492,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the qualitative relation ('after') and roughly the hate-crime number timing, but it misplaces the anchor significantly (1313.0s vs correct 1306.635s) and omits the earlier mention of hate crimes beginning at 1312.001s, so timings are not accurately aligned."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker explains that colourblind racism leads to the omission and avoidance of race issues in the classroom, when does she mention that teachers fear talking about race?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1376.326,
        "end": 1379.45
      },
      "pred_interval": {
        "start": 1383.0,
        "end": 1386.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.673999999999978,
        "end": 6.5499999999999545,
        "average": 6.611999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.7226248979568481,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the utterance content and that it occurs after the explanation, but both E1 and E2 timestamps are substantially incorrect (E1 off by ~7.5s, E2 starts ~3.6s after the true window) and the relation is less precise than the reference 'once_finished'."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says that Critical Race Theory \"really underpins everything that I do when it comes to research\", when does she start discussing the \"Methods\" of their research?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1453.971,
        "end": 1486.746
      },
      "pred_interval": {
        "start": 1527.5,
        "end": 1533.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.529,
        "end": 46.253999999999905,
        "average": 59.89149999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.3137254901960784,
        "text_similarity": 0.7440288662910461,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly approximates the anchor timing but is off by several seconds; the target timing and content are substantially incorrect (begins ~75\u2013100s later and uses slide appearance rather than the cited verbal cue), so it fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker describes the first tenet of Critical Race Theory as the assertion that \"racism is normal, it's ordinary, it's systemic\", when does she describe the next tenet?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1440.328,
        "end": 1450.256
      },
      "pred_interval": {
        "start": 1447.0,
        "end": 1456.0
      },
      "iou": 0.20775906074528333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.6720000000000255,
        "end": 5.7439999999999145,
        "average": 6.20799999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.288659793814433,
        "text_similarity": 0.7093785405158997,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the second tenet content and that it follows the first, but the timestamps are significantly off (predicts start 1447.0 vs correct 1440.328 and end 1456.0 vs 1450.256), so the timing is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that students wholeheartedly disagreed with the idea of equal chance regardless of race/ethnicity, when does she introduce Omar's quote about teachers trying to motivate them?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.0,
        "end": 1618.0
      },
      "pred_interval": {
        "start": 1619.5,
        "end": 1625.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 7.5,
        "average": 7.0
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962028,
        "text_similarity": 0.6482838988304138,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer preserves the correct relation (E2 occurs after E1) but the temporal boundaries are substantially incorrect (predicted E1/E2 are ~8\u20136.5 seconds later than the reference), so it fails to match the ground-truth timings."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker concludes that white privilege is persistent in daily lives, when does the next slide titled 'Interest Convergence and Colourblind Racism' appear?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1706.0,
        "end": 1707.0
      },
      "pred_interval": {
        "start": 1706.0,
        "end": 1710.0
      },
      "iou": 0.25,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.0,
        "end": 3.0,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3529411764705882,
        "text_similarity": 0.6581884622573853,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the slide transition around 1706s and the 'after' relation, but it misstates the speaker's finish time (1705s vs the correct 1699s) and omits the precise E2 interval (1706.0\u20131707.0s), so it's only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says she emailed 31 schools, when does she state how many responses she received?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1782.3,
        "end": 1783.5
      },
      "pred_interval": {
        "start": 1788.5,
        "end": 1791.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.2000000000000455,
        "end": 7.5,
        "average": 6.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.14634146341463414,
        "text_similarity": 0.7182802557945251,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the utterances and their order, but the timestamps are several seconds off and misalign the anchor/target relative to the reference (anchor should be ~1775s and target ~1782\u20131783s), so it is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that one of the secured schools dropped out before recruiting, when does she mention that the second school dropped out a day before the focus groups began?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1818.0,
        "end": 1825.4
      },
      "pred_interval": {
        "start": 1825.0,
        "end": 1831.5
      },
      "iou": 0.029629629629636365,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 6.099999999999909,
        "average": 6.5499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.1836734693877551,
        "text_similarity": 0.6825723648071289,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the sequence (second dropout mentioned immediately after the first) but the provided timestamps are significantly misaligned with the reference (predicted E1/E2 occur several seconds later and E2\u2019s end time is incorrect), so the temporal alignment is largely wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker describes the gatekeeper's reason for not including Black students, when does she state that the gatekeeper didn't ask them to participate?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1907.394,
        "end": 1909.8
      },
      "pred_interval": {
        "start": 1913.5,
        "end": 1916.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.1059999999999945,
        "end": 6.7000000000000455,
        "average": 6.40300000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1414141414141414,
        "text_similarity": 0.6280947923660278,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the content of E1 and E2, and E1 timing is close, but the predicted E2 timestamps (1913.5\u20131916.5s) are significantly later than the ground truth (1907.394\u20131909.8s) and contradict the ground truth's assertion that the non\u2011participation statement follows immediately."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says teachers avoided the topic because they didn't want to be seen as racist, when does she explain that a lack of interest convergence led to inaction?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.768,
        "end": 1967.955
      },
      "pred_interval": {
        "start": 1977.2,
        "end": 1986.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.432000000000016,
        "end": 18.045000000000073,
        "average": 17.738500000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962265,
        "text_similarity": 0.6140928864479065,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the correct semantic order and content (E2 follows E1 and references lack of interest convergence), but it misplaces both event timestamps by about 10 seconds and incorrectly states they occur in immediate succession rather than with the actual ~3s gap, so timing is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide titled 'The Normalcy of Racism', when does the speaker explain why whiteness is considered neutral?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1991.32,
        "end": 2002.951
      },
      "pred_interval": {
        "start": 1999.5,
        "end": 2008.5
      },
      "iou": 0.20087310826542543,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.180000000000064,
        "end": 5.548999999999978,
        "average": 6.864500000000021
      },
      "rationale_metrics": {
        "rouge_l": 0.25531914893617025,
        "text_similarity": 0.7686480283737183,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the explanation occurs during the slide and captures the explanatory content, but the reported time intervals do not match the ground truth (E1 lacks the correct range and E2 is shifted later and longer), so key temporal details are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining Rashida's reasoning for not wearing a hijab, when does she mention Omar's comment about jokes hurting?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2082.096,
        "end": 2085.039
      },
      "pred_interval": {
        "start": 2087.5,
        "end": 2091.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.403999999999996,
        "end": 6.460999999999785,
        "average": 5.932499999999891
      },
      "rationale_metrics": {
        "rouge_l": 0.13483146067415733,
        "text_similarity": 0.7118725776672363,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamps and temporal relation are significantly incorrect: it places both events much later and as immediately successive, whereas the ground truth has E1 ending at 2074.367s and E2 starting at 2082.096s (a several-second gap). This misaligns both spans and the true temporal relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker discusses students internalizing their experience of 'othering' and exclusion, when does she mention that teachers would mostly ignore comments or engage in biased language?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2148.8,
        "end": 2166.4
      },
      "pred_interval": {
        "start": 2156.0,
        "end": 2171.2
      },
      "iou": 0.4642857142857259,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.199999999999818,
        "end": 4.799999999999727,
        "average": 5.999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.27956989247311825,
        "text_similarity": 0.5813283920288086,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the target segment and its content and preserves the after relation, and the E2 start is within the acceptable range, but E1 is inaccurately described as \"the beginning of the clip\" rather than the specified 2136.0s and the E2 end timestamp is several seconds off."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker states she is glad to have been part of the study, when does she say that the students did not feel heard or supported?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2205.5,
        "end": 2210.0
      },
      "pred_interval": {
        "start": 2212.0,
        "end": 2217.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 7.199999999999818,
        "average": 6.849999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.5631067961165048,
        "text_similarity": 0.7445706725120544,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the quoted phrases and the 'once finished' relation (E2 occurs after E1), but the provided timestamps are significantly shifted (~7\u20138 seconds later) compared to the ground truth, so the timing is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes her statement about acknowledging bias being scary but important, when does the slide transition to show the 'Schools can:' recommendations?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2333.0,
        "end": 2333.5
      },
      "pred_interval": {
        "start": 2334.0,
        "end": 2335.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 1.5,
        "average": 1.25
      },
      "rationale_metrics": {
        "rouge_l": 0.4324324324324324,
        "text_similarity": 0.6143626570701599,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the correct utterance and the slide change, but the anchor time is off by ~6 seconds (2334.0s vs 2328.0s) and it incorrectly aligns both events as simultaneous; the target slide time (2334.0s) is only ~0.5s later than the reference but the relation (once_finished) is not preserved."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces implementing curriculum that explicitly includes race talk and counter narratives, when does she explain how teachers can learn to put this into practice?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2345.1,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2351.0,
        "end": 2370.0
      },
      "iou": 0.742971887550198,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 5.900000000000091,
        "end": 0.5,
        "average": 3.2000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.26506024096385544,
        "text_similarity": 0.6931136846542358,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the correct content and quotes for the explanation segment, but the provided timestamps are noticeably shifted later than the ground truth (anchor and target start times are several seconds off), making it only a partial match."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker mentions that the racial equality framework from a couple of years ago is 'very general,' when does she suggest specific, practical training would be more helpful?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2453.2,
        "end": 2458.5
      },
      "pred_interval": {
        "start": 2459.0,
        "end": 2465.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.800000000000182,
        "end": 6.5,
        "average": 6.150000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.3092783505154639,
        "text_similarity": 0.5902027487754822,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the correct semantic content and the anchor location approximately, but the target segment timings are notably later than the ground truth (start ~5.8s and end ~6.5s off), so temporal accuracy is insufficient."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker says 'Thank you', when does the title slide for the presentation appear on screen and is acknowledged?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2535.7,
        "end": 2536.7
      },
      "pred_interval": {
        "start": 2536.0,
        "end": 2542.0
      },
      "iou": 0.11111111111107903,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3000000000001819,
        "end": 5.300000000000182,
        "average": 2.800000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.36170212765957444,
        "text_similarity": 0.7762532234191895,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor event and the target slide appearance and relation ('after') with start times close to the reference, but it gives an incorrect/extended end time (2542.0s vs. 2536.7s) and adds extra acknowledgement details that contradict the reference."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Outline' slide, when does Dr. Nighet Riaz state that racism is normalized in everyday interactions?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2593.7,
        "end": 2602.4
      },
      "pred_interval": {
        "start": 2600.0,
        "end": 2604.0
      },
      "iou": 0.2330097087378688,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.300000000000182,
        "end": 1.599999999999909,
        "average": 3.9500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.27499999999999997,
        "text_similarity": 0.7148779630661011,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the 'during' relation and approximates the anchor start and quoted phrase, but it gives inaccurate target timings (starts later and ends later than reference) and omits the anchor end and the explicit containment detail, so it is partially incorrect/incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After Dr. Nighet Riaz states her name, when does she explain her roles at the University of the West of Scotland and Advance HE?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2550.6,
        "end": 2567.6
      },
      "pred_interval": {
        "start": 2558.0,
        "end": 2565.0
      },
      "iou": 0.4117647058823529,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.400000000000091,
        "end": 2.599999999999909,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.33999999999999997,
        "text_similarity": 0.6917015314102173,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor (name) and the target (roles) and the relation 'after'; the target time window falls within the reference span, with only minor timestamp offsets for the anchor and start of the target. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions disrupting the narrative, when does she start discussing global citizenship through the lens of the beneficent other?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2700.74,
        "end": 2707.407
      },
      "pred_interval": {
        "start": 2708.0,
        "end": 2714.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.260000000000218,
        "end": 6.592999999999847,
        "average": 6.926500000000033
      },
      "rationale_metrics": {
        "rouge_l": 0.3409090909090909,
        "text_similarity": 0.682236909866333,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly shifts both anchor and target by ~7 seconds (predicting ~2707\u20132714s vs. correct 2700.079\u20132707.407s). While it notes a sequential relationship, the timestamps and boundaries are materially wrong."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing global citizenship and Scotland's curricular intention to imbricate it through the curriculum, when does she specifically mention it presenting a cross-curricular and whole school approach?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2790.853,
        "end": 2797.969
      },
      "pred_interval": {
        "start": 2801.0,
        "end": 2804.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.146999999999935,
        "end": 6.030999999999949,
        "average": 8.088999999999942
      },
      "rationale_metrics": {
        "rouge_l": 0.38554216867469876,
        "text_similarity": 0.8425025939941406,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the quoted phrase and that it occurs during the Scotland/global citizenship discussion, but the reported anchor/target timestamps are significantly off (by ~8\u201312 seconds) and misalign with the ground-truth boundaries, so the timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Decolonising the Curriculum', when does the speaker begin talking about that specific term?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2851.15,
        "end": 2854.233
      },
      "pred_interval": {
        "start": 2857.0,
        "end": 2860.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.849999999999909,
        "end": 5.766999999999825,
        "average": 5.808499999999867
      },
      "rationale_metrics": {
        "rouge_l": 0.49382716049382713,
        "text_similarity": 0.8863722085952759,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the event order and quoted phrase but the timestamps are substantially incorrect (about 5\u20136 seconds later and a mismatched end time), so it fails to match the precise intervals in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that decolonisation moves out of a western framework, when does she start mentioning Sophia Kell?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2904.8,
        "end": 2905.4
      },
      "pred_interval": {
        "start": 2911.2,
        "end": 2915.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.399999999999636,
        "end": 9.599999999999909,
        "average": 7.999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.2765957446808511,
        "text_similarity": 0.7293903231620789,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the mention occurs immediately after the anchor, but gives a substantially incorrect timestamp (~2911s vs 2904.8s) and misnames Sophia Kell as 'Akel,' so it contains significant factual errors."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker describes her journey from compulsory to higher education, when does she identify internalized racism as a large part of her imposter syndrome?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3077.4,
        "end": 3085.5
      },
      "pred_interval": {
        "start": 3084.0,
        "end": 3090.0
      },
      "iou": 0.1190476190476199,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.599999999999909,
        "end": 4.5,
        "average": 5.5499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.20224719101123595,
        "text_similarity": 0.5866098403930664,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the relation and semantic content (internalized racism identified after the journey) but the timestamps are significantly shifted and misaligned with the ground-truth ranges, omitting the true start of E2 and placing E1 incorrectly, so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker recounts a SAMI colleague advising her to channel frustration into something positive, when does she mention the planning of the project called Humari Pehchan?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3060.6,
        "end": 3064.5
      },
      "pred_interval": {
        "start": 3064.0,
        "end": 3070.0
      },
      "iou": 0.053191489361701615,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.400000000000091,
        "end": 5.5,
        "average": 4.4500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.5707719326019287,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the sequence and full project name, but the time spans are noticeably misaligned (E1 shifted later and extended, E2 starts and ends later than the reference), so timestamps are inaccurate though relation and content are preserved."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker outlines the project's aim to bring families, schools, and community organizations together for storytelling, when does she state that the project is a call for action and a provocation?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3121.9,
        "end": 3125.0
      },
      "pred_interval": {
        "start": 3138.0,
        "end": 3144.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.09999999999991,
        "end": 19.0,
        "average": 17.549999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.25263157894736843,
        "text_similarity": 0.6454514265060425,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the quoted phrasing and the 'after' relation, but the timestamps are substantially misaligned: predicted E1 largely misses the correct E1 span and predicted E2 occurs about 16\u201317s later than the reference, so the temporal grounding is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining the research methodology's approach to power imbalances, when does she introduce the project's aim for children and parents?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.427,
        "end": 3304.244
      },
      "pred_interval": {
        "start": 3295.0,
        "end": 3301.0
      },
      "iou": 0.3793386862236832,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.572999999999865,
        "end": 3.244000000000142,
        "average": 4.908500000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.2580645161290323,
        "text_similarity": 0.511306881904602,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the event ordering and provides E1/E2 onset and offset times, but the timestamps are notably shifted (\u22486.5s later for the starts and \u22483.2s earlier for the end) and it adds quoted phrasing not present in the reference, so it is only partially accurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker concludes the description of story development using heritage language, when does she start listing the project participants?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3305.525,
        "end": 3316.596
      },
      "pred_interval": {
        "start": 3313.0,
        "end": 3326.5
      },
      "iou": 0.17144219308700925,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.474999999999909,
        "end": 9.903999999999996,
        "average": 8.689499999999953
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.4851728677749634,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the correct ordering (listing begins after finishing), but all timestamps are substantially later than the reference (E1 ~+6.8s, E2 start ~+7.5s, E2 end ~+9.9s) and the end time is shifted well beyond the ground truth; it also adds quoted wording not present in the reference, so it is not accurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the project was postponed to September, when does she state the duration of the project and its output?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3369.8,
        "end": 3378.21
      },
      "pred_interval": {
        "start": 3376.5,
        "end": 3384.5
      },
      "iou": 0.11632653061224882,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.699999999999818,
        "end": 6.289999999999964,
        "average": 6.494999999999891
      },
      "rationale_metrics": {
        "rouge_l": 0.24390243902439024,
        "text_similarity": 0.76017165184021,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the 'after' relation but the timestamps are substantially off (E1 ~8.7s later; E2 start ~6.7s later and end ~6.3s later) and it includes extra/unverified phrasing, so the temporal localization is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker (Niget) finishes saying 'thank you', when does the other speaker (Katerina) start thanking her?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3413.516,
        "end": 3415.117
      },
      "pred_interval": {
        "start": 3419.0,
        "end": 3422.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.483999999999924,
        "end": 6.882999999999811,
        "average": 6.183499999999867
      },
      "rationale_metrics": {
        "rouge_l": 0.14925373134328357,
        "text_similarity": 0.5118472576141357,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the order right (Katerina thanks after Niget) but the timestamps are substantially off (predicted ~3417\u20133422s vs ground truth 3413\u20133415s) and it introduces likely hallucinated utterances and a non-immediate gap, contradicting the once_finished/immediate-follow relation."
      }
    },
    {
      "question_id": "003",
      "question": "While Diane is discussing Sophie's comment, when does she apologize for the dogs?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3457.09,
        "end": 3459.233
      },
      "pred_interval": {
        "start": 3463.0,
        "end": 3466.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.9099999999998545,
        "end": 6.766999999999825,
        "average": 6.33849999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.5128205128205128,
        "text_similarity": 0.8001599311828613,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the quoted apology phrase correct but substantially misstates the timing (predicted 3463\u20133466 vs correct 3457.090\u20133459.233) and the start of discussion, and introduces an unverified barking interruption; thus it fails to align temporally and adds hallucinated detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker in the bottom left talks about extreme prevent agendas, when does she talk about overt acts of racism in schools?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3579.7,
        "end": 3585.6
      },
      "pred_interval": {
        "start": 3585.0,
        "end": 3592.0
      },
      "iou": 0.04878048780486993,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.300000000000182,
        "end": 6.400000000000091,
        "average": 5.850000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.17391304347826086,
        "text_similarity": 0.32320213317871094,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly identifies the same speaker, the sequence (anchor then target), and provides matching relative timestamps and quoted content; differences in exact second rounding are minor and do not change the meaning."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker in the bottom right discusses the concept of 'racism without racists', when does she explain that the system itself is inherently racist?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3628.4,
        "end": 3675.8
      },
      "pred_interval": {
        "start": 3635.0,
        "end": 3639.0
      },
      "iou": 0.08438818565400828,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.599999999999909,
        "end": 36.80000000000018,
        "average": 21.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.21505376344086022,
        "text_similarity": 0.5021869540214539,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the ordering, core phrasing, and relative timing (anchor ~00:41, target beginning ~01:05) but understates the full target segment duration (ends at 01:09 vs the longer span in the reference)."
      }
    },
    {
      "question_id": "001",
      "question": "After the host thanks the speakers, when does she introduce a question for Jackie?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3771.2,
        "end": 3772.9
      },
      "pred_interval": {
        "start": 3777.0,
        "end": 3789.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.800000000000182,
        "end": 16.09999999999991,
        "average": 10.950000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.25000000000000006,
        "text_similarity": 0.7626316547393799,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly identifies the temporal relationship ('after') but the event timestamps are substantially misaligned with the reference (both E1 and E2 times and durations are off by several seconds) and the prediction adds extra/unfounded details about the reading of the question."
      }
    },
    {
      "question_id": "002",
      "question": "After Jackie states that the US has been using CRT in anti-discrimination training, when does she mention that it hasn't been implemented in Scotland?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3861.8,
        "end": 3866.4
      },
      "pred_interval": {
        "start": 3868.0,
        "end": 3872.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.199999999999818,
        "end": 5.599999999999909,
        "average": 5.899999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.2352941176470588,
        "text_similarity": 0.7522061467170715,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the content and that the Scotland remark immediately follows the US CRT comment, but the provided timestamps are several seconds off from the reference, so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After Jackie concludes her answer about diversity being everyone's issue, when does the host pick up on Greg's statement and question?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3918.884,
        "end": 3925.172
      },
      "pred_interval": {
        "start": 3925.0,
        "end": 3947.0
      },
      "iou": 0.0061175131597675896,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.1159999999999854,
        "end": 21.827999999999975,
        "average": 13.97199999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.7237833738327026,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the relative ordering ('after') and the general events, but the timestamps deviate substantially from the reference (E1 ~6s late; E2 start ~6s late and E2 end ~22s late) and it adds quoted/extra wording not present in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman in the top-right finishes her sentence about normalising provocation, when does the woman in the top-left start speaking about a national campaign?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3954.0,
        "end": 4036.3
      },
      "pred_interval": {
        "start": 3966.0,
        "end": 3970.0
      },
      "iou": 0.048602673147022976,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.0,
        "end": 66.30000000000018,
        "average": 39.15000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.6824584603309631,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the target event follows the anchor and that the top-left speaker references a national campaign, but it gives notably different timestamps (anchor and start times off by several seconds), fabricates anchor wording, and omits the correct target end time, so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman in the top-right finishes saying they have 10 minutes before wrapping up, when does the woman in the bottom-left start speaking?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4129.3,
        "end": 4130.2
      },
      "pred_interval": {
        "start": 4135.0,
        "end": 4138.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.699999999999818,
        "end": 7.800000000000182,
        "average": 6.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2716049382716049,
        "text_similarity": 0.6072882413864136,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the basic relation (bottom-left starts after the top-right finishes) but the timestamps are off by ~5.7s, it omits the correct end time, and it adds unverified details (speaker name and quoted words), so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After Lisa (woman in bottom-left) asks if anyone would like to put their hand up, when is the next time an unidentified woman speaks to assist her?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4214.2,
        "end": 4215.3
      },
      "pred_interval": {
        "start": 4220.0,
        "end": 4223.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.800000000000182,
        "end": 7.699999999999818,
        "average": 6.75
      },
      "rationale_metrics": {
        "rouge_l": 0.1904761904761905,
        "text_similarity": 0.7347157597541809,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that an unidentified woman speaks to assist Lisa next, but the timestamps differ by about 5\u20138 seconds from the reference and it adds a specific quoted utterance and longer duration not supported by the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After Lisa (woman in bottom-left) says 'You have the floor' to Ken, when does Ken (man in bottom-right) start asking his question?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4227.7,
        "end": 4304.7
      },
      "pred_interval": {
        "start": 4234.0,
        "end": 4239.0
      },
      "iou": 0.06493506493506493,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.300000000000182,
        "end": 65.69999999999982,
        "average": 36.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.5700781345367432,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the events and their order (Ken speaks after Lisa) and notes Ken begins by thanking before asking, but both timestamps differ by ~6s from the reference and it omits the provided completion time of Ken's question, so it is incomplete and slightly inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker (top right) says she was hoping to be told who the next Education Minister was, when does the speaker (top left) say she was excited for an announcement about a new education minister?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4405.248,
        "end": 4411.436
      },
      "pred_interval": {
        "start": 4411.0,
        "end": 4418.0
      },
      "iou": 0.03419071518190719,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.7520000000004075,
        "end": 6.564000000000306,
        "average": 6.1580000000003565
      },
      "rationale_metrics": {
        "rouge_l": 0.22471910112359547,
        "text_similarity": 0.6116943955421448,
        "llm_judge_score": 6,
        "llm_judge_justification": "The predicted answer correctly identifies the anchor event and that the target follows it, and the quoted content matches, but the target event timestamps are notably later than the ground truth (predicted start ~4411s vs true 4405.248s and end ~4418s vs true 4411.436s), so timing is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker (top right) says there are many voices missing within policy construction, when does the speaker (top left) start talking about Kokab Stewart?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4411.577,
        "end": 4421.13
      },
      "pred_interval": {
        "start": 4421.0,
        "end": 4425.0
      },
      "iou": 0.009684869254273362,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.422999999999774,
        "end": 3.869999999999891,
        "average": 6.646499999999833
      },
      "rationale_metrics": {
        "rouge_l": 0.24691358024691357,
        "text_similarity": 0.6836735606193542,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves that the target occurs after the anchor but gives inaccurate timestamps: the anchor time (~4337s) diverges from the correct finish (4345.617s) and the predicted target start (4421.0s) is ~9.4s later than the correct start (4411.577s) and even extends beyond the true end (4421.130s). It also adds extraneous detail about describing her background not present in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker (bottom left) says 'I am a lowly teacher more so than a policy expert', when does she start talking about mandated teacher training in anti-racism?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4463.676,
        "end": 4476.028
      },
      "pred_interval": {
        "start": 4469.0,
        "end": 4476.0
      },
      "iou": 0.5667098445595918,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.323999999999614,
        "end": 0.028000000000247383,
        "average": 2.675999999999931
      },
      "rationale_metrics": {
        "rouge_l": 0.26506024096385544,
        "text_similarity": 0.6324677467346191,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction identifies the correct subsequent topic and matches the target end time and quoted content, but the anchor and target start timestamps are off by about 5\u20136 seconds compared to the reference, so it's slightly imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that a policy won't translate into practice without teacher buy-in, when does she start talking about specific and mandated training for teachers?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4487.6,
        "end": 4494.5
      },
      "pred_interval": {
        "start": 4494.0,
        "end": 4501.0
      },
      "iou": 0.037313432835821905,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.399999999999636,
        "end": 6.5,
        "average": 6.449999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6107609272003174,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the sequential relation and the content of E2, but the timestamps are substantially off (both anchor and target are shifted later by ~6\u201310 seconds and the end time differs), so it does not match the ground-truth timing."
      }
    },
    {
      "question_id": "002",
      "question": "After David finishes asking if it's appropriate to apply critical race theory to Irish racism in Scotland, when does Jackie respond?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4674.198,
        "end": 4676.359
      },
      "pred_interval": {
        "start": 4550.0,
        "end": 4581.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 124.19800000000032,
        "end": 95.35900000000038,
        "average": 109.77850000000035
      },
      "rationale_metrics": {
        "rouge_l": 0.19753086419753088,
        "text_similarity": 0.6017000675201416,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates Jackie responds after David, but the timestamps are substantially off (\u2248117s earlier) and the predicted target misrepresents the event length and content (it adds extended elaboration instead of the brief 'yes' at the correct times), so it largely fails to match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once Jackie finishes saying she will stop before making a political boo-boo, when does the speaker (top right) begin to discuss critical race theory's applicability beyond color racial issues?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4576.21,
        "end": 4586.726
      },
      "pred_interval": {
        "start": 4582.0,
        "end": 4598.0
      },
      "iou": 0.216888480954551,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.789999999999964,
        "end": 11.274000000000342,
        "average": 8.532000000000153
      },
      "rationale_metrics": {
        "rouge_l": 0.20224719101123595,
        "text_similarity": 0.5249432921409607,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the event ordering (E2 starts after E1) but the timestamps are substantially off (both start and end times differ by several seconds to over 10s) and the predicted end time adds unfounded content, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the top-left female speaker finishes stating she is looking forward to inviting Nicola to present her work, when does she explain the reason for the invitation?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4663.9,
        "end": 4672.2
      },
      "pred_interval": {
        "start": 4669.0,
        "end": 4678.0
      },
      "iou": 0.2269503546099103,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.100000000000364,
        "end": 5.800000000000182,
        "average": 5.450000000000273
      },
      "rationale_metrics": {
        "rouge_l": 0.30630630630630634,
        "text_similarity": 0.6899248361587524,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the explanation immediately follows, and even quotes the explanatory phrase, but its timestamps/intervals are imprecise and slightly inconsistent with the reference (E2 is shifted several seconds later and the anchor/target timing is reported ambiguously)."
      }
    },
    {
      "question_id": "002",
      "question": "After the top-left female speaker asks if there are any more questions, when does the top-right female speaker begin to answer a question from 'Sarah Khan'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4697.9,
        "end": 4703.6
      },
      "pred_interval": {
        "start": 4704.0,
        "end": 4713.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.100000000000364,
        "end": 9.399999999999636,
        "average": 7.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3577235772357724,
        "text_similarity": 0.7888957858085632,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target speakers, their order, and that the top-right speaker acknowledges Sarah Khan, but the reported timing windows are noticeably shifted (\u22486s later) and the predicted target duration contradicts the reference end time, so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the top-right female speaker mentions that UWS has included a clear statement in placement handbooks, when does she describe the challenge of students having the confidence to speak up about discrimination?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4738.4,
        "end": 4750.8
      },
      "pred_interval": {
        "start": 4757.0,
        "end": 4770.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.600000000000364,
        "end": 19.199999999999818,
        "average": 18.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.2809917355371901,
        "text_similarity": 0.6958615779876709,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target content and their immediate-after relationship, but the provided timestamps are inconsistent with the ground truth (the target is shifted ~18\u201319 seconds later and E1 timing/mapping is unclear), so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the top-left woman finishes speaking about BAME students experiencing racism and leaving, when does the bottom-right woman begin speaking about the important message?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4841.8,
        "end": 4845.0
      },
      "pred_interval": {
        "start": 4848.0,
        "end": 4852.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.199999999999818,
        "end": 7.0,
        "average": 6.599999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.5715437531471252,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the speakers, the quoted phrase, and that E2 occurs after E1, but all provided timestamps are off by about 6\u20137 seconds compared to the ground truth, so the temporal information is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the bottom-right woman states that including an explicit statement in handbooks can make a difference in a student's life, when does she mention that they only have four minutes left?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4880.8,
        "end": 4897.0
      },
      "pred_interval": {
        "start": 4893.0,
        "end": 4897.0
      },
      "iou": 0.24691358024691634,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.199999999999818,
        "end": 0.0,
        "average": 6.099999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.1904761904761905,
        "text_similarity": 0.544929027557373,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction captures the correct ordering and E2's end time, but both timestamps are notably off (E1 ~4873s vs 4866.6s; E2 start 4893s vs 4880.8s) and it adds unsupported logistical detail about raised hands."
      }
    },
    {
      "question_id": "003",
      "question": "Once the bottom-right woman finishes describing the story from the book 'Whistling Vivaldi', when does she mention that there are many other examples in that book?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4986.36,
        "end": 4989.384
      },
      "pred_interval": {
        "start": 4991.0,
        "end": 4995.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.640000000000327,
        "end": 5.6159999999999854,
        "average": 5.128000000000156
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.5375066995620728,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction preserves the relation and even includes the quoted line, but the timestamps are shifted by about 4\u20136 seconds from the reference, so it\u2019s semantically correct but temporally imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker expresses her upset about the schools' reluctance to participate, when does she mention Negat having difficulties with recruitment?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 5023.8,
        "end": 5035.8
      },
      "pred_interval": {
        "start": 5034.5,
        "end": 5042.2
      },
      "iou": 0.07065217391305476,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.699999999999818,
        "end": 6.399999999999636,
        "average": 8.549999999999727
      },
      "rationale_metrics": {
        "rouge_l": 0.23655913978494625,
        "text_similarity": 0.5751206874847412,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the events and their 'after' relation and accurately quotes the target content, but the provided timestamps are substantially shifted later (E1 misaligned by ~10s and E2 begins ~10.7s later and ends ~6.4s later) versus the reference, so timing accuracy is insufficient."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'there is no neutral position' for the first time following Jackie's quote, when does she say it again?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 5084.475,
        "end": 5085.8
      },
      "pred_interval": {
        "start": 5090.2,
        "end": 5092.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.724999999999454,
        "end": 6.199999999999818,
        "average": 5.962499999999636
      },
      "rationale_metrics": {
        "rouge_l": 0.32876712328767127,
        "text_similarity": 0.5934127569198608,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies two occurrences and that the second is an immediate repetition, but the reported timestamps (5088s / 5090.2\u20135092.0s) are several seconds later and durations differ from the ground truth (5080.0\u20135083.8s and 5084.475\u20135085.8s), making it factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes quoting the first Martin Luther King line, when does she start quoting the second one about accepting evil?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 5105.5,
        "end": 5114.1
      },
      "pred_interval": {
        "start": 5112.3,
        "end": 5120.1
      },
      "iou": 0.1232876712328861,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.800000000000182,
        "end": 6.0,
        "average": 6.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.38966691493988037,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the quote texts and the temporal relation (second quote begins after the first ends), but the reported timestamps differ from the reference by about 6\u20137 seconds for each event, so it is not fully temporally accurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker (bottom left) finishes mentioning adding links to the work of Sam, Khadija, and Nigit, when does she pass it on to Stella?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5190.0,
        "end": 5382.825
      },
      "gt_interval": {
        "start": 5300.0,
        "end": 5305.0
      },
      "pred_interval": {
        "start": 5306.5,
        "end": 5313.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 8.0,
        "average": 7.25
      },
      "rationale_metrics": {
        "rouge_l": 0.26,
        "text_similarity": 0.5501757264137268,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies a handover to Stella after the links mention, but it gives substantially different timestamps (both for the end of mentioning links and the handover) and adds hallucinated wording and timings, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says that the team is going to do a quick introduction, when does Ashley Satri introduce herself?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 84.156,
        "end": 102.754
      },
      "pred_interval": {
        "start": 83.0,
        "end": 106.0
      },
      "iou": 0.8086086956521739,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.156000000000006,
        "end": 3.245999999999995,
        "average": 2.2010000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.23655913978494625,
        "text_similarity": 0.8484188318252563,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that Ashley introduces herself after it, and the content matches; the timestamps are slightly off (E2 starts ~1.1s earlier and ends ~3.2s later than the ground truth) but not materially misleading."
      }
    },
    {
      "question_id": "002",
      "question": "Next, after Ashley Satri finishes introducing herself, when does Carly Thibodeau introduce herself?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 106.54,
        "end": 116.471
      },
      "pred_interval": {
        "start": 106.0,
        "end": 117.0
      },
      "iou": 0.9028181818181816,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.5400000000000063,
        "end": 0.5289999999999964,
        "average": 0.5345000000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.2736842105263158,
        "text_similarity": 0.868454098701477,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly matches the target introduction window for Carly (start/end within ~0.5s) but incorrectly places Ashley's finish time (106.0s vs 102.754s) and adds hallucinated content (phrasing and '21 years' detail). These factual errors and the wrong anchor timestamp reduce correctness."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning the \"IDEA Supervision, Monitoring, and Support team\", when does she begin listing other teams within that department?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.641,
        "end": 188.788
      },
      "pred_interval": {
        "start": 195.0,
        "end": 204.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.359000000000009,
        "end": 15.211999999999989,
        "average": 12.785499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306123,
        "text_similarity": 0.6744570732116699,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the general content (listing other teams) but the timestamps are substantially incorrect\u2014the anchor/target times are off by ~5\u201315 seconds and the predicted target does not immediately follow the anchor as stated in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining the purpose of an IEP, when does she highlight the phrase \"prepare them\" on the slide?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.569,
        "end": 304.375
      },
      "pred_interval": {
        "start": 305.0,
        "end": 306.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.430999999999983,
        "end": 1.625,
        "average": 10.527999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.2272727272727273,
        "text_similarity": 0.6609221696853638,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the phrase and that it's emphasized, but it misstates the event type and timing\u2014claiming a verbal articulation at 305\u2013306s\u2014whereas the ground truth specifies the visual highlight occurring from 285.569s to 304.375s during the explanation."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes saying \"So please feel free to reach out\", when does the slide transition to \"The IEP Decision Making Process\"?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 324.55,
        "end": 326.4
      },
      "pred_interval": {
        "start": 266.0,
        "end": 267.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.55000000000001,
        "end": 59.39999999999998,
        "average": 58.974999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.6139142513275146,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction identifies the anchor phrase but gives an incorrect timeline: anchor end is slightly off (259s vs 254.65s) and crucially the slide transition time (266.0s) is far earlier than the correct start at 324.55s, contradicting the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks what the IEP meeting is, when does she define it as a communication vehicle?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 348.721,
        "end": 354.0
      },
      "pred_interval": {
        "start": 355.2,
        "end": 357.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.478999999999985,
        "end": 3.8000000000000114,
        "average": 5.139499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.1971830985915493,
        "text_similarity": 0.7148734331130981,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the relation ('after') and the content (defines IEP as a communication vehicle), but the provided timestamps and event boundaries substantially disagree with the ground truth, so the answer is largely temporally incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker explains that the SAU has the ultimate responsibility for FAPE, when does she mention that they will discuss disagreement on the next slide?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 404.242,
        "end": 409.428
      },
      "pred_interval": {
        "start": 449.5,
        "end": 454.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.25799999999998,
        "end": 44.572,
        "average": 44.91499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.25581395348837205,
        "text_similarity": 0.6854426860809326,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the correct relation ('after') and the quoted utterance, but the reported timestamps deviate substantially from the ground truth (off by ~46\u201349 seconds), a significant factual mismatch for a temporal question."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Recap' slide appears, when does the speaker state that the IEP meeting serves as a communication vehicle?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 529.94,
        "end": 533.504
      },
      "pred_interval": {
        "start": 535.5,
        "end": 538.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.559999999999945,
        "end": 4.995999999999981,
        "average": 5.277999999999963
      },
      "rationale_metrics": {
        "rouge_l": 0.3466666666666666,
        "text_similarity": 0.7805585861206055,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the relation and event content roughly right, but both timestamps are significantly offset from the ground truth (E1 ~4s late; E2 ~5.5s late), so the temporal spans are not accurately aligned."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that the SAU has ultimate responsibility for FAPE, when does she mention that dispute resolution options are available?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 544.0,
        "end": 547.0
      },
      "pred_interval": {
        "start": 548.9,
        "end": 552.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.899999999999977,
        "end": 5.5,
        "average": 5.199999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.25000000000000006,
        "text_similarity": 0.6434540152549744,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the same two events and that the dispute-resolution mention occurs after the SAU responsibility statement, but the provided timestamps are several seconds later than the reference intervals, so the timing is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Required Participants for IEP Meetings' slide, when does the speaker describe the qualifications of a representative from the SAU?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 584.0,
        "end": 600.0
      },
      "pred_interval": {
        "start": 630.5,
        "end": 646.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.5,
        "end": 46.0,
        "average": 46.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2173913043478261,
        "text_similarity": 0.6540378332138062,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction places the SAU qualifications at 630.5\u2013646.0s, which materially contradicts the reference timing of 584.0\u2013600.0s, though it correctly states the event occurs during the slide; additionally it adds specific qualification details not present in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the special education director, IP coordinator, and assistant principal as part of the team, when does she state that the child must be invited?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 700.0,
        "end": 713.5
      },
      "pred_interval": {
        "start": 737.2,
        "end": 740.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.200000000000045,
        "end": 26.700000000000045,
        "average": 31.950000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.5985779166221619,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the quoted phrase but the timestamps are substantially shifted and durations are incorrect (anchor and target are ~35s later than ground truth and target end is much shorter), so it fails to match the reference temporal alignment."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the conditions for when a team member's attendance is not necessary, when does she begin discussing the conditions for an excusal?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.0,
        "end": 776.0
      },
      "pred_interval": {
        "start": 825.1,
        "end": 835.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.10000000000002,
        "end": 59.5,
        "average": 57.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230776,
        "text_similarity": 0.41076505184173584,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly quotes the transition phrase but the timestamps are substantially incorrect (predicted ~825s vs correct 769.0s begin and 776.0s end), so it fails the timing requirement of the question."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'What if the parent can't attend the IEP meeting?', when does she begin explaining the requirements for public agencies?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 909.0,
        "end": 924.0
      },
      "pred_interval": {
        "start": 884.0,
        "end": 911.0
      },
      "iou": 0.05,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.0,
        "end": 13.0,
        "average": 19.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2156862745098039,
        "text_similarity": 0.2541654706001282,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are substantially different from the ground truth (anchor ~870.35s vs 879s; target should be 870.39\u2013870.54s but prediction says 884.0\u2013911.0s), giving a much longer, incorrect segment; although both imply an 'after' relation, the temporal alignment and segment boundaries are largely wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses offering other methods for parents to attend IEP meetings, when does she explain that a meeting might be conducted without a parent?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 950.0,
        "end": 965.0
      },
      "pred_interval": {
        "start": 924.0,
        "end": 951.0
      },
      "iou": 0.024390243902439025,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.0,
        "end": 14.0,
        "average": 20.0
      },
      "rationale_metrics": {
        "rouge_l": 0.18691588785046725,
        "text_similarity": 0.3254108428955078,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction largely misaligns the time intervals: it places the anchor ending around 924s and the target starting at 924s, whereas the ground truth has the anchor at 936.06\u2013946.18s and the target at 950.0\u2013965.0s; only a brief overlap exists, so the timing assignment is mostly incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After Ashley suggests recording attempts to contact parents in the written notice, when does Carly agree with this recommendation?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1076.3,
        "end": 1077.4
      },
      "pred_interval": {
        "start": 1081.1,
        "end": 1082.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.7999999999999545,
        "end": 5.099999999999909,
        "average": 4.949999999999932
      },
      "rationale_metrics": {
        "rouge_l": 0.19672131147540983,
        "text_similarity": 0.6047859191894531,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that Carly agrees after Ashley, but the key timestamps are inaccurate (predicted E1/E2 are ~18\u201319s later and the agreement interval does not match the reference), so it is factually incorrect on the crucial temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "Once Ashley finishes posing the question about holding an IEP meeting with only an 18-year-old student, when does Carly offer her initial thought on the matter?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1117.7,
        "end": 1122.7
      },
      "pred_interval": {
        "start": 1123.0,
        "end": 1129.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.2999999999999545,
        "end": 6.2999999999999545,
        "average": 5.7999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.3370786516853933,
        "text_similarity": 0.6618776321411133,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer captures the content of Carly's initial belief but gives substantially incorrect timestamps (and misstates Ashley's finish time), omitting the correct timings of 1117.7\u20131122.7, so it is largely temporally inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'determining those present levels', when does she mention the 'Office Hours Archives \u2013 Data Collection Modules' link?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1233.32,
        "end": 1234.36
      },
      "pred_interval": {
        "start": 1260.5,
        "end": 1269.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.180000000000064,
        "end": 35.1400000000001,
        "average": 31.160000000000082
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.7103204727172852,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction's anchor and target timestamps are substantially different from the reference and the quoted target content/timing appears hallucinated, so it does not align with the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'determining modifications and/or accommodations', when does she mention the 'MTSS office'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1291.054,
        "end": 1294.278
      },
      "pred_interval": {
        "start": 1294.5,
        "end": 1299.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.4459999999999127,
        "end": 4.72199999999998,
        "average": 4.083999999999946
      },
      "rationale_metrics": {
        "rouge_l": 0.17721518987341772,
        "text_similarity": 0.7852298021316528,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the MTSS mention occurs after it, but the timestamps are notably inaccurate (E1 off by ~1\u20132s and E2 shifted several seconds later than the reference) and the predicted phrasing/additional timing details do not match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'This is an IEP checklist that I think Carly developed', when does she describe what the checklist tells you to do?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1366.516,
        "end": 1375.503
      },
      "pred_interval": {
        "start": 1373.5,
        "end": 1380.5
      },
      "iou": 0.1432351258581193,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.983999999999924,
        "end": 4.997000000000071,
        "average": 5.990499999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2247191011235955,
        "text_similarity": 0.7223225831985474,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies both the anchor and target and that the target follows the anchor, but the provided timestamps are shifted later by about 6\u20138 seconds and the predicted E2 only partially overlaps the reference interval, so the timing is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"number five\", when does the \"Amendments\" slide fully appear on screen?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1443.918,
        "end": 1444.018
      },
      "pred_interval": {
        "start": 1444.1,
        "end": 1446.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.18200000000001637,
        "end": 2.08199999999988,
        "average": 1.1319999999999482
      },
      "rationale_metrics": {
        "rouge_l": 0.4838709677419355,
        "text_similarity": 0.7829138040542603,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the relation and E2 approximately right, but it significantly misstates E1 (1443.8s vs correct 1439.347s), a key factual error, so it is largely incorrect despite E2 being close."
      }
    },
    {
      "question_id": "002",
      "question": "After the \"IEP Meeting Timelines\" slide appears on screen, when does the speaker state that timelines can be a little bit confusing?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1517.804,
        "end": 1519.454
      },
      "pred_interval": {
        "start": 1524.0,
        "end": 1526.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.195999999999913,
        "end": 6.546000000000049,
        "average": 6.370999999999981
      },
      "rationale_metrics": {
        "rouge_l": 0.5526315789473684,
        "text_similarity": 0.8540071249008179,
        "llm_judge_score": 3,
        "llm_judge_justification": "While the relation ('after') is correct, the predicted timestamps are significantly inaccurate (E1 ~1.7s later than reference and E2 ~6.2s later), so the answer is factually imprecise."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker explains that an advanced written notice needs to go out seven days prior to the IEP meeting, when do they state that parents must sign to waive this 7-day advanced written notice?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1560.813,
        "end": 1570.038
      },
      "pred_interval": {
        "start": 1566.5,
        "end": 1570.5
      },
      "iou": 0.3652317538969803,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.686999999999898,
        "end": 0.4619999999999891,
        "average": 3.0744999999999436
      },
      "rationale_metrics": {
        "rouge_l": 0.41025641025641024,
        "text_similarity": 0.7334569692611694,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the statement about parents signing to waive the 7\u2011day notice and the 'after' relation; the time spans largely overlap the reference but have minor start/end discrepancies. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker explains the 60-calendar-day and 45-school-day evaluation timelines, when does she explain that evaluation reports must be provided to the parent at least three days prior to the IEP meeting?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1633.362,
        "end": 1641.913
      },
      "pred_interval": {
        "start": 1638.5,
        "end": 1647.0
      },
      "iou": 0.2502566358703645,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.13799999999992,
        "end": 5.086999999999989,
        "average": 5.1124999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.7571269273757935,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the target utterance about the evaluation reports but provides incorrect timing and relation: E2 start/end times differ from the reference by several seconds and E1 is inaccurately described as ending 'immediately before' the target (reference shows a ~35s gap), so the temporal alignment is wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide changes to 'Requirement that Program be in Effect', when does the speaker clarify that the 30-day timeline applies to both IEP development and implementation?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1719.674,
        "end": 1731.971
      },
      "pred_interval": {
        "start": 1700.5,
        "end": 1711.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.173999999999978,
        "end": 20.471000000000004,
        "average": 19.82249999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7616939544677734,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the semantic point and correct 'after' relation, but the timestamps are substantially incorrect: the anchor is off by ~4s and the target interval is ~19\u201320s earlier than the ground truth, mislocating the clarification."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the annual meeting date for the student as January 6th, 2022, when does she state when the next annual meeting must be held?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1785.48,
        "end": 1793.83
      },
      "pred_interval": {
        "start": 1790.5,
        "end": 1799.0
      },
      "iou": 0.24630177514792395,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.019999999999982,
        "end": 5.170000000000073,
        "average": 5.095000000000027
      },
      "rationale_metrics": {
        "rouge_l": 0.2823529411764706,
        "text_similarity": 0.7751936912536621,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the target follows the anchor (same relation) and that the anchor is the student's meeting date, but the timestamps differ notably from the reference and the prediction adds a specific next-meeting date (Jan 5, 2023) not supported by the correct answer, indicating inaccurate timing and added/hallucinated detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the annual meeting date of January 6, 2022, when does she mention that the duration of the IEP begins on January 16?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.116,
        "end": 1878.561
      },
      "pred_interval": {
        "start": 1878.0,
        "end": 1884.0
      },
      "iou": 0.05154355016537312,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.8840000000000146,
        "end": 5.439000000000078,
        "average": 5.161500000000046
      },
      "rationale_metrics": {
        "rouge_l": 0.37209302325581395,
        "text_similarity": 0.8872957825660706,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both events, the quoted phrasing, and the 'after' relation, but the timestamps are consistently ~5\u20136 seconds later than the reference (minor timing discrepancies)."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Annual IEP & Duration of IEP' diagram, when does the speaker explain the 7-day notice period?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1901.094,
        "end": 1909.493
      },
      "pred_interval": {
        "start": 1862.0,
        "end": 1874.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.09400000000005,
        "end": 35.49299999999994,
        "average": 37.293499999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.3666666666666667,
        "text_similarity": 0.6310129165649414,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the diagram is displayed but gives substantially incorrect timing for the 7-day notice explanation (1862\u20131874s vs the reference 1901.094\u20131909.493s), so it fails to match the key temporal facts."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says that there are two sets of 364-day timelines, when does she next discuss parents waiving the 7-day notice?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1896.915,
        "end": 1901.942
      },
      "pred_interval": {
        "start": 1902.0,
        "end": 1934.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.085000000000036,
        "end": 32.05799999999999,
        "average": 18.571500000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.4941176470588235,
        "text_similarity": 0.742491602897644,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly identifies the same two events and a nearby start time for E2, but it misstates E1's end time, claims E2 begins immediately after (ignoring the actual ~6s gap), truncates E2 much earlier than the true end of the video, and includes a minor transcription error, so it omits and contradicts key timing details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining that reevaluations cannot occur more frequently than once a year, when does she explain that they must be completed every three years?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2107.0,
        "end": 2114.469
      },
      "pred_interval": {
        "start": 2049.0,
        "end": 2057.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.0,
        "end": 57.46900000000005,
        "average": 57.734500000000025
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.6608082056045532,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the correct semantic relation and utterance content (target immediately follows anchor), but the timestamps are substantially different from the ground truth (off by ~53\u201365s), making the temporal alignment incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if there are any other questions about timelines, when does she say they are 'good for now'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2192.362,
        "end": 2131.025
      },
      "pred_interval": {
        "start": 2196.5,
        "end": 2198.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.13799999999992,
        "end": 67.47499999999991,
        "average": 35.806499999999915
      },
      "rationale_metrics": {
        "rouge_l": 0.36111111111111116,
        "text_similarity": 0.6290979981422424,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both events and their order, and E1 timing matches the reference range, but E2 timings are shifted later by about 3\u20134 seconds compared to the ground truth, so it's mostly correct but not exact."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the procedural manual, when does she introduce the Maine Unified Special Education Regulations (MUSER)?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2219.043,
        "end": 2229.826
      },
      "pred_interval": {
        "start": 2224.0,
        "end": 2228.0
      },
      "iou": 0.37095427988500757,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.95699999999988,
        "end": 1.8260000000000218,
        "average": 3.391499999999951
      },
      "rationale_metrics": {
        "rouge_l": 0.18918918918918917,
        "text_similarity": 0.6120801568031311,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the MUSER introduction and the 'once finished' relation, but the timestamps are substantially misaligned (E1 is placed ~20s later and E2 start differs by ~5s from the reference), so the temporal information is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the 'Special Education Laws and Regulations', when does the '2024-25 Professional Development Schedule' slide appear?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2361.5,
        "end": 2421.5
      },
      "pred_interval": {
        "start": 2366.0,
        "end": 2380.5
      },
      "iou": 0.24166666666666667,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.5,
        "end": 41.0,
        "average": 22.75
      },
      "rationale_metrics": {
        "rouge_l": 0.38383838383838387,
        "text_similarity": 0.7599145174026489,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the temporal relation (the schedule slide appears after the mention), but the timestamps differ substantially from the reference\u2014E1 is placed ~4\u20136s late and E2 start ~4.5s late, while E2 end is ~41s earlier than ground truth\u2014so it omits a large portion of the slide's true duration."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes encouraging viewers to reach out to them, when does the speaker say, 'I think that is it'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2490.0,
        "end": 2538.75
      },
      "gt_interval": {
        "start": 2514.0,
        "end": 2516.5
      },
      "pred_interval": {
        "start": 2520.0,
        "end": 2521.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 4.599999999999909,
        "average": 5.2999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.24528301886792453,
        "text_similarity": 0.5141894817352295,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the same utterances and the sequence (target follows the reach-out), but the timestamps are several seconds later than the reference (E1 predicted 2517.0s vs 2512.8s; E2 predicted 2520.0\u20132521.1s vs 2514.0\u20132516.5s), so it misaligns the events temporally and adds unwarranted details about a pause."
      }
    },
    {
      "question_id": "003",
      "question": "Once the main speaker finishes saying 'so thank you for being here', when does another person's voice say 'Have a great afternoon, everybody. Thank you.'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2490.0,
        "end": 2538.75
      },
      "gt_interval": {
        "start": 2534.6,
        "end": 2537.1
      },
      "pred_interval": {
        "start": 2536.6,
        "end": 2538.7
      },
      "iou": 0.12195121951219783,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 1.599999999999909,
        "average": 1.7999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.39560439560439553,
        "text_similarity": 0.6686485409736633,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the correct ordering/relation (E1 finishes before E2) but the timestamps are noticeably shifted (E1 ~2.8s late, E2 start ~2.0s late and end ~1.6s late) and it adds an unsupported detail ('female' voice); therefore it is partially correct but imprecise."
      }
    },
    {
      "question_id": "002",
      "question": "After the host introduces Stephen McKinney, when does Stephen McKinney start talking about the dramatic impact of the pandemic?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 101.9,
        "end": 107.8
      },
      "pred_interval": {
        "start": 102.0,
        "end": 109.0
      },
      "iou": 0.8169014084507045,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.09999999999999432,
        "end": 1.2000000000000028,
        "average": 0.6499999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.47368421052631576,
        "text_similarity": 0.8736211061477661,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor end and the target start and wording about the pandemic with only minor timing offsets (~1s) and an extended quote; it slightly differs on the interruption cause (muting vs background noise) and the target end time, so not a perfect match."
      }
    },
    {
      "question_id": "003",
      "question": "After Stephen McKinney mentions that social problems like child mental health pre-existed COVID-19 and were exacerbated, when does he bring up the Carers Scotland Act 2016?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 160.326,
        "end": 171.144
      },
      "pred_interval": {
        "start": 160.0,
        "end": 168.0
      },
      "iou": 0.6886216798277103,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3259999999999934,
        "end": 3.1440000000000055,
        "average": 1.7349999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.3738317757009346,
        "text_similarity": 0.8792053461074829,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor region and the start of the Carers Scotland Act 2016 segment, preserving the 'after' relation; the only issue is a small discrepancy in the target end time (168.0s vs reference 171.144s)."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states the Carers Scotland Act 2016 was published in 2018 by the Scottish Government, when does he state that the Act applies to adult and young carers?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.5,
        "end": 171.0
      },
      "pred_interval": {
        "start": 171.1,
        "end": 174.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5999999999999943,
        "end": 3.9000000000000057,
        "average": 3.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2682926829268293,
        "text_similarity": 0.7142524719238281,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the semantic relation ('immediately after') and the target content, but the anchor and target timestamps are substantially incorrect and overlap/misalign with the reference segments, so the temporal localization is wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker defines a young carer as a person under 18 with caring responsibilities, when does he provide an additional condition for defining a young carer?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 217.0,
        "end": 222.5
      },
      "pred_interval": {
        "start": 220.2,
        "end": 227.8
      },
      "iou": 0.2129629629629638,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.1999999999999886,
        "end": 5.300000000000011,
        "average": 4.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.843884289264679,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that the anchor gives the under-18 definition and the target adds a further condition, but the provided timestamps are notably shifted/longer than the ground truth (anchor ends at 216.5 vs predicted 220.2; target should be 217.0\u2013222.5 vs predicted 220.2\u2013227.8), so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker cites the 2011 census data about the age distribution of young carers in the UK, when does he mention that Scottish Government guidance acknowledges very young carers?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 236.0,
        "end": 244.5
      },
      "pred_interval": {
        "start": 238.5,
        "end": 249.2
      },
      "iou": 0.4545454545454549,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 4.699999999999989,
        "average": 3.5999999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.3595505617977528,
        "text_similarity": 0.8763424158096313,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target events and that the target follows immediately after the anchor, but the provided timestamps differ substantially from the ground truth (anchor ends later and the target starts and ends several seconds later than the reference)."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker says he just wanted to introduce the topic, when does he refer to 'invisible children'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 424.5,
        "end": 426.1
      },
      "pred_interval": {
        "start": 340.0,
        "end": 342.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 84.5,
        "end": 84.10000000000002,
        "average": 84.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.5717096924781799,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the relative order and the target phrase but the timestamps are significantly wrong (anchor predicted ~331s vs ground truth ~416s and target ~340\u2013342s vs ~424.5\u2013426.1s), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "002",
      "question": "After John says 'Many thanks, Stephen', when is the next time he speaks to introduce the next presentation?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 461.0,
        "end": 465.0
      },
      "pred_interval": {
        "start": 417.5,
        "end": 428.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.5,
        "end": 37.0,
        "average": 40.25
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195125,
        "text_similarity": 0.8172358274459839,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly identifies that John next speaks to introduce the next presentation, but the timestamps are significantly incorrect and it adds unsupported details (applause button), so it largely contradicts the reference timing information."
      }
    },
    {
      "question_id": "003",
      "question": "While Katie's first slide 'Widening the gap? The challenges for equitable music education in Scotland' is displayed, when does she mention Leo Moscardini?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 490.7,
        "end": 504.0
      },
      "pred_interval": {
        "start": 457.0,
        "end": 462.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.69999999999999,
        "end": 42.0,
        "average": 37.849999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.3132530120481927,
        "text_similarity": 0.7609977722167969,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that Katie mentions Leo Moscardini, but the provided timestamps for both the slide appearance and the mention conflict substantially with the reference, and it adds an affiliation not present in the ground truth\u2014so the answer is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes listing what the presentation will cover, when does she say 'Okay'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 526.04,
        "end": 527.9
      },
      "pred_interval": {
        "start": 532.0,
        "end": 533.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.960000000000036,
        "end": 5.100000000000023,
        "average": 5.53000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3125,
        "text_similarity": 0.6179189085960388,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that 'Okay' follows the topics list, but the timestamps are significantly off (ground truth ~526.04s vs predicted 532.2s), so it fails on precise temporal alignment."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing Case Study B, when does she begin describing Case Study C?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 561.5,
        "end": 567.5
      },
      "pred_interval": {
        "start": 568.0,
        "end": 574.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 6.5,
        "average": 6.5
      },
      "rationale_metrics": {
        "rouge_l": 0.32098765432098764,
        "text_similarity": 0.6514015793800354,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the sequence of case studies but contradicts the reference timestamps (correct E1/E2 boundary at 561.5s), giving E1 end and E2 start around 567.5\u2013568.0s, so the timing is significantly incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the number of pupils taking Advanced Higher music in Case Study A, when does she mention the number of pupils taking qualifications in Case Study B?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 627.5,
        "end": 634.2
      },
      "pred_interval": {
        "start": 634.0,
        "end": 643.0
      },
      "iou": 0.012903225806454546,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 8.799999999999955,
        "average": 7.649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.30434782608695654,
        "text_similarity": 0.8340885639190674,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that Case Study B's qualifications follow Case Study A, but the timestamps and endpoints are significantly incorrect and it introduces extra/unsubstantiated phrasing and a specific pupil number not present in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that inequality in music education was beginning in primary schools and persisting, when does she explain that the focus on performance privileges middle-class pupils?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 728.2,
        "end": 740.8
      },
      "pred_interval": {
        "start": 728.0,
        "end": 741.0
      },
      "iou": 0.9692307692307622,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.20000000000004547,
        "end": 0.20000000000004547,
        "average": 0.20000000000004547
      },
      "rationale_metrics": {
        "rouge_l": 0.34146341463414637,
        "text_similarity": 0.7037343978881836,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately conveys the temporal relation and content, with only minor rounding of timestamps (728s vs 727.7/728.2 and 741s vs 740.8), and preserves the meaning that the discussion of performance privileging middle-class pupils occurs after the prior remark."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'What this means?' is displayed, when does the speaker state that working-class, poorer households, disabled children, and those with additional support needs are effectively excluded?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 763.3,
        "end": 771.2
      },
      "pred_interval": {
        "start": 763.0,
        "end": 773.0
      },
      "iou": 0.7900000000000091,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.2999999999999545,
        "end": 1.7999999999999545,
        "average": 1.0499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.3225806451612903,
        "text_similarity": 0.8603812456130981,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the slide start and the target utterance timing and content, with the start matching exactly; it slightly overestimates the end time (773s vs 771.2s) and omits the slide's explicit end time (789.2s)."
      }
    },
    {
      "question_id": "001",
      "question": "Once Katie finishes saying 'Thanks very much', when does John begin thanking her?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 882.288,
        "end": 883.549
      },
      "pred_interval": {
        "start": 884.0,
        "end": 886.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.711999999999989,
        "end": 2.951000000000022,
        "average": 2.3315000000000055
      },
      "rationale_metrics": {
        "rouge_l": 0.24,
        "text_similarity": 0.6691620349884033,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (John speaks immediately after Katie) and gives approximate timings, but the timestamps are off by ~1\u20133 seconds (especially John's end time) and thus not precisely aligned with the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the first slide of Lindsay's presentation appears on screen, when does Lindsay begin to introduce her project?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 921.97,
        "end": 989.732
      },
      "pred_interval": {
        "start": 922.0,
        "end": 928.0
      },
      "iou": 0.08854520232578739,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.029999999999972715,
        "end": 61.73199999999997,
        "average": 30.880999999999972
      },
      "rationale_metrics": {
        "rouge_l": 0.25531914893617025,
        "text_similarity": 0.6417996883392334,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly locates E1 and the start of E2 (~922s) and notes the intervening exchange, but it significantly underestimates the end of Lindsay's introduction (predicts ~928s vs the reference 989.732s), omitting a key timing detail."
      }
    },
    {
      "question_id": "003",
      "question": "During the 'Background to study' slide, when does Lindsay state that poverty is detrimental to academic attainment?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 964.634,
        "end": 969.402
      },
      "pred_interval": {
        "start": 966.0,
        "end": 970.5
      },
      "iou": 0.5799522673031116,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3659999999999854,
        "end": 1.0979999999999563,
        "average": 1.231999999999971
      },
      "rationale_metrics": {
        "rouge_l": 0.325,
        "text_similarity": 0.8294079303741455,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately matches the key elements: the slide timing, that Lindsay's statement occurs during the slide, and the quoted content; timestamp differences are minor rounding variations only."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining the 'Study design' slide, when does she start discussing the 'Research Participants and School Profiles'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1085.64,
        "end": 1103.0
      },
      "pred_interval": {
        "start": 1085.0,
        "end": 1110.0
      },
      "iou": 0.694399999999996,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.6400000000001,
        "end": 7.0,
        "average": 3.82000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.38095238095238093,
        "text_similarity": 0.6606717109680176,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the relative order and roughly the start time of the 'Research Participants' discussion, but the end time and the earlier 'Study design' finish time are off by several seconds (E1 ~+3s, E2 end ~+7s), so it is mostly correct but not fully temporally accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the female presenter finishes speaking about the previous research, when does she transition to the 'Reflective questions' slide?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1249.4,
        "end": 1250.5
      },
      "pred_interval": {
        "start": 1246.0,
        "end": 1249.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.400000000000091,
        "end": 1.5,
        "average": 2.4500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.2686567164179105,
        "text_similarity": 0.6605896949768066,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures that the slide change occurs after the presenter finishes, but the timestamps are notably off (predicts 1246s vs gold 1242.8s for finish, and 1248s vs gold 1249.4s for slide change), it omits the transition-completion time (1250.5s), and it adds a quoted utterance not present in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the female presenter finishes talking about the reflective questions, when does the male presenter start speaking?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1272.5,
        "end": 1273.0
      },
      "pred_interval": {
        "start": 1302.0,
        "end": 1327.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.5,
        "end": 54.0,
        "average": 41.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3448275862068965,
        "text_similarity": 0.4993266761302948,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the general order (male speaks after the female) but gives incorrect absolute timings (1301/1302s vs correct 1271.0/1272.5s) and adds extraneous details about thanking/introducing and a long conclusion, so it does not match the reference. "
      }
    },
    {
      "question_id": "003",
      "question": "While the first male presenter is speaking about digital exclusion, when does he mention the conditions that education systems need to meet to be successful?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1343.9,
        "end": 1346.5
      },
      "pred_interval": {
        "start": 1405.0,
        "end": 1440.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.09999999999991,
        "end": 93.5,
        "average": 77.29999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.18421052631578944,
        "text_similarity": 0.3747459948062897,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction locates the mention much later (1405s\u20131418s+) than the correct timestamps (1343.9s\u20131346.5s) and thus contradicts the reference timing, so it is largely incorrect though on-topic."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker says 'There you go', when does the screen transition to the presentation slide with the second speaker in a small window?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1426.2,
        "end": 1426.5
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1417.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.200000000000045,
        "end": 9.5,
        "average": 10.350000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.3809523809523809,
        "text_similarity": 0.7932027578353882,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same events and correctly states the temporal relation ('after'), but the timestamps are substantially off (predicted ~1411.5\u20131417.0s vs reference 1420.0\u20131420.7s and 1426.2\u20131426.5s), so it is factually inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses how many participants experienced difficulties getting up to speed with technology and having appropriate platforms, when does he talk about the positive aspects of teachers generating vast amounts of online material?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1587.0,
        "end": 1604.0
      },
      "pred_interval": {
        "start": 1610.0,
        "end": 1620.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.0,
        "end": 16.0,
        "average": 19.5
      },
      "rationale_metrics": {
        "rouge_l": 0.20869565217391306,
        "text_similarity": 0.6334980726242065,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same topics and the 'after' relation, but the timestamps are substantially wrong (E1/E2 shifted ~35\u201340s later than the reference) and the segment boundaries do not match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker states that online lessons could be quite useful, when does he discuss gaining insights into pupils' lives and building better relationships with parents?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1637.5,
        "end": 1645.0
      },
      "pred_interval": {
        "start": 1653.0,
        "end": 1713.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.5,
        "end": 68.0,
        "average": 41.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3440860215053763,
        "text_similarity": 0.5236136317253113,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly preserves that the comment about pupils/parents follows the remark about online lessons and captures the content, but the provided timestamps are substantially incorrect and it adds an unfounded end time/invite (1713.0s), so the answer is inaccurate on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker finishes asking Kevin to pick up some stuff, when does Kevin begin to talk about the work being done to provide technology to young people?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1660.0,
        "end": 1676.0
      },
      "pred_interval": {
        "start": 1725.0,
        "end": 1733.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.0,
        "end": 57.0,
        "average": 61.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3846153846153846,
        "text_similarity": 0.5828205943107605,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the speakers and the content (Kevin discussing providing technology) and preserves the order, but the timestamps are substantially off (roughly 56\u201365 seconds later) and the E2 boundary disagrees with the ground truth, so the answer is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning digital inclusion, when does she begin discussing finances and support?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1787.8,
        "end": 1790.0
      },
      "pred_interval": {
        "start": 1791.5,
        "end": 1794.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.7000000000000455,
        "end": 4.0,
        "average": 3.8500000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.3466666666666667,
        "text_similarity": 0.6742138862609863,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction preserves the correct ordering (finances/support begin immediately after 'digital inclusion') and gives both anchor and target spans, but the timestamps are consistently ~3.5\u20134.0 seconds later than the reference, so the temporal accuracy is lacking."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces the 'Key findings' section, when does she mention parents on low incomes being more concerned about money?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1815.4,
        "end": 1829.0
      },
      "pred_interval": {
        "start": 1818.5,
        "end": 1827.0
      },
      "iou": 0.6250000000000042,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.099999999999909,
        "end": 2.0,
        "average": 2.5499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.3404255319148936,
        "text_similarity": 0.6441895961761475,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction captures the correct content and the same once_finished relation, but the timestamps are shifted by a few seconds (E1 ~1.6s late, E2 starts ~3.1s late and ends ~2s early) so it is not precisely aligned with the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that 'progress clearly being made' regarding digital inclusion, when does she mention that children on free meals are more likely to share devices?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1952.9,
        "end": 1958.5
      },
      "pred_interval": {
        "start": 1957.5,
        "end": 1963.5
      },
      "iou": 0.09433962264151025,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.599999999999909,
        "end": 5.0,
        "average": 4.7999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.325,
        "text_similarity": 0.6384643912315369,
        "llm_judge_score": 4,
        "llm_judge_justification": "The anchor timing is roughly correct, but the predicted target is shifted significantly later (1957.5\u20131963.5 vs correct 1952.9\u20131955.0), so the key temporal span is misaligned despite quoting the same line."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces 'Free meal replacements', when does she discuss the importance of choice and dignity in food provision?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2003.8,
        "end": 2010.5
      },
      "pred_interval": {
        "start": 2008.0,
        "end": 2016.0
      },
      "iou": 0.20491803278688447,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.2000000000000455,
        "end": 5.5,
        "average": 4.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.26373626373626374,
        "text_similarity": 0.5749858021736145,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly identifies E1 and E2, preserves the relation (E2 occurs after E1), and accurately captures the discussion of choice and dignity with timestamps very close to the reference (minor wording/timestamp variances do not affect correctness)."
      }
    },
    {
      "question_id": "001",
      "question": "After the female speaker mentions \"cash first approaches\", when does the male speaker begin speaking?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2167.9,
        "end": 2172.6
      },
      "pred_interval": {
        "start": 2173.0,
        "end": 2178.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.099999999999909,
        "end": 5.400000000000091,
        "average": 5.25
      },
      "rationale_metrics": {
        "rouge_l": 0.23157894736842105,
        "text_similarity": 0.697810173034668,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the male speaks immediately after the female, but its timestamps are inaccurate (predicts ~2173.0s vs the reference start 2167.9s and misstates the female segment timing) and includes an unsupported quoted utterance."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker asks Angela Japp's question about creative approaches, when does Katie start her answer by mentioning 'the digital'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.835,
        "end": 2259.242
      },
      "pred_interval": {
        "start": 2242.0,
        "end": 2247.0
      },
      "iou": 0.2136113128551274,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.164999999999964,
        "end": 12.24200000000019,
        "average": 9.203500000000076
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.8549283146858215,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies Katie saying 'And the second point about the digital' after the male speaker, but the reported timestamps are notably off (anchor and target start times differ by ~5\u20136s) and it adds that Katie first answers a different question, which contradicts the reference that the target begins immediately after the male's question."
      }
    },
    {
      "question_id": "003",
      "question": "Once Katie finishes discussing culturally valued aspects in schools, when does the male speaker thank her?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2297.355,
        "end": 2298.476
      },
      "pred_interval": {
        "start": 2302.0,
        "end": 2305.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.644999999999982,
        "end": 6.523999999999887,
        "average": 5.5844999999999345
      },
      "rationale_metrics": {
        "rouge_l": 0.34883720930232553,
        "text_similarity": 0.7500901222229004,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states the male speaker thanks immediately after Katie and quotes his line, but the provided timestamps are several seconds later than the reference, so timing accuracy is off though the semantic relation is preserved."
      }
    },
    {
      "question_id": "001",
      "question": "After John asks whether initiatives like 'Big Noise' would impact music provision generally if targeted at deprived areas, when does Alistair start speaking?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2390.458,
        "end": 2391.922
      },
      "pred_interval": {
        "start": 2392.0,
        "end": 2437.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5419999999999163,
        "end": 45.077999999999975,
        "average": 23.309999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.20454545454545459,
        "text_similarity": 0.8417900800704956,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction roughly identifies Alistair's start (~2392s) which is close to the correct 2390.46\u20132391.92s, but it misstates the anchor (E1) end time by ~18\u201326s and hallucinates a long E2 duration to 2437.0s not supported by the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After Alistair says that some programs are 'hugely expensive', when does he advise treating them with caution?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2406.7,
        "end": 2414.2
      },
      "pred_interval": {
        "start": 2408.0,
        "end": 2415.0
      },
      "iou": 0.7469879518071906,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.300000000000182,
        "end": 0.8000000000001819,
        "average": 1.050000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.650635838508606,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer accurately captures the anchor remark and the cautionary advice and even quotes the line; the predicted timestamps are slightly shifted (by ~0.3\u20131.3s) from the reference, a minor temporal adjustment without semantic error."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker states that recovery plans were produced by the Scottish and English governments, when does he explain what those recovery plans are about?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2499.117,
        "end": 2513.724
      },
      "pred_interval": {
        "start": 2503.0,
        "end": 2517.0
      },
      "iou": 0.5996756696303905,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.882999999999811,
        "end": 3.27599999999984,
        "average": 3.5794999999998254
      },
      "rationale_metrics": {
        "rouge_l": 0.2280701754385965,
        "text_similarity": 0.4915355443954468,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the timestamps and largely misrepresents the content: it invents a pandemic-preparedness description and a later \u2018forgotten documents\u2019 shift, whereas the reference pinpoints a different start/end and mentions parents and carers; only the general idea that an explanation follows is correct."
      }
    },
    {
      "question_id": "002",
      "question": "After Sarah mentions that digital literacy for parents wasn't something they specifically looked at, when does she explain the challenges parents faced with remote learning?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2558.855,
        "end": 2578.0
      },
      "pred_interval": {
        "start": 2557.0,
        "end": 2581.0
      },
      "iou": 0.7977083333333326,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.8550000000000182,
        "end": 3.0,
        "average": 2.427500000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.24719101123595505,
        "text_similarity": 0.27651822566986084,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the segment about parental digital challenges and device sharing, but it misstates key timestamps (E1 end and E2 start/end differ from the reference) and adds an extra detail about working while managing a household that the correct answer does not specify."
      }
    },
    {
      "question_id": "001",
      "question": "After the male host mentions a question from Katharine Reid, when does Sarah laugh?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.86,
        "end": 2741.43
      },
      "pred_interval": {
        "start": 2788.0,
        "end": 2789.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.13999999999987,
        "end": 48.070000000000164,
        "average": 47.60500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.21333333333333332,
        "text_similarity": 0.6090497970581055,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction largely contradicts the reference: event times are off by ~60s and the anchor content differs (no mention of Katharine Reid), though both state Sarah laughs after the host; therefore it is mostly incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes saying 'Yes', when does she begin to explain how more money for families leads to better outcomes for children?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.15,
        "end": 2772.16
      },
      "pred_interval": {
        "start": 2791.0,
        "end": 2796.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.84999999999991,
        "end": 23.840000000000146,
        "average": 35.34500000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.1917808219178082,
        "text_similarity": 0.5527499318122864,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the relation (explanation begins shortly after 'Yes') and identifies a start of substantive talk, but the anchor and target timestamps are substantially off from the reference (errors of ~24\u201347s) and it adds unverified/intervening details, so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "Once the male host mentions people working in rural areas, when does he ask Lindsay for her thoughts?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2828.315,
        "end": 2829.617
      },
      "pred_interval": {
        "start": 2872.0,
        "end": 2879.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.684999999999945,
        "end": 49.38299999999981,
        "average": 46.53399999999988
      },
      "rationale_metrics": {
        "rouge_l": 0.2380952380952381,
        "text_similarity": 0.5250460505485535,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the ordering (E2 follows immediately after E1) and the content of the question, but the timestamps are substantially off (~44s later) and the end time/duration of E2 is inaccurately reported, so it is largely incorrect on temporal alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman states that all schools must be very mindful to poverty-proof themselves, when does she mention that teaching pedagogies and strategies should be transparent and inclusive?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2858.72,
        "end": 2868.63
      },
      "pred_interval": {
        "start": 2861.0,
        "end": 2868.0
      },
      "iou": 0.7063572149343876,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 2.2800000000002,
        "end": 0.6300000000001091,
        "average": 1.4550000000001546
      },
      "rationale_metrics": {
        "rouge_l": 0.3466666666666666,
        "text_similarity": 0.689477801322937,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target events and the temporal order, with only small timing offsets (anchor ~1\u20132s later, target start ~2.3s later and end ~0.6s earlier) and it uses 'after' rather than the finer 'immediately follows' phrasing."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman suggests giving probationers and undergraduates more practical tools before they go into probation, when does she say that a lot can be learned from autism education?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2896.13,
        "end": 2901.89
      },
      "pred_interval": {
        "start": 2898.0,
        "end": 2902.0
      },
      "iou": 0.662691652470178,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.8699999999998909,
        "end": 0.11000000000012733,
        "average": 0.9900000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.24444444444444446,
        "text_similarity": 0.6006432175636292,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately identifies the same anchor and target events, preserves the quoted target wording, and correctly labels the temporal relation as 'after'; the minor timestamp differences are within acceptable tolerance."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man reminds people about the PACT project launch, when does he describe it as a professional learning project funded by the Scottish Government?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2951.199,
        "end": 2960.769
      },
      "pred_interval": {
        "start": 2952.0,
        "end": 2956.0
      },
      "iou": 0.4179728317659479,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8009999999999309,
        "end": 4.768999999999778,
        "average": 2.7849999999998545
      },
      "rationale_metrics": {
        "rouge_l": 0.2597402597402597,
        "text_similarity": 0.7442580461502075,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor within the reference anchor interval and locates the target within the reference target interval, including the key phrasing and the 'after' relationship; minor temporal inaccuracies (predicted target end is earlier than the reference end) account for a small deduction."
      }
    },
    {
      "question_id": "001",
      "question": "Once the first speaker puts in an advert for John McKendrick, when does he praise the work of the Caledonian Club?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3049.4,
        "end": 3053.3
      },
      "pred_interval": {
        "start": 3051.5,
        "end": 3065.0
      },
      "iou": 0.11538461538462771,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.099999999999909,
        "end": 11.699999999999818,
        "average": 6.899999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.3414634146341463,
        "text_similarity": 0.8146365880966187,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the advert then a praise of the Caledonian Club, but the timing is substantially off: E1 time is roughly close, but E2 is reported ~2s later to start and extends ~12s later than the reference, failing the immediate 'once_finished' relation and misaligning the end boundary."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker finishes asking Mary a question, when does the second speaker (John) appear and begin to speak?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3079.0,
        "end": 3082.0
      },
      "pred_interval": {
        "start": 3080.0,
        "end": 3090.0
      },
      "iou": 0.18181818181818182,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 8.0,
        "average": 4.5
      },
      "rationale_metrics": {
        "rouge_l": 0.33766233766233766,
        "text_similarity": 0.7193458080291748,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly reflects that John speaks after the first speaker, but it gives incorrect timestamps (E1/E2 ~1\u20131.6s later than the reference), omits the reported completion time for John's initial sentence, and introduces specific quoted dialogue not present in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After Mary finishes discussing how to best support students, when does John appear on screen and comment on her questions?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3152.3,
        "end": 3159.5
      },
      "pred_interval": {
        "start": 3188.5,
        "end": 3208.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.19999999999982,
        "end": 49.0,
        "average": 42.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.6825543642044067,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same two events but the timestamps are substantially off (differences of ~36\u201349s) and it places E1 and E2 simultaneously rather than John appearing after Mary as in the reference; it also adds quoted phrases not present in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the first speaker asks if something happened and how it is going, when does he state that he will put the question to the Glasgow team first?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3213.51,
        "end": 3214.09
      },
      "pred_interval": {
        "start": 3217.0,
        "end": 3219.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.4899999999997817,
        "end": 4.9099999999998545,
        "average": 4.199999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.1686746987951807,
        "text_similarity": 0.6945886611938477,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the order and that the second utterance follows the first, but the provided timestamps are substantially shifted and inaccurate (target start/end times are several seconds later than the ground truth), so it fails to match the key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker with the beard begins speaking, when does he mention the rollout of 50,000 plus iPads?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3232.12,
        "end": 3237.0
      },
      "pred_interval": {
        "start": 3238.0,
        "end": 3241.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.880000000000109,
        "end": 4.0,
        "average": 4.940000000000055
      },
      "rationale_metrics": {
        "rouge_l": 0.24390243902439024,
        "text_similarity": 0.5522743463516235,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target utterances and the 'after' relation, but the provided timestamps are several seconds off from the reference ranges, reducing temporal accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman states that getting information out to all families about support is available, when does she finish her statement that this is really critical?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3390.0,
        "end": 3482.1099999999997
      },
      "gt_interval": {
        "start": 3396.5,
        "end": 3398.0
      },
      "pred_interval": {
        "start": 3401.3,
        "end": 3403.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.800000000000182,
        "end": 5.900000000000091,
        "average": 5.350000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.1951219512195122,
        "text_similarity": 0.5822411775588989,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the order and similar phrasing but the timestamps are substantially misaligned (E1 predicted ~3401.2s vs correct 3391.0s; E2 predicted 3401.3\u20133403.9s vs correct 3396.5\u20133398.0s) and the relation timing ('immediately after') differs from the reference, so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the man states that the presenters were exemplary in their timekeeping, when does he continue to say he will be exemplary in his timekeeping?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3390.0,
        "end": 3482.1099999999997
      },
      "gt_interval": {
        "start": 3427.0,
        "end": 3431.0
      },
      "pred_interval": {
        "start": 3432.4,
        "end": 3434.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.400000000000091,
        "end": 3.800000000000182,
        "average": 4.600000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.1839080459770115,
        "text_similarity": 0.4932689368724823,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that the speaker about his own timekeeping follows the remark about the presenters, but the reported timestamps are significantly inaccurate (predicted ~3432\u20133434.8s vs correct 3423.7\u20133431.0s) and durations are off, so the answer is factually incorrect despite matching the sequence."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks to virtually clap, when does he physically clap his hands?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3390.0,
        "end": 3482.1099999999997
      },
      "gt_interval": {
        "start": 3476.0,
        "end": 3478.0
      },
      "pred_interval": {
        "start": 3481.3,
        "end": 3481.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.300000000000182,
        "end": 3.900000000000091,
        "average": 4.600000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.22499999999999998,
        "text_similarity": 0.7251806259155273,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the events and the 'after' relation and matches the verbal cue, but the timestamps are shifted several seconds from the reference (E1 is placed after the annotated finish time and E2 is ~3\u20135s later), so it misses the precise timing details."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the 'Strategic Priority 3' slide is displayed, when does the speaker mention the Alliance's 2021 to 2025 strategy?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.0,
        "end": 27.7
      },
      "pred_interval": {
        "start": 24.0,
        "end": 28.0
      },
      "iou": 0.6166666666666666,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 0.3000000000000007,
        "average": 1.1500000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.273972602739726,
        "text_similarity": 0.4308928847312927,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies that the speaker's mention (approx. 24\u201328s) occurs during the slide display and the speaker timing closely matches the reference, but it incorrectly reports the slide end time (01:16 \u2248 76s) instead of 115.5s, omitting that key detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the NFDHR logo and name are fully displayed, when does the text indicating its establishment appear?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 165.0,
        "end": 168.0
      },
      "pred_interval": {
        "start": 166.0,
        "end": 176.0
      },
      "iou": 0.18181818181818182,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 8.0,
        "average": 4.5
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.7671946287155151,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly places E1 around 160\u2013162s and E2 after E1 (starts at 166s), which is close to the ground truth (E2 start 165s); it omits the precise 'fully visible by 168s' detail and adds an end time not specified in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the statistics for Education, Food Security, and Health & Nutrition programs are fully displayed, when do the statistics for WASH, Peace Building, Protection & Gender, and Shelter & CCCM programs appear?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 211.0
      },
      "pred_interval": {
        "start": 205.0,
        "end": 216.0
      },
      "iou": 0.36363636363636365,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 5.0,
        "average": 3.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23157894736842105,
        "text_similarity": 0.6345566511154175,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies two events (E1 and E2) and their order, but the timestamps conflict with the reference (E1 given as ending at 204s vs 200s; E2 start at 205s vs 207s) and it adds an unsupported end time (216s) while omitting the stated 'once_finished' relation; these factual discrepancies and the hallucinated timing warrant a low score."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the main descriptive text for the 'Education Overview 2022' slide, when do the icons and numerical statistics appear?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 237.0,
        "end": 243.0
      },
      "pred_interval": {
        "start": 235.0,
        "end": 243.0
      },
      "iou": 0.75,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 2.0,
        "end": 0.0,
        "average": 1.0
      },
      "rationale_metrics": {
        "rouge_l": 0.33707865168539325,
        "text_similarity": 0.7026126980781555,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction contradicts the reference by claiming the main text fades out rather than remaining visible when E2 appears, and it gives the wrong start time for E2 (235.0s vs. 237.0s); it only correctly matches the end time (~243.0s)."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that the Syrian crisis created a fragmented society unable to benefit from its expertise, when does she mention that they started working together from 2018?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 351.3,
        "end": 364.9
      },
      "pred_interval": {
        "start": 358.0,
        "end": 361.0
      },
      "iou": 0.2205882352941182,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.699999999999989,
        "end": 3.8999999999999773,
        "average": 5.299999999999983
      },
      "rationale_metrics": {
        "rouge_l": 0.22413793103448276,
        "text_similarity": 0.5992975234985352,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the speaker mentions working together from 2018, but the provided timestamps for E2 are notably shifted later than the reference and the relation is labeled 'after' rather than the immediate 'once_finished', so timing/relation accuracy is only partial."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that 2 million Syrian children are out of education and tens of thousands are in North Syrian camps, when does she begin to list the specific numbers of camps and schools?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 418.5,
        "end": 427.8
      },
      "pred_interval": {
        "start": 421.0,
        "end": 424.0
      },
      "iou": 0.3225806451612899,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 3.8000000000000114,
        "average": 3.1500000000000057
      },
      "rationale_metrics": {
        "rouge_l": 0.2291666666666667,
        "text_similarity": 0.6249063611030579,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the listing follows the anchor statement, but the timestamps are substantially off (predicted E1/E2 at ~421.0s vs correct 418.0/418.5s) and it omits the correct E2 end time (427.8s), so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that IRC has invested a lot in research and social and emotional learning, when does she explain how these learnings can be used for out-of-school and in-school children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.0,
        "end": 568.9
      },
      "pred_interval": {
        "start": 554.0,
        "end": 573.0
      },
      "iou": 0.6772727272727262,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 4.100000000000023,
        "average": 3.5500000000000114
      },
      "rationale_metrics": {
        "rouge_l": 0.23214285714285712,
        "text_similarity": 0.6376041173934937,
        "llm_judge_score": 8,
        "llm_judge_justification": "The predicted answer correctly identifies the two segments, their immediate succession, and the target explanation content, but the provided timestamps are slightly shifted (E1 ends later and E2 starts/ends a few seconds later than the reference), so timing is not perfectly aligned."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces the PRIEST project as one of IRC's flagship programs, when does she state the countries where it is implemented?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.9,
        "end": 627.597
      },
      "pred_interval": {
        "start": 627.0,
        "end": 630.0
      },
      "iou": 0.08408450704225043,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.100000000000023,
        "end": 2.40300000000002,
        "average": 3.2515000000000214
      },
      "rationale_metrics": {
        "rouge_l": 0.3132530120481928,
        "text_similarity": 0.722954273223877,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the target content (names the countries and keeps the same order) and that the target follows the anchor, but the provided timestamps are shifted several seconds later and do not match the reference timings precisely."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces Ahlam Ahmed as the Education Programme Manager, when does Ahlam Ahmed greet the speaker?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 777.178,
        "end": 778.34
      },
      "pred_interval": {
        "start": 781.0,
        "end": 783.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.8220000000000027,
        "end": 4.659999999999968,
        "average": 4.2409999999999854
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7446047067642212,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the greeting and that it follows the introduction, but it misaligns the timestamps by several seconds, downgrades 'immediately after' to merely 'after', and introduces an extra moderator utterance not present in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After Ahlam Ahmed asks for the next slide, when does the slide visually change to 'Session Objectives'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 867.576,
        "end": 869.038
      },
      "pred_interval": {
        "start": 869.5,
        "end": 871.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.9239999999999782,
        "end": 2.461999999999989,
        "average": 2.1929999999999836
      },
      "rationale_metrics": {
        "rouge_l": 0.34210526315789475,
        "text_similarity": 0.7405171394348145,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the same two events and their temporal relation ('after'), but the provided timestamps differ noticeably from the reference intervals (E1 is placed later and E2 slightly later), so it's mostly correct but not exact."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker asks to move to the next slide, when does the slide visually change?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 962.9,
        "end": 963.4
      },
      "pred_interval": {
        "start": 967.5,
        "end": 968.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.600000000000023,
        "end": 5.100000000000023,
        "average": 4.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5228831768035889,
        "llm_judge_score": 2,
        "llm_judge_justification": "While both say the slide changes immediately after the request, the predicted timestamps are off by about 4\u20136 seconds and misstate the request/end times, so it largely disagrees with the ground-truth timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states the project's duration and donor, when does she mention the number of targeted children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1031.1,
        "end": 1039.3
      },
      "pred_interval": {
        "start": 1066.0,
        "end": 1069.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.90000000000009,
        "end": 29.700000000000045,
        "average": 32.30000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.22695989906787872,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the relative ordering (target follows the anchor) but gives substantially incorrect absolute timestamps (\u22481065\u20131069s vs correct 1029.1\u20131039.3s) and adds unverified detail, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions 'with ALP classrooms', when does she begin to introduce 'the second activity or the second intervention'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1104.5,
        "end": 1109.5
      },
      "pred_interval": {
        "start": 1104.7,
        "end": 1108.6
      },
      "iou": 0.7799999999999727,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.20000000000004547,
        "end": 0.900000000000091,
        "average": 0.5500000000000682
      },
      "rationale_metrics": {
        "rouge_l": 0.10256410256410256,
        "text_similarity": 0.41493141651153564,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer matches the reference closely: the target interval (\u22481104.5\u20131109.5s) is accurately captured and the temporal relation 'after' is preserved. The only minor discrepancy is the anchor time (predicted \u22481053s vs reference end 1054.5s), which is a small timing difference that does not materially affect the relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes talking about 'on the safe school protocols', when does she describe how 'Temporary learning spaces will also be provided with wash facilities and essential cleaning hygiene materials'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1138.5,
        "end": 1148.0
      },
      "pred_interval": {
        "start": 1138.3,
        "end": 1148.2
      },
      "iou": 0.9595959595959508,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.20000000000004547,
        "end": 0.20000000000004547,
        "average": 0.20000000000004547
      },
      "rationale_metrics": {
        "rouge_l": 0.3736263736263737,
        "text_similarity": 0.5849764943122864,
        "llm_judge_score": 9,
        "llm_judge_justification": "Prediction correctly identifies the target utterance, its start/end times, and the 'after' relation; only minor timing discrepancies (anchor 1104s vs 1102.5s) warrant a slight deduction."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions community sensitization, when does she describe the creation of a community-based support system for children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1246.823,
        "end": 1274.838
      },
      "pred_interval": {
        "start": 1267.0,
        "end": 1274.0
      },
      "iou": 0.249866143137606,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.176999999999907,
        "end": 0.8379999999999654,
        "average": 10.507499999999936
      },
      "rationale_metrics": {
        "rouge_l": 0.4050632911392405,
        "text_similarity": 0.8032186031341553,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly locates the anchor roughly and that the target follows it, but the predicted target start (1267.0s) is about 20s later than the ground truth (1246.823s), omitting a large portion of the target segment; the end time is close."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning integration into the formal learning system, when does she state the overall objective of the program?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1339.066,
        "end": 1350.221
      },
      "pred_interval": {
        "start": 1340.0,
        "end": 1351.0
      },
      "iou": 0.8564605329311237,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.9339999999999691,
        "end": 0.7789999999999964,
        "average": 0.8564999999999827
      },
      "rationale_metrics": {
        "rouge_l": 0.2564102564102564,
        "text_similarity": 0.7662649154663086,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer accurately identifies the same anchor and target segments and preserves the stated objective, with only minor timing offsets (under ~1s) compared to the reference timestamps, so it is essentially correct."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing school referrals and observation capacity, when does she mention that guidelines for pathways and referral will be revised?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1389.248,
        "end": 1400.984
      },
      "pred_interval": {
        "start": 1390.0,
        "end": 1402.0
      },
      "iou": 0.8613550815558316,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.7519999999999527,
        "end": 1.0160000000000764,
        "average": 0.8840000000000146
      },
      "rationale_metrics": {
        "rouge_l": 0.3116883116883117,
        "text_similarity": 0.7460561990737915,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target segments and their ordering, with only minor timing offsets (~0.7\u20131.1s) and one small extra detail about 'training packages' not present in the reference; overall the meaning and timing align closely."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker finishes mentioning case management and referral pathways, when does she start listing additional skills training in the capacity building package?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1471.0,
        "end": 1480.5
      },
      "pred_interval": {
        "start": 1470.0,
        "end": 1478.0
      },
      "iou": 0.6666666666666666,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 2.5,
        "average": 1.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3294117647058824,
        "text_similarity": 0.7759062051773071,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the ordering ('after') and the listed items, but the timestamps are slightly off (E1 about 1.8s early; E2 start ~1s early and end ~2.5s early), causing a minor temporal misalignment with the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the first speaker finishes confirming the handover to the next presenter, when does the second speaker begin introducing Sundas?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.0,
        "end": 1574.5
      },
      "pred_interval": {
        "start": 1520.0,
        "end": 1533.0
      },
      "iou": 0.1834862385321101,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 41.5,
        "average": 22.25
      },
      "rationale_metrics": {
        "rouge_l": 0.22857142857142856,
        "text_similarity": 0.7174354791641235,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction matches the overall 'after' relationship and approximates the start times, but it significantly misstates the end time (1533.0s vs 1574.5s) and omits the key detail about the title mention, plus it introduces an unverified thank-you remark\u2014a substantial factual omission/error."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker says \"Yeah, next slide, please\" for the first time, when does the green box with the English text for the \"Commitment indicator\" appear on screen?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1634.9,
        "end": 1720.9
      },
      "pred_interval": {
        "start": 1604.0,
        "end": 1610.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.90000000000009,
        "end": 110.90000000000009,
        "average": 70.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.3418803418803419,
        "text_similarity": 0.6636034250259399,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events and that the green box appears after the verbal cue, but the timestamps and duration are substantially off (about 28\u201331 seconds earlier and far shorter than the reference), so it is mostly incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the male speaker finishes asking to move to the next slide, when does the slide actually change?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1785.53,
        "end": 1785.6
      },
      "pred_interval": {
        "start": 1786.9,
        "end": 1787.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3700000000001182,
        "end": 1.6000000000001364,
        "average": 1.4850000000001273
      },
      "rationale_metrics": {
        "rouge_l": 0.2903225806451613,
        "text_similarity": 0.6539773344993591,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the correct ordering (slide changes after the request) but the timestamps are substantially off (~4\u20135 seconds later than the ground truth) and it omits the precise start vs completion timing of the visual transition."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the child's achievement in the first case study, when does she ask for the next slide?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1909.926,
        "end": 1911.04
      },
      "pred_interval": {
        "start": 1913.4,
        "end": 1914.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.47400000000016,
        "end": 3.5599999999999454,
        "average": 3.5170000000000528
      },
      "rationale_metrics": {
        "rouge_l": 0.2898550724637681,
        "text_similarity": 0.5307978391647339,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the event ordering (ask occurs after finish) but the timestamps are off by ~3\u20134 seconds and it adds a likely incorrect detail about switching to English; thus it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks for the next slide, when does the slide transition to the domestic violence case study?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1915.72,
        "end": 1921.8
      },
      "pred_interval": {
        "start": 1914.8,
        "end": 1915.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.9200000000000728,
        "end": 6.7000000000000455,
        "average": 3.810000000000059
      },
      "rationale_metrics": {
        "rouge_l": 0.38095238095238093,
        "text_similarity": 0.6606528162956238,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly links the slide change to after the speaker's request but gives an inaccurate timestamp for the slide transition (1914.8s vs the reference start 1915.72s) and omits the completion time (by 1921.8s); the speaker end time is slightly off as well."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes her detailed explanation of how they help children facing domestic violence, when does she say 'Next slide'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2003.389,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 1958.4,
        "end": 1959.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.988999999999805,
        "end": 44.90000000000009,
        "average": 44.94449999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.18666666666666665,
        "text_similarity": 0.4861219525337219,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates 'Next slide' occurs after the speaker's explanation, but the timestamps are off by ~45 seconds and it introduces unverified details (language switch and handing to Sundus), so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the Arabic speaker (Sundus) finishes her conclusion about the link between protection and education, when does the English speaker thank her?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2072.045,
        "end": 2076.5
      },
      "pred_interval": {
        "start": 2106.0,
        "end": 2107.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.95499999999993,
        "end": 31.0,
        "average": 32.477499999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.44690194725990295,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: the timestamps are ~34s later than the reference and the thank-you interval is much shorter; it also omits that the English speaker thanks both Sundus and Sahar. These substantial temporal and content mismatches warrant a very low score."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the PEACE project as a multi-country project in Nigeria, Cameroon, and Niger, when does he specify the states in Nigeria where it is implemented?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2211.28,
        "end": 2223.708
      },
      "pred_interval": {
        "start": 2221.0,
        "end": 2224.0
      },
      "iou": 0.2128930817610162,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.7199999999998,
        "end": 0.2919999999999163,
        "average": 5.005999999999858
      },
      "rationale_metrics": {
        "rouge_l": 0.22,
        "text_similarity": 0.751075029373169,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the three Nigerian states (Borno, Adamawa, Yobe) and places this mention after the project introduction, with timestamping very close to the reference interval; the slight ~0.3s end-time discrepancy is minor."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker states that the project has three main results, when does he begin describing the first result, 'Access'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2250.478,
        "end": 2262.09
      },
      "pred_interval": {
        "start": 2250.0,
        "end": 2263.0
      },
      "iou": 0.8932307692307754,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.4780000000000655,
        "end": 0.9099999999998545,
        "average": 0.69399999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.2653061224489796,
        "text_similarity": 0.5718199014663696,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states that Result 1 begins immediately after the anchor at about 2250s and lasts until ~2262\u20132263s; only minor rounding discrepancies (~0.5\u20130.9s) and an inconsistent mm:ss labeling prevent a perfect match."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the 'Accelerated Learning Program' for children who are out of school, when does he specify the age range of these children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2337.405,
        "end": 2348.025
      },
      "pred_interval": {
        "start": 2337.0,
        "end": 2340.0
      },
      "iou": 0.23537414965984385,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.4050000000002001,
        "end": 8.025000000000091,
        "average": 4.2150000000001455
      },
      "rationale_metrics": {
        "rouge_l": 0.3302752293577982,
        "text_similarity": 0.6294074654579163,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the age range and roughly the start (~2337s) but misstates the anchor timing, gives an incorrect/too-early end time (03:30/2340s vs 2348.025s), and inconsistently mixes mm:ss with seconds, including a false claim that the video concludes at 03:30."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker transitions to discussing Result 2, when does he mention 'Parenting Sessions'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.824,
        "end": 2369.824
      },
      "pred_interval": {
        "start": 2370.0,
        "end": 2372.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.1759999999999309,
        "end": 2.175999999999931,
        "average": 1.6759999999999309
      },
      "rationale_metrics": {
        "rouge_l": 0.12121212121212122,
        "text_similarity": 0.5189939737319946,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the anchor within the reference interval and the target occurs after the anchor as stated, but the predicted E2 timing is slightly shifted later and its duration differs from the ground truth by about 0.2\u20132.2 seconds."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"Next slide,\" when does he begin asking about integrating child protection and education activities?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2755.7,
        "end": 2766.6
      },
      "pred_interval": {
        "start": 2758.0,
        "end": 2770.0
      },
      "iou": 0.6013986013985874,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.300000000000182,
        "end": 3.400000000000091,
        "average": 2.8500000000001364
      },
      "rationale_metrics": {
        "rouge_l": 0.325,
        "text_similarity": 0.7392160296440125,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies both events and that the question follows the 'Next slide' prompt, but the timestamps are shifted later by ~2\u20135 seconds and the relation 'after' is a less precise phrasing than the ground-truth 'once_finished.'"
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker (Kunja) finishes explaining that child protection activities require more funding, when does Amanda thank him?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2899.8,
        "end": 2900.8
      },
      "pred_interval": {
        "start": 2902.0,
        "end": 2904.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.199999999999818,
        "end": 3.199999999999818,
        "average": 2.699999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.3582089552238806,
        "text_similarity": 0.7776591777801514,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies both speakers and the 'after' relation, but the event timestamps are several seconds off from the ground truth and it adds an unverified quote for Kunja, causing significant temporal/factual mismatch."
      }
    },
    {
      "question_id": "002",
      "question": "Once Amanda finishes introducing Mike and hands over to him, when does Mike thank Amanda?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2938.9,
        "end": 2940.5
      },
      "pred_interval": {
        "start": 2942.0,
        "end": 2944.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.099999999999909,
        "end": 3.5,
        "average": 3.2999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.39506172839506176,
        "text_similarity": 0.7684977054595947,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction preserves the key relation and quoted phrase (Mike thanking Amanda) and maintains correct ordering, but the absolute timestamps for both events differ by several seconds from the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "While the male speaker introduces the first question about project findings, when does he ask the panelists to be brief?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3039.0,
        "end": 3046.5
      },
      "pred_interval": {
        "start": 3043.0,
        "end": 3050.0
      },
      "iou": 0.3181818181818182,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 3.5,
        "average": 3.75
      },
      "rationale_metrics": {
        "rouge_l": 0.23214285714285712,
        "text_similarity": 0.6592335104942322,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the target as occurring during the introductory remarks and its interval partially overlaps the reference E2, but it gives incorrect/contradictory timestamps (misplaces E1 at the start of the video and shifts/extends E2) and adds extraneous quoted wording not in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker thanks Ahlam for her input, when does he introduce Sundus?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3153.0,
        "end": 3159.0
      },
      "pred_interval": {
        "start": 3157.0,
        "end": 3164.0
      },
      "iou": 0.18181818181818182,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 5.0,
        "average": 4.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3061224489795918,
        "text_similarity": 0.7914727926254272,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that Sundus is introduced immediately after the speaker's thank-you/commentary and gives a time window near the reference, but the provided timestamps are several seconds off, contain inconsistent mm:ss\u2192absolute mappings, and include unsupported quoted phrasing."
      }
    },
    {
      "question_id": "003",
      "question": "After Sundus finishes speaking in Arabic, when does Paul ask 'Can you say that again?'",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3234.7,
        "end": 3235.7
      },
      "pred_interval": {
        "start": 3238.0,
        "end": 3240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.300000000000182,
        "end": 4.300000000000182,
        "average": 3.800000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.2826086956521739,
        "text_similarity": 0.8429805040359497,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that Paul\u2019s question occurs after Sundus finishes and after a male introduction, but it gives incorrect/shifted timestamps for E2 (predicted 3238\u20133240s vs correct 3234.7\u20133235.7s) and is imprecise about the anchor timing and speaker labeling, so it only partially matches the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After Sundus finishes speaking, when does Mike thank her for her input?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3217.7,
        "end": 3221.9
      },
      "pred_interval": {
        "start": 3223.0,
        "end": 3227.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.300000000000182,
        "end": 5.099999999999909,
        "average": 5.2000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.4444444444444444,
        "text_similarity": 0.7853227853775024,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction preserves the correct temporal relation ('after') and gives start/end times, but the timestamps are shifted by about 5\u20137 seconds relative to the ground truth, so the timing is significantly inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After Mike asks Paul to share a main finding from his project, when does Paul ask Mike to repeat the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3234.3,
        "end": 3235.5
      },
      "pred_interval": {
        "start": 3239.0,
        "end": 3242.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.699999999999818,
        "end": 6.5,
        "average": 5.599999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.5066666666666667,
        "text_similarity": 0.7797468900680542,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that Paul asks to repeat and that the temporal relation is 'after', but the provided timestamps are substantially off from the ground truth (E1 end and E2 start/end differ by several seconds and durations do not match), so the answer is inaccurate on key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "Once Paul finishes explaining how the integrated approach helps children, when does Mike thank him for his insights?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3306.5,
        "end": 3307.4
      },
      "pred_interval": {
        "start": 3311.0,
        "end": 3323.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.5,
        "end": 15.599999999999909,
        "average": 10.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.3488372093023256,
        "text_similarity": 0.7016767263412476,
        "llm_judge_score": 3,
        "llm_judge_justification": "While the predicted answer correctly captures the temporal relation ('once_finished') and that Mike thanks Paul immediately after, the timestamps and durations are significantly off from the ground truth (predicted E1/E2 times and E2 length contradict the reference), so the prediction is largely incorrect on timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once Sarah finishes explaining that multi-year programs allow for transition and protection support, when does she mention Niger's innovation of a cash intervention?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3520.695,
        "end": 3536.3
      },
      "pred_interval": {
        "start": 3521.0,
        "end": 3534.0
      },
      "iou": 0.8330663248958657,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.3049999999998363,
        "end": 2.300000000000182,
        "average": 1.302500000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.4096385542168675,
        "text_similarity": 0.8941586017608643,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer matches the reference both semantically and temporally with only minor rounding differences (fractions of seconds to ~2.3s) and no factual discrepancies."
      }
    },
    {
      "question_id": "001",
      "question": "After Ahlam states that the first lesson involves integrating child protection with educational activities, when does she explain how child protection creates a safe environment for children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3626.1,
        "end": 3634.8
      },
      "pred_interval": {
        "start": 3628.0,
        "end": 3637.0
      },
      "iou": 0.6238532110091858,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.900000000000091,
        "end": 2.199999999999818,
        "average": 2.0499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.26804123711340205,
        "text_similarity": 0.7126049995422363,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events, their semantic content, and the 'after' relation; timings are close (E1 ~3613s falls within the reference interval, E2 start is within range) but the predicted E2 end is ~2.2s later than the reference and E1 is given as a single timestamp, so a small precision penalty is warranted."
      }
    },
    {
      "question_id": "002",
      "question": "Once Ahlam finishes speaking and says 'Thanks Mike. Over to you.', when does the host thank Ahlam for her insights?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3679.3,
        "end": 3687.5
      },
      "pred_interval": {
        "start": 3676.0,
        "end": 3686.0
      },
      "iou": 0.5826086956521581,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.300000000000182,
        "end": 1.5,
        "average": 2.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.2758620689655173,
        "text_similarity": 0.6969373822212219,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction gets the relation and semantic content right (host thanks Ahlam), but the event time boundaries are noticeably inaccurate (E1 end and E2 start/end differ by several seconds from the reference), so the timing information is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks Sundus about the lessons learned from the monitoring system in Northern Syria, when does Sundus provide her initial lessons learned?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3704.2,
        "end": 3724.0
      },
      "pred_interval": {
        "start": 3702.0,
        "end": 3718.0
      },
      "iou": 0.6272727272727355,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.199999999999818,
        "end": 6.0,
        "average": 4.099999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.22857142857142856,
        "text_similarity": 0.6527048349380493,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relation and gives approximate timestamps for E1 and E2, but the timestamps deviate from the reference (E1 end ~2.6s early, E2 start ~2.2s early and E2 end ~6s early) and it adds content detail not present in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sundus finishes asking Mike to repeat the question, when does Mike start repeating the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3785.8,
        "end": 3796.2
      },
      "pred_interval": {
        "start": 3785.0,
        "end": 3803.0
      },
      "iou": 0.5777777777777575,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8000000000001819,
        "end": 6.800000000000182,
        "average": 3.800000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.3516483516483517,
        "text_similarity": 0.7852654457092285,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that Mike begins repeating immediately after Sundus, but the timestamps conflict with the reference: E1 is 2.3s later than the ground truth, E2 starts ~0.8s earlier and ends ~6.8s later than the cited end (3796.2s). These timing discrepancies make the answer only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After Sundus finishes providing her answer, when does Mike thank her for her input?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3851.7,
        "end": 3853.6
      },
      "pred_interval": {
        "start": 3853.0,
        "end": 3857.0
      },
      "iou": 0.11320754716979027,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.300000000000182,
        "end": 3.400000000000091,
        "average": 2.3500000000001364
      },
      "rationale_metrics": {
        "rouge_l": 0.45714285714285713,
        "text_similarity": 0.8018093109130859,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that Mike thanks Sundus after she finishes, but the timestamps are noticeably off (E1 off by ~2.6s; E2 start off by ~1.3s and end by ~3.4s), and the predicted timing/duration therefore does not align precisely with the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After Mike says he will ask Ahlam the same question, when does Ahlam ask for clarification on the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3864.0,
        "end": 3872.7
      },
      "pred_interval": {
        "start": 3866.0,
        "end": 3875.0
      },
      "iou": 0.6090909090908926,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 2.300000000000182,
        "average": 2.150000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.41025641025641024,
        "text_similarity": 0.7505504488945007,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the sequence and that Ahlam asks for clarification after Mike, but the timestamps differ notably (E1 ~5s late, E2 start/end ~2s late) and it adds unverified details (e.g., 'offering to repeat', 'silence follows'), so it is partially accurate but imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman in the bottom left finishes explaining how all staff were working together, when does the male host in the top left thank Ahlam?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3937.666,
        "end": 3939.047
      },
      "pred_interval": {
        "start": 3940.5,
        "end": 3942.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.8339999999998327,
        "end": 3.4529999999999745,
        "average": 3.1434999999999036
      },
      "rationale_metrics": {
        "rouge_l": 0.1694915254237288,
        "text_similarity": 0.6091316938400269,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same event (the host thanking Ahlam) but the timestamps are several seconds off: Ahlam actually ends at 3935.823s and the thanks occurs 3937.666\u20133939.047s, whereas the prediction places both ~4\u20135s later, so it is largely temporally incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male host finishes asking what type of evidence ECHO asked for, when does the female speaker (Sarah) in the top middle-right start to respond?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3981.063,
        "end": 3984.022
      },
      "pred_interval": {
        "start": 3984.5,
        "end": 3987.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.436999999999898,
        "end": 3.4780000000000655,
        "average": 3.457499999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.2571428571428572,
        "text_similarity": 0.522050142288208,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misreports both timestamps (host end and Sarah start) and relocates Sarah's response much later than the ground truth, even adding a quoted phrase not in the reference; it captures only that Sarah responds after the host but is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once Paul finishes explaining how learning is put into action and fits into different contexts, when does he say 'Thank you'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 4068.612,
        "end": 4069.152
      },
      "pred_interval": {
        "start": 4072.0,
        "end": 4073.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.38799999999992,
        "end": 3.8479999999999563,
        "average": 3.617999999999938
      },
      "rationale_metrics": {
        "rouge_l": 0.2807017543859649,
        "text_similarity": 0.6120641231536865,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates 'Thank you' occurs immediately after the explanation, but the provided timestamps (4072.0\u20134073.0s) do not match the ground truth (4068.612\u20134069.152s) and thus are factually incorrect. The timing and duration errors make the answer largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host says \"go ahead Paul, sorry\", when does Paul begin his response?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4123.162,
        "end": 4123.743
      },
      "pred_interval": {
        "start": 4127.0,
        "end": 4131.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.837999999999738,
        "end": 7.256999999999607,
        "average": 5.547499999999673
      },
      "rationale_metrics": {
        "rouge_l": 0.225,
        "text_similarity": 0.7972708940505981,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (Paul speaks immediately after the host), but the timestamps are offset by about 4 seconds from the reference and it introduces a quoted utterance not present in the ground truth, so the answer is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "Once Paul finishes his feedback and says \"Thank you\", when does the host respond?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4179.089,
        "end": 4183.52
      },
      "pred_interval": {
        "start": 4183.0,
        "end": 4187.0
      },
      "iou": 0.06573126027056411,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.911000000000058,
        "end": 3.4799999999995634,
        "average": 3.695499999999811
      },
      "rationale_metrics": {
        "rouge_l": 0.4155844155844156,
        "text_similarity": 0.863060474395752,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that the host responds immediately and matches the verbal content, but the reported timestamps deviate significantly from the reference (several seconds earlier), so the timing details are inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the host explicitly says \"So thank you for that\" to Kunja, when does she transition to Lynn's question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4298.586,
        "end": 4300.0
      },
      "pred_interval": {
        "start": 4300.0,
        "end": 4304.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.41399999999976,
        "end": 4.0,
        "average": 2.70699999999988
      },
      "rationale_metrics": {
        "rouge_l": 0.4285714285714286,
        "text_similarity": 0.745667040348053,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the utterance and that the host moves to Lynn's question, but it gives inaccurate timestamps\u2014placing the end/start at 4300.0s rather than the correct ~4295.9s (E1) and ~4298.6s (E2), so timing is noticeably off."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker thanks the previous participant, when does he introduce a question from Lynn?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4296.586,
        "end": 4299.158
      },
      "pred_interval": {
        "start": 4301.0,
        "end": 4328.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.41399999999976,
        "end": 28.841999999999643,
        "average": 16.6279999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.6796045303344727,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the relation ('after') and the introduction of Lynn's question, but the timestamps are substantially off (E1 and E2 shifted several seconds later and E2 extended far beyond the reference) and it includes extra/extended text not supported by the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes reading Lynn's question, when does he ask Sundus for her opinion?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4324.216,
        "end": 4328.945
      },
      "pred_interval": {
        "start": 4329.0,
        "end": 4347.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.783999999999651,
        "end": 18.05500000000029,
        "average": 11.419499999999971
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195122,
        "text_similarity": 0.6477914452552795,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer gets the temporal relation ('after') correct but the event timestamps and durations substantially disagree with the ground truth (both E1 and E2 times are shifted and E2's end time is much later), so key factual timing details are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After Sundus finishes stating that violence is not the only challenge, when does the speaker confirm that she answered part of the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4415.375,
        "end": 4425.293
      },
      "pred_interval": {
        "start": 4423.0,
        "end": 4435.0
      },
      "iou": 0.11684076433119314,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.625,
        "end": 9.707000000000335,
        "average": 8.666000000000167
      },
      "rationale_metrics": {
        "rouge_l": 0.23809523809523808,
        "text_similarity": 0.6296727657318115,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the qualitative relation right and captures the speaker's confirmation content, but the provided timestamps are substantially shifted from the reference (E1 off by ~13s, E2 start/end off by ~8\u201310s) and include extra unverified details, so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host asks if the panelist agrees with his statement, when does Ahlam reply with 'Yes, yes, Mike'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4479.36,
        "end": 4480.3
      },
      "pred_interval": {
        "start": 4479.0,
        "end": 4481.0
      },
      "iou": 0.47000000000025466,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3599999999996726,
        "end": 0.6999999999998181,
        "average": 0.5299999999997453
      },
      "rationale_metrics": {
        "rouge_l": 0.25641025641025644,
        "text_similarity": 0.6769495010375977,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction roughly captures the events and ordering but has notable timing errors (E1 ~1.2s late, E2 start ~0.36s early and end ~0.7s late) and incorrectly implies Ahlam replied immediately at the host's finish rather than after a short delay."
      }
    },
    {
      "question_id": "001",
      "question": "After the host finishes asking who would like to answer the question, when does Paul Bagambe begin to speak?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4707.194,
        "end": 4709.296
      },
      "pred_interval": {
        "start": 4708.0,
        "end": 4710.0
      },
      "iou": 0.4618674269424334,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8059999999995853,
        "end": 0.7039999999997235,
        "average": 0.7549999999996544
      },
      "rationale_metrics": {
        "rouge_l": 0.22857142857142856,
        "text_similarity": 0.422014981508255,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly indicates Paul speaks shortly after the host, but it misstates the host's end time (\u22484707s vs 4705.662s) and slightly shifts Paul's start (4708s vs 4707.194s) while omitting the anchor's start time, so it's close but not precisely aligned."
      }
    },
    {
      "question_id": "002",
      "question": "Once Paul Bagambe mentions 'praise singers', when does he elaborate on what they do?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4717.127,
        "end": 4732.251
      },
      "pred_interval": {
        "start": 4718.0,
        "end": 4736.0
      },
      "iou": 0.7550998781328094,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.8729999999995925,
        "end": 3.7489999999997963,
        "average": 2.3109999999996944
      },
      "rationale_metrics": {
        "rouge_l": 0.2823529411764706,
        "text_similarity": 0.7521857023239136,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the sequence (elaboration follows the mention) but the timestamps are noticeably shifted and inconsistent with the reference (E1 is placed later than the correct window and E2\u2019s start/end times are several seconds off), so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the host thanks Paul, when does Sindus (woman in bottom-left video) start speaking?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4827.512,
        "end": 4830.216
      },
      "pred_interval": {
        "start": 4830.0,
        "end": 4835.0
      },
      "iou": 0.028846153846199395,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.4880000000002838,
        "end": 4.783999999999651,
        "average": 3.6359999999999673
      },
      "rationale_metrics": {
        "rouge_l": 0.393939393939394,
        "text_similarity": 0.7259446382522583,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction approximates E1 reasonably, but it places Sindus speaking ~2.5s later than the true start and introduces an unsupported detail ('Shukran Mike') and a different framing ('invitation' vs the host thanking Paul), so it is partially correct but imprecise and contains likely hallucination."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker (Sundus) finishes her concluding remarks in Arabic, when does the moderator thank her and explain the fast wrap-up session?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4897.7,
        "end": 4916.5
      },
      "pred_interval": {
        "start": 4899.0,
        "end": 4924.0
      },
      "iou": 0.6653992395437216,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.300000000000182,
        "end": 7.5,
        "average": 4.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.44061434268951416,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures that the moderator speaks immediately after Sundus (matching the 'once_finished' relation) and gives a close start time, but it has small timing discrepancies and includes extra unsupported details (the '20 seconds per panelist' rule, the final question, and the Sarah prompt time) that are not in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "During Sarah's key message, when does she mention strengthening the existing system and training teachers?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4936.0,
        "end": 4942.9
      },
      "pred_interval": {
        "start": 4936.0,
        "end": 4943.0
      },
      "iou": 0.9857142857142337,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 0.1000000000003638,
        "average": 0.0500000000001819
      },
      "rationale_metrics": {
        "rouge_l": 0.271604938271605,
        "text_similarity": 0.5909953117370605,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly identifies the key-message interval and the mention timing and relation ('during'); only negligible rounding differences in the E1 start and E2 end times are present."
      }
    },
    {
      "question_id": "001",
      "question": "After the host asks Sundus for her key takeaway message, when does Sundus begin speaking in Arabic?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 4985.7,
        "end": 5026.77
      },
      "pred_interval": {
        "start": 5026.0,
        "end": 5070.0
      },
      "iou": 0.009134045077110735,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.30000000000018,
        "end": 43.22999999999956,
        "average": 41.76499999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.375,
        "text_similarity": 0.6154108047485352,
        "llm_judge_score": 2,
        "llm_judge_justification": "While both answers agree Sundus speaks after the host, the predicted timings are substantially off (shifted ~40s later), the end time differs from the reference, and it adds unsupported details (host thanks), so it is largely factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the host thanks Paul, when does Amanda, the next speaker, start speaking?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5190.0,
        "end": 5356.2699999999995
      },
      "gt_interval": {
        "start": 5251.699,
        "end": 5254.524
      },
      "pred_interval": {
        "start": 5255.0,
        "end": 5290.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.3010000000003856,
        "end": 35.47599999999966,
        "average": 19.388500000000022
      },
      "rationale_metrics": {
        "rouge_l": 0.2077922077922078,
        "text_similarity": 0.5168654918670654,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction largely mismatches the timeline: it places the host's thank-you much later than the reference and extends Amanda's turn far beyond the annotated end; only Amanda's start time is roughly close (within a few seconds). Several key temporal facts are incorrect or contradicted."
      }
    },
    {
      "question_id": "002",
      "question": "Once Amanda says 'Over to you, David', when does David start speaking?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5190.0,
        "end": 5356.2699999999995
      },
      "gt_interval": {
        "start": 5287.087,
        "end": 5288.53
      },
      "pred_interval": {
        "start": 5291.0,
        "end": 5348.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.912999999999556,
        "end": 59.470000000000255,
        "average": 31.691499999999905
      },
      "rationale_metrics": {
        "rouge_l": 0.2077922077922078,
        "text_similarity": 0.5639580488204956,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates David speaks after Amanda, but the timestamps are off by several seconds (predicted 5290/5291s vs actual ~5286.8/5287.1s), it greatly overstates David's speech duration (ends at 5348s vs 5288.53s), and adds likely hallucinatory detail, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After David finishes explaining about the feedback form, when does he start giving instructions about the FILO page and WELO coffee lounge?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5190.0,
        "end": 5356.2699999999995
      },
      "gt_interval": {
        "start": 5309.965,
        "end": 5315.734
      },
      "pred_interval": {
        "start": 5314.0,
        "end": 5333.0
      },
      "iou": 0.07527675276754457,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0349999999998545,
        "end": 17.26599999999962,
        "average": 10.650499999999738
      },
      "rationale_metrics": {
        "rouge_l": 0.22916666666666669,
        "text_similarity": 0.6359756588935852,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer's timestamps are significantly off from the reference (predicts E1 ending at 5313s vs 5304.217s, and E2 spanning 5314\u20135333s vs 5309.965\u20135315.734s), misrepresenting both start/end times and duration of the FILO/WELO instruction. It therefore contradicts the correct temporal boundaries despite matching the topic."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes describing the expectations for IRC Child Protection Team Members, when does he finish describing the expectations for IRC Education Team Members?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2490.27,
        "end": 2535.335
      },
      "pred_interval": {
        "start": 2520.5,
        "end": 2529.0
      },
      "iou": 0.18861644291578808,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.230000000000018,
        "end": 6.335000000000036,
        "average": 18.282500000000027
      },
      "rationale_metrics": {
        "rouge_l": 0.2280701754385965,
        "text_similarity": 0.7353997826576233,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer largely contradicts the reference: the anchor and target timestamps are significantly different (predicted E1 ~2509s vs correct 2440.27s; predicted E2 2520.5\u20132529.0s vs correct 2490.27\u20132535.335s), and it shortens/relocates the target event instead of covering the entire education-team description as stated in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says that 'cross-sector collaboration is really needed to achieve peace expectation', when does he start talking about the integration across the four education models?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2555.112,
        "end": 2569.771
      },
      "pred_interval": {
        "start": 2553.5,
        "end": 2568.0
      },
      "iou": 0.7920840759633565,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.61200000000008,
        "end": 1.7710000000001855,
        "average": 1.6915000000001328
      },
      "rationale_metrics": {
        "rouge_l": 0.2197802197802198,
        "text_similarity": 0.7072359323501587,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the 'after' relation and gives times close to the reference, but the anchor/target timestamps differ by a few seconds and the prediction omits one of the four models (lists only three), so it is partially incomplete."
      }
    }
  ]
}