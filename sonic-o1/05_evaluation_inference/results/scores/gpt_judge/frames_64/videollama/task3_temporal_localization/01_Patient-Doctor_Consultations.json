{
  "topic_id": 1,
  "topic_name": "Patient-Doctor Consultations",
  "num_evaluated": 266,
  "aggregated_metrics": {
    "mean_iou": 0.042397799211613414,
    "std_iou": 0.10547218463585056,
    "median_iou": 0.0030551182557280133,
    "R@0.3": {
      "recall": 0.03007518796992481,
      "count": 8,
      "total": 266
    },
    "R@0.5": {
      "recall": 0.015037593984962405,
      "count": 4,
      "total": 266
    },
    "R@0.7": {
      "recall": 0.007518796992481203,
      "count": 2,
      "total": 266
    },
    "mae": {
      "start_mean": 242.80596616541354,
      "end_mean": 3777.037436090225,
      "average_mean": 2009.9217011278195
    },
    "rationale": {
      "rouge_l_mean": 0.24961546826049044,
      "rouge_l_std": 0.09986932358005221,
      "text_similarity_mean": 0.5193570497606818,
      "text_similarity_std": 0.1844581116146802,
      "llm_judge_score_mean": 2.4586466165413534,
      "llm_judge_score_std": 2.134610169180371
    },
    "rationale_cider": 0.28569479779340173
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "After the speaker welcomes viewers and introduces himself as 'Karma Medic', when does he state that he is a 'final year medical student'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 35.0,
        "end": 36.62
      },
      "pred_interval": {
        "start": 2.5,
        "end": 36.6
      },
      "iou": 0.046893317702227474,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.5,
        "end": 0.01999999999999602,
        "average": 16.259999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.8918918918918919,
        "text_similarity": 0.9790400266647339,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the target phrase, its timing, and the 'after' relationship; the only issue is a minor discrepancy in the anchor start time (~1.0s earlier) and slight rounding of the end time."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'Now with that lovely disclaimer out of the way, let's get right into it', when does the text 'before the history' appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.06,
        "end": 57.06
      },
      "pred_interval": {
        "start": 38.4,
        "end": 58.8
      },
      "iou": 0.04901960784313726,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.660000000000004,
        "end": 1.7399999999999949,
        "average": 9.7
      },
      "rationale_metrics": {
        "rouge_l": 0.3428571428571428,
        "text_similarity": 0.8948771953582764,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the 'once_finished' relationship but the timestamps are largely incorrect and contradictory to the reference (anchor finish and target appearance/end times are wrong), so it fails on factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'So before starting the history, there's generally two things that I try and keep in mind', when does he begin describing 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 206.36,
        "end": 207.36
      },
      "pred_interval": {
        "start": 60.6,
        "end": 109.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 145.76000000000002,
        "end": 97.56000000000002,
        "average": 121.66000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.8538204431533813,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase and the 'after' relation but is largely incorrect: the anchor timestamp is off by several seconds and the target timestamps are entirely wrong (the correct target occurs ~206s, not 60.6\u2013109.8s), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the acronym 'ICE', when does he explain what it stands for?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 155.7,
        "end": 158.7
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 150.5,
        "end": 122.1,
        "average": 136.3
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424243,
        "text_similarity": 0.5043727159500122,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction fails to identify the ICE mention or its explanation and gives completely different timestamps and event content; only the relation label matches, so it does not align with the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the components of the WIPER acronym, when does he start elaborating on 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 212.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 172.0,
        "end": 175.4,
        "average": 173.7
      },
      "rationale_metrics": {
        "rouge_l": 0.2647058823529412,
        "text_similarity": 0.5533481240272522,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer misidentifies both event timings and the relationship: it gives entirely different start/end times and labels the relation 'after' rather than 'once_finished', so it does not match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what brought the patient in, when does he explain what the 'history of presenting complaint' is about?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 346.0,
        "end": 351.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 540.0
      },
      "iou": 0.023809523809523808,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.0,
        "end": 189.0,
        "average": 102.5
      },
      "rationale_metrics": {
        "rouge_l": 0.25316455696202533,
        "text_similarity": 0.6588420867919922,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly labels the relation as 'after' and roughly locates the anchor, the target event timing and quoted content are grossly different from the reference (off by ~140s and inconsistent wording), so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "How long after the speaker says he'll put a picture of all possible questions does the \"REVIEW OF SYSTEMS\" checklist first appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 539.8,
        "end": 543.7
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 534.5999999999999,
        "end": 507.1,
        "average": 520.8499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2077922077922078,
        "text_similarity": 0.5090097188949585,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly labels the relation as 'after' and roughly matches the anchor time, but it substantially mis-times the checklist (E2) and misidentifies its span, omitting the correct 29.8\u201333.7s window and adding unfounded end times."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is giving examples of systems review questions, when does he ask about \"tummy pain\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 565.74,
        "end": 566.422
      },
      "pred_interval": {
        "start": 147.5,
        "end": 207.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 418.24,
        "end": 358.922,
        "average": 388.581
      },
      "rationale_metrics": {
        "rouge_l": 0.28070175438596484,
        "text_similarity": 0.6589067578315735,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the reference on all key points: timestamps are different, the 'tummy pain' interval is misassigned, and the true relation is 'during' whereas the prediction says 'before', so it fails to match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the \"JAM THREADS\" mnemonic, when does he say the name \"Sketchy Medical\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 696.0,
        "end": 699.531
      },
      "pred_interval": {
        "start": 180.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 516.0,
        "end": 489.53099999999995,
        "average": 502.7655
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.7070549726486206,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gives completely incorrect timestamps (off by several minutes) and omits E2's start time, though it correctly identifies the temporal relation as 'after'; major factual elements are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker describes Sketchy Medical, when does he mention drugs' mechanism of action and side effects?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 701.0,
        "end": 703.982
      },
      "pred_interval": {
        "start": 690.0,
        "end": 723.4
      },
      "iou": 0.0892814371257477,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 19.418000000000006,
        "average": 15.209000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.4313725490196078,
        "text_similarity": 0.5977901220321655,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamp (690.0s) is incorrect and contradicts the reference, which locates the mechanism/side-effects discussion at 701.0\u2013703.982s (and notes Sketchy Medical description begins at 697.491s); the prediction also omits the correct time interval."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks a general question about family health, when does he suggest being specific about asthma, diabetes, and hypertension?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 742.914,
        "end": 745.914
      },
      "pred_interval": {
        "start": 723.4,
        "end": 900.0
      },
      "iou": 0.01698754246885617,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.51400000000001,
        "end": 154.086,
        "average": 86.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424246,
        "text_similarity": 0.3880208730697632,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives a single start time of 723.4s which contradicts the reference interval 742.914\u2013745.914s and is earlier than the general question at 730.749s, misplacing the event and omitting the correct interval."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the importance of signposting, when does he ask if the patient uses any recreational drugs?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 811.123,
        "end": 812.664
      },
      "pred_interval": {
        "start": 723.4,
        "end": 900.0
      },
      "iou": 0.008725934314835445,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 87.72300000000007,
        "end": 87.33600000000001,
        "average": 87.52950000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322035,
        "text_similarity": 0.6307390332221985,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer identifies the same question but gives a grossly incorrect timestamp (723.4s) that contradicts the correct times (question at 811.123\u2013812.664s) and the statement that it immediately follows the explanation, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"concerns from ICE\", when does he start saying \"Just generally, if you're feeling stuck\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 880.187,
        "end": 883.471
      },
      "pred_interval": {
        "start": 38.4,
        "end": 52.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 841.787,
        "end": 830.571,
        "average": 836.1790000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.380952380952381,
        "text_similarity": 0.4524604082107544,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the utterance occurs after 'concerns from ICE' and its coarse interval [870.0s, 923.0s] contains the true start time (~880.187s), but it is imprecise and omits the specific anchor and target timestamps and exact relation details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"golden rulebook\", when does he open both hands outwards in a gesture?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 895.8,
        "end": 897.5
      },
      "pred_interval": {
        "start": 467.5,
        "end": 517.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 428.29999999999995,
        "end": 380.1,
        "average": 404.2
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962262,
        "text_similarity": 0.584879994392395,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the gesture occurs after saying 'golden rulebook' and its broad time window includes the true interval, but it omits the precise anchor and target timestamps (892.849s and 895.8\u2013897.5s) and is overly imprecise."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying \"I hope you find this video useful\", when does he say \"Peace\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 910.148,
        "end": 910.609
      },
      "pred_interval": {
        "start": 870.0,
        "end": 916.0
      },
      "iou": 0.010021739130435059,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.148000000000025,
        "end": 5.390999999999963,
        "average": 22.769499999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.3728813559322034,
        "text_similarity": 0.4789274334907532,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the order (he says 'Peace' after the anchor) and the broad interval (870\u2013923s) contains the ground-truth times, but it omits the precise timestamps and is overly vague compared to the specific anchor/target times given."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying he has an appointment at 10 am, when does the green text 'Sure, what's your name?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 6.1,
        "end": 8.2
      },
      "pred_interval": {
        "start": 25.6,
        "end": 37.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.5,
        "end": 28.8,
        "average": 24.15
      },
      "rationale_metrics": {
        "rouge_l": 0.22857142857142856,
        "text_similarity": 0.7412378191947937,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives completely different time intervals and an incorrect temporal relation ('after' vs 'once_finished'), contradicting the ground truth that the target appears immediately after the anchor at ~6.1\u20138.2s."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes stating his name, when does the green text 'Thank you, Lucas. Please take a seat...' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 11.9,
        "end": 19.0
      },
      "pred_interval": {
        "start": 28.4,
        "end": 37.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.5,
        "end": 18.0,
        "average": 17.25
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333334,
        "text_similarity": 0.6920107007026672,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is largely incorrect: it gives different timestamps (and a start time instead of the anchor finish at 10.6s), misidentifies the target segment and its times (35.0\u201336.6s vs correct 11.9\u201319.0s), and states the wrong relation ('after' vs once_finished)."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'How long is the wait?', when does the green text 'About 10 minutes. Would you like some water while you wait?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 22.1,
        "end": 25.3
      },
      "pred_interval": {
        "start": 35.0,
        "end": 37.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.899999999999999,
        "end": 11.7,
        "average": 12.299999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1764705882352941,
        "text_similarity": 0.7998083829879761,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies both anchor and target timestamps and their spoken content, only matching the vague 'after' relation; because the segments and times are largely incorrect and contain hallucinated details, it fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the video explains the 'we're a team' approach with animated graphics, when does the speaker appear at his desk looking at a computer?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 34.6,
        "end": 36.0
      },
      "pred_interval": {
        "start": 48.9,
        "end": 59.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.299999999999997,
        "end": 23.0,
        "average": 18.65
      },
      "rationale_metrics": {
        "rouge_l": 0.10389610389610389,
        "text_similarity": 0.4506312310695648,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction describes an 'OK' hand emoji at 48.9\u201359.0s, which is a different element and time window than the correct event (speaker at desk around 34.0\u201336.0s overlapping the 'we're a team' audio at 29.5\u201334.6s), so it is incorrect and non-aligned."
      }
    },
    {
      "question_id": "001",
      "question": "After Nurse Kim mentions graduating as a registered nurse, when does she talk about working for many different pharmaceutical companies?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 43.0,
        "end": 50.475
      },
      "pred_interval": {
        "start": 28.5,
        "end": 69.4
      },
      "iou": 0.18276283618581907,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.5,
        "end": 18.925000000000004,
        "average": 16.712500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322035,
        "text_similarity": 0.6473675966262817,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') and roughly locates the nursing comment, but it gives a significantly incorrect time for the pharmaceutical companies segment (60.0s vs. 43.0\u201350.475s), so it fails to match the key timing detail."
      }
    },
    {
      "question_id": "002",
      "question": "Once Nurse Kim finishes describing her background as an 'incredible journey', when does she mention training side-by-side with Dr. Jugenberg for five years?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 149.87,
        "end": 153.25
      },
      "pred_interval": {
        "start": 60.0,
        "end": 103.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 89.87,
        "end": 49.45,
        "average": 69.66
      },
      "rationale_metrics": {
        "rouge_l": 0.29729729729729726,
        "text_similarity": 0.6301203966140747,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the relation and content but the timestamps are substantially incorrect (E1 and E2 times and endpoints diverge greatly from the reference), so it fails to match the key factual timing information."
      }
    },
    {
      "question_id": "001",
      "question": "While Nurse Kim explains options and possible outcomes, when does she begin examining the patient's stomach?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 157.5,
        "end": 160.5
      },
      "pred_interval": {
        "start": 152.8,
        "end": 169.4
      },
      "iou": 0.18072289156626511,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.699999999999989,
        "end": 8.900000000000006,
        "average": 6.799999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.3384615384615385,
        "text_similarity": 0.6927427649497986,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction contradicts the reference timing: it says the exam starts after she finishes speaking, whereas the ground truth states the stomach exam begins at 157.5s and occurs during her speech; it also adds an unsupported detail about the patient sitting in a chair."
      }
    },
    {
      "question_id": "002",
      "question": "After Nurse Kim finishes discussing the benefits, risks, and possible complications of the procedure, when does she start talking about asymmetry?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 169.7,
        "end": 172.0
      },
      "pred_interval": {
        "start": 173.8,
        "end": 190.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.100000000000023,
        "end": 18.80000000000001,
        "average": 11.450000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.2535211267605634,
        "text_similarity": 0.5425935983657837,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that discussion of asymmetry follows the prior risks/benefits/complications (matching the temporal relation) but fails to provide the specific timestamps and adds an unfounded detail about the patient looking away, so it is incomplete and contains a hallucination."
      }
    },
    {
      "question_id": "003",
      "question": "Once Nurse Kim finishes explaining that the one-hour consultation cannot provide everything you need to know, when does she mention that they are always available?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 201.5,
        "end": 203.71
      },
      "pred_interval": {
        "start": 194.8,
        "end": 211.4
      },
      "iou": 0.13313253012048246,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.699999999999989,
        "end": 7.689999999999998,
        "average": 7.194999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.38888888888888895,
        "text_similarity": 0.5485638380050659,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that Nurse Kim says they are always available, but it omits the crucial timing information (the 201.5s immediate transition) required by the correct answer and adds an unrelated detail about a nod, so it is incomplete and includes extraneous content."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces himself and the topic, when does the slide change to 'Objectives for today's lesson'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 24.379,
        "end": 24.5
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.003853503184713333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.179000000000002,
        "end": 12.100000000000001,
        "average": 15.639500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.22950819672131148,
        "text_similarity": 0.6761195659637451,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the temporal relation 'after' is correct, the predicted E2 is completely incorrect (wrong time and wrong event) and E1 timing is imprecise/partial, so key factual elements are missing or hallucinated."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the objectives for the lesson, when does the slide change to 'Brain storming time'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 46.529,
        "end": 47.0
      },
      "pred_interval": {
        "start": 74.5,
        "end": 100.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.970999999999997,
        "end": 53.0,
        "average": 40.4855
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.617577075958252,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relation that the slide changes once the speaker finishes, but it omits the key factual timestamps (45.800s and 46.529s) requested in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes defining communication as the successful passage of a message from one person to another, when does he start explaining how good communication manifests in medical practice by informing patients of their diagnosis?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 153.0,
        "end": 177.0
      },
      "pred_interval": {
        "start": 5.2,
        "end": 35.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 147.8,
        "end": 142.0,
        "average": 144.9
      },
      "rationale_metrics": {
        "rouge_l": 0.3125,
        "text_similarity": 0.6294234991073608,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies both anchor and target timestamps (completely different seconds) and the target span/content, and it fails to capture that the target immediately follows the anchor; only the vague 'after' relation is weakly aligned."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the 'Importance of communication' slide, when does he begin discussing that good doctor-patient communication has been linked to improved patient satisfaction?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 190.0,
        "end": 198.0
      },
      "pred_interval": {
        "start": 36.6,
        "end": 109.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 153.4,
        "end": 88.6,
        "average": 121.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7371151447296143,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly identifies the relationship as 'after' but the anchor and target timestamps are entirely different from the reference (predicted 36.6s/109.4\u2013111.0s vs. reference 177.5\u2013179.5s/190.0\u2013198.0s), so it fails to match the correct segments."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker starts talking about how a lot of malpractice lawsuits have been documented, when does he explicitly advise being aware of communication's importance to avoid lawsuits?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 226.0,
        "end": 271.0
      },
      "pred_interval": {
        "start": 111.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 115.0,
        "end": 61.0,
        "average": 88.0
      },
      "rationale_metrics": {
        "rouge_l": 0.275,
        "text_similarity": 0.7118804454803467,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer's time spans and event boundaries do not match the reference (anchor predicted at 111s vs 198\u2013212s; target at 210s vs 226\u2013271s) and it misstates the relationship, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the initial slide 'Communication is not just talking' is displayed, when does the speaker mention that physicians can improve health outcomes?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 339.28,
        "end": 346.0
      },
      "pred_interval": {
        "start": 335.7,
        "end": 428.9
      },
      "iou": 0.0721030042918458,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.579999999999984,
        "end": 82.89999999999998,
        "average": 43.23999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.29629629629629634,
        "text_similarity": 0.37426504492759705,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states the relative ordering (the mention occurs after the slide), but it omits the specific timing details (start/end timestamps) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide showing two images (bored girl vs. smiling doctor/patient), when does the speaker describe the first image as depicting a 'horribly bored' lady?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.8,
        "end": 359.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 540.0
      },
      "iou": 0.019999999999999945,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.80000000000001,
        "end": 181.0,
        "average": 102.9
      },
      "rationale_metrics": {
        "rouge_l": 0.27118644067796605,
        "text_similarity": 0.36819887161254883,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer is vague and frames the remark relative to when the speaker finishes defining 'verbal communication' rather than giving the concrete timing; it omits the key timestamp (354.8\u2013359.0s) and the fact the description occurs while the slide is visible, so it is not sufficiently accurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker defines verbal communication as 'using spoken words', when is the next time they define non-verbal communication?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 428.87,
        "end": 433.596
      },
      "pred_interval": {
        "start": 429.0,
        "end": 540.0
      },
      "iou": 0.04135696931521645,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.12999999999999545,
        "end": 106.404,
        "average": 53.266999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.1739130434782609,
        "text_similarity": 0.4804001450538635,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys that the non-verbal definition follows the verbal one, but it omits the specific timing information and details provided in the reference, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the 'golden minute', when does he describe the patient's hypothetical response?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 613.818,
        "end": 630.0
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 608.6179999999999,
        "end": 593.4,
        "average": 601.009
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.7011753916740417,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives completely different timestamps and event descriptions for both the anchor and target compared to the reference, so it fails to identify the correct moments; merely stating the relation as 'after' does not compensate for the incorrect events and times."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions 'Checking facts', when does he mention the next essential element of listening?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 641.157,
        "end": 642.461
      },
      "pred_interval": {
        "start": 35.0,
        "end": 47.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 606.157,
        "end": 595.061,
        "average": 600.609
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.7284024953842163,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely mismatches the reference: it gives incorrect anchor/target timestamps and the wrong target content, whereas the reference names 'Checking feelings' immediately after 'Checking facts'; only the vague temporal relation ('after') aligns."
      }
    },
    {
      "question_id": "003",
      "question": "Before the speaker says 'So, for example, we have three main types of reflective listening', when does he explain what reflective listening involves?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 667.457,
        "end": 687.051
      },
      "pred_interval": {
        "start": 40.5,
        "end": 68.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 626.957,
        "end": 618.6510000000001,
        "average": 622.8040000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.19444444444444445,
        "text_similarity": 0.7691540718078613,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely incorrect: it gives wrong timestamps, reverses/mislabels the events, and states an 'at once' relationship contrary to the correct answer that the definition occurs before the examples."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the three main types of reflective listening, when does he start explaining the 'Repeating' example?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 710.0,
        "end": 737.0
      },
      "pred_interval": {
        "start": 690.0,
        "end": 723.5
      },
      "iou": 0.2872340425531915,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.0,
        "end": 13.5,
        "average": 16.75
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367344,
        "text_similarity": 0.5007836818695068,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the relation ('after') but omits the required timing details (start at 710.0s and end at 737.0s) and thus fails to answer the 'when' question fully."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the 'Repeating' example, when does he introduce 'Rephrasing'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 720.0,
        "end": 720.4
      },
      "pred_interval": {
        "start": 723.5,
        "end": 748.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 27.600000000000023,
        "average": 15.550000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.6649036407470703,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relation that 'Rephrasing' is introduced after finishing 'Repeating', but it omits key factual details from the reference\u2014specifically the timestamps (698.0s and 720.0s) and the exact phrasing\u2014making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing 'Reflection of feeling by showing empathy', when does the 'Non-verbal' slide appear?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 780.0,
        "end": 821.5
      },
      "pred_interval": {
        "start": 748.0,
        "end": 800.0
      },
      "iou": 0.272108843537415,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.0,
        "end": 21.5,
        "average": 26.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3255813953488372,
        "text_similarity": 0.6095125675201416,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relation that the 'Non-verbal' slide appears once the speaker finishes discussing empathy, but it omits the key numerical timestamps (778.5s and 780.0s) given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises to smile, when does he mention checking for signs of pain?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.045,
        "end": 882.0
      },
      "pred_interval": {
        "start": 875.0,
        "end": 913.6
      },
      "iou": 0.17260510417950903,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.955000000000041,
        "end": 31.600000000000023,
        "average": 16.777500000000032
      },
      "rationale_metrics": {
        "rouge_l": 0.27692307692307694,
        "text_similarity": 0.6947934627532959,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives an incorrect characterization (saying it occurs after the patient shows pain) and substantially misreports the event timing (start slightly off and end far later than ~882.0s), indicating factual errors and added/unfounded content."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the cultural interpretations of folding arms, when does he advise to avoid folding arms?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 932.0,
        "end": 936009.0
      },
      "pred_interval": {
        "start": 914.0,
        "end": 940.0
      },
      "iou": 8.55528047952347e-06,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.0,
        "end": 935069.0,
        "average": 467543.5
      },
      "rationale_metrics": {
        "rouge_l": 0.393939393939394,
        "text_similarity": 0.7169414758682251,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction omits the correct E1 timestamp, adds an unfounded claim about patient pain, and gives an imprecise, overly broad E2 interval (914\u2013940s) instead of the correct 932\u2013936.009s."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker instructs to introduce yourself to the patient, when does he advise to explain your role as a student or intern?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 985.0,
        "end": 990.853
      },
      "pred_interval": {
        "start": 941.0,
        "end": 967.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.0,
        "end": 23.852999999999952,
        "average": 33.926499999999976
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.4945976734161377,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives completely different timing (941.0\u2013967.0s vs. the correct 985.0\u2013990.1s) and mischaracterizes the sequence (ties it to an anchor event), so it does not match the correct intervals or description."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"if you're in the hospital\", when does he refer to \"inpatient patients\"?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1059.6,
        "end": 1059.8
      },
      "pred_interval": {
        "start": 1056.0,
        "end": 1073.4
      },
      "iou": 0.011494252873565772,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.599999999999909,
        "end": 13.600000000000136,
        "average": 8.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.10169491525423728,
        "text_similarity": 0.17412668466567993,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only gets the temporal relation ('after') right but fails to identify the correct anchor/target phrases or provide the required timestamps, instead giving unrelated content about consultations and the 'golden minute.' It omits key factual elements from the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining how to start a consultation, when does he give the example \"how can I help you today?\"",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1069.0,
        "end": 1070.0
      },
      "pred_interval": {
        "start": 1056.0,
        "end": 1073.4
      },
      "iou": 0.05747126436781579,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.0,
        "end": 3.400000000000091,
        "average": 8.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.11428571428571428,
        "text_similarity": 0.21270224452018738,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the example occurs after the preceding explanation, but it misidentifies the anchor as the 'golden minute' instead of the open-ended question segment and omits the precise timing details provided in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes explaining the 'golden minute', when does he announce the end of the lecture?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1090.0,
        "end": 1094.0
      },
      "pred_interval": {
        "start": 1056.0,
        "end": 1073.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 20.59999999999991,
        "average": 27.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.0909090909090909,
        "text_similarity": 0.19226285815238953,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only captures the correct temporal relation ('after') but omits the required timestamps and misdescribes the event (adds unrelated content about starting a consultation), so it is largely incorrect and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "While Raquel is talking about the hospital providing opportunities for nurses, when is she shown smiling and opening a package?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 2.0,
        "end": 4.5
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.2,
        "end": 32.1,
        "average": 17.650000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.3661971830985915,
        "text_similarity": 0.6874352097511292,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timings and temporal relation contradict the ground truth: the correct visual event overlaps the anchor speech (2.0\u20134.5s within 0.031\u20135.0s), whereas the prediction gives much later, non-overlapping times (5.2s and 35.0\u201336.6s) and labels the relation 'after', so it is fully incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria finishes saying that new nurses will be nudged to become lifelong learners, when does Precious state that the teamwork is strong?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 14.321,
        "end": 16.486
      },
      "pred_interval": {
        "start": 48.5,
        "end": 53.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.179,
        "end": 36.513999999999996,
        "average": 35.3465
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.6837915182113647,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps and speaker segments do not match the reference (completely different times) and the predicted content/relationship is inconsistent with the correct answer, so it is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After Reny states that the hospital does things up to a magnet level, when does Raquel say her values align with the hospital's values?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 42.854,
        "end": 50.692
      },
      "pred_interval": {
        "start": 35.0,
        "end": 48.5
      },
      "iou": 0.3598011725720113,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.853999999999999,
        "end": 2.192,
        "average": 5.023
      },
      "rationale_metrics": {
        "rouge_l": 0.30555555555555564,
        "text_similarity": 0.5552694201469421,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gives incorrect and inconsistent timestamps and mislabels anchor/target boundaries (including an unsupported quoted phrase), so it fails to match the precise timing in the correct answer; it only correctly identifies the temporal relation as 'after'."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that healthcare in Siem Reap is not the best, when is the Royal Angkor International Hospital first shown on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 94.0,
        "end": 99.1
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 88.8,
        "end": 62.49999999999999,
        "average": 75.64999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.23376623376623376,
        "text_similarity": 0.5961345434188843,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives completely different event timestamps and incorrect event identities (introductions instead of the specified hospital visual/description), so it fails to match the correct timings; only the vague 'after' relationship aligns."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he begin describing the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 180.289,
        "end": 185.074
      },
      "pred_interval": {
        "start": 35.0,
        "end": 49.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 145.289,
        "end": 135.674,
        "average": 140.48149999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.136986301369863,
        "text_similarity": 0.4421563446521759,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer's timestamps and quoted utterances do not match the ground truth events (GT E1 at 165.611s and GT E2 beginning at 180.289s); it misidentifies both segments and their timings, so it is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he visited a clinic for chest congestion, when does he mention the Paschern Dental Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 209.8,
        "end": 211.4
      },
      "pred_interval": {
        "start": 156.9,
        "end": 207.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.900000000000006,
        "end": 3.5999999999999943,
        "average": 28.25
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962262,
        "text_similarity": 0.6044299006462097,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the Paschern Dental Clinic is mentioned after the chest-congestion clinic), but it omits the specific time intervals provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he introduce the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.0,
        "end": 184.8
      },
      "pred_interval": {
        "start": 208.3,
        "end": 239.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.30000000000001,
        "end": 54.89999999999998,
        "average": 39.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5540448427200317,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the clinic is mentioned after Neak Tep Hospital) but omits the key factual details\u2014specific timestamps (182.0s and 184.0\u2013184.8s) required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker introduces the Cigna International Health Policy, when is the insurance quote form displayed with personal information?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 240.2,
        "end": 269.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 110.80000000000001,
        "end": 90.19999999999999,
        "average": 100.5
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.6542690992355347,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the form appears after the speaker finishes introducing the Cigna policy) but omits the specific timing details provided in the correct answer (exact seconds and event intervals)."
      }
    },
    {
      "question_id": "002",
      "question": "After the voiceover states that the Cigna policy is \"fairly typical of policies of this type\", when does the Cigna website display the form for inputting personal details to get a quote?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 352.9,
        "end": 358.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 456.0
      },
      "iou": 0.04047619047619066,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.899999999999977,
        "end": 98.0,
        "average": 60.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3188405797101449,
        "text_similarity": 0.543038547039032,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the reference by giving wrong start/end times (330.0s\u2013456.0s vs correct 352.9s\u2013358.0s) and misidentifies the anchor phrase, so it is largely incorrect and contains hallucinated timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the host concludes his introduction about the fight in modern healthcare, when does he introduce Sarah?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 19.4,
        "end": 22.0
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.08280254777070067,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.2,
        "end": 14.600000000000001,
        "average": 14.4
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.684635579586029,
        "llm_judge_score": 1,
        "llm_judge_justification": "While the temporal relation ('after') is correct, the prediction misidentifies both events and provides substantially wrong timestamps and speaker descriptions (E1/E2 intervals and contents do not match the ground truth), so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While Sarah is introducing herself and her genetic condition, when does she mention having her very first surgery?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.08,
        "end": 108.8
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 69.08,
        "end": 72.19999999999999,
        "average": 70.63999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518515,
        "text_similarity": 0.523755669593811,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect: it gives the wrong timestamps, wrong speaker, and irrelevant content that contradicts the reference (which places the first surgery mention at 104.08\u2013108.08s during Sarah's introduction)."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sarah finishes describing her role as a volunteer patient representative for a non-profit organization, when does the static image showing her behind a 'CHILDREN'S TUMOR FOUNDATION' table appear?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 185.0,
        "end": 190.0
      },
      "pred_interval": {
        "start": 150.0,
        "end": 210.0
      },
      "iou": 0.08333333333333333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.0,
        "end": 20.0,
        "average": 27.5
      },
      "rationale_metrics": {
        "rouge_l": 0.38235294117647056,
        "text_similarity": 0.5324774980545044,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that the image appears after Sarah finishes but omits the key timestamps (E1 at 150s; E2 from 185\u2013190s) and the explicit note that the target immediately follows the anchor, so it is largely incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes explaining the purpose of the 'Shine a Light Walk' to raise money and awareness, when does the video clip showing children running at an outdoor event play?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 189.0,
        "end": 192.0
      },
      "pred_interval": {
        "start": 150.0,
        "end": 210.0
      },
      "iou": 0.05,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 18.0,
        "average": 28.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.5361976623535156,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the clip plays after Sarah finishes, but it omits the key timing details (E1 at 179.0s; E2 from 189.0\u2013192.0) and the note that the target immediately follows the anchor, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once Steve asks if the 'Shine a Light Walk' goes throughout the world, when does Sarah begin to explain that the walks do not?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 253.2,
        "end": 258.88
      },
      "pred_interval": {
        "start": 150.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 103.19999999999999,
        "end": 48.879999999999995,
        "average": 76.03999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413793,
        "text_similarity": 0.336152046918869,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that Sarah explains the walks do not, but it fails to provide the required timing information (the timestamps 253.2s\u2013258.88s and 252.5s anchor), so it omits key factual details needed to answer 'when'."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes asking Sarah what things in miscommunication can lead to delays or misdiagnosis, when does the woman start responding?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 362.48,
        "end": 365.44
      },
      "pred_interval": {
        "start": 330.0,
        "end": 420.0
      },
      "iou": 0.03288888888888866,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.48000000000002,
        "end": 54.56,
        "average": 43.52000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.19999999999999998,
        "text_similarity": 0.4087495803833008,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction significantly misaligns with the reference: timestamps for both events are incorrect, the temporal relation ('after') contradicts the correct 'once_finished' (almost immediate), and it introduces unsupported dialogue content, so it fails to match the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman gives the example of writing 'hyperthyroid instead of hypothyroid', when does the man respond with 'That that's pretty bad'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 389.2,
        "end": 432.5
      },
      "pred_interval": {
        "start": 420.0,
        "end": 510.0
      },
      "iou": 0.10347682119205297,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.80000000000001,
        "end": 77.5,
        "average": 54.150000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.18666666666666665,
        "text_similarity": 0.6045702695846558,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted relation 'after' matches the reference, the predicted event timestamps and event labeling are substantially incorrect and misaligned with the ground truth, including fabricated start/end times, so it fails to correctly identify the actual occurrences."
      }
    },
    {
      "question_id": "003",
      "question": "After the man says he tried researching miscommunication problems, when does he state his finding about thousands of preventable deaths?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 446.56,
        "end": 535.68
      },
      "pred_interval": {
        "start": 510.0,
        "end": 660.0
      },
      "iou": 0.12031484257871042,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.44,
        "end": 124.32000000000005,
        "average": 93.88000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.13157894736842105,
        "text_similarity": 0.44692903757095337,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer has substantially incorrect timestamps and appears to mislabel the events (placing the statements much later than the ground truth), so while it gets the temporal relation ('after') right, it fails on factual alignment of event boundaries and identities."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks, \"What's in my budget to fix it?\", when does she start asking, \"How important is it to me to fix this issue?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 518.66,
        "end": 522.26
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 513.4599999999999,
        "end": 485.65999999999997,
        "average": 499.55999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.34782608695652173,
        "text_similarity": 0.7172229290008545,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the temporal relation ('after') right but the timestamps and utterance content are completely incorrect compared to the reference (major mismatch in start times and the target phrase), so it earns minimal credit."
      }
    },
    {
      "question_id": "002",
      "question": "After the man finishes saying, \"not continuing medical bills,\" when does he start asking, \"So, what does successful self-advocacy look like?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 643.04,
        "end": 646.32
      },
      "pred_interval": {
        "start": 37.4,
        "end": 63.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 605.64,
        "end": 582.5200000000001,
        "average": 594.08
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.7018862962722778,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: timestamps and anchor/target labeling do not match the reference (predicted times 37.4s/63.8s vs. 634.36s/643.04\u2013646.32s), and the target span is wrong, though it correctly labels the relationship as 'after'."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining what a doctor's follow-up might entail, when does the woman start asking, \"Or will I actually be able to get into your office in two weeks?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 679.0,
        "end": 683.92
      },
      "pred_interval": {
        "start": 64.6,
        "end": 90.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 614.4,
        "end": 593.7199999999999,
        "average": 604.06
      },
      "rationale_metrics": {
        "rouge_l": 0.2318840579710145,
        "text_similarity": 0.7650924921035767,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer contradicts the correct timings and segment assignments (wrong start/end times and places the woman's question in the wrong segment); it fails to match the anchor/target boundaries given, so it is incorrect despite noting an 'after' relation."
      }
    },
    {
      "question_id": "001",
      "question": "Immediately after the woman asks if she should follow up if she is still experiencing symptoms, when does the man ask what if the symptoms go away?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.38,
        "end": 707.15
      },
      "pred_interval": {
        "start": 690.0,
        "end": 723.5
      },
      "iou": 0.23194029850746214,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.379999999999995,
        "end": 16.350000000000023,
        "average": 12.865000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.2823529411764706,
        "text_similarity": 0.7188711166381836,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets only the general ordering ('after') but the timestamps are substantially different from the reference (E1: 690.0 vs 698.78; E2: 701.5\u2013723.5 vs 699.38\u2013707.15), it fails to state that the target immediately follows the anchor, and it introduces an unsupported visual cue."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying to voice symptoms and concerns clearly, when does he give an example about shoulder pain?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 734.59,
        "end": 737.0
      },
      "pred_interval": {
        "start": 723.5,
        "end": 768.0
      },
      "iou": 0.0541573033707858,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.090000000000032,
        "end": 31.0,
        "average": 21.045000000000016
      },
      "rationale_metrics": {
        "rouge_l": 0.35714285714285715,
        "text_similarity": 0.6732677817344666,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only correctly identifies a vague 'after' relationship and roughly the target start, but the anchor time, target end time, and durations are significantly wrong and it adds an unsupported visual cue, so it fails to match key factual timings."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes warning not to try putting a hand in an electrical outlet, when does the woman agree and say not to try that?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 810.0,
        "end": 812.0
      },
      "pred_interval": {
        "start": 768.0,
        "end": 800.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.0,
        "end": 12.0,
        "average": 27.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4155844155844156,
        "text_similarity": 0.804795503616333,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timings and durations conflict substantially with the ground truth (off by ~40s and non-contiguous), and it fails to capture the immediate-follow temporal relation; it also adds an unsupported visual cue (woman's nod)."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes saying to assume benevolence of your doctor, when does the man begin to speak?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.9,
        "end": 879.1
      },
      "pred_interval": {
        "start": 870.0,
        "end": 960.0
      },
      "iou": 0.0022222222222227275,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.899999999999977,
        "end": 80.89999999999998,
        "average": 44.89999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322037,
        "text_similarity": 0.4160378575325012,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the man speaks after the woman (matches the 'once_finished' relation) but omits the precise timestamps given in the reference and includes extraneous/hallucinated scene details about a video call and bookshelves."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks about trying non-surgical options first, when does the woman reply 'Yes'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 899.7,
        "end": 900.1
      },
      "pred_interval": {
        "start": 960.0,
        "end": 1080.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 60.299999999999955,
        "end": 179.89999999999998,
        "average": 120.09999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.17391304347826086,
        "text_similarity": 0.40527844429016113,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the woman replies after the man's question (captures order), but it omits the crucial timing details and relation (E1 ends at 899.5s, E2 starts at 899.7s, once_finished), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the man concludes his statement about how to ask for another opinion, when does the woman respond that asking for another opinion is definitely valid?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 982.0,
        "end": 988.72
      },
      "pred_interval": {
        "start": 1080.0,
        "end": 1290.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 98.0,
        "end": 301.28,
        "average": 199.64
      },
      "rationale_metrics": {
        "rouge_l": 0.13157894736842105,
        "text_similarity": 0.29088449478149414,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation ('after') but omits the essential specific event labels and timestamps (E1 at 976.0s and E2 at 982.*s) required by the reference, and adds irrelevant visual description."
      }
    },
    {
      "question_id": "001",
      "question": "After the man suggests bringing someone along if you're not feeling safe, when does the woman agree that it's advisable?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1127.0,
        "end": 1130.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1160.0
      },
      "iou": 0.02727272727272727,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.0,
        "end": 30.0,
        "average": 53.5
      },
      "rationale_metrics": {
        "rouge_l": 0.345679012345679,
        "text_similarity": 0.6614087224006653,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the two events (man suggests, woman agrees) but the timestamps are substantially misaligned: E1 is off by ~70s (1050.0s vs 1120.0s) and E2 start is about 10.5s later than the reference (1137.5s vs 1127.0s) with an added end time not in the ground truth. These timing errors make the answer largely incorrect. "
      }
    },
    {
      "question_id": "002",
      "question": "After the woman talks about a doctor not trusting a patient's pain because they don't act like they're in pain, when does she give an example of a loved one vouching for the patient?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1167.68,
        "end": 1174.48
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.03238095238095216,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 117.68000000000006,
        "end": 85.51999999999998,
        "average": 101.60000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.3508771929824561,
        "text_similarity": 0.610344648361206,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps conflict substantially with the ground truth: E1 is given as 1161\u20131166s but the prediction says 1050.0s, and E2 is 1167.68\u20131174.48s but the prediction gives 1187.5\u20131260.0s; these large timing errors and misplacements make the answer essentially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks if it is legal to be given your own medical records, when does the woman confirm that it is?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1268.6,
        "end": 1270.7
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.010000000000000649,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.59999999999991,
        "end": 169.29999999999995,
        "average": 103.94999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.3055555555555555,
        "text_similarity": 0.6495823264122009,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives completely different timestamps and event content (speaker intro and a student statement) that do not correspond to the man's question or the woman's confirmation described in the correct answer, so it fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman mentions that things have changed a lot with electronic medical records, when does the man state that bureaucracy reminds him of common barriers?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1333.0,
        "end": 1339.5
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.030952380952380953,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 103.0,
        "end": 100.5,
        "average": 101.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3466666666666667,
        "text_similarity": 0.7693173885345459,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gives completely different anchor/target timestamps and a different target utterance, so it fails to match the correct events; it only correctly states the relative relation ('after'), meriting minimal partial credit."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks about common barriers and how to overcome them, when does the woman share her fear of ants?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.36,
        "end": 1383.7
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.030190476190476885,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 147.3599999999999,
        "end": 56.299999999999955,
        "average": 101.82999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.3582089552238806,
        "text_similarity": 0.7300493717193604,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly labels the relationship as 'after', it gives entirely incorrect timestamps and identifies the wrong speakers/events for both anchor and target, failing to match the substance of the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says to write things down on paper and give it to the doctor, when does he mention a doctor refusing to look at the paper?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1484.96,
        "end": 1490.0
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1620.0
      },
      "iou": 0.023999999999999827,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.96000000000004,
        "end": 130.0,
        "average": 102.48000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424238,
        "text_similarity": 0.6685428619384766,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer misidentifies both anchor and target events and their timestamps, only matching the temporal relation ('after'); therefore it largely fails to capture the correct events and times."
      }
    },
    {
      "question_id": "002",
      "question": "While the woman discusses prioritizing cognition, when does she state that she would rather be in pain than have her mental capacity harmed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1534.64,
        "end": 1542.24
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1620.0
      },
      "iou": 0.03619047619047576,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 124.6400000000001,
        "end": 77.75999999999999,
        "average": 101.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.39999999999999997,
        "text_similarity": 0.7289382219314575,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the target quote and the temporal relation ('after'), but it fails to locate the correct anchor (mislabels the speaker introduction) and gives inconsistent timestamps, omitting the key anchor phrase and accurate timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'Nord, what is that?', when does the woman state what NORD stands for?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.4,
        "end": 1615.4
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1620.0
      },
      "iou": 0.06666666666666667,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.40000000000009,
        "end": 4.599999999999909,
        "average": 14.0
      },
      "rationale_metrics": {
        "rouge_l": 0.1686746987951807,
        "text_similarity": 0.7041836977005005,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly timestamps and labels the events (E1 and E2) with substantially different start/end times and durations, and misses the key detail that E2 immediately follows the anchor; it only loosely matches that E2 occurs after E1."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says 'I read that I need to start this at 30', when does she explain why she needs the doctor to order it?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1692.24,
        "end": 1711.28
      },
      "pred_interval": {
        "start": 1630.0,
        "end": 1660.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.24000000000001,
        "end": 51.27999999999997,
        "average": 56.75999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2884615384615385,
        "text_similarity": 0.6765724420547485,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies and misaligns the events and times (wrong start/end times and swaps which utterance is E1 vs E2) and thus fails to match the reference's direct-continuation relation; only a vague topical overlap exists."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman explains how to mirror a planned course of action, when does she suggest asking the doctor what they heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.0,
        "end": 1799.8
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1980.0
      },
      "iou": 0.013333333333333117,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.0,
        "end": 180.20000000000005,
        "average": 103.60000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1111111111111111,
        "text_similarity": 0.07010512053966522,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures that the suggestion comes after the explanation, but it omits the key detail that it occurs after a brief additional explanation about miscommunication (i.e., not immediately upon finishing speaking), so the timing/nuance is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the man advises to 'just dig' and not use a medical dictionary, when does he ask if medical language can be 'dumbed down'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1836.56,
        "end": 1841.52
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1980.0
      },
      "iou": 0.023619047619047793,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.55999999999995,
        "end": 138.48000000000002,
        "average": 102.51999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.06666666666666667,
        "text_similarity": -0.06229736655950546,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction notes that he asks about 'dumbing down' medical language but omits the required precise timestamps and context (E1/E2 intervals) and gives a vague/likely incorrect timing ('once finished speaking'), so it fails to match the ground truth details."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks what to do when doctors look rushed, when does the woman describe slowing down and capturing their attention?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1965.6,
        "end": 1973.5
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2160.0
      },
      "iou": 0.03761904761904805,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.599999999999909,
        "end": 186.5,
        "average": 101.04999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.1095890410958904,
        "text_similarity": 0.3384978771209717,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction describes the scene and topics but omits the required timing details and the explicit anchor\u2192target relation (timestamps and that the woman's action follows the man's question), so it fails to answer the question. "
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes suggesting a doctor might be having a bad day, when does the man humorously ask if doctors have bad days?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2002.5,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2160.0
      },
      "iou": 0.007142857142857143,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.5,
        "end": 156.0,
        "average": 104.25
      },
      "rationale_metrics": {
        "rouge_l": 0.15789473684210525,
        "text_similarity": 0.3749060034751892,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the man asks after the woman, but it omits the precise timing (2001.5s\u21922002.5s\u20132004.0s) and the detail that the target immediately follows the anchor, and adds irrelevant visual description."
      }
    },
    {
      "question_id": "001",
      "question": "After the man introduces the 'five practical tips to advocate for yourself', when does the woman begin talking about writing down questions?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2195.28,
        "end": 2199.7
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.02104761904761723,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.2800000000002,
        "end": 140.30000000000018,
        "average": 102.79000000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.09195402298850576,
        "text_similarity": 0.16267836093902588,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (2130.0\u20132340.0s) are wildly inaccurate and inconsistent with the correct anchor/target times (2174\u20132180s and 2195.28\u20132199.7s), and the prediction even contradicts the required ordering; it also adds irrelevant visual detail."
      }
    },
    {
      "question_id": "002",
      "question": "During the man's explanation about preparing beforehand, when does he demonstrate by pointing to his neck?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.0,
        "end": 2237.0
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.009523809523809525,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 105.0,
        "end": 103.0,
        "average": 104.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21917808219178084,
        "text_similarity": 0.4996405243873596,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the man points to his neck during an explanation but fails to give the required event times (2235\u20132237) and provides incorrect speech times (2130\u20132340) plus irrelevant details, so it is largely inaccurate and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the man describes getting dizzy when walking up and down stairs, when does the woman mention repeating back what was heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2316.0,
        "end": 2317.0
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2520.0
      },
      "iou": 0.004761904761904762,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 203.0,
        "average": 104.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23999999999999996,
        "text_similarity": 0.5296519994735718,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely misidentifies both events and gives incorrect timestamps (introductions and 'final year medical student' instead of the man's dizziness and the woman's mention of repeating back). Although both label the temporal relation as 'after', the key events and times do not match the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman expresses her inability to distract herself from the pain, when does the man advise her to be specific?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.7,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2520.0
      },
      "iou": 0.0038095238095246756,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.69999999999982,
        "end": 150.5,
        "average": 104.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.26086956521739135,
        "text_similarity": 0.6495152711868286,
        "llm_judge_score": 2,
        "llm_judge_justification": "Although the predicted relation 'after' matches the reference, both event timestamps and described event content are incorrect (E1 and E2 times and contents do not align with the ground truth), indicating major factual mismatches and hallucination."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says 'document everything', when does the woman affirm the advice and tell viewers to take notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2504.5,
        "end": 2506.0
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2587.5
      },
      "iou": 0.015384615384615385,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.5,
        "end": 81.5,
        "average": 48.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3380281690140845,
        "text_similarity": 0.3944004774093628,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer's anchor and target times are far from the ground truth (2499.9s and 2504.5\u20132506.0s), and it misidentifies the anchor event timing; therefore it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes asking if one should ask permission before recording their doctor, when does the woman respond?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2531.6,
        "end": 2533.5
      },
      "pred_interval": {
        "start": 2587.5,
        "end": 2600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.90000000000009,
        "end": 66.5,
        "average": 61.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.2318840579710145,
        "text_similarity": 0.3075822591781616,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction misidentifies the anchor, gives timestamps that are ~56\u201369 seconds off the correct interval, and changes the event content, so it fails to match the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman begins explaining the hope that doctors will focus more on patients with AI recording, when does she explain why she almost always checks her online appointment notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.0,
        "end": 2579.0
      },
      "pred_interval": {
        "start": 2600.0,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 121.0,
        "average": 77.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.41734760999679565,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly identifies the anchor event (man at 2490.0s vs correct woman at 2556.7s) and gives target timestamps (2600.0\u20132700.0s) that do not match the correct interval (2566.0\u20132579.0s), so it fails to align with the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks if one should be assertive, when does he introduce the topic of emotional intelligence?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2701.0,
        "end": 2710.0
      },
      "pred_interval": {
        "start": 2706.5,
        "end": 2839.4
      },
      "iou": 0.025289017341040446,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.5,
        "end": 129.4000000000001,
        "average": 67.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.15584415584415584,
        "text_similarity": 0.4994116425514221,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the introductory utterance and its start (2706.5s falls within the 2701.0\u20132710.0s window), but it wrongly extends the end time to 2839.4s\u2014adding large, unfounded duration\u2014so it partly matches but is factually inaccurate about the timing/extent."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man says 'You wanna learn some breathing control', when does he start describing box breathing?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.0,
        "end": 2747.0
      },
      "pred_interval": {
        "start": 2839.4,
        "end": 2950.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 99.40000000000009,
        "end": 203.80000000000018,
        "average": 151.60000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.3174603174603174,
        "text_similarity": 0.7267988920211792,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives times that are far off from the reference (2839.4\u20132950.8s vs. 2740.0\u20132747.0s) and incorrectly states the description starts immediately with the prompt, contradicting the reference timing and duration."
      }
    },
    {
      "question_id": "002",
      "question": "While the man is saying 'If you want, share your story in the comments', when is the 'COMMENT BELOW' graphic displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 2992.0
      },
      "iou": 0.02112676056338028,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.0,
        "end": 69.0,
        "average": 69.5
      },
      "rationale_metrics": {
        "rouge_l": 0.10389610389610389,
        "text_similarity": 0.2523740231990814,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction contradicts the ground truth timing by saying the graphic appears after the speaker and remains until the end, while the reference specifies the graphic is displayed during the man's speech from 2920.0\u20132923.0s; the prediction omits the correct overlap and adds an unfounded \u2018until end\u2019 claim."
      }
    },
    {
      "question_id": "001",
      "question": "After Marissa Fourie introduces herself, when does she mention cross-cultural communication?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 34.2,
        "end": 36.5
      },
      "pred_interval": {
        "start": 23.4,
        "end": 58.6
      },
      "iou": 0.065340909090909,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.800000000000004,
        "end": 22.1,
        "average": 16.450000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.25396825396825395,
        "text_similarity": 0.614647388458252,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the temporal relation ('after') and approximate timing of the second event are roughly correct, the prediction misidentifies the content of E2 (it should be 'cross-cultural communication') and gives an incorrect E1 timing/identity, so it contains significant factual errors."
      }
    },
    {
      "question_id": "002",
      "question": "After mentioning cross-cultural communication, when does Marissa Fourie next mention personality-specific communication skills?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 37.0,
        "end": 39.0
      },
      "pred_interval": {
        "start": 59.0,
        "end": 71.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.0,
        "end": 32.400000000000006,
        "average": 27.200000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.2941176470588235,
        "text_similarity": 0.6189266443252563,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it misidentifies the anchor (wrong speaker/time) and the target content and timings differ substantially from the reference; while both state a sequential relation, the key factual elements and timestamps do not match."
      }
    },
    {
      "question_id": "003",
      "question": "After encouraging viewers to join PhysioPlus, when does Marissa Fourie say 'See you there!'?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 62.9,
        "end": 63.7
      },
      "pred_interval": {
        "start": 69.0,
        "end": 71.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.100000000000001,
        "end": 7.700000000000003,
        "average": 6.900000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.26086956521739135,
        "text_similarity": 0.5891600251197815,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction identifies entirely different timestamps, speaker/content (a male final-year student intro) and segments than the reference (Marissa saying 'join me on PhysioPlus' at ~48.6s and 'See you there!' at ~62.9s), so it fails to match the correct answer; only the generic 'after' relation coincidentally agrees."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes mentioning \"the dosage in each area\", when does the woman in blue gloves point to the glabella area of the patient's forehead?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 4.469,
        "end": 4.8
      },
      "pred_interval": {
        "start": 5.2,
        "end": 16.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7309999999999999,
        "end": 11.899999999999999,
        "average": 6.315499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1875,
        "text_similarity": 0.615397572517395,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction completely misidentifies both event timings and descriptions (E1 and E2 times differ greatly and E2 is described as speech not pointing); only the temporal relation ('after') matches, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the dosage for the brow lift, when does the woman in blue gloves point to the patient's upper lip?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 12.121,
        "end": 12.5
      },
      "pred_interval": {
        "start": 17.3,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.179,
        "end": 24.1,
        "average": 14.639500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.14084507042253522,
        "text_similarity": 0.6355817317962646,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction largely disagrees with the reference: it gives completely different timestamps (17.3s and 25.0\u201336.6s vs 12.080s and 12.121\u201312.500s) and a different temporal relation ('after' vs 'once_finished'), so it is mostly incorrect though it attempts to identify related events."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the dosage for the lip flip, when does the text \"TIME TO INJECT!\" appear on screen?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 18.291,
        "end": 21.0
      },
      "pred_interval": {
        "start": 36.6,
        "end": 48.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.309,
        "end": 27.0,
        "average": 22.6545
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.597186803817749,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely conflicts with the reference: both event timestamps and durations are incorrect, E1 is mischaracterized (intro vs finishing explanation), E2 is treated as spoken words rather than on-screen text and ends earlier than stated in the reference, and the relation differs; only the general ordering (E2 after E1) is preserved."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host welcomes Rich, when does Rich begin his response?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 33.015,
        "end": 34.078
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.03385350318471345,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.815,
        "end": 2.5219999999999985,
        "average": 15.1685
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6211949586868286,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that Rich's response occurs after the host, but the reported anchor time (5.2s vs 31.333s) and the target start time (35.0s vs 33.015s) are inaccurate and an extra end time is hallucinated, so key factual timings are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While Rich is explaining how medicine may have let relationships with patients deteriorate, when does he say that scientific facts will protect us?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 89.0,
        "end": 93.76
      },
      "pred_interval": {
        "start": 35.0,
        "end": 74.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.0,
        "end": 19.36,
        "average": 36.68
      },
      "rationale_metrics": {
        "rouge_l": 0.1875,
        "text_similarity": 0.5576557517051697,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timings and relation are completely incorrect: E1 and E2 start/end times do not match the reference (predicted E2 occurs much earlier and is not within the stated E1), so the answer fails to align with the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks what trust looks like in the future with intermediaries, when does Rich first discuss the stethoscope in relation to technology in medicine?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 112.0,
        "end": 113.0
      },
      "pred_interval": {
        "start": 108.0,
        "end": 158.4
      },
      "iou": 0.01984126984126984,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 45.400000000000006,
        "average": 24.700000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962025,
        "text_similarity": 0.8147075176239014,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the stethoscope remark and that it occurs after the host's question, but the timestamps are inaccurate (gives the anchor start rather than the anchor end and lists a different start time for the stethoscope segment than the reference)."
      }
    },
    {
      "question_id": "001",
      "question": "After the man in glasses finishes describing the giant TV screen in a new hospital exam room, when does the video show a patient interacting with a screen in a hospital bed?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 167.6,
        "end": 177.6
      },
      "pred_interval": {
        "start": 150.0,
        "end": 228.0
      },
      "iou": 0.1282051282051282,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.599999999999994,
        "end": 50.400000000000006,
        "average": 34.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21917808219178084,
        "text_similarity": 0.43210309743881226,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the sequence (man in glasses describing the screen then a cut to a patient with a screen) but omits the key factual details from the reference\u2014explicit timestamps and the precise anchor/target timing\u2014which reduces completeness."
      }
    },
    {
      "question_id": "002",
      "question": "While the interviewer asks if technology can bring doctors and patients closer together, when is he holding a small white 'Trust tv' card?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 178.0,
        "end": 183.5
      },
      "pred_interval": {
        "start": 150.0,
        "end": 228.0
      },
      "iou": 0.07051282051282051,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.0,
        "end": 44.5,
        "average": 36.25
      },
      "rationale_metrics": {
        "rouge_l": 0.12307692307692307,
        "text_similarity": 0.32054904103279114,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the interviewer holds the 'Trust tv' card during the interview but fails to provide the requested temporal information (178.0s\u2013183.5s) or state that the holding spans the entire anchor speech, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the interviewer thanks Rich and says viewers learned a lot, when does Rich respond 'It's really a pleasure'?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 210.3,
        "end": 212.1
      },
      "pred_interval": {
        "start": 150.0,
        "end": 228.0
      },
      "iou": 0.02307692307692286,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 60.30000000000001,
        "end": 15.900000000000006,
        "average": 38.10000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.27692307692307694,
        "text_similarity": 0.4310939311981201,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the sequence\u2014that Rich speaks after the interviewer thanks him and mentions viewers learning a lot\u2014but it omits the key timing details (specific start/end timestamps and the immediate follow-on) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions learning about 'patient rapport', when does he discuss charting and interacting with other healthcare providers?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 2.075,
        "end": 9.55
      },
      "pred_interval": {
        "start": 25.7,
        "end": 49.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.625,
        "end": 40.25,
        "average": 31.9375
      },
      "rationale_metrics": {
        "rouge_l": 0.37037037037037035,
        "text_similarity": 0.6684737801551819,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that discussion of charting follows the mention of patient rapport, but it omits the precise timestamps and the explicit 'immediately follows' (once_finished) relation given in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker talks about developing skills like putting an IV, when does he mention getting a patient discharged?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 15.42,
        "end": 24.583
      },
      "pred_interval": {
        "start": 43.5,
        "end": 59.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.08,
        "end": 35.217,
        "average": 31.6485
      },
      "rationale_metrics": {
        "rouge_l": 0.18461538461538463,
        "text_similarity": 0.4102620482444763,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the discharge mention follows the discussion of putting an IV (once_finished), but it omits the specific timestamps and explicit note that the target immediately follows the anchor."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Make their problem, your problem', when does he introduce the importance of self-care?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 45.009,
        "end": 48.396
      },
      "pred_interval": {
        "start": 50.5,
        "end": 60.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.491,
        "end": 11.604,
        "average": 8.5475
      },
      "rationale_metrics": {
        "rouge_l": 0.2153846153846154,
        "text_similarity": 0.6087685823440552,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that the self-care point comes after 'Make their problem, your problem', but it omits the specific timing (45.009s-48.396s) and exact phrasing provided in the reference, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker's introduction of herself, when does she mention specializing in wounds?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.605,
        "end": 26.329
      },
      "pred_interval": {
        "start": 2.5,
        "end": 4.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.105,
        "end": 21.529,
        "average": 20.817
      },
      "rationale_metrics": {
        "rouge_l": 0.2456140350877193,
        "text_similarity": 0.4924543499946594,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the specialization is mentioned during the speaker's introduction but gives incorrect timestamps (2.5\u20134.8s vs. ~0.18\u20130.26s) and omits the precise name/time detail, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of 'getting the most out of your GP consultation', when does she mention that GP practices are getting a huge injection of funding?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.82,
        "end": 75.533
      },
      "pred_interval": {
        "start": 63.5,
        "end": 84.5
      },
      "iou": 0.36728571428571466,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.319999999999993,
        "end": 8.966999999999999,
        "average": 6.643499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.2105263157894737,
        "text_similarity": 0.5395299196243286,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly places the funding mention after the slide appears and its 63.5\u201384.5s window includes the true 67.82\u201375.53s interval, but it fails to give the specific timestamps and is imprecise about when the funding comment occurs."
      }
    },
    {
      "question_id": "003",
      "question": "While the slide titled 'Appointments are precious' is on screen, when does the speaker mention that GP practices are moving back towards face-to-face appointments?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 123.0,
        "end": 129.0
      },
      "pred_interval": {
        "start": 101.5,
        "end": 123.5
      },
      "iou": 0.01818181818181818,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.5,
        "end": 5.5,
        "average": 13.5
      },
      "rationale_metrics": {
        "rouge_l": 0.4166666666666667,
        "text_similarity": 0.9107657074928284,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the mention occurs while the slide is on screen but gives incorrect time ranges: the slide appears at ~100.74 and remains, and the speaker's remark is 123.0\u2013129.0, whereas the prediction claims 101.5\u2013123.5, only overlapping briefly and misrepresenting durations."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that GP practices are very different places now, when does she begin listing the specific roles in a GP practice?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.0,
        "end": 204.0
      },
      "pred_interval": {
        "start": 153.9,
        "end": 204.6
      },
      "iou": 0.019723865877712035,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.099999999999994,
        "end": 0.5999999999999943,
        "average": 24.849999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.24137931034482757,
        "text_similarity": 0.533011257648468,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the relation ('after') but omits key factual details from the reference\u2014no timestamps (185.8s and 203.0\u2013204.0s) and no mention that the listing begins with 'GP's'\u2014so it's incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide displays the question 'Does it need to be a GP?', when does the speaker mention that paramedics work in primary care?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "pred_interval": {
        "start": 180.5,
        "end": 209.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.5,
        "end": 30.099999999999994,
        "average": 42.3
      },
      "rationale_metrics": {
        "rouge_l": 0.2105263157894737,
        "text_similarity": 0.447181761264801,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction vaguely indicates the comment occurs later (after discussing GP practice roles) but omits the key anchor to the slide change and the timing details (235\u2013240s) provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker talks about paramedics working in primary care, when does she begin to explain the role of Advanced Clinical Practitioners?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 241.0,
        "end": 249.0
      },
      "pred_interval": {
        "start": 216.1,
        "end": 245.7
      },
      "iou": 0.1428571428571425,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.900000000000006,
        "end": 3.3000000000000114,
        "average": 14.100000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.4891624450683594,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the relative relation ('after') that the speaker begins discussing Advanced Clinical Practitioners after paramedics, but it omits the specific timing (around 241.0s start) provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the problem of a wound on your foot, when does she strongly advise mentioning if you are diabetic?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 337.875,
        "end": 343.0
      },
      "pred_interval": {
        "start": 335.7,
        "end": 368.4
      },
      "iou": 0.1567278287461774,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.1750000000000114,
        "end": 25.399999999999977,
        "average": 13.787499999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.07116743922233582,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly indicates the discussion begins around 335.7s and that the diabetic-warning comes immediately after the introduction, but it omits the precise timestamp for the advice (\u2248337.9s) and is vague about timing ('once finished')."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having a new wound on your leg, when does she suggest going to a local pharmacist for simple dressings?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 363.968,
        "end": 366.552
      },
      "pred_interval": {
        "start": 368.4,
        "end": 401.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.4319999999999595,
        "end": 34.548,
        "average": 19.48999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.136986301369863,
        "text_similarity": 0.25403016805648804,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is largely incorrect: it gives the wrong timestamp (368.4s vs the correct 356.666\u2013358.0s/relative times) and misstates the context (says after discussing pain rather than after nurse appointments), so it fails to match key facts."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker explains that a nurse's appointment is needed for long-standing wounds, when does she advise to clearly state how long the wound has been there?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 409.579,
        "end": 439.62
      },
      "pred_interval": {
        "start": 401.1,
        "end": 433.8
      },
      "iou": 0.6287902388369682,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.478999999999985,
        "end": 5.819999999999993,
        "average": 7.149499999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.10256410256410256,
        "text_similarity": 0.2750432789325714,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives an incorrect timestamp (401.1s vs. ~424.5\u2013440.0s/439.98\u2013448.52s) and adds an unfounded detail that the advice comes 'after discussing the pain and discomfort,' which contradicts the reference that the advice follows immediately; thus it fails to match the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if you feel more short of breath, when does she state that a GP or nurse practitioner might be needed the same day?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 522.783,
        "end": 525.113
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 517.583,
        "end": 488.51300000000003,
        "average": 503.048
      },
      "rationale_metrics": {
        "rouge_l": 0.2972972972972973,
        "text_similarity": 0.6963120698928833,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives completely different timestamps, events, and content that do not match the reference anchor/target or their relation; it is factually incorrect and unrelated to the correct segments."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to measure your ankle and calf, when does she give an example of a calf measurement that would 'perk up more interest'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.623,
        "end": 586.297
      },
      "pred_interval": {
        "start": 35.0,
        "end": 40.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 548.623,
        "end": 545.597,
        "average": 547.11
      },
      "rationale_metrics": {
        "rouge_l": 0.3283582089552239,
        "text_similarity": 0.709295392036438,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives entirely different timestamps, speakers, and quoted content unrelated to the correct example; it fails to match the ground-truth segment or timings and thus is essentially incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Photography', when does the speaker advise to 'expect to be asked for a photo'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 670.384,
        "end": 672.807
      },
      "pred_interval": {
        "start": 60.0,
        "end": 720.0
      },
      "iou": 0.0036712121212121238,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 610.384,
        "end": 47.192999999999984,
        "average": 328.7885
      },
      "rationale_metrics": {
        "rouge_l": 0.24691358024691357,
        "text_similarity": 0.7707384824752808,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps and segment boundaries contradict the ground truth (predicted times are far off from 650.676\u2013672.807s), and it introduces incorrect/unsupported content and relationship, so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions some GP practices use video consultations, when does she state that a good quality photograph is better than a video?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.278,
        "end": 717.251
      },
      "pred_interval": {
        "start": 692.5,
        "end": 738.4
      },
      "iou": 0.06477124183006444,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.77800000000002,
        "end": 21.149,
        "average": 21.46350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.29508196721311475,
        "text_similarity": 0.4852418899536133,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the gist that a photograph is preferred over a video and implies it occurs afterward, but it omits the required timestamps and uses a different anchor ('after talking about a close-up picture') instead of the precise timing relation in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the slide changes to 'Photography tips', when does the speaker begin discussing taking a close-up and further-away picture?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 738.601,
        "end": 740.91
      },
      "pred_interval": {
        "start": 738.4,
        "end": 774.3
      },
      "iou": 0.06431754874651728,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.20100000000002183,
        "end": 33.389999999999986,
        "average": 16.795500000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.32786885245901637,
        "text_similarity": 0.6139417290687561,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the slide change precedes the discussion, but it omits the required timestamps and wrongly frames the relation as occurring after the speaker finishes discussing the close-up; key temporal details are missing and the relation is misstated."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide changes to 'General top tips- face to face appointments', when does the speaker advise to 'Go suitably dressed'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 860.136,
        "end": 860.846
      },
      "pred_interval": {
        "start": 774.3,
        "end": 800.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 85.83600000000001,
        "end": 60.64599999999996,
        "average": 73.24099999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2424242424242424,
        "text_similarity": 0.5349836349487305,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that 'Go suitably dressed' occurs after the speaker discusses close-up and further-away pictures), but it omits the key numeric timestamps (E1=805.957s, E2=860.136s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises not to wear tight socks, trousers, or wellies, when does she suggest wearing something with quick access to lower limbs?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.0,
        "end": 877.5
      },
      "pred_interval": {
        "start": 875.0,
        "end": 906.0
      },
      "iou": 0.07575757575757576,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 28.5,
        "average": 15.25
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367346,
        "text_similarity": 0.4800559878349304,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates when the warning against tight clothing begins (870.0s) and fails to provide the timing (873.0\u2013877.5s) or mention that the accessible-clothing suggestion comes after, omitting the key event asked for."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes advising not to make chit-chat about the weather, when does she advise not to dodge the real problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 893.0,
        "end": 894.5
      },
      "pred_interval": {
        "start": 913.4,
        "end": 938.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.399999999999977,
        "end": 43.5,
        "average": 31.94999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424246,
        "text_similarity": 0.6936218738555908,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly identifies the 'once finished' relation but the temporal intervals are drastically different from the ground truth (913.4\u2013938.0s vs. 888.297\u2013890.0s and 893.0\u2013894.5s), so the timing information is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker advises to take a list of the medications you are actually taking, when does she advise against describing tablets by their appearance?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 948.0,
        "end": 969.0
      },
      "pred_interval": {
        "start": 943.0,
        "end": 968.0
      },
      "iou": 0.7692307692307693,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 5.0,
        "end": 1.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.358974358974359,
        "text_similarity": 0.6159772872924805,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relation but misstates both event timings and misattributes the E1 cue (timestamps differ significantly from 935.297\u2013938.967 for E1 and 948.0\u2013969.0 for E2), so it is largely incorrect. "
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker advises speaking to the practice in advance about a relative, when does she explain the reason for this advance arrangement due to confidentiality?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1065.0,
        "end": 1095.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.14285714285714285,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.0,
        "end": 165.0,
        "average": 90.0
      },
      "rationale_metrics": {
        "rouge_l": 0.23880597014925373,
        "text_similarity": 0.4950386881828308,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction recognises an advance-advice and a later explanation but gives incorrect timestamps (saying 1050.0s vs the correct 1055.0s end and 1173.4s vs the correct 1065.0\u20131095.0s window) and adds an unfounded claim about 'listing top tips', contradicting the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker suggests writing things down before an appointment to help structure what you say, when does she first ask 'How did it start?' regarding the leg problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1130.415,
        "end": 1131.738
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.0063000000000004415,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.41499999999996,
        "end": 128.26199999999994,
        "average": 104.33849999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.38805970149253727,
        "text_similarity": 0.44814684987068176,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction references the correct events but gives significantly incorrect timestamps for both (1050.0s vs 1130.0s and 1173.4s vs 1130.415s) and omits the correct immediate 'once_finished' relation, so it does not match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes advising to ask to be referred to a specialist service, when does she start introducing the referrals examples?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.105,
        "end": 1249.385
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.006095238095237965,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.105000000000018,
        "end": 190.615,
        "average": 104.36000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.13043478260869565,
        "text_similarity": 0.29049283266067505,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the sequence (the referrals examples come after the advice) but omits the key timing details and precise event timestamps/duration provided in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that lymphoedema services can be patchy, when does she first advise writing to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.0,
        "end": 1378.0
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.004761904761904762,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 147.0,
        "end": 62.0,
        "average": 104.5
      },
      "rationale_metrics": {
        "rouge_l": 0.35555555555555557,
        "text_similarity": 0.5873475074768066,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not provide the requested timing; it merely restates the relation without the timestamp (1377\u20131378s) required by the correct answer, thus omitting the key factual element."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions that a GP will assess new leg swelling for onward referral, when does she explain there are many different causes?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1429.846,
        "end": 1432.0
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.01025714285714284,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 199.846,
        "end": 8.0,
        "average": 103.923
      },
      "rationale_metrics": {
        "rouge_l": 0.27692307692307694,
        "text_similarity": 0.7951297760009766,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits the precise timestamps and interval given in the reference (E1 at 1405s; E2 at 1429.846\u20131432.0), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what information you could take with you, when does she suggest looking up the National Wound Care Strategy Lower Limb Recommendations?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1465.0,
        "end": 1469.5
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1495.0
      },
      "iou": 0.05625,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.0,
        "end": 25.5,
        "average": 37.75
      },
      "rationale_metrics": {
        "rouge_l": 0.1935483870967742,
        "text_similarity": 0.20873212814331055,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the suggestion follows the question (implying sequence) but omits the precise timing information and explicit 'after' relation provided in the reference, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions escalating concerns to the practice manager, when does she mention escalating concerns to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.6,
        "end": 1525.7
      },
      "pred_interval": {
        "start": 1426.0,
        "end": 1530.0
      },
      "iou": 0.020192307692309005,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.59999999999991,
        "end": 4.2999999999999545,
        "average": 50.94999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.51276695728302,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the sequence (practice manager then MP) but omits the precise timestamps, the start/end times for each event, and the explicit 'next' relation specified in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'I'll stop sharing', when does she start reading the first question from a viewer?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1574.5,
        "end": 1578.5
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1770.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.5,
        "end": 191.5,
        "average": 103.5
      },
      "rationale_metrics": {
        "rouge_l": 0.31578947368421056,
        "text_similarity": 0.5296622514724731,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the speaker begins reading a question after saying 'I'll stop sharing', but it omits all precise timing (start/end timestamps and the 'once_finished' relation detail) from the reference, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially suggests the mum needs compression hosiery, when does she mention asking for an appointment with the nurse for stronger compression?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1654.942,
        "end": 1664.2
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1638.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.94200000000001,
        "end": 25.799999999999955,
        "average": 45.37099999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2711864406779661,
        "text_similarity": 0.5245507955551147,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the nurse appointment suggestion comes after the hosiery advice) but omits the key factual details from the reference\u2014specifically the start/end timestamps and event labels\u2014so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'That is such a good question', when does she state that self-diagnosis via the internet is never a good idea?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1757.815,
        "end": 1762.821
      },
      "pred_interval": {
        "start": 1638.4,
        "end": 1708.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 119.41499999999996,
        "end": 54.82099999999991,
        "average": 87.11799999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290322,
        "text_similarity": 0.4505649507045746,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relation (the statement occurs after the anchor) but omits the precise timestamps and implies immediate succession, whereas the correct answer specifies the target starts ~74.8 seconds later (1757.815s) and includes exact start/end times."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes that approaching a GP is about framing the conversation, when does she tell the viewer not to worry about being labeled a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1795.335,
        "end": 1798.383
      },
      "pred_interval": {
        "start": 1708.0,
        "end": 1800.0
      },
      "iou": 0.033130434782608714,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 87.33500000000004,
        "end": 1.6169999999999618,
        "average": 44.476
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.19866721332073212,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately conveys the key relation that the 'don't worry about being labeled a difficult patient' remark occurs after the comment about framing the conversation, matching the reference; it omits timestamps but preserves the intended meaning."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker first says, 'Please don't worry about things like that', when does she next advise not to worry about being labelled as a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1827.66,
        "end": 1831.19
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1822.46,
        "end": 1794.5900000000001,
        "average": 1808.525
      },
      "rationale_metrics": {
        "rouge_l": 0.059701492537313446,
        "text_similarity": 0.15467208623886108,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the key time-stamp information (E2 at 1827.66s\u20131831.19s) given in the correct answer, and it introduces an unverified detail about 'leg problems' that is not in the reference, so it fails to accurately match the specific next instance."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks, 'What can I do to maintain healthy legs or feet so I don't get any problems?', when does she start listing actions like 'walk' and 'legs up'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1865.412,
        "end": 1883.383
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1830.412,
        "end": 1846.7830000000001,
        "average": 1838.5975
      },
      "rationale_metrics": {
        "rouge_l": 0.13559322033898305,
        "text_similarity": 0.3842894434928894,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and only restates that the actions occur after the question; it omits the key factual elements (the specific anchor/target timestamps and explicit mention of the 'walk, legs up' timing) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks how much is in the GP curriculum, when does she say 'I don't know'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1983.7,
        "end": 1984.201
      },
      "pred_interval": {
        "start": 205.7,
        "end": 218.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1778.0,
        "end": 1765.301,
        "average": 1771.6505
      },
      "rationale_metrics": {
        "rouge_l": 0.09302325581395349,
        "text_similarity": 0.10111246258020401,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and only restates that the phrase occurs afterward; it omits the key factual details (the precise anchor/target timestamps and that the target immediately follows the anchor) required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'I think it is something that Legs Matter can help with', when does she discuss Legs Matter influencing GP curriculums?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2004.063,
        "end": 2009.063
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2160.0
      },
      "iou": 0.023809523809523808,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.0630000000001,
        "end": 150.9369999999999,
        "average": 102.5
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.04753828048706055,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the discussion occurs after the quoted line (the relative ordering), but it omits the key factual details\u2014the specific anchor/target time ranges\u2014required by the question."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks if seeing a nurse practitioner is appropriate, when does she state that nurse practitioners are 'extremely experienced clinicians'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2062.584,
        "end": 2066.851
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2160.0
      },
      "iou": 0.020319047619048954,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 112.58399999999983,
        "end": 93.14899999999989,
        "average": 102.86649999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.08,
        "text_similarity": -0.10745465010404587,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the timing\u2014saying the phrase occurs when she asks the question\u2014whereas the correct answer specifies it occurs immediately after the question with precise timestamps; it also omits those timestamps."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I understand the issue of smartphones and taking pictures too\", when does she first ask \"is there somebody who can help you?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2174.0,
        "end": 2176.0
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2318.5
      },
      "iou": 0.010610079575596816,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.0,
        "end": 142.5,
        "average": 93.25
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.03685171157121658,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states the temporal relation\u2014the question is asked about 1 second after the prior utterance\u2014matching the reference (anchor ends at 2173s, target begins at 2174s); only absolute timestamps are omitted."
      }
    },
    {
      "question_id": "002",
      "question": "During the period when the speaker discusses the importance of planning phone calls to the GP, when does she ask, \"What am I feeling?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2197.721,
        "end": 2198.663
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2318.5
      },
      "iou": 0.00499734748010614,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.721,
        "end": 119.83699999999999,
        "average": 93.779
      },
      "rationale_metrics": {
        "rouge_l": 0.14545454545454545,
        "text_similarity": 0.14515164494514465,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the question is asked during the discussion but gives an ambiguous and incorrect timing ('after 1 second') and omits the precise timestamps (2197.721\u20132198.663 within 2057.721\u20132207.721), so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once Dr. Angelos finishes introducing Dr. Tolchin, when does Dr. Tolchin begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.128,
        "end": 109.393
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 99.928,
        "end": 72.793,
        "average": 86.3605
      },
      "rationale_metrics": {
        "rouge_l": 0.19718309859154928,
        "text_similarity": 0.5559086799621582,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: timestamps and event content do not match the reference (predicted E1/E2 occur much earlier and describe different utterances), and while both state an 'after' relation, the predicted temporal offsets and durations contradict the ground truth once_finished timing."
      }
    },
    {
      "question_id": "002",
      "question": "After Dr. Angelos describes Dr. Tolchin's research on crisis standards of care, when does he describe his research on functional neurological disorders and epilepsy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.426,
        "end": 116.456
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.426000000000002,
        "end": 79.856,
        "average": 50.641
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5145715475082397,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives completely different time segments and content for both events and does not identify the correct E1/E2 intervals; it contradicts the reference and fails to locate the described research on functional neurological disorders and epilepsy."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating the second learning objective, when does he start explaining the third learning objective?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 181.0
      },
      "pred_interval": {
        "start": 23.8,
        "end": 45.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 143.2,
        "end": 135.4,
        "average": 139.3
      },
      "rationale_metrics": {
        "rouge_l": 0.2647058823529412,
        "text_similarity": 0.6090729832649231,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer mostly contradicts the reference: event timestamps, spans, and described content are incorrect (different start/ end times and events), though both state the relation as 'after', so it is not completely unrelated."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'Why conduct clinical ethics consultations?' is displayed, when does the speaker discuss moral distress among clinicians and staff?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.4,
        "end": 304.0
      },
      "pred_interval": {
        "start": 153.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 132.39999999999998,
        "end": 94.0,
        "average": 113.19999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.31746031746031744,
        "text_similarity": 0.6693982481956482,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the speaker discusses moral distress but is factually incorrect about the slide timing ('throughout the video') and gives a vague, unsupported temporal relation (after the second learning objective) rather than the correct 'during' interval with timestamps; it omits the key timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that clinical ethics consultations were helpful, when does he state that they were more likely to achieve consensus in clinical decisions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 350.2,
        "end": 357.0
      },
      "pred_interval": {
        "start": 335.7,
        "end": 468.9
      },
      "iou": 0.05105105105105114,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.5,
        "end": 111.89999999999998,
        "average": 63.19999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307691,
        "text_similarity": -0.00223727710545063,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation ('after' / 'once finished') but omits the required specific timestamps and start/end times given in the correct answer, so it is only partially complete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of resource utilization, when does he specifically state that there was a reduced length of stay?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 438.9,
        "end": 450.3
      },
      "pred_interval": {
        "start": 470.5,
        "end": 681.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.600000000000023,
        "end": 231.40000000000003,
        "average": 131.50000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.04081632653061224,
        "text_similarity": 0.21230988204479218,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and lacks all required timestamp details and the explicit temporal relation; it only vaguely implies the statement occurred after the introduction, failing to match the precise times and relation in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'to look at disparities', when does he begin to introduce Ellen Fox's team and their survey?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 493.5,
        "end": 499.0
      },
      "pred_interval": {
        "start": 683.3,
        "end": 894.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 189.79999999999995,
        "end": 395.5,
        "average": 292.65
      },
      "rationale_metrics": {
        "rouge_l": 0.18867924528301885,
        "text_similarity": 0.2557087540626526,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates the temporal relation ('once finished') without providing the required timestamps or precise timing (393.0s, 493.5\u2013499.0s) and is therefore largely incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'hospitals with less than 400 beds', when does he mention 'little or no growth over that two decade period'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 527.809,
        "end": 530.91
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 522.6089999999999,
        "end": 494.30999999999995,
        "average": 508.45949999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.1518987341772152,
        "text_similarity": 0.5676376819610596,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect: it gives wrong timestamps and unrelated utterances for both anchor and target, and misstates the temporal relationship; it contradicts the reference events."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide titled 'Prior Healthcare System Ethics Committees' is fully displayed, when do the images of the six hospitals with their bed counts appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.7,
        "end": 552.0
      },
      "pred_interval": {
        "start": 37.4,
        "end": 66.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 514.3000000000001,
        "end": 485.2,
        "average": 499.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3380281690140845,
        "text_similarity": 0.43530598282814026,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (images appear after the slide) but the timestamps are vastly incorrect compared to the reference (predicted 37.4s\u219266.8s vs. actual 536.2s\u2192551.7\u2013552.0s), so it fails on factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the number of ethics consults at Yale New Haven Hospital increased from 50 to 239, when does he describe this as 'approximately a five-fold increase in consult volume'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.7,
        "end": 624.7
      },
      "pred_interval": {
        "start": 67.6,
        "end": 97.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 555.1,
        "end": 527.7,
        "average": 541.4000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.46511627906976744,
        "text_similarity": 0.4632526934146881,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (67.6\u201397.0s) completely mismatch the correct timing (622.7\u2013624.7s) for when the speaker calls it 'approximately a five-fold increase,' so it fails to identify the correct moment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially mentions the 'Community Bioethics Forum', when does he start describing its community members?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 887.216,
        "end": 905.918
      },
      "pred_interval": {
        "start": 870.0,
        "end": 934.5
      },
      "iou": 0.289953488372093,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.216000000000008,
        "end": 28.581999999999994,
        "average": 22.899
      },
      "rationale_metrics": {
        "rouge_l": 0.1923076923076923,
        "text_similarity": 0.5802017450332642,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the description occurs after the mention, but it gives an incorrect anchor time (870.0s vs. 882.782\u2013885.106s) and omits the target description timestamps (887.216\u2013905.918s), so it is factually inaccurate and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that the primary focus of the Center for Clinical Ethics has been ethics education, when does he start listing 'Systemwide Ethics Forum and Newsletter'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1055.54,
        "end": 1069.28
      },
      "pred_interval": {
        "start": 934.5,
        "end": 1080.0
      },
      "iou": 0.09443298969072171,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 121.03999999999996,
        "end": 10.720000000000027,
        "average": 65.88
      },
      "rationale_metrics": {
        "rouge_l": 0.26415094339622636,
        "text_similarity": 0.4365556240081787,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly implies the mention occurs later, but it references the wrong preceding item ('Community Bioethics Forum' instead of the ethics education statement) and omits the specific timing details, so it does not match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker lists 'ICU Walk Rounds', when does he mention 'HEC-C Certification'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1048.0,
        "end": 1052.0
      },
      "pred_interval": {
        "start": 1080.0,
        "end": 1170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.0,
        "end": 118.0,
        "average": 75.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2040816326530612,
        "text_similarity": 0.6023746728897095,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that 'HEC-C Certification' occurs after 'ICU Walk Rounds') but omits the key factual details (the exact timestamps and 'next' relation formatted as in the reference), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"ethics consultation services,\" when does he start talking about collecting feedback?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.8,
        "end": 1249.8
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1380.0
      },
      "iou": 0.06,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.799999999999955,
        "end": 130.20000000000005,
        "average": 70.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1639344262295082,
        "text_similarity": 0.5198140740394592,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction bears no semantic or temporal alignment with the reference: it identifies entirely different segments and timestamps and gives an incorrect relation ('after' vs. 'once_finished'), so it fails to match the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that participant satisfaction is not the \"be-all and end-all,\" when does he say they have begun the survey process with clinicians?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.3,
        "end": 1282.8
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.02142857142857143,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.299999999999955,
        "end": 157.20000000000005,
        "average": 102.75
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.5224272012710571,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer identifies entirely different events and timestamps (intro and 'I am a final year medical student') that do not match the reference events or times, and thus fails to capture the correct relation and content."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes describing the first pie chart about helpful advice/guidance, when does the second pie chart about communication appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1367.5,
        "end": 1367.9
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.0019047619047623378,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 137.5,
        "end": 72.09999999999991,
        "average": 104.79999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.5408607721328735,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect: both event timestamps and described events do not match (5.2s/35.0s vs 1356.0s/1376.5s), and the relation ('after') does not correspond to the correct 'once_finished' relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he wants to turn to some of the organizational ethics consultation work, when does the slide showing the 'Organizational ethics consultations' table appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1472.0,
        "end": 1472.5
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1620.0
      },
      "iou": 0.0024390243902439024,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.0,
        "end": 147.5,
        "average": 102.25
      },
      "rationale_metrics": {
        "rouge_l": 0.15873015873015872,
        "text_similarity": 0.4429172873497009,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the slide appears after the speaker's introduction, but it omits the precise timestamps and falsely asserts it appears 'immediately' afterward (actual slide change occurs ~34 seconds later), so it is incomplete and temporally inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining that organizational ethics work is new to them, when do they state that it began during the COVID pandemic?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1469.5,
        "end": 1472.0
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1620.0
      },
      "iou": 0.012195121951219513,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.5,
        "end": 148.0,
        "average": 101.25
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.33334314823150635,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states it began during COVID but gives an incorrect timestamp (~1530.0s vs. the correct ~1469.5\u20131472.0s) and omits the consecutive event timing detail, so it is largely wrong on timing and completeness."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the 'Organizational ethics consultations' table, when does the speaker mention the 'Blood products scarcity protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1510.0,
        "end": 1513.0
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1620.0
      },
      "iou": 0.014634146341463415,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 95.0,
        "end": 107.0,
        "average": 101.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3214285714285714,
        "text_similarity": 0.7046653032302856,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the mention occurs while the table is displayed, but it gives an inaccurate timestamp (~1530s vs the actual 1510\u20131513s) and omits the precise time range."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the 'sequential organ failure assessment or SOFA score', when does he begin to explain what it is?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1647.6,
        "end": 1697.0
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1642.3999999999999,
        "end": 1660.4,
        "average": 1651.4
      },
      "rationale_metrics": {
        "rouge_l": 0.27848101265822783,
        "text_similarity": 0.5739962458610535,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is fundamentally incorrect: the reported anchor/target timestamps and quoted utterance do not match the reference intervals or content, and it fails to identify the actual explanation that follows the SOFA score introduction."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that '70% of publicly available crisis standards of care used either the SOFA score or a modified version', when does he mention the SOFA score being used in Alaska?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1726.0,
        "end": 1733.0
      },
      "pred_interval": {
        "start": 70.4,
        "end": 118.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1655.6,
        "end": 1614.6,
        "average": 1635.1
      },
      "rationale_metrics": {
        "rouge_l": 0.3692307692307692,
        "text_similarity": 0.6381547451019287,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps and spans (70.4s / 70.4\u2013118.4s) do not match the ground-truth segments (1705.0\u20131712.0s and 1726.0\u20131733.0), and the predicted relationship/spans are incorrect, so it fails to identify the correct example."
      }
    },
    {
      "question_id": "003",
      "question": "Once the 'SOFA Disparities' slide appears, when does the speaker begin discussing concerns about the score's accuracy and contributions to disparities?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1770.0,
        "end": 1776.606
      },
      "pred_interval": {
        "start": 119.0,
        "end": 180.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1651.0,
        "end": 1596.606,
        "average": 1623.8029999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.4137931034482759,
        "text_similarity": 0.7200567722320557,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps and durations are completely different from the reference (119s vs 1762\u20131776s) and the described relationship ('once finished') contradicts the correct note that the speaker immediately addresses the slide, so the prediction is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that the center was able to test the triage protocol before it was used, when does he state that they developed a SOFA calculation system?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1799.553,
        "end": 1807.997
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1794.353,
        "end": 1771.3970000000002,
        "average": 1782.875
      },
      "rationale_metrics": {
        "rouge_l": 0.23684210526315788,
        "text_similarity": 0.6379215717315674,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives completely different event times and descriptions that do not match the ground-truth anchor/target intervals or content; the only shared relation ('after') is insufficient to compensate for the factual mismatches."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the retrospective cohort study, when does he detail the demographic breakdown of the patients?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1846.122,
        "end": 1858.077
      },
      "pred_interval": {
        "start": 37.4,
        "end": 66.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1808.722,
        "end": 1791.277,
        "average": 1799.9995
      },
      "rationale_metrics": {
        "rouge_l": 0.28205128205128205,
        "text_similarity": 0.6230478286743164,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the demographics follow the study introduction, but the timestamps and event boundaries are completely different from the reference (major factual mismatch in timing), so it largely fails to match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker highlights that non-Hispanic Black patients had greater odds of an elevated SOFA score, when does he state that no significant difference by race in mortality was found when controlling for other factors?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.642,
        "end": 1879.694
      },
      "pred_interval": {
        "start": 67.6,
        "end": 97.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1806.0420000000001,
        "end": 1782.694,
        "average": 1794.368
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.6976107358932495,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gets the general relation (E2 follows E1) but the timestamps and segment boundaries are completely different from the ground truth, so it fails to correctly locate the statements in the video."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the early small cohort out of Wuhan, China, when does he state that subsequent larger cohorts in the United States did not show such high accuracy rates?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.0,
        "end": 1966.5
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2160.0
      },
      "iou": 0.03571428571428571,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.0,
        "end": 193.5,
        "average": 101.25
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.2787851095199585,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates the speaker's claim but omits the required temporal information (the specific start/end times and anchor/target events). It therefore fails to answer the 'when' aspect specified in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'This graph here is a calibration curve', when does he explain that the diagonal line shows a perfectly calibrated predictor of mortality?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2014.0,
        "end": 2020.0
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2160.0
      },
      "iou": 0.02857142857142857,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.0,
        "end": 140.0,
        "average": 102.0
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.42008793354034424,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the speaker explains the diagonal line represents a perfectly calibrated predictor, but it fails to provide the required timing information (the anchor/target timestamps and the note about relative timing), so it is incomplete for the 'when' question."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that SOFA predicted mortality with less accuracy than age in their own COVID cohort, when does he mention that SOFA predicted mortality with better accuracy than age in the pre-COVID eICU cohort?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2066.0,
        "end": 2069.0
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2160.0
      },
      "iou": 0.014285714285714285,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 116.0,
        "end": 91.0,
        "average": 103.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.33341309428215027,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the semantic point that SOFA was later said to predict mortality better in the pre-COVID eICU cohort, but it fails to provide the required timing information (anchor/target timestamps and the quoted contrast phrase), so it is incomplete for the question asked."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the Omicron surge increasing, when does he talk about working with the healthcare system's legal team?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2153.6,
        "end": 2174.93
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2160.0
      },
      "iou": 0.14244380146895425,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.59999999999991,
        "end": 14.929999999999836,
        "average": 19.264999999999873
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.6161354780197144,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not provide the requested timing and instead gives an unrelated slide-based description; it neither matches the provided timestamps nor indicates when the speaker discusses working with the legal team."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the policy was active until late February of 2022, when does the first 'Scope of protocol' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2194.0,
        "end": 2234.0
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.19047619047619047,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.0,
        "end": 106.0,
        "average": 85.0
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306123,
        "text_similarity": 0.747160792350769,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the slide appears after the speaker's remark but omits all timestamps and implies it appears immediately; the reference specifies exact times (speaker at 2192.0s, slide from 2194.0\u20132234.0), so key factual details are missing and timing is slightly misrepresented."
      }
    },
    {
      "question_id": "003",
      "question": "After the second 'Scope of protocol' slide appears, when does the speaker mention 'renal replacement therapy'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2263.679,
        "end": 2254.733
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 133.6790000000001,
        "end": 85.26699999999983,
        "average": 109.47299999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962267,
        "text_similarity": 0.755669355392456,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only states a vague ordering ('after') and omits the crucial timestamp details and precise event interval provided in the correct answer, thus missing key factual information required for a full match."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that goals of care discussions significantly changed, when does the speaker mention that patients were more likely to choose limited life-sustaining interventions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2320.0,
        "end": 2327.0
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2520.0
      },
      "iou": 0.03333333333333333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 193.0,
        "average": 101.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3703703703703704,
        "text_similarity": 0.6467732787132263,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction does not provide the event times requested (2313.0s and 2320.0s) and fails to state when patients chose limited interventions; instead it gives an unrelated slide interval, omitting the key factual elements and relation."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states he wants to highlight some takeaway points, when does the first takeaway point appear on the screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2520.0
      },
      "iou": 0.023809523809523808,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 85.0,
        "end": 120.0,
        "average": 102.5
      },
      "rationale_metrics": {
        "rouge_l": 0.19999999999999998,
        "text_similarity": 0.7153382301330566,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives wildly incorrect timestamps (predicts speaker mention at 2310.0s and takeaway spanning 2310.0\u20132520.0) that contradict the reference (speaker 2392\u20132394s, takeaway 2395\u20132400s), so it is essentially wrong despite noting the takeaway follows the remark."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I'll stop and take questions,\" when does an audience member begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2541.6,
        "end": 2544.0
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2537.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.59999999999991,
        "end": 6.5,
        "average": 29.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.490566037735849,
        "text_similarity": 0.6928938627243042,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction places the audience speaking at 2490.0s, which contradicts the ground-truth timing (speaker at 2517.9s and audience at 2541.6s) and omits the audience end time, so it is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the audience member finishes complimenting the center, when does he ask a specific question about local hospital ethics committees?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2571.5,
        "end": 2580.5
      },
      "pred_interval": {
        "start": 2537.5,
        "end": 2604.0
      },
      "iou": 0.13533834586466165,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 23.5,
        "average": 28.75
      },
      "rationale_metrics": {
        "rouge_l": 0.5384615384615384,
        "text_similarity": 0.5747269988059998,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a specific time but it is incorrect and contradicts the reference: the correct question starts at 2571.5s (after the 2565.5s compliment), whereas the prediction wrongly places it at 2537.5s (before the compliment)."
      }
    },
    {
      "question_id": "003",
      "question": "After the audience member mentions the low numbers of ethics consultations, when does the speaker begin to answer the question?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2624.0,
        "end": 2634.8
      },
      "pred_interval": {
        "start": 2604.0,
        "end": 2670.5
      },
      "iou": 0.16240601503759672,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.0,
        "end": 35.69999999999982,
        "average": 27.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.49122807017543857,
        "text_similarity": 0.5716506242752075,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted start time (2604.0s) contradicts the reference (2624.0s) and precedes the audience mention (2621.0s); it also omits the end time and relation, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the listener asks about assessing the quality of care across the system, when does the speaker respond by calling it a 'great question'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.1,
        "end": 2745.7
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2880.0
      },
      "iou": 0.007619047619047186,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.09999999999991,
        "end": 134.30000000000018,
        "average": 104.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.17142857142857143,
        "text_similarity": 0.3229817748069763,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps and utterances do not match the reference: it identifies different segments (speaker intro and 'I am a final year medical student') rather than the listener's question at 2739\u20132743s and the speaker's 'So that's a great question' at 2744.1s, so the prediction is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions starting to survey clinicians for feedback, when does he mention planning to survey patients and families?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2807.8,
        "end": 2821.6
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2880.0
      },
      "iou": 0.06571428571428442,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 137.80000000000018,
        "end": 58.40000000000009,
        "average": 98.10000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.1978021978021978,
        "text_similarity": 0.5330832004547119,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies and mis-times the events (places the clinicians remark at ~2745\u20132753.6s instead of 2800\u20132802s) and fails to locate the patients/families remark at 2807.8\u20132821.6s, so the temporal relation and target are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that hospitals in the healthcare system can join together, when does he state that they will preferentially present cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2854.49,
        "end": 2856.13
      },
      "pred_interval": {
        "start": 2856.7,
        "end": 2903.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.2100000000000364,
        "end": 47.26999999999998,
        "average": 24.74000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.34342771768569946,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly indicates the event occurs after the hospitals 'join together' remark, but it omits the timestamp details and adds an unsupported detail ('once finished'), which is a mild hallucination and reduces accuracy."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces 'a third method of feedback', when does he describe it as 'formal needs assessments'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2877.53,
        "end": 2879.53
      },
      "pred_interval": {
        "start": 2864.5,
        "end": 2901.1
      },
      "iou": 0.054644808743169536,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.0300000000002,
        "end": 21.56999999999971,
        "average": 17.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.33962264150943394,
        "text_similarity": 0.5713996887207031,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the phrase occurs after the introduction, but is vague and omits the key timing details and explicit anchor-to-target relation (timestamps and precise 'after' placement) present in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'the overwhelming response was number one', when does he specify the first response as 'a lack of ethics education'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2901.56,
        "end": 2903.46
      },
      "pred_interval": {
        "start": 2870.8,
        "end": 2907.4
      },
      "iou": 0.05191256830601354,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.759999999999764,
        "end": 3.9400000000000546,
        "average": 17.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.4262295081967213,
        "text_similarity": 0.7109606266021729,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the specification comes after the anchor phrase, but it is vague and lacks the precise timing information given in the reference (specific start/end timestamps) and uses an unclear phrase ('once finished')."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"The more medically complex cases tend to transfer,\" when does he start listing examples of such cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3044.3,
        "end": 3048.2
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3039.1000000000004,
        "end": 3011.6,
        "average": 3025.3500000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.5960861444473267,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives entirely different timestamps and a wrong target utterance, and labels the relation as 'after' rather than occurring immediately; it does not match the correct timing or description."
      }
    },
    {
      "question_id": "002",
      "question": "After the questioner asks about the 'escalation of care policy', when does the slide titled 'Escalation of Care Protocol' appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3114.8,
        "end": 3117.8
      },
      "pred_interval": {
        "start": 14.7,
        "end": 19.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3100.1000000000004,
        "end": 3098.1000000000004,
        "average": 3099.1000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.24561403508771928,
        "text_similarity": 0.43240559101104736,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misattributes the slide's trigger to a speaker remark rather than the questioner's query and omits the precise timestamps and the 'after' relation; it thus fails to match the key factual details in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions \"boarding 190 patients in the emergency department\", when does he discuss concerns about the level of care?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3154.983,
        "end": 3143.945
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3119.983,
        "end": 3107.3450000000003,
        "average": 3113.664
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.25055891275405884,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly references that the speaker discusses concerns about level of care, but it misidentifies the anchor phrase\u2014the correct anchor is the 'boarding 190 patients' remark and the concern occurs immediately after that; the predicted answer points to a different sentence and thus fails to match the required temporal alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker mentions 'in all 26 of those cases', when does he then talk about 'many more cases'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3214.9,
        "end": 3215.4
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3209.7000000000003,
        "end": 3178.8,
        "average": 3194.25
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5125531554222107,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer references entirely different utterances and times than the ground truth (wrong events and timestamps); although both label the relation 'after', the content and timing do not match, so it is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker states that the 'escalation of care protocol' was nice, when does he mention a 'SOFA-based protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3246.0,
        "end": 3249.0
      },
      "pred_interval": {
        "start": 14.7,
        "end": 34.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3231.3,
        "end": 3214.5,
        "average": 3222.9
      },
      "rationale_metrics": {
        "rouge_l": 0.27848101265822783,
        "text_similarity": 0.7564353942871094,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and the 'after' relation, but the timestamps do not match the reference (both start/end times differ and offsets are inconsistent), and the predicted answer omits E1's end time\u2014making it factually incorrect/incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the second speaker says 'SOFA is horrendous', when does he mention 'SOFA's AUC goes up'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3322.32,
        "end": 3324.71
      },
      "pred_interval": {
        "start": 26.8,
        "end": 34.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3295.52,
        "end": 3290.21,
        "average": 3292.865
      },
      "rationale_metrics": {
        "rouge_l": 0.225,
        "text_similarity": 0.6393296718597412,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely mismatches the reference: it identifies different utterances and incorrect timing (26.8s vs ~3320s), misaligns event boundaries, and only correctly states the relation as 'after'."
      }
    },
    {
      "question_id": "001",
      "question": "After the question about equity monitoring is asked, when does the speaker begin explaining the logging process for patient cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3401.583,
        "end": 3406.09
      },
      "pred_interval": {
        "start": 3407.5,
        "end": 3662.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.916999999999916,
        "end": 256.40999999999985,
        "average": 131.16349999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962265,
        "text_similarity": 0.45609527826309204,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not provide the start time and introduces an unrelated slide, failing to state that the speaker begins explaining logging at 3401.583s (before the equity-monitoring question at 3406.535s) and thus contradicts the required temporal information."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the 'Escalation of Care Protocol', when does the 'Conscientious Practice Policy' slide appear on screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3429.8,
        "end": 3430.5
      },
      "pred_interval": {
        "start": 3662.5,
        "end": 3760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 232.69999999999982,
        "end": 329.5,
        "average": 281.0999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.7281937599182129,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the causal relation (the slide appears once the speaker finishes), but it omits the key factual details\u2014specific timestamps (3424.0s and 3429.8s)\u2014so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Conscientious Practice Policy' slide appears, when does the speaker mention tracking outcomes and looking back retrospectively for this policy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3444.0,
        "end": 3492.0
      },
      "pred_interval": {
        "start": 3760.0,
        "end": 3816.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 316.0,
        "end": 324.0,
        "average": 320.0
      },
      "rationale_metrics": {
        "rouge_l": 0.425531914893617,
        "text_similarity": 0.7586603164672852,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the relation (that the mention occurs after the slide) and the action (tracking outcomes/looking back), but it omits the essential timing details (the specific start/end timestamps 3444.0s\u20133492.0s and slide time 3434.0s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions an increasing disparity over time, when does he discuss how they can provide support to all hospitals?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 707.399,
        "end": 742.972
      },
      "pred_interval": {
        "start": 693.5,
        "end": 724.8
      },
      "iou": 0.351734314359637,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.899000000000001,
        "end": 18.172000000000025,
        "average": 16.035500000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.34615384615384615,
        "text_similarity": 0.24012313783168793,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence (disparity then support) but omits the key temporal details and exact timestamps/occurrence information provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the organizational chart for the Center for Clinical Ethics is displayed, when does the speaker describe the Ethics Education program?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.177,
        "end": 786.763
      },
      "pred_interval": {
        "start": 437.5,
        "end": 468.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 331.677,
        "end": 318.26300000000003,
        "average": 324.97
      },
      "rationale_metrics": {
        "rouge_l": 0.392156862745098,
        "text_similarity": 0.6591887474060059,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the description occurs after the organizational chart is displayed, but it omits the precise timing and confirmation that the description (769.177s\u2013786.763s) happens during the slide's display (749s\u2013810s), missing key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says he will go into depth on the programs, when does he first mention the Yale Interdisciplinary Center for Bioethics?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 837.605,
        "end": 845.26
      },
      "pred_interval": {
        "start": 726.0,
        "end": 756.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 111.60500000000002,
        "end": 89.25999999999999,
        "average": 100.4325
      },
      "rationale_metrics": {
        "rouge_l": 0.3188405797101449,
        "text_similarity": 0.6837160587310791,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction is directionally correct\u2014he mentions the Yale Interdisciplinary Center for Bioethics after saying he'd go into depth\u2014but it omits the specific timestamps (837.605\u2013845.260s) provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the title 'Systemwide Ethics Forum and Newsletter', when does he describe it as a hybrid meeting?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1070.5,
        "end": 1076.5
      },
      "pred_interval": {
        "start": 10.8,
        "end": 15.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1059.7,
        "end": 1061.2,
        "average": 1060.45
      },
      "rationale_metrics": {
        "rouge_l": 0.12048192771084339,
        "text_similarity": 0.5177964568138123,
        "llm_judge_score": 1,
        "llm_judge_justification": "Although the relation 'after' matches, the predicted answer misidentifies both events and their content/timestamps (it does not cite the title 'Systemwide Ethics Forum and Newsletter' nor the phrase 'It is a hybrid...'), so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining that they looked through the 26 specific patient cases individually, when does the slide transition to 'Scope of protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3425.8,
        "end": 3429.0
      },
      "pred_interval": {
        "start": 3405.0,
        "end": 3462.2
      },
      "iou": 0.05594405594405294,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.800000000000182,
        "end": 33.19999999999982,
        "average": 27.0
      },
      "rationale_metrics": {
        "rouge_l": 0.16,
        "text_similarity": 0.5818498730659485,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') between the speaker finishing and the 'Scope of protocol' slide, but it omits the crucial timestamps and transition timing (3417.5s, 3425.8s, 3429.0s) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the 'Scope of protocol' slide finishes being displayed, when does the 'Conscientious Practice Policy' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3429.0,
        "end": 3519.5
      },
      "pred_interval": {
        "start": 3468.0,
        "end": 3547.2
      },
      "iou": 0.4357021996615912,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 27.699999999999818,
        "average": 33.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.31111111111111117,
        "text_similarity": 0.6946045160293579,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('once_finished') that the Conscientious Practice Policy slide appears immediately after the Scope of protocol slide, but it omits the specific timestamps and duration (3429.0s start and until 3519.5s) given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes discussing the tracking of equity, socioeconomic status, and other demographic characteristics, when is the presentation window minimized?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3530.0,
        "end": 3531.0
      },
      "pred_interval": {
        "start": 3554.0,
        "end": 3581.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.0,
        "end": 50.59999999999991,
        "average": 37.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367346,
        "text_similarity": 0.5212981104850769,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') between the two events, but it omits the key factual details\u2014specific timestamps for when the speaker finishes (3508.5s) and when the window is minimized (3530.0\u20133531.0s)\u2014so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the audience will be on mute, when does he mention that the live event can be paused?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 38.524,
        "end": 43.729
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.324,
        "end": 7.128999999999998,
        "average": 20.226499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.3249380588531494,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is unrelated and incorrect: it gives an intro at 5.2s about being a medical student rather than identifying the mute (33.102s) and pause (38.524s) mentions or the target span 38.524\u201343.729s, so it fails to address the question."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses changing the speed of presentations and speakers, when does he advise on what to do if Wi-Fi or connection is lost?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 55.563,
        "end": 59.787
      },
      "pred_interval": {
        "start": 107.4,
        "end": 133.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.837,
        "end": 74.013,
        "average": 62.925000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.32142857142857145,
        "text_similarity": 0.38164734840393066,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the event occurs after the anchor, but the timestamp is incorrect (predicted 107.4s vs. the correct target span 55.563s\u201359.787s), so it is factually wrong. "
      }
    },
    {
      "question_id": "001",
      "question": "After the presenter mentions Tom Gardner in the background, when does he mention Stephanie Fraser joining in place of Jane Preston?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.258,
        "end": 171.201
      },
      "pred_interval": {
        "start": 153.7,
        "end": 208.4
      },
      "iou": 0.05380255941499054,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.558000000000021,
        "end": 37.19900000000001,
        "average": 25.878500000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.27848101265822783,
        "text_similarity": 0.6581552028656006,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly names the anchor and target events and preserves their order, but the timestamps (153.7s and 208.4s) are massively inconsistent with the ground-truth times (~12.3s and ~18.8s) and the target end time is omitted, so the answer is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male presenter finishes introducing Stephanie Fraser, when does Stephanie Fraser begin speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 223.86,
        "end": 224.8
      },
      "pred_interval": {
        "start": 208.4,
        "end": 360.0
      },
      "iou": 0.006200527704485473,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.460000000000008,
        "end": 135.2,
        "average": 75.33
      },
      "rationale_metrics": {
        "rouge_l": 0.21212121212121215,
        "text_similarity": 0.46681857109069824,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction misidentifies both the anchor and target events and gives completely different timestamps (153.7s and 208.4s) that contradict the correct times (anchor ends at 222.0s; target starts at 223.86s), so it fails to match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker is discussing the recent research undertaken by the Neurological Alliance of Scotland, when does she state that 57% of respondents reported not being able to access a face-to-face appointment?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 433.0,
        "end": 434.9
      },
      "pred_interval": {
        "start": 335.7,
        "end": 446.2
      },
      "iou": 0.0171945701357464,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.30000000000001,
        "end": 11.300000000000011,
        "average": 54.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1558441558441558,
        "text_similarity": 0.1993740200996399,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly restates that 57% were unable to access face-to-face appointments but fails to provide the requested timing information (anchor and target timestamps, specifically ~433.0\u2013434.9s), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that nearly two-thirds of respondents had not had a video appointment, when does she state that telephone appointments were the most common way to access care?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.8,
        "end": 452.9
      },
      "pred_interval": {
        "start": 446.2,
        "end": 539.9
      },
      "iou": 0.05442902881536784,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.6000000000000227,
        "end": 87.0,
        "average": 44.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.3412390351295471,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only restates that telephone appointments were most common and provides no timing information or timestamps required by the correct answer, omitting the key factual elements."
      }
    },
    {
      "question_id": "003",
      "question": "After the blue slide with the speaker's title disappears, when does the speaker begin to mention what factors clinicians should consider for appointment formats?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 479.3,
        "end": 480.3
      },
      "pred_interval": {
        "start": 540.0,
        "end": 750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 60.69999999999999,
        "end": 269.7,
        "average": 165.2
      },
      "rationale_metrics": {
        "rouge_l": 0.2413793103448276,
        "text_similarity": 0.2991308271884918,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that she begins to mention the factors after the slide disappears but omits the key timing details (E1 at 476.3s and E2 starting at 479.3s) required by the question, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stephanie finishes speaking and hands over to Mark, when does Mark begin to speak?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 606.5,
        "end": 607.0
      },
      "pred_interval": {
        "start": 513.8,
        "end": 720.0
      },
      "iou": 0.0024248302618816676,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 92.70000000000005,
        "end": 113.0,
        "average": 102.85000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.6053667664527893,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction matches the relation (Mark speaks after Stephanie) but gives a single start time (513.8s) that contradicts the correct start interval (606.5\u2013607.0s) and omits the Stephanie end time (593.7\u2013594.0s), so the timing is significantly incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Mark finishes introducing Calum Duncan, when does Calum Duncan start speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 638.3,
        "end": 639.3
      },
      "pred_interval": {
        "start": 513.8,
        "end": 720.0
      },
      "iou": 0.004849660523763335,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 124.5,
        "end": 80.70000000000005,
        "average": 102.60000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.5314547419548035,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted start time (513.8s) contradicts the reference (638.3\u2013639.3s) and does not match the given end time for Mark (636.3\u2013636.6s), so the timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once Calum Duncan says 'Next slide please', when does the second presentation slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 685.7,
        "end": 686.0
      },
      "pred_interval": {
        "start": 513.8,
        "end": 720.0
      },
      "iou": 0.00145489815712878,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 171.9000000000001,
        "end": 34.0,
        "average": 102.95000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.5619062185287476,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (513.8s) is far from the ground-truth second-slide time (685.7\u2013686.0s) and fails to reflect the relation that the slide appears after Calum finishes speaking, so it is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 'near me is what we're going to focus on today', when does he describe it as 'internet-based'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 702.7,
        "end": 703.5
      },
      "pred_interval": {
        "start": 695.0,
        "end": 723.4
      },
      "iou": 0.028169014084505464,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.7000000000000455,
        "end": 19.899999999999977,
        "average": 13.800000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.08888888888888889,
        "text_similarity": 0.2832186222076416,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the anchor time (giving 'after 5.2s' instead of ~699.8s) and provides an incorrect target time (700.6s vs 702.7s); it therefore fails to match the key timestamps and relation despite roughly approximating the target. "
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states there were '330 consultations per week' before the pandemic, when does he mention it went up to '10,000'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 737.0,
        "end": 739.0
      },
      "pred_interval": {
        "start": 695.0,
        "end": 723.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.0,
        "end": 15.600000000000023,
        "average": 28.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.12244897959183673,
        "text_similarity": 0.04975759983062744,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (695.0s and 700.6s) do not match the correct timestamps (731.5\u2013733.0s and 737.0\u2013739.0s), so the prediction is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' for the first time, when does he point to the map on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.0,
        "end": 767.5
      },
      "pred_interval": {
        "start": 700.6,
        "end": 766.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.39999999999998,
        "end": 1.5,
        "average": 33.94999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.3435159921646118,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the temporal relation (pointing occurs after 'Next slide'), but both reported timestamps are substantially incorrect (anchor off by ~55s and target off by ~47s), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'go back to the next slide', when does the slide titled 'Video consulting using near me via attend anywhere platform' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 874.0,
        "end": 874.1
      },
      "pred_interval": {
        "start": 875.0,
        "end": 960.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 85.89999999999998,
        "average": 43.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.15686274509803924,
        "text_similarity": 0.48212653398513794,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states the slide appears immediately when the speaker issues the instruction, matching the key timing relation, but it omits the exact timestamps (873.91s and 874.0s) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that 'Stephanie Fraser has talked about' the survey, when does he then say 'Back to next slide, Mark, please'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 884.0
      },
      "pred_interval": {
        "start": 42.0,
        "end": 58.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 841.0,
        "end": 825.4,
        "average": 833.2
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320756,
        "text_similarity": 0.3526615500450134,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the utterance follows the mention (and the slide change), but it omits the key timing details and explicit timestamp/relative timing information provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'Next slide, please' at the 42-second mark, when does the slide titled 'Clinician and patient experience - Scotland' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 913.0,
        "end": 913.1
      },
      "pred_interval": {
        "start": 42.0,
        "end": 58.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 871.0,
        "end": 854.5,
        "average": 862.75
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.44796115159988403,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that the slide appears after the instruction but provides no timing information or timestamps as in the correct answer, omitting the key temporal details required by the question."
      }
    },
    {
      "question_id": "001",
      "question": "During the discussion of what works well with video calls, when does the speaker express finding it much easier to interact with groups on a video call than on the telephone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1053.0,
        "end": 1062.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.04523809523809524,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 197.5,
        "average": 100.25
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.4411858022212982,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the general content (video calls are easier for group interaction) but omits the required precise timestamps and relation, and adds vague/uncertain timing instead of the specified times, so it is incomplete and imprecise."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions technical issues with patient bandwidth, when does he advise to choose patients correctly to avoid those difficulties?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1134.0,
        "end": 1135.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.007142857142857143,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 84.0,
        "end": 124.5,
        "average": 104.25
      },
      "rationale_metrics": {
        "rouge_l": 0.22857142857142856,
        "text_similarity": 0.6207815408706665,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction notes the mention of bandwidth issues but omits the required timestamps and the specific later mention ('if you choose your patients correctly') and its temporal relation, instead offering vague speculation\u2014so it is largely incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' to introduce the smart phone camera, when does he specifically point out his wife's iPhone on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1213.0,
        "end": 1215.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.009523809523809525,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 163.0,
        "end": 45.0,
        "average": 104.0
      },
      "rationale_metrics": {
        "rouge_l": 0.18461538461538463,
        "text_similarity": 0.5241689085960388,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction is vague but not contradictory\u2014it agrees that the wife\u2019s iPhone is pointed out during a smartphone camera discussion toward the segment's end; however it omits the precise timing and the explicit temporal relation given in the reference (1213\u20131215s, after 1203s), so key factual details are missing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying 'Next slide please', when does the 'Sharing content' slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.574,
        "end": 1249.574
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.004761904761904762,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.57400000000007,
        "end": 190.42599999999993,
        "average": 104.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.6972259879112244,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the order right (the slide appears after the utterance) but gives a completely incorrect anchor time (5.2s vs. ~1247.133\u20131248.173s) and omits the precise target timestamp (1248.574s), so it is largely incorrect and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'You can share things', when does he point towards the screen showing the brain scan?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1252.25,
        "end": 1252.85
      },
      "pred_interval": {
        "start": 1360.0,
        "end": 1440.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 107.75,
        "end": 187.1500000000001,
        "average": 147.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454546,
        "text_similarity": 0.539862871170044,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives an incorrect timestamp for the spoken phrase and does not state the pointing interval (1252.250\u20131252.850s), instead only noting the screen is visible; it omits the key temporal information and is therefore largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "During the discussion about poor picture quality, when does the speaker suggest clearing browser history?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1313.823,
        "end": 1315.286
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1360.0
      },
      "iou": 0.011253846153845889,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.82300000000009,
        "end": 44.71399999999994,
        "average": 64.26850000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.196078431372549,
        "text_similarity": 0.49420008063316345,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timing (5.2s) does not match the correct relative timing (7.0\u20138.463s) and introduces an unsupported detail about 'Next slide please', so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying \"Thank you very much for that\", when does he state he is handing over to Jane?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.837,
        "end": 1430.682
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1430.0
      },
      "iou": 0.07416145899757746,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.836999999999989,
        "end": 0.6820000000000164,
        "average": 7.259500000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.29999999999999993,
        "text_similarity": 0.49614331126213074,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes that the speaker hands over to Jane, but it omits the requested timing and exact phrasing (timestamps 1427.0 and 1428.837\u20131430.682), so it fails to answer the 'when' component. "
      }
    },
    {
      "question_id": "003",
      "question": "After the woman (Jane) describes the challenges of managing patients over the telephone, when does she mention that they had a pilot of 'Near Me' even prior to Covid?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1609.855,
        "end": 1624.692
      },
      "pred_interval": {
        "start": 1520.0,
        "end": 1600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 89.85500000000002,
        "end": 24.692000000000007,
        "average": 57.27350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.23376623376623376,
        "text_similarity": 0.5956484079360962,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the basic sequence and the claim that Near Me was piloted prior to COVID, but it omits the key factual details required by the correct answer\u2014explicit event timestamps, event boundaries, and the specified temporal relation\u2014so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that using 'Near Me' felt quite adventurous, when does she state that its use became vital to their whole service?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1636.0,
        "end": 1643.0
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1800.0
      },
      "iou": 0.03333333333333333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.0,
        "end": 157.0,
        "average": 101.5
      },
      "rationale_metrics": {
        "rouge_l": 0.39436619718309857,
        "text_similarity": 0.6132516264915466,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes that the remark about Near Me being vital follows the adventurous comment and preserves the main claim, but it fails to provide the required timestamps/temporal span and introduces an unsupported detail ('after the COVID-19 lockdown'), which is a hallucination."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes asking Mark to go back to the previous slide, when does she say 'Thank you'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1676.54,
        "end": 1678.02
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1800.0
      },
      "iou": 0.007047619047619134,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 86.53999999999996,
        "end": 121.98000000000002,
        "average": 104.25999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2641509433962264,
        "text_similarity": 0.7382090091705322,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction restates the relation but omits all required temporal details (timestamps and target span) from the correct answer, so it is essentially incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the 'Training and preparation' slide appears, when does the speaker mention the 'Level 1' training?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1791.0,
        "end": 1791.5
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1785.8,
        "end": 1754.9,
        "average": 1770.35
      },
      "rationale_metrics": {
        "rouge_l": 0.1764705882352941,
        "text_similarity": 0.5156719088554382,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer misidentifies both the anchor and target events and their timestamps (they do not correspond to the 'Training and preparation' slide at 1774.4s or the 'Level 1 training' utterance at 1791.0s); only the relation 'after' coincidentally matches."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing tele-swallowing partners as 'our eyes and our hands and our ears', when does she start talking about preparing the clinical room?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1897.0,
        "end": 1901.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 74.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1862.0,
        "end": 1826.6,
        "average": 1844.3
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.5961905717849731,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely fails: it cites entirely different events and timestamps, and hallucinates content and boundaries that contradict the reference; only the relation label matches, so it is almost entirely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses tele-swallowing partners preparing the clinical room, when does she next talk about them providing reassurance to patients?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1906.0,
        "end": 1910.0
      },
      "pred_interval": {
        "start": 74.4,
        "end": 109.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1831.6,
        "end": 1800.2,
        "average": 1815.9
      },
      "rationale_metrics": {
        "rouge_l": 0.2037037037037037,
        "text_similarity": 0.4951515793800354,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect: it gives entirely different event IDs and timestamps, misstates the event content and timing, and uses a different relation ('once_finished') rather than the correct 'next', thus failing to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning emergency procedures in place onsite, when does the slide change to 'Technology/equipment'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1971.6,
        "end": 1972.0
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2160.0
      },
      "iou": 0.0019047619047623378,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.59999999999991,
        "end": 188.0,
        "average": 104.79999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.16949152542372883,
        "text_similarity": 0.37352851033210754,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the sequence (slide changes after the speaker finishes) but gives a wrong timestamp (2083.7s vs correct 1971.6\u20131972.0s) and omits the anchor interval, so it is factually incorrect and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the time the 'Technology/equipment' slide is displayed, when does the speaker discuss the need for a device with a webcam and microphone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2024.079,
        "end": 2026.579
      },
      "pred_interval": {
        "start": 2083.7,
        "end": 2160.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.62099999999987,
        "end": 133.42100000000005,
        "average": 96.52099999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.13888888888888887,
        "text_similarity": 0.3811810612678528,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives incorrect slide timing (2083.7\u20132160.0s vs correct 1971.6\u20132148.197s) and thus places the mention outside that interval; it misaligns the key timestamps despite correctly identifying the topic."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the general category of 'certain resources' for teleswallow sessions, when does she mention 'appropriate diet and fluid consistencies'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.952,
        "end": 2061.952
      },
      "pred_interval": {
        "start": 2160.0,
        "end": 2160.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 101.04799999999977,
        "end": 98.04799999999977,
        "average": 99.54799999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.19672131147540983,
        "text_similarity": 0.15216322243213654,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a single timestamp (2160.0s) that is \u2248100 seconds later than the correct target interval (2058.952\u20132061.952s) and fails to preserve the anchor/target timing and 'next' relation, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that remote swallowing assessments are not intended to fully replace face-to-face assessments, when does she mention that they are a very useful addition?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2159.677,
        "end": 2162.619
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2160.0
      },
      "iou": 0.009902204236790337,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.677000000000135,
        "end": 2.619000000000142,
        "average": 16.14800000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.3870967741935484,
        "text_similarity": 0.47271478176116943,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the sequence (she says it right after), but it omits the required timing detail (2159.677s) and the explicit note that the target immediately follows the anchor's speech, so it fails to fully answer the 'when' aspect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning gathering feedback from those who completed the training, when does she start talking about evaluating quantitative data?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2164.643,
        "end": 2186.427
      },
      "pred_interval": {
        "start": 2160.0,
        "end": 2185.0
      },
      "iou": 0.7703106671207427,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 4.643000000000029,
        "end": 1.4270000000001346,
        "average": 3.035000000000082
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.5207555294036865,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that she begins discussing quantitative data but provides no timestamps or the relative timing; it omits the key factual details (specific seconds and that the target immediately follows the anchor) required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes her presentation by saying 'thank you very much for listening', when does the video visually transition to the male presenter?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2257.0,
        "end": 2258.0
      },
      "pred_interval": {
        "start": 2185.0,
        "end": 2200.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.0,
        "end": 58.0,
        "average": 65.0
      },
      "rationale_metrics": {
        "rouge_l": 0.41509433962264153,
        "text_similarity": 0.651172399520874,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that the visual transition follows the first speaker's closing line, but it omits the key factual details (the exact timestamps E1=2256.0s and E2=2257.0s and that the transition immediately follows the speech)."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that picking up cues is difficult, when does she start talking about 'points to consider' for virtual technology?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2491.8,
        "end": 2498.2
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2670.0
      },
      "iou": 0.035555555555553536,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.800000000000182,
        "end": 171.80000000000018,
        "average": 86.80000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333334,
        "text_similarity": 0.3458312749862671,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures that she immediately transitions to 'points to consider' (once finished), but it omits the key timing details (the exact start at 2491.8s and the duration until 2498.2s) present in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions conducting a 'sprint audit' with patients, when does she state that 'most were very satisfied' with the virtual appointments?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2515.0,
        "end": 2516.0
      },
      "pred_interval": {
        "start": 2580.0,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.0,
        "end": 184.0,
        "average": 124.5
      },
      "rationale_metrics": {
        "rouge_l": 0.37931034482758624,
        "text_similarity": 0.5965785980224609,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (that the 'most were very satisfied' remark comes after the sprint audit), but it omits the key factual details required by the correct answer\u2014specifically the timestamps for E1 (2509.5s) and E2 (2515.0\u20132516.0)."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that patients found virtual technology 'more acceptable', when does she say 'So moving on to the next slide'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2638.0,
        "end": 2639.3
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.0,
        "end": 60.69999999999982,
        "average": 46.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.43333333333333335,
        "text_similarity": 0.47047457098960876,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that she says the phrase after finishing the prior remark but omits the requested timing details (2637.6s and 2638.0\u20132639.3s) and thus fails to answer 'when'."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing confidentiality, when does she begin to mention the subtlety of the therapeutic relationship?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2693.583,
        "end": 2697.126
      },
      "pred_interval": {
        "start": 2700.0,
        "end": 2760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.416999999999916,
        "end": 62.873999999999796,
        "average": 34.645499999999856
      },
      "rationale_metrics": {
        "rouge_l": 0.23255813953488377,
        "text_similarity": 0.6388046741485596,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the sequence (confidentiality then therapeutic relationship) but omits the requested timing information and precise event timestamps, so it fails to answer the 'when' aspect of the question."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'It all comes down to Wi-Fi', when does she state that 'delivery of remote therapy is very, very difficult'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.0,
        "end": 2729.0
      },
      "pred_interval": {
        "start": 2820.0,
        "end": 2880.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 93.0,
        "end": 151.0,
        "average": 122.0
      },
      "rationale_metrics": {
        "rouge_l": 0.5483870967741935,
        "text_similarity": 0.611865222454071,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly indicates the target utterance occurs after the anchor (matching the required relative judgment), but it omits the specific timing interval given in the reference (2727.0s\u20132729.0s)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'So next slide', when does the slide visually change to 'Practical considerations'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2884.0,
        "end": 2884.2
      },
      "pred_interval": {
        "start": 2856.0,
        "end": 3060.0
      },
      "iou": 0.0009803921568618534,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.0,
        "end": 175.80000000000018,
        "average": 101.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.27450980392156865,
        "text_similarity": 0.6890342235565186,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the slide changes to 'Practical considerations' after the verbal cue and notes the slide titles, but it omits the precise timestamps (2883.0s \u2192 2884.0s) and the immediacy of the change specified in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing 'Practical considerations', when does she first mention 'increasing reflective feedback'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2913.483,
        "end": 2916.268
      },
      "pred_interval": {
        "start": 2856.0,
        "end": 3060.0
      },
      "iou": 0.013651960784313012,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.483000000000175,
        "end": 143.73199999999997,
        "average": 100.60750000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.24000000000000002,
        "text_similarity": 0.7688053846359253,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states the mention occurs during the 'Practical considerations' segment and the provided interval (2856.0\u20133060.0s) contains the ground-truth mention at 2913.483s; it only slightly misstates the segment start time and omits the exact mention timestamp."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"for the patients\", when does the slide change to \"WHERE WE ARE NOW\"?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3067.769,
        "end": 3068.2
      },
      "pred_interval": {
        "start": 3030.0,
        "end": 3240.0
      },
      "iou": 0.002052380952381143,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.76899999999978,
        "end": 171.80000000000018,
        "average": 104.78449999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.5565940141677856,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives vastly different timestamps than the reference (5.2s vs 3066.8s for the anchor; 35\u201336.6s vs ~3067.8\u20133068.2s for the slide) and thus is factually incorrect, though it implicitly places the slide after the utterance."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says \"open up for some discussion\", when does the discussion slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3163.435,
        "end": 3163.7
      },
      "pred_interval": {
        "start": 3240.0,
        "end": 3450.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.56500000000005,
        "end": 286.3000000000002,
        "average": 181.43250000000012
      },
      "rationale_metrics": {
        "rouge_l": 0.3018867924528302,
        "text_similarity": 0.5531208515167236,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the order right (discussion appears after the utterance) but the timestamps are substantially incorrect and do not match the ground-truth timings (predicted ~35\u201340s vs ground-truth ~3120\u20133163s), failing on precise temporal accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "After the first male speaker asks about attendees' experience with Near Me, when does the second male speaker begin talking about starting to use NearMe?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.9,
        "end": 3312.0
      },
      "pred_interval": {
        "start": 3210.0,
        "end": 3420.0
      },
      "iou": 0.2052380952380948,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.90000000000009,
        "end": 108.0,
        "average": 83.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.3287671232876712,
        "text_similarity": 0.520892322063446,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target events and the 'after' relation, but the reported start time for the second speaker (3375.0s) is substantially different from the correct 3268.9s and it introduces an unsupported end time, so the timing is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second male speaker finishes stating the advantages and utility of NearMe, when does he mention supplementing normal activities?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.4,
        "end": 3293.32
      },
      "pred_interval": {
        "start": 3210.0,
        "end": 3420.0
      },
      "iou": 0.023428571428571774,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.40000000000009,
        "end": 126.67999999999984,
        "average": 102.53999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.2285714285714286,
        "text_similarity": 0.39409494400024414,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the relation and target event conceptually right but misidentifies the anchor event and provides incorrect timestamps (contradicting the reference), so it contains major factual errors."
      }
    },
    {
      "question_id": "001",
      "question": "After the first man finishes reading Jenny's chat message, when does he ask the audience if they would find guidance helpful?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3411.0,
        "end": 3415.0
      },
      "pred_interval": {
        "start": 3407.5,
        "end": 3600.0
      },
      "iou": 0.02077922077922078,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 185.0,
        "average": 94.25
      },
      "rationale_metrics": {
        "rouge_l": 0.19999999999999998,
        "text_similarity": 0.40387454628944397,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys the ordering (he asks after reading), but it fails to provide the required timing information (the specific timestamps/relative time span), so it does not answer the 'when' question."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first man finishes reading John Hogan's comment about clinical interviewing, when does he state he was quite skeptical?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3434.9,
        "end": 3437.7
      },
      "pred_interval": {
        "start": 3407.5,
        "end": 3600.0
      },
      "iou": 0.014545454545453128,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.40000000000009,
        "end": 162.30000000000018,
        "average": 94.85000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.39285714285714285,
        "text_similarity": 0.4440957009792328,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly restates the relation (that he says he was quite skeptical once the man finishes reading) but omits the key factual timing information/target span (e.g., 3434.9\u20133437.7s and associated event timestamps), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the second woman mentions neuropsychology bringing out guidance, when is the next time a woman speaks about professional guidance?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3511.043,
        "end": 3528.447
      },
      "pred_interval": {
        "start": 3407.5,
        "end": 3600.0
      },
      "iou": 0.0904103896103896,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 103.54300000000012,
        "end": 71.55299999999988,
        "average": 87.548
      },
      "rationale_metrics": {
        "rouge_l": 0.1851851851851852,
        "text_similarity": 0.5350977182388306,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not provide the requested timing or speaker change and contradicts the reference (the correct answer specifies the third woman speaks about guidance at 3500.0), so it fails to match the correct information."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 36 people joined the session, when does he talk about taking the next steps with Richard and the team?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3574.7,
        "end": 3576.5
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3618.0
      },
      "iou": 0.03750000000000379,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.699999999999818,
        "end": 41.5,
        "average": 23.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.1,
        "text_similarity": 0.2804517149925232,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the speaker makes the 'next steps with Richard and the team' remark after mentioning 36 people, but it omits the key timing details (the specific timestamps) provided in the reference answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker makes a plea to fill in the survey, when does he ask if listeners would like to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3592.9,
        "end": 3594.1
      },
      "pred_interval": {
        "start": 3594.0,
        "end": 3618.0
      },
      "iou": 0.003984063745016311,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.099999999999909,
        "end": 23.90000000000009,
        "average": 12.5
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413796,
        "text_similarity": 0.27021825313568115,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the required timestamps and explicit anchor/target relation; saying 'after a pause' does not provide the factual timing or the specific occurrence after the plea as given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes thanking everyone for joining the session today, when does he mention that the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3599.8,
        "end": 3603.2
      },
      "pred_interval": {
        "start": 3615.0,
        "end": 3618.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.199999999999818,
        "end": 14.800000000000182,
        "average": 15.0
      },
      "rationale_metrics": {
        "rouge_l": 0.14705882352941177,
        "text_similarity": 0.2259834110736847,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys that the speaker mentions recording and resources after thanking attendees, but it fails to provide the requested timing details (timestamps) and even implies a pause contrary to the reference's immediate follow; thus it is incomplete for the question asked."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'where did we start?', when does she mention considering moving to Near Me for patient contacts?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2332.719,
        "end": 2336.344
      },
      "pred_interval": {
        "start": 2316.7,
        "end": 2458.9
      },
      "iou": 0.025492264416315,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.019000000000233,
        "end": 122.55600000000004,
        "average": 69.28750000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.23011453449726105,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and incorrect: it only says 'after 2310.0s' which does not match the precise anchor (2320.0s) and target interval (2332.719\u20132336.344s) given in the correct answer, omitting the exact target timestamps and relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says the pandemic came along, when does she mention adopting Near Me as their default for routine people?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2367.217,
        "end": 2412.045
      },
      "pred_interval": {
        "start": 2461.3,
        "end": 2518.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 94.08300000000008,
        "end": 106.85500000000002,
        "average": 100.46900000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.10344827586206896,
        "text_similarity": 0.2696034610271454,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that Near Me was adopted after the pandemic, but gives an incorrect timestamp (after 2461.3s) and omits the correct anchor/target time span (2367.217\u20132412.045), so the timing and segmentation are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the results of the focus groups for the qualitative study, when does she introduce the quotes from the participants?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2511.0,
        "end": 2512.0
      },
      "pred_interval": {
        "start": 2521.3,
        "end": 2731.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.300000000000182,
        "end": 219.30000000000018,
        "average": 114.80000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.17241379310344826,
        "text_similarity": 0.3822494149208069,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the quotes come after the results description, but the timestamp (2521.3s) does not match the reference start (2511.0s) and end (2512.0s), so the timing is incorrect and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks to fill in the survey, when does he ask if listeners want to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3591.7,
        "end": 3595.8
      },
      "pred_interval": {
        "start": 3576.8,
        "end": 3614.2
      },
      "iou": 0.10962566844920865,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.899999999999636,
        "end": 18.399999999999636,
        "average": 16.649999999999636
      },
      "rationale_metrics": {
        "rouge_l": 0.28169014084507044,
        "text_similarity": 0.32089561223983765,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relative order (the advisory-committee question occurs after the survey request) but adds an incorrect detail about a 'show of hands' and omits the specific timestamps and phrasing from the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Before the speaker thanks the speakers for their expertise, when does he mention the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3599.9,
        "end": 3603.7
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3617.0
      },
      "iou": 0.08085106382978142,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.90000000000009,
        "end": 13.300000000000182,
        "average": 21.600000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.35465478897094727,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction mentions both the thank-you and the recording/resources statement, but it fails to establish the key temporal relation that the recording/resources comment occurs before the thanks and omits the timestamp details, so it is incomplete relative to the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker initially thanks the audience for joining, when does he deliver his final 'thank you very much' for the session?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3614.6,
        "end": 3615.4
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3617.0
      },
      "iou": 0.01702127659574855,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.59999999999991,
        "end": 1.599999999999909,
        "average": 23.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.43434369564056396,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction introduces an unsupported detail (after introducing the next speaker) and omits the specific timing and anchor/target relation given in the reference, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After Mark introduces Dr. John Mckeown and Dr. Naomi Dow, when does he ask Dr. Dow to describe how they've been using Near Me?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.48,
        "end": 34.4
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.09299363057324835,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.28,
        "end": 2.200000000000003,
        "average": 14.240000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.24615384615384617,
        "text_similarity": 0.7124098539352417,
        "llm_judge_score": 2,
        "llm_judge_justification": "While both answers agree the relation is 'after', the predicted answer misidentifies both event segments and timestamps (E1 and E2 times and content conflict with the reference), so it fails to match key factual elements."
      }
    },
    {
      "question_id": "002",
      "question": "Once Dr. Naomi Dow finishes explaining how students take part in consultations, when does Mark ask Dr. Mckeown about the impact on the teaching team?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.96,
        "end": 124.4
      },
      "pred_interval": {
        "start": 35.0,
        "end": 48.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.96,
        "end": 76.0,
        "average": 79.97999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2894736842105263,
        "text_similarity": 0.6738297343254089,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer largely disagrees with the reference: both event timestamps and the speaker identification are incorrect (predicted E1 at 35.0s vs correct 117.60s; predicted E2 48.4\u201350.0s vs correct 118.96\u2013124.4s). Only the relation label roughly matches, so minimal credit is given."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker introduces the concept of emotions in the session, when does the female speaker first mention 'real patients'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.9,
        "end": 202.6
      },
      "pred_interval": {
        "start": 153.7,
        "end": 204.8
      },
      "iou": 0.013698630136986073,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.20000000000002,
        "end": 2.200000000000017,
        "average": 25.200000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.208955223880597,
        "text_similarity": 0.6290202140808105,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the temporal relation ('after') and approximate anchor time are similar, the predicted target interval and content are incorrect (it cites a different utterance and speaker rather than the female speaker saying 'real patients' at ~201.9\u2013202.6s), so it fails to capture the key factual element."
      }
    },
    {
      "question_id": "002",
      "question": "Once the interviewer finishes asking the question about comparing models, when does the female speaker finish explaining the advantages of 'Near Me' regarding real patients and capacity?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 198.7,
        "end": 306.9
      },
      "pred_interval": {
        "start": 208.5,
        "end": 279.6
      },
      "iou": 0.6571164510166362,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.800000000000011,
        "end": 27.299999999999955,
        "average": 18.549999999999983
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.5942514538764954,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely contradicts the reference: it gives entirely different start/end times and misidentifies events/speakers (e.g., E1 208.5 vs correct 186.4; E2 279.6\u2013281.3 vs correct 198.7\u2013306.9). Only the vague 'after' relation loosely matches, but key factual elements are incorrect or omitted."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the man is speaking on screen, when does he mention 'Near Me'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 342.0,
        "end": 344.0
      },
      "pred_interval": {
        "start": 335.7,
        "end": 361.0
      },
      "iou": 0.07905138339920945,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.300000000000011,
        "end": 17.0,
        "average": 11.650000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.16438356164383564,
        "text_similarity": 0.6311414241790771,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives completely different timestamps and a different quoted utterance, and it contradicts the correct temporal relation (says 'after' instead of 'during'), so it fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying 'Thank you and goodbye', when do the 'NHS Scotland' and 'Near Me' logos appear with text links?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 361.0,
        "end": 382.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 22.600000000000023,
        "average": 16.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.6133633852005005,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer incorrectly identifies both events and their timestamps (different segments entirely) and provides wrong time ranges; the vague 'after' relation does not salvage the substantial factual mismatches."
      }
    },
    {
      "question_id": "003",
      "question": "After the initial voiceover concludes with 'patient that day', when does the man on screen begin to say 'Thanks very much John and Amy'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 336.4,
        "end": 341.6
      },
      "pred_interval": {
        "start": 382.6,
        "end": 413.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.200000000000045,
        "end": 72.0,
        "average": 59.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324326,
        "text_similarity": 0.5806282758712769,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer is largely incorrect\u2014it misidentifies both event times and the spoken content, failing to match the ground-truth timestamps and utterance; only the temporal relation ('after') is correct."
      }
    }
  ]
}