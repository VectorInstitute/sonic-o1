{
  "topic_id": 5,
  "topic_name": "Courtroom Proceedings",
  "num_evaluated": 13,
  "aggregated_metrics": {
    "detailed": {
      "rouge_l_mean": 0.12741091760176024,
      "rouge_l_std": 0.03658168184694336,
      "text_similarity_mean": 0.330379205254408,
      "text_similarity_std": 0.17498502603364302,
      "llm_judge_score_mean": 0.9230769230769231,
      "llm_judge_score_std": 0.8284868934053085
    },
    "short": {
      "rouge_l_mean": 0.09998651893098662,
      "rouge_l_std": 0.04095117183029242,
      "text_similarity_mean": 0.2888646920999655,
      "text_similarity_std": 0.16898893086146574,
      "llm_judge_score_mean": 0.8461538461538461,
      "llm_judge_score_std": 0.8634593969478326
    },
    "cider": {
      "cider_detailed": 0.0024133440780724933,
      "cider_short": 0.0005130917867555334
    }
  },
  "per_entry_results": [
    {
      "video_id": "TVriGlkPexA",
      "video_number": "001",
      "detailed": {
        "rouge_l": 0.12195121951219512,
        "text_similarity": 0.40324026346206665,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures only minimal visual elements (a man in court, seated at a table, and a 'freekeene' end screen) but omits virtually all substantive content: the sentencing hearing, the dropped breach-of-bail charge, Frank's vocal protest and First Amendment claims, specific dialogue/quotes, and the promotional segment about censorship and alternate platforms."
      },
      "short": {
        "rouge_l": 0.14606741573033707,
        "text_similarity": 0.47392165660858154,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures only basic visual moments (man in court, seated with laptop, ends with 'freekeene') but omits nearly all key factual elements from the correct answer\u2014no mention of the attorney's statements, dropped charge/sentencing, Frank's First Amendment protests and quoted line, or the video's censorship/Odyssey promotion."
      }
    },
    {
      "video_id": "Z_6JBsE07b8",
      "video_number": "002",
      "detailed": {
        "rouge_l": 0.16615384615384615,
        "text_similarity": 0.24466843903064728,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction only describes visual details of a courtroom scene and omits all substantive content: it fails to report the prosecutor's summary, victims' impact statements, the defendant's lack of remorse and admissions, sentencing history, and the judge's response."
      },
      "short": {
        "rouge_l": 0.16216216216216217,
        "text_similarity": 0.255462646484375,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction provides only a superficial visual description of a man speaking in court and omits almost all key factual elements from the correct answer (criminal history, victim impact statements, Skolman's declarations of no remorse, and the judge's remarks), so it fails to capture the video\u2019s substantive content."
      }
    },
    {
      "video_id": "u0IZ4j1g25s",
      "video_number": "003",
      "detailed": {
        "rouge_l": 0.12209302325581395,
        "text_similarity": 0.734127402305603,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the core fact that Halderson was found guilty and instead describes an ongoing trial, invents that he was a former police officer, and misstates key evidence and outcomes while omitting almost all details from the correct summary."
      },
      "short": {
        "rouge_l": 0.12903225806451613,
        "text_similarity": 0.7257959842681885,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes Halderson was found guilty but omits most key details (charges, verdict speed, judge/DA comments, specific forensic evidence, sentencing) and introduces unsupported or inaccurate claims (calling him a former police officer and saying he killed his father, and citing text messages/witness statements rather than DNA/fingerprint/cell data)."
      }
    },
    {
      "video_id": "xwZ2K8b_pBw",
      "video_number": "004",
      "detailed": {
        "rouge_l": 0.1951219512195122,
        "text_similarity": 0.6183631420135498,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only vaguely touches on AI in courts but fails to capture the central incident (the 74-year-old using an AI-generated avatar), the judge's reaction and quotes, and the video's broader discussion of legal trends, risks, and adoption\u2014additionally it mischaracterizes the visuals and incorrectly references the Supreme Court."
      },
      "short": {
        "rouge_l": 0.14569536423841062,
        "text_similarity": 0.26182788610458374,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer only lists visual fragments (shots of people) and fails to capture any key facts from the correct summary\u2014no mention of the 74-year-old, the AI-generated lawyer avatar, the judge stopping the video, the man's admission/promotion of his startup, or the ensuing ethical discussion."
      }
    },
    {
      "video_id": "2B_e7fvwi90",
      "video_number": "005",
      "detailed": {
        "rouge_l": 0.12389380530973453,
        "text_similarity": 0.3193909525871277,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction describes visual courtroom behavior but omits the core semantic content\u2014the video\u2019s focus on Lyle Menendez alleging sexual abuse by his father\u2014so it fails to capture the key factual element of the correct summary."
      },
      "short": {
        "rouge_l": 0.0,
        "text_similarity": 0.2737533450126648,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only gives superficial visual actions (a man speaking and covering his face) and omits the key factual elements\u2014Lyle Menendez's identity, the allegation of his father's sexual abuse, and the Menendez Brothers case context."
      }
    },
    {
      "video_id": "5yNgC39Q2HE",
      "video_number": "006",
      "detailed": {
        "rouge_l": 0.06472491909385114,
        "text_similarity": 0.22574660181999207,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is entirely incorrect and misses all key facts: it describes a generic virtual meeting about technology/regulation rather than the Hothi v. Musk court session, omitting attorneys, legal issues (public interest, constitutional malice, anti\u2011SLAPP), and cited cases."
      },
      "short": {
        "rouge_l": 0.09183673469387756,
        "text_similarity": 0.19887065887451172,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated and factually incorrect: it describes a generic virtual meeting about technology, omitting all key legal details, parties, and arguments from the correct summary and introducing unsupported visual claims."
      }
    },
    {
      "video_id": "9U_cQz-7sT4",
      "video_number": "007",
      "detailed": {
        "rouge_l": 0.1212121212121212,
        "text_similarity": 0.47528785467147827,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only notes generic visual details and that it's a judge confirmation, but it omits the core substance\u2014Sen. Ted Cruz's hypothetical questions about self\u2011identification and Article III standing and Judge Ketanji Brown Jackson's substantive responses\u2014so it is largely incomplete."
      },
      "short": {
        "rouge_l": 0.09937888198757765,
        "text_similarity": 0.368922621011734,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction only gives generic visual descriptions and omits all substantive content about Senator Cruz's questioning, the hypotheticals on self-identification and discrimination, and Judge Jackson's refusal and judicial explanation."
      }
    },
    {
      "video_id": "gTBoJ9W8zQ8",
      "video_number": "010",
      "detailed": {
        "rouge_l": 0.12218649517684886,
        "text_similarity": 0.21488602459430695,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction provides only vague visual shots and no substantive details from the video; it omits the core narrative (Haller's cross\u2011examination, Pettis admitting coercion, naming Lankford, Lankford's outburst and contempt, and the adjournment), so it fails to capture the video's content."
      },
      "short": {
        "rouge_l": 0.08888888888888889,
        "text_similarity": 0.24030336737632751,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives only vague visual scene descriptions and omits all key factual elements (cross\u2011examination, threats, identification of Detective Lee Lankford, contempt and recess) from the correct answer."
      }
    },
    {
      "video_id": "hXN6cDKyk4g",
      "video_number": "009",
      "detailed": {
        "rouge_l": 0.056451612903225805,
        "text_similarity": 0.22022022306919098,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer only describes the speaker's appearance and gestures and omits the entire substantive content of the talk (legal advice, recommendations, and detailed points), so it fails to match the correct summary."
      },
      "short": {
        "rouge_l": 0.06037735849056604,
        "text_similarity": 0.20869232714176178,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer only describes the speaker's appearance and gestures and contains none of the substantive legal advice, recommendations, or key points from the correct summary, thus failing to capture any of the video\u2019s content."
      }
    },
    {
      "video_id": "DelhQUg8eH4",
      "video_number": "011",
      "detailed": {
        "rouge_l": 0.13768115942028986,
        "text_similarity": 0.277718722820282,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated to the correct summary: it describes title text and administrative/script details about translation and interpretation, while omitting all events, people, crimes, and evidence described in the prosecutor's opening\u2014no substantive overlap."
      },
      "short": {
        "rouge_l": 0.09039548022598871,
        "text_similarity": 0.21612557768821716,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct summary, describing text screens and unrelated items instead of the case against Carl Miller, eyewitness accounts, the getaway, license plate identification, and forensic cocaine evidence."
      }
    },
    {
      "video_id": "k28NMpEkuRU",
      "video_number": "012",
      "detailed": {
        "rouge_l": 0.14746543778801843,
        "text_similarity": 0.0793619155883789,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated to the correct summary, omitting all key facts about the vehicle break-in, identification of Walter Merchant, the assault on the deputy, and items found, while introducing hallucinated details about a clock and a translation app."
      },
      "short": {
        "rouge_l": 0.0819672131147541,
        "text_similarity": 0.013863971456885338,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated to the correct summary, describing a graphics/app instead of the crime, arrest, and identification details; it omits all key facts and introduces irrelevant content."
      }
    },
    {
      "video_id": "RHq_CJJDpUY",
      "video_number": "013",
      "detailed": {
        "rouge_l": 0.1656050955414013,
        "text_similarity": 0.24928978085517883,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction offers a superficial visual description and unrelated points about legal education, omitting almost all substantive content about appellate criminal law, drafting, Section 313, judge psychology, and case examples from the correct summary; only the presence of a speaking, turbaned man and bookshelves aligns with the reference."
      },
      "short": {
        "rouge_l": 0.12068965517241378,
        "text_similarity": 0.39669495820999146,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only notes a lawyer speaking and a vague emphasis on legal education, but it omits nearly all substantive themes from the correct summary (appellate advocacy, categories of appeals, drafting, case examples, oral advocacy, evidence issues), making it largely incomplete and not aligned."
      }
    },
    {
      "video_id": "L_dJ23CLzTo",
      "video_number": "014",
      "detailed": {
        "rouge_l": 0.11180124223602485,
        "text_similarity": 0.23262834548950195,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only describes superficial visual details and scene composition, failing to capture any of the substantive content about witness preparation, key challenges, or the training methodology discussed in the correct answer."
      },
      "short": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.12100599706172943,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only lists superficial visual details (men talking, pointing, logo) and omits the video's substantive points about witness preparation, its challenges, and familiarisation training, so it fails to match the correct answer."
      }
    }
  ]
}