{
  "topic_id": 3,
  "topic_name": "Parent-Teacher Conferences",
  "num_evaluated": 519,
  "aggregated_metrics": {
    "mean_iou": 0.02101621231123869,
    "std_iou": 0.09365195083048253,
    "median_iou": 0.0,
    "R@0.3": {
      "recall": 0.030828516377649325,
      "count": 16,
      "total": 519
    },
    "R@0.5": {
      "recall": 0.015414258188824663,
      "count": 8,
      "total": 519
    },
    "R@0.7": {
      "recall": 0.0019267822736030828,
      "count": 1,
      "total": 519
    },
    "mae": {
      "start_mean": 1042.4920211946048,
      "end_mean": 1040.3418901734103,
      "average_mean": 1041.4169556840077
    },
    "rationale": {
      "rouge_l_mean": 0.18424253949729022,
      "rouge_l_std": 0.09147001101708899,
      "text_similarity_mean": 0.38460938602341393,
      "text_similarity_std": 0.18160557040979336,
      "llm_judge_score_mean": 3.277456647398844,
      "llm_judge_score_std": 2.4416292622522064
    },
    "rationale_cider": 0.23368982975716915
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "Once the speaker states he used to be a teacher, when does he explain why he would be called upon to interpret?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 25.699,
        "end": 29.902
      },
      "pred_interval": {
        "start": 58.7,
        "end": 64.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.001000000000005,
        "end": 34.397999999999996,
        "average": 33.6995
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.4218953251838684,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time window (58.7\u201364.3s) is completely different from the correct explanation interval (25.699\u201329.902s) and thus fails to identify when the speaker explains why he'd be called upon to interpret."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker announces the opening poll, when does he start explaining how to format the name for the certificate?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 71.748,
        "end": 78.603
      },
      "pred_interval": {
        "start": 139.6,
        "end": 146.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.85199999999999,
        "end": 68.19700000000002,
        "average": 68.0245
      },
      "rationale_metrics": {
        "rouge_l": 0.0851063829787234,
        "text_similarity": 0.48333385586738586,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer correctly states the explanation occurs after the poll but gives timestamps (139.6\u2013146.8s) that are far from the ground truth (71.748\u201378.603s), so the timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Next, after the speaker states that those who don't need a certificate can ignore the poll, when does he start explaining what to do if the pop-up doesn't appear?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 83.778,
        "end": 88.445
      },
      "pred_interval": {
        "start": 199.4,
        "end": 202.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 115.622,
        "end": 114.155,
        "average": 114.8885
      },
      "rationale_metrics": {
        "rouge_l": 0.10256410256410255,
        "text_similarity": 0.4051634669303894,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives a much later timestamp (199.4\u2013202.6s) and a different action (click his name) instead of the correct explanation about iPad users and the pop-up starting at ~83.78s, so it fails to match key facts."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker mentions not leaving the webinar by 'X-ing out', when does he instruct to use the 'red button' to close out?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 172.8,
        "end": 174.7
      },
      "pred_interval": {
        "start": 194.6,
        "end": 205.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.799999999999983,
        "end": 31.0,
        "average": 26.39999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.09302325581395349,
        "text_similarity": 0.35932183265686035,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction (~1:34 / ~94s) is far from the correct target time (172.8\u2013174.7s) and fails to reflect the anchor/target timing relation; therefore it is essentially incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker says he will leave up the poll, when does he mention sharing links in the chat?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 193.9,
        "end": 195.4
      },
      "pred_interval": {
        "start": 185.2,
        "end": 188.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.700000000000017,
        "end": 6.900000000000006,
        "average": 7.800000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.10169491525423728,
        "text_similarity": 0.33661937713623047,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the relative ordering (sharing links happens after the poll) but omits the specific timestamps and precise temporal relation given in the reference, and adds an extra detail about 'X-ing out' that is not present in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the male speaker discusses the second link, a webinar called 'Translation for Teachers', when does he introduce the third link for the Refugee Services of Texas charity?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 231.5,
        "end": 236.0
      },
      "pred_interval": {
        "start": 174.5,
        "end": 182.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.0,
        "end": 53.099999999999994,
        "average": 55.05
      },
      "rationale_metrics": {
        "rouge_l": 0.0784313725490196,
        "text_similarity": 0.31059420108795166,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction is vague\u2014saying the link is introduced right before its explanation\u2014but it omits the required temporal/relative details (the specific anchor and target intervals) and does not state that it is the next link after the anchor as in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once Graciela finishes asking the participants to unmute and then mute themselves, when does she say \"Perfect\"?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 380.807,
        "end": 381.3
      },
      "pred_interval": {
        "start": 256.7,
        "end": 260.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 124.10700000000003,
        "end": 121.0,
        "average": 122.55350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3214285714285714,
        "text_similarity": 0.7104390859603882,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures that Graciela says 'Perfect' after participants unmute and mute, preserving the intended meaning, but it omits the specific timestamps and precise timing details provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once Graciela finishes explaining how questions will be handled, when does she mention the glossary of terms?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 425.281,
        "end": 429.266
      },
      "pred_interval": {
        "start": 418.9,
        "end": 420.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.381000000000029,
        "end": 8.966000000000008,
        "average": 7.673500000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.25396825396825395,
        "text_similarity": 0.741113543510437,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a single timestamp (418.9s) that contradicts the reference (glossary begins at 425.281s and finishes at 429.266s) and omits the event boundaries; it's therefore largely incorrect though on the same general segment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the modes of interpretation used in educational settings, when does the slide transition to 'Educational Settings'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 560.8,
        "end": 560.9
      },
      "pred_interval": {
        "start": 58.2,
        "end": 63.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 502.59999999999997,
        "end": 497.0,
        "average": 499.79999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2580645161290322,
        "text_similarity": 0.4856269955635071,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the slide transitions after the speaker's mention) but omits the precise anchor/target timing and labels (546.1\u2013549.7s and 560.8\u2013560.9s) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker defines an educational setting, when does she list the types of institutions that can be included?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 575.0,
        "end": 585.8
      },
      "pred_interval": {
        "start": 74.1,
        "end": 77.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 500.9,
        "end": 507.9,
        "average": 504.4
      },
      "rationale_metrics": {
        "rouge_l": 0.07272727272727272,
        "text_similarity": 0.1998191475868225,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction does not match the reference: it ties the listing to an explanation of where interpreters are called rather than to the immediately-following listing after the educational-setting definition (566.1\u2013570.0s \u2192 575.0\u2013585.8s), omitting the correct anchor and temporal relation."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining where interpreters are mostly called, when does the slide change to an image with a diploma and US flag?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 628.0,
        "end": 628.1
      },
      "pred_interval": {
        "start": 78.8,
        "end": 82.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 549.2,
        "end": 545.2,
        "average": 547.2
      },
      "rationale_metrics": {
        "rouge_l": 0.2028985507246377,
        "text_similarity": 0.5580259561538696,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that the slide change occurs immediately after the speaker's explanation, but it omits the precise timestamps and event labels provided in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the mandatory schooling age in the United States, when do they state the mandatory schooling age in Mexico?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 749.416,
        "end": 751.6
      },
      "pred_interval": {
        "start": 73.8,
        "end": 77.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 675.6160000000001,
        "end": 674.1,
        "average": 674.8580000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.2999005913734436,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives entirely different timestamps and content (referring to junior high grades at ~74\u201377s) that do not match the correct post-US event at ~749.4\u2013751.6s; it contradicts and omits the key timing relationship stated in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning the number of public schools in the U.S. in 2021, when does she state the average number of students per public school?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.167,
        "end": 877.377
      },
      "pred_interval": {
        "start": 497.5,
        "end": 523.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 375.66700000000003,
        "end": 353.577,
        "average": 364.622
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.6371042728424072,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer provides the average number (528) rather than the timing requested; it omits the timestamps given in the correct answer and introduces a specific number not present in the reference, so it only partially aligns with the intent."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states the total allocation for K-12 schools, when does she mention the average amount per student?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 920.147,
        "end": 925.432
      },
      "pred_interval": {
        "start": 564.0,
        "end": 580.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 356.14700000000005,
        "end": 345.23199999999997,
        "average": 350.6895
      },
      "rationale_metrics": {
        "rouge_l": 0.21818181818181817,
        "text_similarity": 0.5603669881820679,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states the sequence (after the $640 billion total) and gives an average per-student figure, but the numeric value differs slightly from the ground truth ($12,624 vs $12,600)."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning 'disciplinary meetings', when does she mention 'classroom instruction'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1191.5,
        "end": 1192.5
      },
      "pred_interval": {
        "start": 114.7,
        "end": 116.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1076.8,
        "end": 1076.1,
        "average": 1076.4499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.08888888888888889,
        "text_similarity": 0.30895259976387024,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is unrelated to the reference: it neither mentions the 'disciplinary meetings' or 'classroom instruction' events or their timing nor the 'once_finished' relation, and instead introduces unrelated details about ARD participants."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes listing the participants of an ARD meeting, when does she begin discussing the purpose of the meeting?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1249.5,
        "end": 1252.8
      },
      "pred_interval": {
        "start": 1293.8,
        "end": 1314.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.299999999999955,
        "end": 61.799999999999955,
        "average": 53.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923078,
        "text_similarity": 0.39711689949035645,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that discussion of the purpose follows the participant list but omits the key factual timing details (start at 1249.5s, end at 1252.8s) required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker asks about the reasons for an ARD meeting, when does she state the first reason?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1294.4,
        "end": 1296.1
      },
      "pred_interval": {
        "start": 1315.7,
        "end": 1340.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.299999999999955,
        "end": 44.40000000000009,
        "average": 32.85000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.37748780846595764,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to answer the 'when' question and provides no timing information; it merely restates that she states the first reason, omitting the timestamps (1294.4s\u20131296.1s) given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks about the different purposes of the ARD meeting, when does she start listing the initial purposes?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1445.358,
        "end": 1450.41
      },
      "pred_interval": {
        "start": 5.2,
        "end": 7.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1440.158,
        "end": 1442.6100000000001,
        "average": 1441.384
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.4214460253715515,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation ('after') but omits the key factual details (the specific start/finish timestamps), so it is incomplete relative to the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide fully displays the 'Review Assessment' section, when does the speaker specifically mention the 'full individual evaluation'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.092,
        "end": 1432.125
      },
      "pred_interval": {
        "start": 143.6,
        "end": 145.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1284.4920000000002,
        "end": 1286.925,
        "average": 1285.7085000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714288,
        "text_similarity": 0.5434558987617493,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only states that the phrase is mentioned in a list and provides no timing or the after/relative relation specified in the reference; it is therefore largely incomplete and not aligned with the detailed correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing parental input, when does the text for 'Review PLAAFP' appear on the slide?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1531.58,
        "end": 1532.59
      },
      "pred_interval": {
        "start": 158.2,
        "end": 160.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1373.3799999999999,
        "end": 1372.3899999999999,
        "average": 1372.8849999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.19607843137254902,
        "text_similarity": 0.5671688318252563,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures a post-speech temporal relation but omits the precise timestamps and wrongly references his mention of goals/performance rather than the completion of parental input; it is vague and partially misaligned with the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions being 'completely clueless' about the ARD meetings, when does she state that the terminology was 'so scary'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1602.75,
        "end": 1607.38
      },
      "pred_interval": {
        "start": 159.4,
        "end": 163.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1443.35,
        "end": 1443.68,
        "average": 1443.5149999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.10169491525423728,
        "text_similarity": 0.16502735018730164,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and incomplete: it gives a single wrong timestamp (~1:20) for 'completely clueless' and does not identify when 'so scary' occurs or the correct relative ordering (anchor at 0:06 and target at 0:12\u20130:17)."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker states 'I am an interpreter', when does she recount the other interpreter responding 'I have to interpret'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1656.82,
        "end": 1658.744
      },
      "pred_interval": {
        "start": 168.1,
        "end": 170.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1488.72,
        "end": 1488.5439999999999,
        "average": 1488.632
      },
      "rationale_metrics": {
        "rouge_l": 0.09999999999999999,
        "text_similarity": 0.17830152809619904,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the response occurs immediately after the speaker's introduction but gives a highly inaccurate timestamp (\u22481:22 vs. the correct ~1655\u20131658s), omitting the precise anchor/target times and thus failing key factual accuracy."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker reviews the IEP goals and objectives, when does she begin to review accommodations?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1758.266,
        "end": 1760.028
      },
      "pred_interval": {
        "start": 180.6,
        "end": 181.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1577.6660000000002,
        "end": 1578.528,
        "average": 1578.0970000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.18867924528301885,
        "text_similarity": 0.3203265070915222,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives a completely incorrect time ('just before 1:30' vs. ~1758s/29m18s) and omits the precise timestamps and context that it is the next ARD agenda item, so it does not match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes discussing the previous assessment, when does she mention the proposal of the STAAR assessment?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1783.7,
        "end": 1791.4
      },
      "pred_interval": {
        "start": 245.9,
        "end": 267.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1537.8,
        "end": 1523.6000000000001,
        "average": 1530.7
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320754,
        "text_similarity": 0.18684151768684387,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a single start time (245.9s) that does not match the correct start (1783.7s) and omits the target end time and the 'once_finished' relation, so it is largely incorrect and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker concludes the topic of district-wide assessments and accommodations, when does she introduce the least restrictive environment?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1810.5,
        "end": 1815.2
      },
      "pred_interval": {
        "start": 267.9,
        "end": 300.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1542.6,
        "end": 1514.4,
        "average": 1528.5
      },
      "rationale_metrics": {
        "rouge_l": 0.18749999999999997,
        "text_similarity": 0.22596034407615662,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the topic shift occurs after district-wide assessments (once_finished), but the reported start time (\u2248267.9s) is drastically inconsistent with the reference start (\u22481810.5s) and it omits the target end time, so the timing is incorrect and incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing the potential harmful effects of an instruction setting, when does she question if the benefits outweigh the harm?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1854.7,
        "end": 1857.3
      },
      "pred_interval": {
        "start": 300.9,
        "end": 316.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1553.8000000000002,
        "end": 1541.1,
        "average": 1547.45
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.16286443173885345,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the relative relation ('right after') but gives a drastically incorrect start time (\u2248300.9s vs the correct ~1854.7s) and omits the target phrase and end time, so it fails on key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says she will send glossaries to Marco, when does she introduce disciplinary action meetings?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1969.3,
        "end": 1975.0
      },
      "pred_interval": {
        "start": 234.9,
        "end": 258.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1734.3999999999999,
        "end": 1716.3,
        "average": 1725.35
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322037,
        "text_similarity": 0.508337140083313,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the disciplinary action meeting is introduced after the glossaries remark, but it omits the precise start/end timestamps and temporal details provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining when disciplinary actions happen, when does the slide transition to 'Potential disciplinary outcomes'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2006.4,
        "end": 2007.1
      },
      "pred_interval": {
        "start": 258.7,
        "end": 263.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1747.7,
        "end": 1743.8999999999999,
        "average": 1745.8
      },
      "rationale_metrics": {
        "rouge_l": 0.4166666666666667,
        "text_similarity": 0.7068971395492554,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction captures the correct temporal relation (the slide changes once the speaker finishes) but omits the key factual details: the precise timestamps for E1 (2005.6s), E2 (2006.4s) and the settle time (2007.1s), and the explicit 'once_finished'/absolute\u2192relative mapping."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what skills are needed to interpret in an educational setting, when does she define the interpreter's role?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2161.0,
        "end": 2168.0
      },
      "pred_interval": {
        "start": 239.4,
        "end": 257.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1921.6,
        "end": 1910.2,
        "average": 1915.9
      },
      "rationale_metrics": {
        "rouge_l": 0.19230769230769232,
        "text_similarity": 0.40702205896377563,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation that the definition comes after the question, but it omits the key factual details (the specific start/end timestamps and the explicit after relation with those time intervals) required by the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker stops sharing the slides, when does the video switch to the gallery view of the participants?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2465.33,
        "end": 2475.337
      },
      "pred_interval": {
        "start": 2436.9,
        "end": 2458.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.429999999999836,
        "end": 16.63700000000017,
        "average": 22.533500000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.5840743184089661,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the gallery appears after the speaker stops sharing, but it omits the key timing details and transition completion timestamps provided in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the 'Simultaneous Interpreting' slide is displayed, when does the speaker mention ARD meetings as a use case?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2409.449,
        "end": 2418.605
      },
      "pred_interval": {
        "start": 2517.9,
        "end": 2520.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 108.45100000000002,
        "end": 101.39499999999998,
        "average": 104.923
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.722588300704956,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction directly contradicts the ground truth: the correct answer states the ARD meetings mention occurs after the Simultaneous Interpreting slide (around 2409.449\u20132418.605s), whereas the prediction claims it occurs before the slide."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker asks if everyone is still awake, when does she begin to explain the practice method?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2490.175,
        "end": 2497.855
      },
      "pred_interval": {
        "start": 2520.0,
        "end": 2520.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.824999999999818,
        "end": 22.144999999999982,
        "average": 25.9849999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.37412530183792114,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction asserts the explanation begins immediately after the question, but the reference shows the practice method starts ~24 seconds later (relation = after, not immediate) and provides precise timestamps, which the prediction omits and contradicts."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states that everyone at home will be interpreting, when does she ask if everyone is good with the plan?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2513.9,
        "end": 2515.1
      },
      "pred_interval": {
        "start": 254.0,
        "end": 256.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2259.9,
        "end": 2258.2999999999997,
        "average": 2259.1
      },
      "rationale_metrics": {
        "rouge_l": 0.27397260273972607,
        "text_similarity": 0.4458765387535095,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction merely restates the scenario and fails to provide the required timing/relative information (timestamps and 'once_finished' relation) present in the correct answer, omitting key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks to discuss a classroom concern about Peter, when does she describe Peter as a sweet boy who enjoys stacking blocks?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2558.467,
        "end": 2564.21
      },
      "pred_interval": {
        "start": 264.7,
        "end": 273.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2293.7670000000003,
        "end": 2290.41,
        "average": 2292.0885
      },
      "rationale_metrics": {
        "rouge_l": 0.08823529411764705,
        "text_similarity": 0.3513007164001465,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction reverses the sequence\u2014saying the description comes before discussing concerns\u2014contradicting the ground truth that the request about concerns occurs first and the positive description follows; it also omits the timestamps and key timing detail."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions Peter may benefit from special education services, when does she discuss the social worker's assessment and concerns at home?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2595.389,
        "end": 2610.228
      },
      "pred_interval": {
        "start": 269.7,
        "end": 270.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2325.6890000000003,
        "end": 2340.228,
        "average": 2332.9585
      },
      "rationale_metrics": {
        "rouge_l": 0.3488372093023256,
        "text_similarity": 0.7416407465934753,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the social worker discussion occurs after the special-education mention, but it omits the precise timestamps and concrete temporal boundaries given in the reference, offering only a vague 'brief pause.'"
      }
    },
    {
      "question_id": "001",
      "question": "During the main speaker's instructions for showing thumbs up, sideways, or down, when do multiple participants start showing their reactions?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2731.0,
        "end": 2736.0
      },
      "pred_interval": {
        "start": 217.9,
        "end": 226.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2513.1,
        "end": 2509.2,
        "average": 2511.1499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.45908141136169434,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly states reactions occur after the instructions, whereas the reference indicates multiple participants start reacting at 2731s during the speaker's instructions (2728.833\u20132741.307) and continue until 2736s; it also omits the timestamps and relation to the anchor event."
      }
    },
    {
      "question_id": "002",
      "question": "After the main speaker asks Marco if he has anything to say, when does Marco start talking about the link he shared?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2760.32,
        "end": 2763.065
      },
      "pred_interval": {
        "start": 237.4,
        "end": 252.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2522.92,
        "end": 2510.965,
        "average": 2516.9425
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962262,
        "text_similarity": 0.44102942943573,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly conveys that Marco speaks about the link after the main speaker's question (preserving the temporal relation), but it omits the precise timing details and could imply an immediate response rather than the several-second delay noted in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Okay' to transition, when does she start talking about questions related to a child's behavior for a rating scale?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2838.512,
        "end": 2846.226
      },
      "pred_interval": {
        "start": 260.4,
        "end": 264.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2578.112,
        "end": 2581.426,
        "average": 2579.7690000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.13793103448275865,
        "text_similarity": 0.327691912651062,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the gist that after saying 'Okay' the speaker discusses questions about a child's behavior, but it omits the crucial timing details and the specific anchor-to-target relation (timestamps and the 'immediately begins' interval) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes instructing to write 'DK' if the answer is unknown, when does she start reading the first child-related question?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2867.07,
        "end": 2872.84
      },
      "pred_interval": {
        "start": 295.4,
        "end": 306.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2571.67,
        "end": 2566.04,
        "average": 2568.855
      },
      "rationale_metrics": {
        "rouge_l": 0.12765957446808512,
        "text_similarity": 0.10264195501804352,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the question is read after the instruction but wrongly implies it occurs immediately and omits the precise timestamps (target starts at 2867.07s, ~7.2s after the anchor), so it is incomplete/misleading."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'My child often argues with adults', when does she start reading the next child-related question?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2888.82,
        "end": 2892.66
      },
      "pred_interval": {
        "start": 297.0,
        "end": 297.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2591.82,
        "end": 2595.06,
        "average": 2593.44
      },
      "rationale_metrics": {
        "rouge_l": 0.13793103448275865,
        "text_similarity": 0.13536234200000763,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the next child-related question is read next in sequence but omits the exact timestamps and incorrectly states it occurs 'immediately afterward'\u2014there is a ~6.04s gap (starts at 2888.82s) after the anchor ends at 2882.78s."
      }
    },
    {
      "question_id": "003",
      "question": "After the video screen changes to a black view displaying names, when does the speaker read the question about the child blurring out answers?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2930.0,
        "end": 2934.78
      },
      "pred_interval": {
        "start": 297.8,
        "end": 298.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2632.2,
        "end": 2636.5800000000004,
        "average": 2634.3900000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.07407407407407407,
        "text_similarity": 0.14293962717056274,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the rough sequence (the question is read after mentioning the child's attention issues) but omits the precise timing/timestamps and the key fact that the target audio occurs while the black screen is visible after the visual change, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker describes a child having difficulty waiting for their turn, when does she describe a child being constantly on the go?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3036.8,
        "end": 3044.7
      },
      "pred_interval": {
        "start": 15.3,
        "end": 24.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3021.5,
        "end": 3019.7999999999997,
        "average": 3020.6499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.0816326530612245,
        "text_similarity": 0.02892766334116459,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only restates that the child is 'often on the go' and omits all timing/timestamp information and the anchor-target relation required by the correct answer, so it fails to answer 'when'."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing a child being often forgetful in daily activities, when does she ask the audience how they did?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3099.8,
        "end": 3101.4
      },
      "pred_interval": {
        "start": 27.8,
        "end": 28.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3072.0,
        "end": 3072.8,
        "average": 3072.4
      },
      "rationale_metrics": {
        "rouge_l": 0.045454545454545456,
        "text_similarity": -0.05991191044449806,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the question occurs after the description, preserving the temporal order, but it omits key details from the reference\u2014namely the specific timing/timestamps and that the question follows after a noticeable pause."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks about the remaining time, when does Marco start responding?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3134.1,
        "end": 3139.2
      },
      "pred_interval": {
        "start": 29.1,
        "end": 30.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3105.0,
        "end": 3109.0,
        "average": 3107.0
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.2262028455734253,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that Marco responds immediately after the question, but it omits the key factual timestamps and precision provided in the correct answer (3131.2\u20133133.0 for the question and 3134.1\u20133139.2 for Marco's response)."
      }
    },
    {
      "question_id": "001",
      "question": "Once Frank finishes asking if the 504 plan is inside the subject of special education, when does the woman in green confirm that it is?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3235.829,
        "end": 3239.914
      },
      "pred_interval": {
        "start": 18.2,
        "end": 19.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3217.6290000000004,
        "end": 3220.614,
        "average": 3219.1215
      },
      "rationale_metrics": {
        "rouge_l": 0.30188679245283023,
        "text_similarity": 0.4811381697654724,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the woman in green confirms it, but it omits all required timing details and the specified temporal relation (timestamps/relative timing), so it fails to answer the 'when' aspect. "
      }
    },
    {
      "question_id": "002",
      "question": "Once Frank finishes stating that he thinks 504 is federal language, when does another woman ask for confirmation?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.61,
        "end": 3269.733
      },
      "pred_interval": {
        "start": 19.7,
        "end": 20.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3248.9100000000003,
        "end": 3249.1330000000003,
        "average": 3249.0215000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.3897612392902374,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the general sequence (that someone asks for confirmation after Frank), but it omits the crucial timestamps and the identification that it is a woman asking, so it fails to provide the specific temporal details required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once Jesse Thompson finishes asking how interpreters can stand up for themselves, when does the woman in green explain what interpreters have control over?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3361.672,
        "end": 3367.782
      },
      "pred_interval": {
        "start": 20.8,
        "end": 23.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3340.872,
        "end": 3344.1820000000002,
        "average": 3342.527
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.42122119665145874,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the correct temporal relation (that the woman explains after Jesse finishes) but omits the key factual elements\u2014the precise start and end timestamps given in the correct answer\u2014so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying she doesn't like being 'used' as an interpreter, when does she begin explaining what she needs for a successful encounter?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3404.5,
        "end": 3411.6
      },
      "pred_interval": {
        "start": 349.8,
        "end": 352.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3054.7,
        "end": 3058.9,
        "average": 3056.8
      },
      "rationale_metrics": {
        "rouge_l": 0.13559322033898305,
        "text_similarity": 0.41879022121429443,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the explanation begins immediately after the anchor event, but it omits the precise timestamps and the end-time adjustment provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that rules can be set ahead of time for pre-sessions, when does she explain what raising a hand means?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3433.1,
        "end": 3436.5
      },
      "pred_interval": {
        "start": 356.4,
        "end": 359.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3076.7,
        "end": 3077.4,
        "average": 3077.05
      },
      "rationale_metrics": {
        "rouge_l": 0.03174603174603175,
        "text_similarity": 0.0820174366235733,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction vaguely states the explanation happens after a prior remark, but it hallucinates a quoted line, misgenders the speaker, and claims it occurs 'right away'\u2014contradicting the given timestamps that show the target starts several seconds after the anchor."
      }
    },
    {
      "question_id": "003",
      "question": "Once the female speaker replies 'Yes' to the question about doing work on Zoom, when does she explain how consecutive interpreting works on Zoom?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3471.0,
        "end": 3493.0
      },
      "pred_interval": {
        "start": 362.8,
        "end": 365.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3108.2,
        "end": 3127.5,
        "average": 3117.85
      },
      "rationale_metrics": {
        "rouge_l": 0.12658227848101264,
        "text_similarity": 0.3164554536342621,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the provided timestamps and explicit anchor-to-target sequence; it introduces unrelated cues ('rules can be set ahead' and 'they will tell you') rather than stating that the target event starts after the anchor finishes, so it does not align with the correct, time-specific answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"And then you as the interpreter will go into that room as well,\" when does she explain what the attendees can hear?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3584.889,
        "end": 3595.545
      },
      "pred_interval": {
        "start": 235.9,
        "end": 267.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3348.989,
        "end": 3327.745,
        "average": 3338.367
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.6432609558105469,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes that the speaker begins to explain what attendees can hear, but it omits the crucial timing details and the relation that the explanation follows after a brief pause, making it incomplete compared to the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After Martha Rosenbaum mentions that schools receive a lot of funding from the government, when does she ask how to change the use of teachers as translators?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3629.646,
        "end": 3632.125
      },
      "pred_interval": {
        "start": 267.8,
        "end": 279.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3361.846,
        "end": 3352.725,
        "average": 3357.2855
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298242,
        "text_similarity": 0.2970670461654663,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (that the question comes after the funding remark) but omits the precise timing information given in the reference and slightly garbles the phrasing about changing teachers' use as translators, so it is incomplete. "
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker first mentions \"Executive Order 13166,\" when does she expand on its details, including its signing by President Clinton?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3669.853,
        "end": 3689.291
      },
      "pred_interval": {
        "start": 279.4,
        "end": 292.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3390.453,
        "end": 3397.0910000000003,
        "average": 3393.772
      },
      "rationale_metrics": {
        "rouge_l": 0.18749999999999997,
        "text_similarity": 0.6500262022018433,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the speaker expands on the order and that it was signed by President Clinton, but it fails to provide the requested timing/timestamps or that the elaboration immediately follows the mention and even misgenders the speaker."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that organizations receiving federal funds must provide meaningful language access, when does she suggest starting those conversations?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3762.0,
        "end": 3764.7
      },
      "pred_interval": {
        "start": 236.4,
        "end": 275.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3525.6,
        "end": 3488.7999999999997,
        "average": 3507.2
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320756,
        "text_similarity": 0.01997116394340992,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction merely repeats the question without providing timing information; it omits the key factual detail that the conversations should start immediately when the anchor ends (at 3762.0s) and the target follows until 3764.7s."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male speaker jokes about Google Translate replacing human interpreters, when does Maria E. Mendoza respond with 'Exactly!'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3789.6,
        "end": 3790.5
      },
      "pred_interval": {
        "start": 275.9,
        "end": 286.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3513.7,
        "end": 3503.9,
        "average": 3508.8
      },
      "rationale_metrics": {
        "rouge_l": 0.044444444444444446,
        "text_similarity": 0.10969437658786774,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction merely restates that Maria responds 'Exactly!' and does not provide the required timestamps or the anchor/target timing relation, so it fails to answer the 'when' and is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once Susanna finishes asking if the Zoom environment for interpreting school meetings is common in other states, when does Maria E. Mendoza begin to respond?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3933.2,
        "end": 3934.2
      },
      "pred_interval": {
        "start": 286.6,
        "end": 298.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3646.6,
        "end": 3635.7,
        "average": 3641.1499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.037037037037037035,
        "text_similarity": 0.20545296370983124,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction merely restates the question and provides no timing or quoted phrase; it omits the key factual details (start time 3933.2s and 'I'm going to venture to say') given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once Maria E. Mendosa finishes saying people are getting more comfortable with in-person meetings, when does the next speaker begin to add her point?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3956.6,
        "end": 3957.8
      },
      "pred_interval": {
        "start": 7.8,
        "end": 9.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3948.7999999999997,
        "end": 3948.2000000000003,
        "average": 3948.5
      },
      "rationale_metrics": {
        "rouge_l": 0.21875,
        "text_similarity": 0.5123948454856873,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that the next speaker adds her point and omits all precise timing details given in the correct answer (start/finish timestamps and alignment adjustments), so it is largely incomplete despite not contradicting the content."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria E. Mendosa interrupts to say 'This is gonna help you feel better', when does she start talking about her conversation with a school district client?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 4002.0,
        "end": 4007.6
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3967.0,
        "end": 3971.0,
        "average": 3969.0
      },
      "rationale_metrics": {
        "rouge_l": 0.15625,
        "text_similarity": 0.2522556781768799,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect\u2014it names a different speaker (Alejandra Mendez), gives entirely different timestamps (35.0\u201336.6s) and context, whereas the correct answer refers to Maria E. Mendosa interrupting and the target speech from 4002.0s to 4007.6s."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks to hear from Alejandra Mendez, when does Alejandra Mendez start speaking?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 4096.7,
        "end": 4098.5
      },
      "pred_interval": {
        "start": 414.0,
        "end": 418.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3682.7,
        "end": 3680.1,
        "average": 3681.3999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.453218013048172,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (414.0\u2013418.4s) do not match the reference (4096.7\u20134098.5s) and it incorrectly implies an immediate start rather than the short pause noted, so it is largely wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says that the meetings are emotionally exhausting, when does Maria ask if the volume of meetings for Spanish-speaking families has increased?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4154.13,
        "end": 4166.78
      },
      "pred_interval": {
        "start": 798.0,
        "end": 835.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3356.13,
        "end": 3331.7799999999997,
        "average": 3343.955
      },
      "rationale_metrics": {
        "rouge_l": 0.0983606557377049,
        "text_similarity": -0.10098215192556381,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the correct temporal relation by saying Maria asks after the speaker says \"it's easier\" instead of after the meetings are described as \"emotionally exhausting,\" and it omits the provided timestamps, so it is factually incorrect and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that there is more parent participation because it is easier, when does she mention a teacher requesting an in-person interpreter for initial ARD meetings?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4232.2,
        "end": 4238.0
      },
      "pred_interval": {
        "start": 1464.0,
        "end": 1482.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2768.2,
        "end": 2756.0,
        "average": 2762.1
      },
      "rationale_metrics": {
        "rouge_l": 0.06451612903225808,
        "text_similarity": 0.11515474319458008,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the relative sequence (she mentions it after discussing remote interpreting/parent participation) but omits the precise timestamps and anchor/target timing details required in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host says, 'let's do one more question from Jesse,' when does Jesse begin asking about teachers interpreting?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4340.45,
        "end": 4347.8
      },
      "pred_interval": {
        "start": 4296.8,
        "end": 4327.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.649999999999636,
        "end": 20.300000000000182,
        "average": 31.97499999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.17543859649122806,
        "text_similarity": 0.4149532914161682,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that Jesse asks after the host's line, but it omits the precise timestamps and the detail about the brief pause, making it incomplete compared to the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once Jesse finishes asking about legal liability for teachers interpreting, when does Maria state there isn't a government push for certification?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4367.0,
        "end": 4370.11
      },
      "pred_interval": {
        "start": 4328.4,
        "end": 4415.9
      },
      "iou": 0.0355428571428534,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.600000000000364,
        "end": 45.789999999999964,
        "average": 42.195000000000164
      },
      "rationale_metrics": {
        "rouge_l": 0.13793103448275862,
        "text_similarity": 0.4875572621822357,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the main causal relationship (Maria replies after Jesse's question) but omits key details from the reference\u2014specific event/timestamp markers and the note that Maria directly addresses the implication\u2014reducing completeness."
      }
    },
    {
      "question_id": "003",
      "question": "After Maria instructs to Google 'Executive Order 13166', when does she mention the CLASs standards for healthcare organizations?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4461.82,
        "end": 4474.23
      },
      "pred_interval": {
        "start": 4416.8,
        "end": 4455.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.01999999999953,
        "end": 19.029999999999745,
        "average": 32.024999999999636
      },
      "rationale_metrics": {
        "rouge_l": 0.21212121212121213,
        "text_similarity": 0.6776310205459595,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that Maria mentions the CLASs standards after instructing to Google the Executive Order, but the timestamp (4416.8s) is substantially inaccurate compared to the reference (\u22484461.8\u20134474.2s), so it fails to match the correct timing."
      }
    },
    {
      "question_id": "001",
      "question": "After Maria E. Mendoza explains Executive Order 13166, when does Jon Thompson ask about the regulation's enforcement mechanisms?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4470.0,
        "end": 4612.51
      },
      "gt_interval": {
        "start": 4479.38,
        "end": 4496.58
      },
      "pred_interval": {
        "start": 4532.9,
        "end": 4567.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.51999999999953,
        "end": 71.22000000000025,
        "average": 62.36999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.25586068630218506,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation ('after') and that Jon Thompson asks about enforcement, but it omits the precise timestamps and E1/E2 segmentation details provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria E. Mendoza finishes stating her uncertainty about the executive order's trickle-down effect to individual schools, when does she mention the federal government's right to withdraw funds?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4470.0,
        "end": 4612.51
      },
      "gt_interval": {
        "start": 4508.48,
        "end": 4516.58
      },
      "pred_interval": {
        "start": 4578.3,
        "end": 4600.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 69.82000000000062,
        "end": 84.31999999999971,
        "average": 77.07000000000016
      },
      "rationale_metrics": {
        "rouge_l": 0.1875,
        "text_similarity": 0.1671454757452011,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the temporal relation (that she mentions it immediately after finishing), but it omits all precise timestamps and the specified relation/details from the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once Maria E. Mendoza finishes giving the healthcare example of funding withdrawal for lack of interpreters, when does she state that 'there are very strict laws'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4470.0,
        "end": 4612.51
      },
      "gt_interval": {
        "start": 4552.98,
        "end": 4555.18
      },
      "pred_interval": {
        "start": 4605.3,
        "end": 4612.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.32000000000062,
        "end": 57.31999999999971,
        "average": 54.820000000000164
      },
      "rationale_metrics": {
        "rouge_l": 0.029850746268656716,
        "text_similarity": 0.004294633865356445,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly associates the phrase with following the healthcare example, but it misattributes the utterance as a response to a question and omits the precise timestamps and the 'once_finished' relation, making it incomplete and partially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that what's most important is helping her kid understand their experience, when does she explain that we often center the other person instead of our kid?",
      "video_id": "Z6o8S8JDg00",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 44.150000000000006
      },
      "gt_interval": {
        "start": 10.281,
        "end": 17.954
      },
      "pred_interval": {
        "start": 23.8,
        "end": 27.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.519,
        "end": 9.546,
        "average": 11.532499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.03278688524590164,
        "text_similarity": 0.06617602705955505,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction conveys the correct temporal relation (that the explanation occurs after the prior remark) but omits the crucial timestamps and segment details given in the ground truth, thus missing key factual elements."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker asks 'Could we do this course together?', when does she say 'That would just be great. You don't have to agree with anything. I think that would be great.'?",
      "video_id": "Z6o8S8JDg00",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 44.150000000000006
      },
      "gt_interval": {
        "start": 25.207,
        "end": 27.812
      },
      "pred_interval": {
        "start": 40.3,
        "end": 42.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.092999999999996,
        "end": 14.788,
        "average": 14.940499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.03571428571428571,
        "text_similarity": 0.013968836516141891,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction repeats the quoted utterance but fails to provide the requested timing (timestamps and temporal relation); it omits the key factual elements from the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces herself as April Rehrig, when does the text 'IEPs' appear on screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 44.229,
        "end": 45.479
      },
      "pred_interval": {
        "start": 6.9,
        "end": 8.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.329,
        "end": 37.278999999999996,
        "average": 37.304
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.59782475233078,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that 'IEPs' appears after the speaker's introduction, but it omits the key timing details and exact timestamps provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker explains that Section 504 is a civil rights statute, when does the text 'Civil Rights Statute' appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.493,
        "end": 71.953
      },
      "pred_interval": {
        "start": 54.7,
        "end": 55.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.792999999999992,
        "end": 16.153000000000006,
        "average": 14.472999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2553191489361702,
        "text_similarity": 0.6885578632354736,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the text appears during the speaker's explanation (matching the relation), but it omits the specific timestamps and duration given in the reference, so it lacks important factual detail."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions '504 meetings with five tips', when does she explain what to do before the meeting?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 26.541,
        "end": 33.582
      },
      "pred_interval": {
        "start": 173.0,
        "end": 176.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 146.459,
        "end": 142.418,
        "average": 144.4385
      },
      "rationale_metrics": {
        "rouge_l": 0.2807017543859649,
        "text_similarity": 0.6287671327590942,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the explanation follows the mention, but gives a drastically wrong start time (about 173s) instead of ~26.54s, so it is factually incorrect on the key timing detail."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"This is a problem because pro tip\", when does the \"Pro-Tip\" visual with a thumbs-up icon appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 177.7,
        "end": 179.0
      },
      "pred_interval": {
        "start": 249.3,
        "end": 256.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.60000000000002,
        "end": 77.80000000000001,
        "average": 74.70000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.08163265306122448,
        "text_similarity": 0.21969299018383026,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the visual appears immediately after the speaker finishes, but it omits the precise appearance/disappearance timestamps and other timing details given in the correct answer, so it's incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"Now it's time to talk about tip two\", when does the text \"Parent Letter of Attachment\" appear on screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 234.0,
        "end": 236.0
      },
      "pred_interval": {
        "start": 273.0,
        "end": 278.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 42.10000000000002,
        "average": 40.55000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1568627450980392,
        "text_similarity": 0.2876262664794922,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the text appears after the spoken cue, but it omits the essential timing details (start/end timestamps and duration) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says it's time to jump into the second part of what they will talk about, when do the animated files appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 357.05,
        "end": 358.05
      },
      "pred_interval": {
        "start": 235.4,
        "end": 247.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 121.65,
        "end": 110.45000000000002,
        "average": 116.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.5061048269271851,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states that the animated files appear after the speaker says it's time to jump into the second part, matching the required relative timing; it omits the precise timing/detail that they appear several seconds later (after the anchor speech ends)."
      }
    },
    {
      "question_id": "002",
      "question": "During the speaker's question 'What is inside a 504 plan?', when do the question mark graphics appear and disappear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.5,
        "end": 457.0
      },
      "pred_interval": {
        "start": 280.2,
        "end": 281.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 167.3,
        "end": 175.2,
        "average": 171.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2909090909090909,
        "text_similarity": 0.5747753977775574,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction notes that the graphics appear/disappear during the question but omits the precise timing and the key detail that the graphics persist into subsequent related speech, so it is incomplete. "
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'now it's time to dive into tip four', when does the large golden number '4' graphic appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 442.05,
        "end": 444.05
      },
      "pred_interval": {
        "start": 327.4,
        "end": 330.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 114.65000000000003,
        "end": 114.05000000000001,
        "average": 114.35000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.17543859649122806,
        "text_similarity": 0.4270913004875183,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the graphic appears immediately after the speaker's line, but it omits the explicit timing details (start at 442.05s and fully animated by 444.05s) present in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning the Parent Report, when does she start explaining what a Parent Report is?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 521.0,
        "end": 526.5
      },
      "pred_interval": {
        "start": 46.2,
        "end": 53.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 474.8,
        "end": 472.7,
        "average": 473.75
      },
      "rationale_metrics": {
        "rouge_l": 0.11111111111111112,
        "text_similarity": 0.28669095039367676,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly indicates the explanation occurs after the mention, but it omits the precise timestamps and inaccurately asserts it happens 'immediately after' despite a short (~2.4s) gap between the anchor and target."
      }
    },
    {
      "question_id": "002",
      "question": "During the speaker's explanation about getting her free guide, when does the visual graphic of the guide appear on the screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 579.8,
        "end": 584.0
      },
      "pred_interval": {
        "start": 71.2,
        "end": 71.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 508.59999999999997,
        "end": 512.6,
        "average": 510.6
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.3515276312828064,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states the graphic appears while the speaker mentions getting the guide (synchronous with the phrase about grabbing a free copy), matching the reference's timing; it omits exact timestamps and disappearance time. "
      }
    },
    {
      "question_id": "001",
      "question": "After the daughter mentions Berkeley, when does she explain why she probably won't get in?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 175.1,
        "end": 180.0
      },
      "pred_interval": {
        "start": 234.9,
        "end": 268.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.80000000000001,
        "end": 88.5,
        "average": 74.15
      },
      "rationale_metrics": {
        "rouge_l": 0.2448979591836735,
        "text_similarity": 0.4738543927669525,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the explanation occurs after the Berkeley mention) but omits the precise timestamps and quoted phrasing provided in the correct answer, losing important specificity."
      }
    },
    {
      "question_id": "002",
      "question": "Once the mother asks how scouting works, when does the daughter start explaining her basketball options?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 191.5,
        "end": 195.9
      },
      "pred_interval": {
        "start": 272.0,
        "end": 306.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.5,
        "end": 110.70000000000002,
        "average": 95.60000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2622950819672131,
        "text_similarity": 0.4153369963169098,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the causal relation (the daughter speaks after the mother asks) but omits the key factual details from the correct answer\u2014explicit timestamps and the fact that she starts immediately after (191.5s) and finishes at 195.9s\u2014making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "While the daughter says she is weighing her options and is not sure yet, when does the mother appear in the frame, leaning on the bed?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 252.3,
        "end": 256.5
      },
      "pred_interval": {
        "start": 289.9,
        "end": 313.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.599999999999966,
        "end": 57.0,
        "average": 47.29999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.23880597014925375,
        "text_similarity": 0.3979082703590393,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction merely restates that the mother appears during the daughter's remark but provides no timestamps or the explicit temporal relation; it omits the key factual timing details given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman on the right says she didn't go to Howard, when does she mention where she did go?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 365.0,
        "end": 368.0
      },
      "pred_interval": {
        "start": 345.6,
        "end": 352.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.399999999999977,
        "end": 15.100000000000023,
        "average": 17.25
      },
      "rationale_metrics": {
        "rouge_l": 0.07407407407407408,
        "text_similarity": 0.18272903561592102,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates the order of events and gives no timestamps or the actual time interval (it implies immediacy), so it omits the key temporal details provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the daughter laughs, when does she state that she has many options for college?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 423.0,
        "end": 428.5
      },
      "pred_interval": {
        "start": 437.3,
        "end": 448.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.300000000000011,
        "end": 20.0,
        "average": 17.150000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.35415881872177124,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a time window of ~4:37\u20134:48 (\u2248277\u2013288s), while the ground truth event occurs at 423.0\u2013428.5s; although it notes the statement follows the laugh, the timestamps are substantially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the mother asks if every college has sororities and fraternities, when does the daughter state that not every school has Greek life?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 538.294,
        "end": 539.697
      },
      "pred_interval": {
        "start": 584.3,
        "end": 627.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.00599999999997,
        "end": 87.70299999999997,
        "average": 66.85449999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.6358192563056946,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (daughter speaks after the mother), but it omits the required precise timing information (start/end times and the mother's timestamp) provided in the reference, so it is incomplete for the question asking 'when'."
      }
    },
    {
      "question_id": "002",
      "question": "After the mother says her one regret in life is not joining a sorority, when does she mention her AP at school is a 'die hard AKA'?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 587.969,
        "end": 592.336
      },
      "pred_interval": {
        "start": 629.7,
        "end": 632.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.730999999999995,
        "end": 39.86400000000003,
        "average": 40.797500000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.5284355878829956,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the mention occurs during the sorority/fraternity discussion (i.e., broadly after the regret), but it omits the precise temporal relation and all specific timestamps provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the girl on the right asks if she did Columbia, when does the girl on the left respond?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 703.8,
        "end": 704.0
      },
      "pred_interval": {
        "start": 796.3,
        "end": 824.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 92.5,
        "end": 120.5,
        "average": 106.5
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.08699718117713928,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the left girl replies after a short pause (aligning with the target occurring immediately after the anchor), but it omits the precise timestamps and anchor/target timing details given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the girl on the left states the acceptance rate, when does she start explaining what scattergrams are?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.6,
        "end": 781.7
      },
      "pred_interval": {
        "start": 878.1,
        "end": 900.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 110.5,
        "end": 118.29999999999995,
        "average": 114.39999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.12048192771084337,
        "text_similarity": 0.5474762916564941,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps are completely incorrect and do not overlap the reference interval (767.6\u2013781.7s); it places the event ~110s later (878.1\u2013900.0s), so it fails to match the correct timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman on the right says \"That Sydney wasn't feeling well\", when does she say \"He's doing well\"?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 917.7,
        "end": 918.6
      },
      "pred_interval": {
        "start": 422.3,
        "end": 433.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 495.40000000000003,
        "end": 485.6,
        "average": 490.5
      },
      "rationale_metrics": {
        "rouge_l": 0.17241379310344826,
        "text_similarity": 0.3247893452644348,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction refers to a different speaker and topic with entirely different timestamps, failing to match the anchor/target times, relation, or content in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the girl on the left finishes listing application platforms, when does she say \"Just word of advice, just start\"?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1086.0,
        "end": 1089.5
      },
      "pred_interval": {
        "start": 115.3,
        "end": 121.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 970.7,
        "end": 967.8,
        "average": 969.25
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.20532822608947754,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation that she says the line after finishing the list of platforms, but it omits the specific timestamp details and explicit anchor/target timing provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the girl on the right asks \"what type of law?\", when does the girl on the left reply saying she'd probably go into civil law?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1119.5,
        "end": 1120.9
      },
      "pred_interval": {
        "start": 120.4,
        "end": 126.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 999.1,
        "end": 994.1000000000001,
        "average": 996.6000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.08695652173913043,
        "text_similarity": 0.1492326557636261,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly identifies the reply content but gives timestamps (\u2248120.4\u2013126.8s) that do not match the referenced/relative timing (around 69\u201370s) and thus fails the key temporal correctness required."
      }
    },
    {
      "question_id": "001",
      "question": "After the mother says \"a small school too\", when does the daughter stretch her arms up?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.741,
        "end": 1242.0
      },
      "pred_interval": {
        "start": 942.3,
        "end": 956.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 298.44100000000003,
        "end": 285.29999999999995,
        "average": 291.8705
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.39441412687301636,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation ('after') but omits the key factual details present in the reference (the precise start and end timestamps and duration), making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "While the mother is explaining how teachers can adjust grades, when does the daughter adjust her body position?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.0,
        "end": 1281.0
      },
      "pred_interval": {
        "start": 1336.5,
        "end": 1348.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.5,
        "end": 67.09999999999991,
        "average": 62.799999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.13043478260869568,
        "text_similarity": 0.3952152132987976,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the daughter adjusts her position during the mother's explanation) but omits the precise timing information (start/end timestamps) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks her daughter what she was doing, when does the daughter respond 'You was yelling her name'?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1410.0,
        "end": 1455.304
      },
      "gt_interval": {
        "start": 1423.817,
        "end": 1429.817
      },
      "pred_interval": {
        "start": 1426.5,
        "end": 1438.7
      },
      "iou": 0.22287173284955983,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.6829999999999927,
        "end": 8.883000000000038,
        "average": 5.7830000000000155
      },
      "rationale_metrics": {
        "rouge_l": 0.05405405405405406,
        "text_similarity": 0.15415969491004944,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only restates that the daughter responds and omits all temporal details, event markers, and the 'after' relation specified in the correct answer, so it fails to answer the question."
      }
    },
    {
      "question_id": "002",
      "question": "Once the daughter finishes saying 'The front door', when does the woman on the right begin responding and laughing?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1410.0,
        "end": 1455.304
      },
      "gt_interval": {
        "start": 1428.184,
        "end": 1432.184
      },
      "pred_interval": {
        "start": 1447.8,
        "end": 1451.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.615999999999985,
        "end": 19.016000000000076,
        "average": 19.31600000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.1276595744680851,
        "text_similarity": 0.38283127546310425,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the basic relation (she responds after the daughter says 'The front door') but omits all precise timing, the specific start/end timestamps, and the required absolute\u2192relative timing relation, making it incomplete for the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After Susan asks the audience to click on the subscribe button, when does she mention that talks will happen every two weeks?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 23.621,
        "end": 26.608
      },
      "pred_interval": {
        "start": 69.2,
        "end": 74.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.57900000000001,
        "end": 47.69199999999999,
        "average": 46.6355
      },
      "rationale_metrics": {
        "rouge_l": 0.07407407407407408,
        "text_similarity": 0.3799930214881897,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misidentifies the moment of the mention (saying it's when she introduces Nick Prollins) and omits the precise temporal information given in the correct answer; it contradicts the provided timestamps and key event description."
      }
    },
    {
      "question_id": "002",
      "question": "Once Susan introduces Nick Prollins, when does Nick greet Susan?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 83.186,
        "end": 83.986
      },
      "pred_interval": {
        "start": 180.8,
        "end": 184.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.614,
        "end": 100.61399999999999,
        "average": 99.114
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.5443708300590515,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the greeting occurs after the introduction but gives a wildly incorrect timestamp (\u2248180.8s vs ~83.2s in the reference) and mischaracterizes the exchange as them introducing each other, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the man states he had a class of 40 grade six boys, when does the woman touch her face in surprise?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 195.0,
        "end": 197.51
      },
      "pred_interval": {
        "start": 327.6,
        "end": 331.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 132.60000000000002,
        "end": 133.79000000000002,
        "average": 133.19500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1276595744680851,
        "text_similarity": 0.23927754163742065,
        "llm_judge_score": 0,
        "llm_judge_justification": "Completely incorrect: the prediction describes a verbal interjection about the Reggio Emilia approach rather than the woman's surprised face touch, and it omits the timing and gesture details given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says he learned mostly about behavior management, when does the woman state that everyone needs classroom management tips?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.3,
        "end": 356.5
      },
      "pred_interval": {
        "start": 367.2,
        "end": 375.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.899999999999977,
        "end": 19.30000000000001,
        "average": 16.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.163265306122449,
        "text_similarity": 0.5579102039337158,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is true but fails to answer the timing question\u2014it omits the required timestamps/when information (354.3s\u2013356.5s) and thus is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying they are digressing, when does the woman state that it is connected to what they will talk about?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 392.9,
        "end": 395.5
      },
      "pred_interval": {
        "start": 422.2,
        "end": 430.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.30000000000001,
        "end": 35.30000000000001,
        "average": 32.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2181818181818182,
        "text_similarity": 0.5193600654602051,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the sequence (she speaks after the man finishes digressing) but omits the key timing details given in the correct answer (the specific timestamps 391.5s and 392.9\u2013395.5s), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman asks about the relationship between families and schools, when does the man describe his previous role at a bilingual school?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 460.0,
        "end": 468.923
      },
      "pred_interval": {
        "start": 475.2,
        "end": 515.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.199999999999989,
        "end": 46.87699999999995,
        "average": 31.03849999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.25396825396825395,
        "text_similarity": 0.43773597478866577,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and does not provide the requested timing; it even implies the description occurs 'right before' he says 'head of primary,' which contradicts the reference that he describes his role as Head of Primary around 460\u2013468.923s."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes asking about the common denominators in the parent-teacher relationship, when does the man say it's a 'really great question'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.804,
        "end": 584.905
      },
      "pred_interval": {
        "start": 63.2,
        "end": 64.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 520.6039999999999,
        "end": 520.105,
        "average": 520.3544999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.25925925925925924,
        "text_similarity": 0.43875113129615784,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer simply repeats the question and provides no timing information or response; it fails to supply the timestamps or any content matching the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes explaining that there was an initial impression among groups that their problems were unique, when does he start describing what they were actually saying?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 610.142,
        "end": 620.738
      },
      "pred_interval": {
        "start": 175.4,
        "end": 176.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 434.7420000000001,
        "end": 444.13800000000003,
        "average": 439.44000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.1875,
        "text_similarity": 0.36502960324287415,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer merely repeats the question and provides no timestamps or substantive response; it fails to match the correct answer's specific timing information."
      }
    },
    {
      "question_id": "001",
      "question": "After the man talks about parents wanting their children to succeed academically, when does he mention that many parents are unsure how to support their child?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.2,
        "end": 724.5
      },
      "pred_interval": {
        "start": 248.6,
        "end": 257.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 465.6,
        "end": 467.2,
        "average": 466.4
      },
      "rationale_metrics": {
        "rouge_l": 0.18749999999999997,
        "text_similarity": 0.3059300482273102,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the event occurs after the discussion of academic success, but it omits the required precise timing (714.2\u2013724.5s) and other timestamp details given in the reference, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes asking what 'the best' means in the context of raising a child, when does the man explain that it looks different in different contexts?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 762.4,
        "end": 767.8
      },
      "pred_interval": {
        "start": 458.9,
        "end": 463.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 303.5,
        "end": 303.99999999999994,
        "average": 303.75
      },
      "rationale_metrics": {
        "rouge_l": 0.0816326530612245,
        "text_similarity": 0.355935275554657,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures that the man replies after the woman's question, but it omits the key factual timing detail\u2014the immediate response and specific timestamps (starting at 762.4s and ending at 767.8s) given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman describes a picture of a parent and infant looking at each other, when does she demonstrate with her phone a shift in parental focus?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 822.7,
        "end": 825.8
      },
      "pred_interval": {
        "start": 700.0,
        "end": 713.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 122.70000000000005,
        "end": 111.89999999999998,
        "average": 117.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2121212121212121,
        "text_similarity": 0.4756584167480469,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes a demonstrated shift in parental focus but omits the precise timestamps and visual 'instead of this is this' demonstration given in the reference, and it hallucinates a specific shift 'from academics to emotional connection' not stated in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the man states he doesn't have children himself, when does he explain how he has spent his career working with children and families?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.7,
        "end": 880.4
      },
      "pred_interval": {
        "start": 279.5,
        "end": 348.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 599.2,
        "end": 532.4,
        "average": 565.8
      },
      "rationale_metrics": {
        "rouge_l": 0.14545454545454548,
        "text_similarity": 0.19911932945251465,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only says the conversation continues afterward and lacks the required specifics: it omits the target utterance ('but I've spent a career working with children'), the precise time boundaries, and the stated 'after' relationship detail provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the man asks 'Tell me what matters to you?', when does the woman ask if he asks this question to parents and teachers?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 902.9,
        "end": 909.0
      },
      "pred_interval": {
        "start": 648.2,
        "end": 707.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 254.69999999999993,
        "end": 201.79999999999995,
        "average": 228.24999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.14084507042253522,
        "text_similarity": 0.30724307894706726,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction fails to provide the requested timing or timestamps and instead adds a hallucinated detail about her discussing personal experiences; it only loosely implies an 'after' relation but omits the key temporal information given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the woman says she has been on a 'triangle' of experiences, when does she list her roles as a parent, teacher, and tutor?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1003.2,
        "end": 1017.677
      },
      "pred_interval": {
        "start": 757.4,
        "end": 802.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 245.80000000000007,
        "end": 214.97699999999998,
        "average": 230.38850000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.19444444444444445,
        "text_similarity": 0.43480730056762695,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction vaguely notes she mentions being a parent but misstates the timing ('once the question is finished') and omits the precise timestamps, the 'once_finished' relation, and explicit listing of teacher and tutor, so it is largely incorrect/incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the male speaker finishes saying 'Really great strategy, really great strategy', when does he begin talking about clarifying something?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1101.703,
        "end": 1108.353
      },
      "pred_interval": {
        "start": 94.6,
        "end": 97.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1007.103,
        "end": 1010.8530000000001,
        "average": 1008.9780000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.07017543859649122,
        "text_similarity": 0.14079399406909943,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states that the clarification begins immediately after the quoted phrase, but it omits the precise timestamps and duration details provided in the reference answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker describes most parents wanting their children and teachers to thrive, when does he start talking about the 1%?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1146.304,
        "end": 1154.554
      },
      "pred_interval": {
        "start": 108.3,
        "end": 113.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1038.0040000000001,
        "end": 1040.854,
        "average": 1039.429
      },
      "rationale_metrics": {
        "rouge_l": 0.07142857142857144,
        "text_similarity": 0.023731308057904243,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the general order and gist (he speaks about the 1% after that point) but omits the key timing details provided in the correct answer (E2 begins at 1146.304s and related timestamps), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'who trains us to deal with these situations?', when does the woman respond 'No one'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1256.9,
        "end": 1257.3
      },
      "pred_interval": {
        "start": 9.4,
        "end": 12.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1247.5,
        "end": 1245.0,
        "average": 1246.25
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.4402559995651245,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction merely restates that the woman responds but gives no timing, timestamps, or relation information as in the correct answer, so it is largely incomplete despite capturing the basic fact of a reply."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes describing demanding parents, when does the woman say she's 'starting to break out in hives'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1302.8,
        "end": 1306.5
      },
      "pred_interval": {
        "start": 107.6,
        "end": 108.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1195.2,
        "end": 1197.6,
        "average": 1196.4
      },
      "rationale_metrics": {
        "rouge_l": 0.22535211267605632,
        "text_similarity": 0.6084469556808472,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly conveys the immediate reaction ('right after') matching the 'once_finished' relation, but it omits the precise timestamps given in the reference answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman says she would love to know more about that, when does the man state that the ABCD trust model is not specifically for schools or parents?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1423.0,
        "end": 1434.135
      },
      "pred_interval": {
        "start": 1497.3,
        "end": 1524.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.29999999999995,
        "end": 90.66499999999996,
        "average": 82.48249999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.1064661294221878,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and provides no timestamps or relation to the anchor; it fails to match the precise timing (1423\u20131434.135s after the woman's line ending at 1421.11s) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "When is the next time the man introduces a letter of the ABCD trust model after he explains 'A is for ability'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1543.182,
        "end": 1544.983
      },
      "pred_interval": {
        "start": 1526.1,
        "end": 1553.2
      },
      "iou": 0.06645756457564288,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.082000000000107,
        "end": 8.217000000000098,
        "average": 12.649500000000103
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.4433995187282562,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that 'B' is introduced next after 'A', but it omits the specific timestamps given in the reference and adds an unsupported label ('believability'), making it incomplete and partially speculative."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes inviting teachers to move beyond the 'us against them' mindset, when does he introduce the idea of 'family engagement'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1496.349,
        "end": 1501.218
      },
      "pred_interval": {
        "start": 1555.3,
        "end": 1612.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.95100000000002,
        "end": 111.58199999999988,
        "average": 85.26649999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.12000000000000002,
        "text_similarity": 0.3861997127532959,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relative ordering (family engagement is introduced after the invitation) but omits the precise timestamps and the detail that the target starts immediately after the anchor, making it incomplete for the requested timing information."
      }
    },
    {
      "question_id": "001",
      "question": "After the man states 'believability', when does he ask if you will do what you say you're going to do?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1659.124,
        "end": 1661.589
      },
      "pred_interval": {
        "start": 93.6,
        "end": 94.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1565.5240000000001,
        "end": 1567.389,
        "average": 1566.4565
      },
      "rationale_metrics": {
        "rouge_l": 0.2978723404255319,
        "text_similarity": 0.4119505286216736,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only restates that the man asks the question and provides no timing, timestamps, or the relative relation ('after') given in the correct answer, omitting key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman asks for an example, when does the man describe the advice 'under promise and over deliver'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1691.205,
        "end": 1694.03
      },
      "pred_interval": {
        "start": 157.0,
        "end": 158.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1534.205,
        "end": 1535.83,
        "average": 1535.0175
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.3552757501602173,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly indicates the man's remark occurs after the woman's request (captures the 'after' relation) but omits the precise timestamps and introduces an unsupported detail about schools not following through, which is not in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining why schools might not always follow through on promises, when does the woman summarize the advice as 'under promise and over deliver'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1742.844,
        "end": 1747.709
      },
      "pred_interval": {
        "start": 179.4,
        "end": 180.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1563.444,
        "end": 1567.1090000000002,
        "average": 1565.2765
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714288,
        "text_similarity": 0.4902859330177307,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the key temporal relation ('after' the man finishes) but omits the specific timestamps provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker asks about initiatives, when does he ask if they have parent representative councils?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1820.1,
        "end": 1826.2
      },
      "pred_interval": {
        "start": 98.4,
        "end": 105.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1721.6999999999998,
        "end": 1720.6000000000001,
        "average": 1721.15
      },
      "rationale_metrics": {
        "rouge_l": 0.10344827586206896,
        "text_similarity": 0.13574717938899994,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and incorrect: it fails to provide the timestamps or the specific follow\u2011up relation and wrongly references the female speaker, whereas the correct answer specifies precise anchor/target times and that the target is the specific question following the initiatives query."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker says the reading breakfast was 'such a cool thing', when does the female speaker react with wide eyes?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1848.0,
        "end": 1849.0
      },
      "pred_interval": {
        "start": 183.6,
        "end": 187.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1664.4,
        "end": 1661.8,
        "average": 1663.1
      },
      "rationale_metrics": {
        "rouge_l": 0.03571428571428571,
        "text_similarity": 0.10784518718719482,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it misattributes the prior statement to the female speaker (should be after the male) and gives no timing\u2014failing to match the correct timestamps and sequence."
      }
    },
    {
      "question_id": "001",
      "question": "After the female speaker mentions the connection with character strengths, when does she give examples of these strengths?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1957.0,
        "end": 1963.8
      },
      "pred_interval": {
        "start": 92.4,
        "end": 93.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1864.6,
        "end": 1870.0,
        "average": 1867.3
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981132,
        "text_similarity": -0.0030578020960092545,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relative order (examples occur after the mention) but gives an incorrect timestamp (92.4s vs ~1952\u20131957s) and omits the target event's precise timing, so key factual details are wrong or missing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the female speaker talks about opportunities for 'loose ties communications between school staff and families', when does the male speaker agree?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2008.0,
        "end": 2009.5
      },
      "pred_interval": {
        "start": 176.0,
        "end": 180.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1832.0,
        "end": 1829.2,
        "average": 1830.6
      },
      "rationale_metrics": {
        "rouge_l": 0.13888888888888887,
        "text_similarity": 0.26224008202552795,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives entirely incorrect timestamps (~176\u2013180s) that do not match the reference (~1999\u20132009s) and thus fails to capture the correct temporal relation (male agreement immediately following the female speaker)."
      }
    },
    {
      "question_id": "003",
      "question": "After the female speaker introduces 'dependability', when does the male speaker explain it as 'being consistent'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2050.0,
        "end": 2054.5
      },
      "pred_interval": {
        "start": 201.6,
        "end": 206.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1848.4,
        "end": 1848.3,
        "average": 1848.35
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.3445654511451721,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the timestamps (201.6\u2013206.2s) versus the reference (2045.0\u20132054.5s), so it is temporally incorrect; it only correctly conveys that the male explanation follows the female introduction."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks 'what do I believe?', when does he state that having a school that has done the thinking makes a teacher feel more supported?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2142.885,
        "end": 2150.675
      },
      "pred_interval": {
        "start": 2135.4,
        "end": 2160.7
      },
      "iou": 0.30790513833992283,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.485000000000127,
        "end": 10.024999999999636,
        "average": 8.754999999999882
      },
      "rationale_metrics": {
        "rouge_l": 0.17857142857142855,
        "text_similarity": 0.4222041964530945,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a single approximate timestamp (21:35) that is far from the correct interval (~35:42\u201335:50) and omits the precise timing and the relative relation; hence it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says she can do her part but asks about the parents' part, when does the man explicitly state they are not talking about a wall regarding boundaries?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2228.336,
        "end": 2229.739
      },
      "pred_interval": {
        "start": 2207.8,
        "end": 2234.6
      },
      "iou": 0.05235074626866648,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.535999999999603,
        "end": 4.860999999999876,
        "average": 12.69849999999974
      },
      "rationale_metrics": {
        "rouge_l": 0.2413793103448276,
        "text_similarity": 0.3521648347377777,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes he explicitly says they are not talking about a wall and that it occurs after, but it gives an incorrect/ambiguous timestamp (22:07) rather than the precise seconds (2228.336\u20132229.739) and omits the woman's timing, so it is incomplete and partially incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes saying he got schooled on something he didn't realize, when does he explain his naive assumption about WhatsApp?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2246.965,
        "end": 2299.733
      },
      "pred_interval": {
        "start": 2277.3,
        "end": 2304.0
      },
      "iou": 0.39331989129481987,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.335000000000036,
        "end": 4.266999999999825,
        "average": 17.30099999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.1904761904761905,
        "text_similarity": 0.5257364511489868,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that the explanation occurs after he finishes speaking, but it gives vague/incorrect timing (claims 'right after' and an end of ~22:40) that contradicts the precise start (2246.965s) and end (2299.733s) in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes describing the participant's WhatsApp call from a mother during her holiday, when does he state that this behavior must stop?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2339.8,
        "end": 2341.0
      },
      "pred_interval": {
        "start": 2437.5,
        "end": 2462.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.69999999999982,
        "end": 121.5,
        "average": 109.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.5280754566192627,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys that he says it must stop after describing the WhatsApp call, but it omits the precise timing and the detail that the statement immediately follows the description (2339.8\u20132341.0)."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks if anyone else would be treated like that in any other industry, when does the woman reply 'No'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2381.0,
        "end": 2381.3
      },
      "pred_interval": {
        "start": 2518.5,
        "end": 2518.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 137.5,
        "end": 137.19999999999982,
        "average": 137.3499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.17543859649122806,
        "text_similarity": 0.40544256567955017,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the woman replies 'No' to that question but gives no timing or indication of the direct/immediate response as required by the reference, so it is incomplete. "
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes talking about the school's duty to create boundaries, when does he suggest working towards positive change?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.2,
        "end": 2575.5
      },
      "pred_interval": {
        "start": 2496.3,
        "end": 2507.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 69.89999999999964,
        "end": 67.69999999999982,
        "average": 68.79999999999973
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.3437037765979767,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction contradicts the reference timeline by asserting the suggestion comes after the woman's 'That's right' instead of immediately after the man finishes; it adds an unfounded speaker-dependent detail and omits the precise immediate timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman says 'That's right', when does she start talking about teachers having problems with school leadership regarding boundaries?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2600.5,
        "end": 2606.0
      },
      "pred_interval": {
        "start": 2519.5,
        "end": 2538.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.0,
        "end": 67.80000000000018,
        "average": 74.40000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.46808510638297873,
        "text_similarity": 0.593222975730896,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that she begins discussing teachers' problems right after saying 'That's right,' but it omits the precise timestamps (E1=2600.0s, E2 start=2600.5s and end=2606.0s), leaving out key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'What's in and what's out for me?', when is the next time he asks 'What are my red lines?'",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2697.043,
        "end": 2698.184
      },
      "pred_interval": {
        "start": 2547.7,
        "end": 2557.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 149.3430000000003,
        "end": 141.0840000000003,
        "average": 145.2135000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.5714285714285714,
        "text_similarity": 0.6381113529205322,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the next question is 'What are my red lines?', but it fails to provide the requested timing information (the timestamps) given in the correct answer, omitting a key factual element."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker talks about reflecting on professional boundaries, when does he ask about boundaries around communication with parents and colleagues?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2677.99,
        "end": 2692.02
      },
      "pred_interval": {
        "start": 1439.0,
        "end": 1526.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1238.9899999999998,
        "end": 1166.02,
        "average": 1202.5049999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.06896551724137931,
        "text_similarity": -0.0010058023035526276,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer does not match the reference: the correct response specifies precise timestamps and that the target event follows the anchor, whereas the prediction incorrectly claims 'after school hours,' adding unsupported information and failing to provide or align with the given timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker asks if teachers are okay with answering WhatsApp messages from colleagues after school hours, when does he ask if they are comfortable sharing their personal mobile number with a parent?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.77,
        "end": 2736.23
      },
      "pred_interval": {
        "start": 1548.0,
        "end": 1595.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1179.77,
        "end": 1141.23,
        "average": 1160.5
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.06900253891944885,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly restates the content of the male speaker's question but fails to provide the requested timing information (the specific timestamps), omitting the key factual elements in the reference answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the female speaker talks about being clear about boundaries and communicating them with 'whole heart', when does the male speaker discuss the comfort derived from setting clear boundaries?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2840.24,
        "end": 2850.66
      },
      "pred_interval": {
        "start": 1613.0,
        "end": 1693.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1227.2399999999998,
        "end": 1157.6599999999999,
        "average": 1192.4499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.136986301369863,
        "text_similarity": 0.2573867440223694,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates the theme about clear boundaries but fails to answer the timing question, omits all timestamps, and does not indicate that the male speaker's remark follows immediately after the female\u2014thus missing the key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says, 'I want this to be practical', when does he say, 'You have no idea'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2960.516,
        "end": 2964.8
      },
      "pred_interval": {
        "start": 295.4,
        "end": 296.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2665.116,
        "end": 2668.5,
        "average": 2666.808
      },
      "rationale_metrics": {
        "rouge_l": 0.08695652173913043,
        "text_similarity": 0.000956457108259201,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to identify the target phrase 'You have no idea', provides no timing information, and incorrectly characterizes the follow-up as the woman's response rather than the specified target occurring after the anchor."
      }
    },
    {
      "question_id": "002",
      "question": "After the man asks, 'Tell me what matters to you right now', when does the woman make a thumbs-up gesture?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 3024.99,
        "end": 3026.99
      },
      "pred_interval": {
        "start": 297.9,
        "end": 298.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2727.0899999999997,
        "end": 2728.89,
        "average": 2727.99
      },
      "rationale_metrics": {
        "rouge_l": 0.0425531914893617,
        "text_similarity": 0.1058507189154625,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states that a thumbs-up occurs after the question (matching the relative 'after' relation), but it omits the precise timestamp details provided in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes saying, 'Thank you for sharing that information with me', when does he immediately advise to 'take note of that teacher'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 3046.646,
        "end": 3049.969
      },
      "pred_interval": {
        "start": 300.1,
        "end": 300.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2746.5460000000003,
        "end": 2749.369,
        "average": 2747.9575000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.0425531914893617,
        "text_similarity": 0.20074373483657837,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and does not provide the required timing or sequence information (timestamps and that the target immediately follows the anchor); it fails to match the specific temporal answer and thus is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes suggesting to invite families to propose solutions, when does the woman react with a wide-eyed expression?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3069.0,
        "end": 3070.0
      },
      "pred_interval": {
        "start": 243.6,
        "end": 259.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2825.4,
        "end": 2810.2,
        "average": 2817.8
      },
      "rationale_metrics": {
        "rouge_l": 0.07999999999999999,
        "text_similarity": 0.2439684420824051,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the woman reacts after the man\u2019s suggestion (relative ordering) but omits the precise timestamps and the required absolute\u2192relative timing detail, so key factual elements are missing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes warning against creating a 'cycle of learned helplessness', when does he ask how they would approach the problem?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3136.766,
        "end": 3138.327
      },
      "pred_interval": {
        "start": 264.8,
        "end": 276.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2871.966,
        "end": 2861.927,
        "average": 2866.9465
      },
      "rationale_metrics": {
        "rouge_l": 0.1851851851851852,
        "text_similarity": 0.417803019285202,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction fails to provide the required timestamps or the relative timing (that the question immediately follows the warning); it is vague and does not answer when the question occurs, though it correctly implies it happens after the warning."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman first states that the advice is about 'a way of being', when does she re-emphasize that 'This is about a way of being'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3178.623,
        "end": 3181.496
      },
      "pred_interval": {
        "start": 276.4,
        "end": 286.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2902.223,
        "end": 2895.2960000000003,
        "average": 2898.7595
      },
      "rationale_metrics": {
        "rouge_l": 0.08571428571428572,
        "text_similarity": 0.13135214149951935,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction acknowledges that the woman re-emphasizes the phrase but omits the precise timestamps and the relative timing information given in the correct answer, so it lacks the key factual details required."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman suggests to 'crack a window open', when does she ask 'what would happen if?'",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3213.0,
        "end": 3217.0
      },
      "pred_interval": {
        "start": 263.7,
        "end": 265.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2949.3,
        "end": 2951.6,
        "average": 2950.45
      },
      "rationale_metrics": {
        "rouge_l": 0.3859649122807018,
        "text_similarity": 0.454867422580719,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the sequence (she suggests cracking a window then asks 'what would happen if?') but omits the crucial timing details and occurrence information (the specific timestamps and that the question occurs at 3213\u20133217s once after the anchor)."
      }
    },
    {
      "question_id": "001",
      "question": "After the man confirms 'building bridges', when does the woman ask him about traveling?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3390.0,
        "end": 3482.7169999999996
      },
      "gt_interval": {
        "start": 3401.076,
        "end": 3404.512
      },
      "pred_interval": {
        "start": 3427.9,
        "end": 3438.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.82400000000007,
        "end": 33.98799999999983,
        "average": 30.40599999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.578382670879364,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits the requested timing details (the start/end timestamps provided in the correct answer), making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says his website is on the screen, when does he mention having other tips and resources?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3390.0,
        "end": 3482.7169999999996
      },
      "gt_interval": {
        "start": 3425.376,
        "end": 3431.514
      },
      "pred_interval": {
        "start": 3460.8,
        "end": 3467.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.42399999999998,
        "end": 36.28600000000006,
        "average": 35.85500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.44191569089889526,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (he mentions tips and resources once the website is shown), matching the reference's 'once_finished' relation and containing no contradictory or hallucinated details."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman asks viewers to click the subscribe button, when does she mention inviting Nick back?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3390.0,
        "end": 3482.7169999999996
      },
      "gt_interval": {
        "start": 3471.07,
        "end": 3474.532
      },
      "pred_interval": {
        "start": 3476.1,
        "end": 3482.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.029999999999745,
        "end": 8.167999999999665,
        "average": 6.598999999999705
      },
      "rationale_metrics": {
        "rouge_l": 0.3555555555555555,
        "text_similarity": 0.5773546695709229,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that she mentions inviting Nick back 'after' asking viewers to subscribe and gives no timestamps or interval; it omits the precise timing (3471.070s\u20133474.532s) and is therefore incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker explains that she will show what to do before, during, and after parent-teacher conferences with five tips, when does the '5' graphic appear on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.258,
        "end": 37.358
      },
      "pred_interval": {
        "start": 9.6,
        "end": 10.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.658,
        "end": 27.157999999999998,
        "average": 24.408
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.5283021926879883,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the graphic appears while the speaker discusses the five tips, but it omits the key factual details (precise onset and offset times: 31.258s\u201337.358s and the speaker mention window 29.8s\u201331.9s) provided in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker introduces herself as a special education advocate, when do the visual overlays 'IEPs' and '504 Plans' appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 47.954,
        "end": 51.274
      },
      "pred_interval": {
        "start": 34.7,
        "end": 35.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.253999999999998,
        "end": 15.874000000000002,
        "average": 14.564
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.5685514211654663,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the overlays appear during her introduction, but it omits the precise timing details (they appear at ~47.954s and disappear at ~51.274s) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what one needs to do to prepare to help their child, when does the 'How Do You Prepare?' graphic appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 192.8,
        "end": 195.0
      },
      "pred_interval": {
        "start": 205.4,
        "end": 209.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.599999999999994,
        "end": 14.800000000000011,
        "average": 13.700000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322037,
        "text_similarity": 0.3346741199493408,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the graphic appears after the speaker's question, but it omits the precise timing/duration and claims it appears 'immediately,' which slightly misrepresents the actual ~0.7s delay and misses the end-of-speech/duration details."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker mentions her guide 'The Ten Keys to Communication', when is the guide's cover displayed on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 238.0,
        "end": 242.0
      },
      "pred_interval": {
        "start": 237.6,
        "end": 242.2
      },
      "iou": 0.8695652173913054,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.4000000000000057,
        "end": 0.19999999999998863,
        "average": 0.29999999999999716
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.5437423586845398,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the cover appears during the speaker's mention, but incorrectly claims it appears as soon as she starts talking and omits the specific timing (cover appears ~238.0\u2013242.0s, a few seconds after the mention began)."
      }
    },
    {
      "question_id": "003",
      "question": "During the speaker's introduction of 'tip two', when does the 'Tip 2' graphic appear on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 294.0,
        "end": 298.0
      },
      "pred_interval": {
        "start": 270.2,
        "end": 275.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.80000000000001,
        "end": 22.600000000000023,
        "average": 23.200000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923078,
        "text_similarity": 0.6681797504425049,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the graphic appears when the speaker introduces tip two, but it omits the precise timing (appears at 294.0s, disappears at 298.0s) and lacks the explicit duration/anchor-speech detail, so key factual elements are missing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what the difference is between IEP and 504 plans, when does the graphic with the number '10' appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 380.8,
        "end": 383.86
      },
      "pred_interval": {
        "start": 239.4,
        "end": 258.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 141.4,
        "end": 125.25999999999999,
        "average": 133.32999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.3395799994468689,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the graphic appears after the question (captures the relation) but omits the key factual details\u2014exact appearance/disappearance timestamps and duration\u2014provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the text overlay 'Academic Adjustments' appears, when does the text overlay 'Accommodations' appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 450.722,
        "end": 451.722
      },
      "pred_interval": {
        "start": 273.4,
        "end": 281.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 177.322,
        "end": 170.12199999999996,
        "average": 173.72199999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.6128120422363281,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the 'Accommodations' overlay appears after the previous one, but incorrectly implies it appears immediately when the previous one finishes and omits the specific timestamps; the ground truth shows a 2-second gap and exact times."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker describes where children might be struggling by listing areas, when do icons representing different areas of need appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 455.722,
        "end": 460.135
      },
      "pred_interval": {
        "start": 287.6,
        "end": 300.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 168.12199999999996,
        "end": 159.935,
        "average": 164.02849999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.40599682927131653,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately conveys that the icons appear concurrently with the speaker's listing of areas of struggle (the correct answer's 'during' relation); although it omits timestamps, it preserves the full semantic meaning."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces question two, when does she first ask what the teacher is doing to support the child?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 516.831,
        "end": 519.018
      },
      "pred_interval": {
        "start": 238.9,
        "end": 246.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 277.93100000000004,
        "end": 272.51800000000003,
        "average": 275.22450000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.10344827586206895,
        "text_similarity": 0.30504748225212097,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the question is asked immediately after introducing question two, matching the relative timing, but it omits the specific timestamps and the note about overlapping speech included in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "During the discussion about the Meeting Toolkit, when does the speaker highlight how it provides clarity on accommodations versus modifications?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 609.57,
        "end": 615.0
      },
      "pred_interval": {
        "start": 272.8,
        "end": 280.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 336.77000000000004,
        "end": 334.8,
        "average": 335.785
      },
      "rationale_metrics": {
        "rouge_l": 0.15873015873015872,
        "text_similarity": 0.45953962206840515,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives a single, incorrect timestamp (\u2248272.8s) and fails to match the correct intervals (E1: 609.5\u2013640.0s, E2: 609.0\u2013615.0s), so it does not align with the reference."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker talking about implementing new supports and services and wanting to follow up, when does the 'Follow Up' graphic appear on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 690.0,
        "end": 887.283
      },
      "gt_interval": {
        "start": 707.435,
        "end": 710.155
      },
      "pred_interval": {
        "start": 769.2,
        "end": 835.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.7650000000001,
        "end": 125.04500000000007,
        "average": 93.40500000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.24137931034482757,
        "text_similarity": 0.45738500356674194,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is incorrect: it states the graphic appears after the speaker and gives a wrong timestamp (~769.2s) instead of appearing during the quoted statement (707.435\u2013710.155s). It contradicts the correct timing and relation."
      }
    },
    {
      "question_id": "001",
      "question": "Once Margaret finishes introducing herself, when does she introduce her husband Marco and sister Mary?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 9.58,
        "end": 12.102
      },
      "pred_interval": {
        "start": 54.7,
        "end": 56.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.120000000000005,
        "end": 44.098,
        "average": 44.609
      },
      "rationale_metrics": {
        "rouge_l": 0.12244897959183673,
        "text_similarity": 0.46879205107688904,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a timestamp (54.7\u201356.2s) that contradicts the correct timestamps (~8.1\u201312.1s) and thus is factually incorrect, despite correctly stating the introductions occur after her self-introduction."
      }
    },
    {
      "question_id": "002",
      "question": "After Margaret states they are speaking to primary and secondary teachers specifically, when does she say that the information can more broadly benefit students?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 50.9,
        "end": 55.67
      },
      "pred_interval": {
        "start": 83.3,
        "end": 84.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.4,
        "end": 28.53,
        "average": 30.465
      },
      "rationale_metrics": {
        "rouge_l": 0.09230769230769231,
        "text_similarity": 0.27026718854904175,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (83.3\u201384.2s) are far from the reference (44.2\u201355.67s) and thus contradict the correct answer that the broader benefit follows immediately after the specific audience mention."
      }
    },
    {
      "question_id": "003",
      "question": "After Margaret tells interpreters and translators to email them for a certificate of attendance, when does she state that they are not producing certificates?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.787,
        "end": 114.451
      },
      "pred_interval": {
        "start": 114.3,
        "end": 115.6
      },
      "iou": 0.015387750942626763,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.512999999999991,
        "end": 1.149000000000001,
        "average": 4.830999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298248,
        "text_similarity": 0.5213022232055664,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction partially overlaps the end of the correct target window but gives a later and narrower interval (114.3\u2013115.6s) and omits the earlier anchor (91\u201398s) and the full target span (\u2248105.8\u2013114.45s), so it is incomplete and temporally inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker touches on budgets and administrators, when does she mention pursuing things career-wise?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 172.462
      },
      "pred_interval": {
        "start": 246.7,
        "end": 253.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.69999999999999,
        "end": 81.43800000000002,
        "average": 80.569
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5392024517059326,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that the career-wise comment comes after the budgets/administrators remark, but it omits the specific timing information (the 167s\u2013172.462s interval) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After Marco says they are all 'language geeks', when does he describe his experience teaching in a bilingual program on the Mexican border?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 278.303,
        "end": 309.735
      },
      "pred_interval": {
        "start": 290.4,
        "end": 311.6
      },
      "iou": 0.5806829444094069,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.09699999999998,
        "end": 1.865000000000009,
        "average": 6.9809999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307693,
        "text_similarity": 0.5396178364753723,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the relevant line ('I taught there for two years') but omits the requested timing and the explicit 'after' relation to the 'we are all language geeks' utterance, failing to provide the key temporal details in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After Marco describes his experience of having to translate English handouts into Spanish, when does Margaret share a similar experience with campus newsletters?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 331.826,
        "end": 355.983
      },
      "pred_interval": {
        "start": 343.2,
        "end": 355.3
      },
      "iou": 0.5008900111768858,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.373999999999967,
        "end": 0.6829999999999927,
        "average": 6.02849999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.4762590527534485,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that Margaret speaks after Marco, but it omits the precise timestamps and incorrectly implies she speaks immediately afterwards ('right after'), whereas the ground truth shows a notable gap between the end of Marco's segment and the start of Margaret's."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions working on the campus newsletter all week for a Friday release, when does she describe being asked to translate it on Thursday afternoon?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.383,
        "end": 355.983
      },
      "pred_interval": {
        "start": 246.5,
        "end": 283.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 107.88299999999998,
        "end": 72.28300000000002,
        "average": 90.083
      },
      "rationale_metrics": {
        "rouge_l": 0.125,
        "text_similarity": 0.31398069858551025,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that she was asked to translate on Thursday afternoon but fails to provide the requested timing details (the specific timestamps and that the target immediately follows the anchor); it is therefore incomplete despite not contradicting the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker finishes her point about being asked to translate due to bilingualism, when does the second speaker (Mary Lamb) introduce herself?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 413.696,
        "end": 416.456
      },
      "pred_interval": {
        "start": 284.1,
        "end": 310.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 129.596,
        "end": 105.55600000000004,
        "average": 117.57600000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.28947368421052627,
        "text_similarity": 0.39881432056427,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes that Mary Lamb introduces herself and even quotes her words, but it fails to provide the requested timing information (timestamps and brief pause) from the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker defines 'language access', when does she start talking about 'LEP'?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 705.6,
        "end": 710.0
      },
      "pred_interval": {
        "start": 264.8,
        "end": 350.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 440.8,
        "end": 359.3,
        "average": 400.05
      },
      "rationale_metrics": {
        "rouge_l": 0.09523809523809523,
        "text_similarity": 0.5382976531982422,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the relative order (LEP is discussed after the definition of language access) but omits the precise timestamps and event boundary details provided in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker clarifies that they are 'not talking about politics today', when does she explain that language comes with 'cultural and emotional baggage'?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 757.048,
        "end": 780.333
      },
      "pred_interval": {
        "start": 445.2,
        "end": 453.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 311.848,
        "end": 326.73299999999995,
        "average": 319.29049999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.12121212121212122,
        "text_similarity": 0.2592647075653076,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction vaguely indicates the event occurs after another speaker but fails to match the referenced anchor/timestamps and omits the precise timing (757.048\u2013780.333s); it may misidentify the preceding utterance and lacks the key factual details in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the male voice finishes inviting participants to the chat, when does the female voice add to the chat invitation?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 822.133,
        "end": 827.458
      },
      "pred_interval": {
        "start": 690.0,
        "end": 702.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 132.13300000000004,
        "end": 125.15800000000002,
        "average": 128.64550000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222227,
        "text_similarity": 0.4814004898071289,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the female speaks after the male finishes, but it omits the precise timing details (start at ~822.133s, end at 827.458s) and the note that her addition begins almost immediately after the male's invitation."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker explains 'back translating' through DeepL, when does she say they will show an example?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 938.629,
        "end": 940.511
      },
      "pred_interval": {
        "start": 360.2,
        "end": 372.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 578.4290000000001,
        "end": 567.711,
        "average": 573.07
      },
      "rationale_metrics": {
        "rouge_l": 0.09836065573770492,
        "text_similarity": 0.24239736795425415,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not provide the requested timing or the 'once_finished' relation, instead introducing unrelated content about cultural meaning; it contradicts and omits key facts from the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker discusses 'a letter referring to a letter jacket', when does she suggest changing the vocabulary for accurate translation?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1107.0,
        "end": 1150.0
      },
      "pred_interval": {
        "start": 113.8,
        "end": 120.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 993.2,
        "end": 1029.1,
        "average": 1011.15
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.3391977548599243,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') but omits the essential timecode details and precise interval (E1: 1089.5\u20131093.0; E2: 1107.0\u20131150.0) and the judge's absolute\u2192relative note, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that Google Translate and DeepL are almost identical and accurate for the student handbook, when does she highlight a minor difference in DeepL's translation?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1151.0,
        "end": 1161.0
      },
      "pred_interval": {
        "start": 117.5,
        "end": 124.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1033.5,
        "end": 1036.4,
        "average": 1034.95
      },
      "rationale_metrics": {
        "rouge_l": 0.07272727272727272,
        "text_similarity": 0.1988915652036667,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly implies the difference is mentioned following the remark that the tools are almost identical, but it is vague and omits the required precise timestamps and relation details (E1 1144\u20131150, E2 1151\u20131161), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining why AI machine translations struggle with literary texts, when does she provide the first example of a mistranslated Russian literary text?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1200.0,
        "end": 1204.0
      },
      "pred_interval": {
        "start": 124.6,
        "end": 132.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1075.4,
        "end": 1071.8,
        "average": 1073.6
      },
      "rationale_metrics": {
        "rouge_l": 0.08450704225352113,
        "text_similarity": 0.39975881576538086,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the example occurs immediately after the explanation (matching the 'once_finished' relation), but it omits the specific anchor/target timestamps and event boundaries given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the Spanish-speaking father begins his first statement, when does the interpreter finish translating it to English?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1467.348,
        "end": 1510.677
      },
      "pred_interval": {
        "start": 1492.3,
        "end": 1508.6
      },
      "iou": 0.37619146530037556,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.951999999999998,
        "end": 2.076999999999998,
        "average": 13.514499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.12,
        "text_similarity": 0.5501765608787537,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the interpreter finishes after the father begins) but is overly vague and omits the key factual details and timestamps (end time and correction) provided in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the lecturer asks what's hard about consecutive interpretation, when does the interpreter finish explaining her challenges?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1509.179,
        "end": 1519.19
      },
      "pred_interval": {
        "start": 1577.2,
        "end": 1600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 68.02099999999996,
        "end": 80.80999999999995,
        "average": 74.41549999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5369707345962524,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the interpreter finishes after the lecturer's question but gives a significantly incorrect finish time (~1600.0s vs. 1519.19s) and omits the precise event timings, so it is largely inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the lecturer introduces sight translation, when does the interpreter begin reading the handwritten note aloud?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1556.54,
        "end": 1558.452
      },
      "pred_interval": {
        "start": 1607.4,
        "end": 1620.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.86000000000013,
        "end": 61.548,
        "average": 56.204000000000065
      },
      "rationale_metrics": {
        "rouge_l": 0.24561403508771928,
        "text_similarity": 0.5675714015960693,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the correct temporal relation (after) but the reported start/end times are substantially off (~50\u201360 seconds later) compared to the reference, so key factual timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the main presenter mentions a side exercise on the next slide, when does he begin discussing the importance of preparation for interpreting?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1615.359,
        "end": 1621.799
      },
      "pred_interval": {
        "start": 764.3,
        "end": 825.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 851.059,
        "end": 795.899,
        "average": 823.479
      },
      "rationale_metrics": {
        "rouge_l": 0.20338983050847456,
        "text_similarity": 0.18294616043567657,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the relative order (the presenter discusses preparation after mentioning the side exercise) but omits key factual details from the reference\u2014specifically the precise timestamps (anchor at 1614.659s; target 1615.359\u20131621.799s) and that the target fully explains the importance of preparation."
      }
    },
    {
      "question_id": "002",
      "question": "After the main presenter describes an interpreter as a 'traffic cop', when does he describe the typical reactions people have to being instructed by an interpreter?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1703.019,
        "end": 1712.776
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 113.019,
        "end": 12.776000000000067,
        "average": 62.897500000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.126984126984127,
        "text_similarity": 0.25616294145584106,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the reaction description occurs after the 'traffic cop' discussion, but it omits the precise anchor/target timestamps, the quoted start ('And often the reaction...'), and details about the interruptions, which are key elements of the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says he will see if the AI can understand him, when does he start speaking in Russian?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1813.0,
        "end": 1829.8
      },
      "pred_interval": {
        "start": 182.9,
        "end": 185.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1630.1,
        "end": 1644.5,
        "average": 1637.3
      },
      "rationale_metrics": {
        "rouge_l": 0.11538461538461539,
        "text_similarity": 0.2852231562137604,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that he speaks Russian after that remark, but it omits the precise timestamps (English 1810.2\u20131812.324, Russian 1813.0\u20131829.8) and the 'once_finished' relation indicating immediate succession, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker describes training attorneys and judges about simultaneous interpretation, when does he explain the purpose of this for non-bilingual people?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.703,
        "end": 1964.21
      },
      "pred_interval": {
        "start": 134.9,
        "end": 145.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1824.8029999999999,
        "end": 1818.6100000000001,
        "average": 1821.7065
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.32608094811439514,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction reverses the temporal order (it says the explanation follows the use description rather than occurring after the training description) and omits the provided timestamps, so it contradicts the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the female speaker says it's hard to hear over the sound of her own voice, when does the male speaker comment about being distracted by reading?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2146.342,
        "end": 2148.204
      },
      "pred_interval": {
        "start": 38.7,
        "end": 45.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2107.6420000000003,
        "end": 2102.304,
        "average": 2104.973
      },
      "rationale_metrics": {
        "rouge_l": 0.2571428571428571,
        "text_similarity": 0.6075935363769531,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the male comment occurs after the female remark but omits the key factual details \u2014 the exact timestamps (female 2137.400\u20132140.800; male 2146.342\u20132148.204) and the note that the male comment directly follows \u2014 so the answer is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Interpreting' slide, when does the female speaker state that teaching and interpreting are two different jobs?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2219.994,
        "end": 2241.697
      },
      "pred_interval": {
        "start": 61.9,
        "end": 67.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2158.094,
        "end": 2174.297,
        "average": 2166.1955
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.5265408158302307,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the remark occurs while the 'Interpreting' slide is displayed, but it omits the key precise timing details (the slide span and the statement's start/end times) given in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the male speaker explains that doing the interpretation exercise makes people more willing to speak slowly and make pauses, what is the next action he suggests?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2169.782,
        "end": 2173.68
      },
      "pred_interval": {
        "start": 78.6,
        "end": 85.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2091.1820000000002,
        "end": 2088.18,
        "average": 2089.681
      },
      "rationale_metrics": {
        "rouge_l": 0.17721518987341772,
        "text_similarity": 0.6010169982910156,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies one of the actions (hire an interpreter) but omits the other key option (providing written information) and adds an unnecessary qualifier ('professional'/'if possible'), so it is only partially complete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the other speaker states that translating 100 pages would take longer than a weekend, when does the main speaker agree and say it would probably take a month?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2348.812,
        "end": 2349.894
      },
      "pred_interval": {
        "start": 2439.5,
        "end": 2467.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.6880000000001,
        "end": 117.9060000000004,
        "average": 104.29700000000025
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320754,
        "text_similarity": 0.2501412034034729,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the content (agreement that it would take about a month) but fails to answer the asked temporal detail \u2014 it omits the provided timestamps and the immediate follow-up relation, so it's incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the hourly rates for interpreters, when does he mention there is often a two-hour minimum?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2378.997,
        "end": 2380.078
      },
      "pred_interval": {
        "start": 2492.5,
        "end": 2498.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 113.50300000000016,
        "end": 118.42200000000003,
        "average": 115.96250000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.6209039688110352,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly restates that a two-hour minimum is mentioned after hourly rates, but it fails to provide the requested timing/timestamps (key factual element) given in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions being aware of the difference between freelancers and agencies, when does he explain that most translators and interpreters are freelancers who work for agencies?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2403.56,
        "end": 2407.963
      },
      "pred_interval": {
        "start": 2518.1,
        "end": 2531.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 114.53999999999996,
        "end": 123.53699999999981,
        "average": 119.03849999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.07142857142857142,
        "text_similarity": -0.007420781999826431,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that translators/interpreters are freelancers working with agencies but omits the required timing/segment information (E1/E2 timestamps and the fact the explanation immediately follows the anchor), so it fails to answer the 'when' aspect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions working for an agency, when does she mention working as a freelancer?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2686.2,
        "end": 2687.5
      },
      "pred_interval": {
        "start": 2748.3,
        "end": 2795.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.100000000000364,
        "end": 108.09999999999991,
        "average": 85.10000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.08,
        "text_similarity": 0.08315791189670563,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence (freelancer mentioned after agency) but omits the requested timing details (the specific timestamps and relative intervals) provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'we can dare to dream', when does Marco start talking about his Spanish interpreting skills?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2733.4,
        "end": 2738.4
      },
      "pred_interval": {
        "start": 2795.6,
        "end": 2808.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.19999999999982,
        "end": 70.40000000000009,
        "average": 66.29999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.047619047619047616,
        "text_similarity": 0.1576085388660431,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that Marco begins speaking after the phrase, but it is vague and omits the key timing details (specific start/end times and the immediate transition) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After Marco describes how teaching Spanish improved his interpreting skills, when does the speaker (Margaret) share her similar experience about teaching young children?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2749.5,
        "end": 2752.9
      },
      "pred_interval": {
        "start": 2808.8,
        "end": 2816.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.30000000000018,
        "end": 63.09999999999991,
        "average": 61.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.060606060606060615,
        "text_similarity": 0.1677725613117218,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that Margaret speaks immediately after Marco, matching the core point, but it omits the precise timestamps (E1/E2) and event boundaries given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the female speaker finishes listing language populations like Vietnamese, German, and French, when does she mention Arabic?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2857.835,
        "end": 2858.836
      },
      "pred_interval": {
        "start": 294.0,
        "end": 308.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2563.835,
        "end": 2550.836,
        "average": 2557.3355
      },
      "rationale_metrics": {
        "rouge_l": 0.044444444444444446,
        "text_similarity": 0.09868624061346054,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that she mentions Arabic and provides no timing information or the anchor/target relation given in the correct answer, omitting the key timestamp details and the immediate-following relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male speaker asks if an agency can provide a price for an interpreter scenario, when does he state that it's not a trade secret?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2915.411,
        "end": 2918.755
      },
      "pred_interval": {
        "start": 297.0,
        "end": 306.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2618.411,
        "end": 2612.755,
        "average": 2615.583
      },
      "rationale_metrics": {
        "rouge_l": 0.03703703703703704,
        "text_similarity": 0.17882226407527924,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction merely restates that he says it\u2019s not a trade secret but provides no timing information or the required timestamps/relative relation; it omits the key factual details requested."
      }
    },
    {
      "question_id": "003",
      "question": "After the male speaker invites participants to unmute and ask questions, when does he mention that an email with a video link will be sent next week?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2969.806,
        "end": 2975.771
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 2857.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 119.80600000000004,
        "end": 118.77100000000019,
        "average": 119.28850000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.09375000000000001,
        "text_similarity": 0.2102719098329544,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the mention occurs after the invitation to unmute, but it omits the precise timestamps and the note about the brief transition between the anchor and target, so it's a partial but incomplete match."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman on the top left panel says \"I would go to that school as a starting point\", how long does she continue explaining the process of approaching a school?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3031.4,
        "end": 3049.5
      },
      "pred_interval": {
        "start": 9.2,
        "end": 18.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3022.2000000000003,
        "end": 3030.8,
        "average": 3026.5
      },
      "rationale_metrics": {
        "rouge_l": 0.12500000000000003,
        "text_similarity": 0.21660171449184418,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction describes what she is doing but fails to provide the requested duration (3031.4s to 3049.5s \u2192 18.1s) and adds an unsupported detail about interpretation services, so it does not answer the question."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man on the top left panel finishes mentioning PTA meetings or board meetings, when does the woman on the top left panel start talking about who they want to know?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3059.8,
        "end": 3062.05
      },
      "pred_interval": {
        "start": 24.6,
        "end": 32.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3035.2000000000003,
        "end": 3029.55,
        "average": 3032.375
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.15598560869693756,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that she speaks after the man, but it omits the key timing details (start at 3059.8s, end at 3062.05s and the immediate follow-up), making it incomplete for the asked 'when'."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man on the top left panel finishes explaining how to use YouTube videos for practice, when does the woman on the top left panel begin mentioning volunteering through church connections?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3110.298,
        "end": 3113.563
      },
      "pred_interval": {
        "start": 32.5,
        "end": 35.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3077.798,
        "end": 3078.3630000000003,
        "average": 3078.0805
      },
      "rationale_metrics": {
        "rouge_l": 0.04,
        "text_similarity": 0.05462053418159485,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the woman speaks after the man, but it omits the precise timestamps and the fact that her mention directly follows his (immediate succession), so it's semantically correct but incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes asking her main question about recommendations for remote interpreting in educational settings, when does the man (Jesse Thompson) ask if she'll be working directly for the school or an agency?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3259.94,
        "end": 3264.367
      },
      "pred_interval": {
        "start": 3402.3,
        "end": 3418.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 142.36000000000013,
        "end": 154.433,
        "average": 148.39650000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.07142857142857144,
        "text_similarity": 0.29421567916870117,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely irrelevant and incorrect: it neither provides the requested timestamps nor the 'once_finished' relation and misreports the dialogue content, so it fails to match the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions she has been doing IEP meetings since January, when does she state that 80% of them were virtual?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3419.487,
        "end": 3423.472
      },
      "pred_interval": {
        "start": 347.5,
        "end": 358.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3071.987,
        "end": 3064.8720000000003,
        "average": 3068.4295
      },
      "rationale_metrics": {
        "rouge_l": 0.10714285714285714,
        "text_similarity": 0.17799264192581177,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the 80% virtual remark follows the statement about doing IEPs since January, but it omits the specific anchor/target timestamps and precise event boundaries provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker describes IEPs as not straightforward, when does another person define an IEP as an individualized education plan under special education?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3472.184,
        "end": 3478.875
      },
      "pred_interval": {
        "start": 361.9,
        "end": 364.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3110.284,
        "end": 3114.575,
        "average": 3112.4295
      },
      "rationale_metrics": {
        "rouge_l": 0.06896551724137931,
        "text_similarity": 0.04857125133275986,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the basic sequence\u2014that the definition follows the first speaker\u2014but it omits the key factual details (the specific start/end timestamps and immediate adjacency) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions that agencies don't get the information, when does she give examples like a brief summary or an IP packet?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3616.2,
        "end": 3624.0
      },
      "pred_interval": {
        "start": 236.5,
        "end": 247.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3379.7,
        "end": 3376.1,
        "average": 3377.8999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.3125,
        "text_similarity": 0.5037786960601807,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the examples occur after the remark about agencies not getting the information, but it omits the specific timing (start and end timestamps) provided in the reference, so it lacks completeness."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says that doing the budget is the hardest part, when does she mention 'numbers, the dates, and all this'?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3631.3,
        "end": 3633.3
      },
      "pred_interval": {
        "start": 252.2,
        "end": 261.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3379.1000000000004,
        "end": 3371.5,
        "average": 3375.3
      },
      "rationale_metrics": {
        "rouge_l": 0.3050847457627119,
        "text_similarity": 0.5420790910720825,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the line occurs after the budget comment, but it omits the required timing details (timestamps/relative timing precision) and is vague, offering contextual description rather than the temporal answer requested."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker suggests asking people to share their screen, when does she suggest asking them to scroll as they read?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3669.7,
        "end": 3672.2
      },
      "pred_interval": {
        "start": 263.9,
        "end": 270.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3405.7999999999997,
        "end": 3401.3999999999996,
        "average": 3403.5999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333336,
        "text_similarity": 0.3853819966316223,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is vague and incorrect: it fails to provide the requested timestamps or state when she asks people to scroll as they read, omitting the key timing details given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the first female speaker asks about inquiring with the school for contacts with various specialists for special education IEPs, when does the second female speaker state that it's a great idea for background information?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3750.0,
        "end": 3853.87
      },
      "gt_interval": {
        "start": 3772.54,
        "end": 3777.487
      },
      "pred_interval": {
        "start": 3750.0,
        "end": 3824.9
      },
      "iou": 0.06604806408544873,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.539999999999964,
        "end": 47.41300000000001,
        "average": 34.97649999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2337662337662338,
        "text_similarity": 0.31369489431381226,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer simply repeats the question and provides no timestamps, relation, or substantive response; it fails to match the reference answer's timing and 'after' relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second female speaker finishes asking what professionals usually talk about, when does she ask about the terminologies they use?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3750.0,
        "end": 3853.87
      },
      "gt_interval": {
        "start": 3782.973,
        "end": 3786.917
      },
      "pred_interval": {
        "start": 3825.0,
        "end": 3846.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.027000000000044,
        "end": 59.983000000000175,
        "average": 51.00500000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.12903225806451615,
        "text_similarity": 0.06463319808244705,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer merely repeats the question and provides none of the required information (timestamps and 'next' relation) present in the correct answer, so it fails to match the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the male speaker finishes saying that interpreters are friendly and help each other, when does the second female speaker explain that it's because it's a small community?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3750.0,
        "end": 3853.87
      },
      "gt_interval": {
        "start": 3843.755,
        "end": 3850.083
      },
      "pred_interval": {
        "start": 3847.0,
        "end": 3853.9
      },
      "iou": 0.3038935436175544,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.244999999999891,
        "end": 3.8170000000000073,
        "average": 3.530999999999949
      },
      "rationale_metrics": {
        "rouge_l": 0.1095890410958904,
        "text_similarity": 0.1559899002313614,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer merely repeats the question and provides no timestamps, relation, or explanatory details required by the correct answer, thus omitting all key information."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker introduces the topic of a parent letter, when does she mention that emotional language is fraught with danger for AI?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1264.183,
        "end": 1268.577
      },
      "pred_interval": {
        "start": 234.8,
        "end": 254.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1029.383,
        "end": 1013.777,
        "average": 1021.58
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.548296332359314,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction vaguely locates the remark around the introduction but provides no timestamps and implies it occurs 'at the end' of the introduction rather than after it as the reference states, so it is imprecise and partially incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker reads the ambiguous phrase 'I would have raised my hand on her child', when does she begin questioning its meaning?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1297.182,
        "end": 1306.16
      },
      "pred_interval": {
        "start": 374.6,
        "end": 424.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 922.582,
        "end": 881.5600000000001,
        "average": 902.071
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.23816663026809692,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the questioning occurs after the phrase is read, but it omits the specific start/end timestamps and interval details provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes saying that something 'doesn't make a lot of sense', when does the second speaker say 'Over to me?'",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1340.99,
        "end": 1341.351
      },
      "pred_interval": {
        "start": 454.6,
        "end": 460.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 886.39,
        "end": 880.7510000000001,
        "average": 883.5705
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981131,
        "text_similarity": 0.22013917565345764,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the basic relation (he says 'Over to me' after she finishes) but omits the key factual details\u2014the precise timestamps (1334.821\u20131341.351) and explicit once_finished transition\u2014required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what she is talking about, when does she begin to explain it?",
      "video_id": "y9bwM3YYMd0",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 23.383
      },
      "gt_interval": {
        "start": 1.974,
        "end": 5.3
      },
      "pred_interval": {
        "start": 4.6,
        "end": 5.7
      },
      "iou": 0.18786902844873865,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.6259999999999994,
        "end": 0.40000000000000036,
        "average": 1.513
      },
      "rationale_metrics": {
        "rouge_l": 0.06896551724137932,
        "text_similarity": 0.23373718559741974,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction does not provide the requested timing information (anchor/target timestamps) and introduces a specific phrase ('before you go') not stated in the ground truth; it fails to match the correct answer's key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to document evidence and justify a request, when does she mention that 'all of this can be documented in writing'?",
      "video_id": "y9bwM3YYMd0",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 23.383
      },
      "gt_interval": {
        "start": 11.189,
        "end": 14.2
      },
      "pred_interval": {
        "start": 8.3,
        "end": 9.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.8889999999999993,
        "end": 4.799999999999999,
        "average": 3.844499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.0655737704918033,
        "text_similarity": 0.05899009481072426,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly restates that the phrase occurs after advising to document evidence and justify a request, but it omits the key factual details (exact timestamps and confirmation that the target fully captures the phrase) required by the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the male student in the plaid shirt says that they were 'invalidated', when does he mention 'mental health'?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 10.6,
        "end": 11.8
      },
      "pred_interval": {
        "start": 65.2,
        "end": 67.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.6,
        "end": 55.60000000000001,
        "average": 55.10000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714288,
        "text_similarity": -0.04310762509703636,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the mention occurs after the 'invalidated' remark, but saying it was 'right after' is misleading and it omits the specific timestamps (anchor 0.031\u20132.0s, target 10.6\u201311.8s) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the female student in the black coat talks about 'basic respect', when does the female student in the purple hoodie question why a first-grader incident is being brought up?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 59.8,
        "end": 64.7
      },
      "pred_interval": {
        "start": 185.3,
        "end": 187.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 125.50000000000001,
        "end": 122.8,
        "average": 124.15
      },
      "rationale_metrics": {
        "rouge_l": 0.06451612903225808,
        "text_similarity": 0.14665502309799194,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and contextually incorrect: it references a discussion about 'trauma-informed approaches' rather than the 'basic respect' anchor, provides no timestamps, and does not align with the specified event ordering, so it fails to match key facts."
      }
    },
    {
      "question_id": "003",
      "question": "After the female student in the black hijab asserts that she 'did put a conclusion', when does the female student in the white hoodie explain the 'trauma-informed approach'?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.0,
        "end": 123.6
      },
      "pred_interval": {
        "start": 199.9,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.9,
        "end": 86.4,
        "average": 84.15
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320754,
        "text_similarity": 0.06368973106145859,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly implies the explanation occurs after the anchor but incorrectly states it happens 'immediately' afterward; the true target starts at 118.0s (finishes 123.6s), about 37.4s after the anchor ended, and the prediction omits these timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the first student finishes speaking about seeing their point of view, when does the man in the black vest and backpack start speaking?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 180.8,
        "end": 184.6
      },
      "pred_interval": {
        "start": 236.8,
        "end": 249.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.0,
        "end": 65.1,
        "average": 60.55
      },
      "rationale_metrics": {
        "rouge_l": 0.25925925925925924,
        "text_similarity": 0.4525221586227417,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the temporal relation (he speaks after the first student) but fails to provide the key factual timestamps and duration given in the reference, so it is incomplete. There is no contradiction or hallucination, just missing precision."
      }
    },
    {
      "question_id": "001",
      "question": "After the girl in the purple hoodie finishes her statement, when does the man with the microphone ask if anyone else wants to speak?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 330.0,
        "end": 384.801
      },
      "gt_interval": {
        "start": 335.3,
        "end": 337.5
      },
      "pred_interval": {
        "start": 342.9,
        "end": 358.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.599999999999966,
        "end": 21.19999999999999,
        "average": 14.399999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.339622641509434,
        "text_similarity": 0.46818822622299194,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the man speaks after the girl (captures the relation) but omits the key temporal details and exact timestamps (335.3s\u2013337.5s) required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the girl in the grey hoodie finishes her explanation about introverts, when does the male student in the blue jacket start speaking?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 330.0,
        "end": 384.801
      },
      "gt_interval": {
        "start": 363.5,
        "end": 372.7
      },
      "pred_interval": {
        "start": 360.9,
        "end": 369.6
      },
      "iou": 0.5169491525423743,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.6000000000000227,
        "end": 3.099999999999966,
        "average": 2.8499999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.38095238095238093,
        "text_similarity": 0.5457594394683838,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the male student speaks after the girl, but it fails to provide the required timestamp (363.5s) and the end time (372.7s), omitting key factual details from the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man with the microphone asks the 'brother' if he wants to say anything, when does the man in the black vest respond?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 330.0,
        "end": 384.801
      },
      "gt_interval": {
        "start": 378.0,
        "end": 383.6
      },
      "pred_interval": {
        "start": 371.8,
        "end": 384.8
      },
      "iou": 0.4307692307692325,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.199999999999989,
        "end": 1.1999999999999886,
        "average": 3.6999999999999886
      },
      "rationale_metrics": {
        "rouge_l": 0.2580645161290323,
        "text_similarity": 0.46790510416030884,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the black-vested man's reply occurs immediately after the question, but it omits the precise timing and duration (377.7s \u2192 378.0\u2013383.6s) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states that the cat comes in whenever it's showtime, when does she ask 'How do you know?'",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 58.579,
        "end": 60.615
      },
      "pred_interval": {
        "start": 98.4,
        "end": 102.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.821000000000005,
        "end": 41.98499999999999,
        "average": 40.903
      },
      "rationale_metrics": {
        "rouge_l": 0.30434782608695654,
        "text_similarity": 0.2466716468334198,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes that she asks the question after the remark, but it omits the key timing details given in the correct answer (the question occurs from 58.579s to 60.615s immediately following 55.094\u201358.036s), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'We are going live', when does she welcome the friends?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.063,
        "end": 104.724
      },
      "pred_interval": {
        "start": 157.3,
        "end": 164.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.23700000000001,
        "end": 59.475999999999985,
        "average": 56.3565
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.28902170062065125,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the welcome occurs after 'We are going live', but fails to provide the required timing details (the specific timestamps 104.063s\u2013104.724s) given in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the Summer Stride Tuesday Night Author Series, when does she mention that it's summertime for adults?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 198.433,
        "end": 202.298
      },
      "pred_interval": {
        "start": 198.7,
        "end": 204.5
      },
      "iou": 0.593044338223176,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.2669999999999959,
        "end": 2.201999999999998,
        "average": 1.234499999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.42740869522094727,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that the speaker mentions 'it's summertime for adults' after the introduction but omits the required timing details (the specific timestamps given in the correct answer), so it is incomplete despite being broadly correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the 'Summer Stride Tuesday Night Author Series', when does she describe the Summer Stride reading challenge for adults?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.9,
        "end": 254.0
      },
      "pred_interval": {
        "start": 235.9,
        "end": 246.8
      },
      "iou": 0.21756487025948118,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.0,
        "end": 7.199999999999989,
        "average": 19.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.12903225806451613,
        "text_similarity": 0.24243289232254028,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the target event occurs after the 'Tuesday Night Author Series' anchor, matching the required relative ordering, but it omits the specific timing and descriptive details (start/end times and mention of the tote bag) given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"And it's really fun.\", when does she mention Malaka Garib doing a zine?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 342.37,
        "end": 345.33
      },
      "pred_interval": {
        "start": 495.6,
        "end": 538.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 153.23000000000002,
        "end": 192.87000000000006,
        "average": 173.05000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.08888888888888889,
        "text_similarity": 0.004190459847450256,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the key relative relation that Malaka Garib is mentioned after the phrase, but it omits the specific timestamps given in the reference and does not explicitly state the 'doing a zine' detail, so it's incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces Rhodessa Jones, when is the next time she says \"So please come check that out.\"?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 388.074,
        "end": 389.334
      },
      "pred_interval": {
        "start": 467.2,
        "end": 485.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.12599999999998,
        "end": 96.26600000000002,
        "average": 87.696
      },
      "rationale_metrics": {
        "rouge_l": 0.12121212121212122,
        "text_similarity": 0.1195320338010788,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives completely different timestamps (467.2s and 485.6s) and adds unrelated details, failing to match the correct next occurrence at 388.074\u2013389.334s."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela mentions that any question is open for the chat, when does she hold up the physical copy of 'The Overly Honest Teacher'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 563.7,
        "end": 567.0
      },
      "pred_interval": {
        "start": 584.9,
        "end": 602.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.199999999999932,
        "end": 35.299999999999955,
        "average": 28.249999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413793,
        "text_similarity": 0.38021448254585266,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the hold-up happens after her remark, but wrongly implies it occurs immediately 'right after' and omits the precise timing; the reference shows the book is held up several seconds later (563.7\u2013567.0s vs 550\u2013555.0s)."
      }
    },
    {
      "question_id": "002",
      "question": "Once Angela finishes saying she will turn it over to Meredith, when does Meredith begin speaking?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 590.0,
        "end": 594.0
      },
      "pred_interval": {
        "start": 575.5,
        "end": 586.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.5,
        "end": 7.100000000000023,
        "average": 10.800000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.0784313725490196,
        "text_similarity": 0.5137245655059814,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the ordering (Meredith speaks after Angela) but gives an incorrect timestamp (575.5s vs the correct 590.0s), contradicting the ground-truth timing and omitting the immediate-follow relation at 590.0s."
      }
    },
    {
      "question_id": "003",
      "question": "After Meredith introduces herself as the author, when does she start talking about what everyone has gone through in the last 18 months regarding education?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 625.0,
        "end": 679.0
      },
      "pred_interval": {
        "start": 581.6,
        "end": 604.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.39999999999998,
        "end": 74.29999999999995,
        "average": 58.849999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.24615384615384617,
        "text_similarity": 0.4027191400527954,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and contradictory: it places the target at ~581.6s (before the anchor at 597\u2013602.5s), whereas the correct target is 625.0\u2013679.0s (after the anchor)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the main topic slide, when does the first specific point, 'Consistency', appear on screen?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 727.0,
        "end": 727.9
      },
      "pred_interval": {
        "start": 138.2,
        "end": 146.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 588.8,
        "end": 581.0,
        "average": 584.9
      },
      "rationale_metrics": {
        "rouge_l": 0.2553191489361702,
        "text_similarity": 0.5300569534301758,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and provides no timing information; it omits the key factual details (the specific timestamps and the precise 'after' relation to the title slide) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the last point, 'Autonomy', appears on screen, when does the speaker begin to talk about her past teaching experience and starting the year with the definition of autonomy?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 749.5,
        "end": 751.9
      },
      "pred_interval": {
        "start": 759.2,
        "end": 778.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.700000000000045,
        "end": 26.5,
        "average": 18.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714288,
        "text_similarity": 0.4204874634742737,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the general relation and topic (the speaker talks about past teaching after 'Autonomy' appears) but is vague and omits the required timing details and explicit 'after' relation with timestamps, failing to answer when this occurs."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker uses the example of traffic lights to explain consistency, when does she give the example of microwave popcorn instructions?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 822.0,
        "end": 831.0
      },
      "pred_interval": {
        "start": 788.8,
        "end": 812.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.200000000000045,
        "end": 18.899999999999977,
        "average": 26.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.3727647066116333,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the traffic-light example precedes the microwave-popcorn example (matching the 'next' relation) but omits the requested timestamps and adds an unsupported detail about 'meal times,' so it is incomplete and partially hallucinated."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions setting meal times as important, when does she elaborate on discussing meals further during the evening?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 891.0
      },
      "pred_interval": {
        "start": 923.7,
        "end": 945.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.700000000000045,
        "end": 54.60000000000002,
        "average": 47.650000000000034
      },
      "rationale_metrics": {
        "rouge_l": 0.09836065573770492,
        "text_similarity": 0.15088137984275818,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits the key factual details from the reference\u2014specific timestamps and the quoted target segment\u2014so it is incomplete. "
      }
    },
    {
      "question_id": "002",
      "question": "While the slide lists 'Daily schedule of classes', 'Set meal times', etc., when does the speaker elaborate on students crashing and burning due to lack of food?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 900.2,
        "end": 911.0
      },
      "pred_interval": {
        "start": 946.5,
        "end": 969.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.299999999999955,
        "end": 58.299999999999955,
        "average": 52.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.11940298507462685,
        "text_similarity": 0.22685971856117249,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the content (students crashing from lack of food) near the 'Set meal times' slide but misstates the temporal relation\u2014saying it occurs after she finishes that line rather than during the slide\u2014and omits the time-span details given in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that all listed things can be implemented at home, when does the slide update to reveal the 'Having a schedule and routine at home mimics...' text?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 964.9,
        "end": 965.0
      },
      "pred_interval": {
        "start": 969.3,
        "end": 992.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.399999999999977,
        "end": 27.100000000000023,
        "average": 15.75
      },
      "rationale_metrics": {
        "rouge_l": 0.12345679012345678,
        "text_similarity": 0.1858585774898529,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the slide updates immediately after the speaker's remark (matching the 'once_finished' relation and new text), but it omits the precise timestamps and visual-change timing details provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes talking about morning hygiene routines, when does she start talking about knowing the time to leave the house?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1059.9,
        "end": 1067.9
      },
      "pred_interval": {
        "start": 1052.8,
        "end": 1067.3
      },
      "iou": 0.49006622516554943,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.100000000000136,
        "end": 0.6000000000001364,
        "average": 3.8500000000001364
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.0935690850019455,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the sequence (she begins discussing when to leave after hygiene), but it omits the required precise timing details (starts at 1059.9s and ends explaining tardies at 1067.9s), so it fails to fully answer the question."
      }
    },
    {
      "question_id": "002",
      "question": "While the 'After school' list of activities is displayed, when does the speaker mention 'making time for dinner'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1104.2,
        "end": 1107.0
      },
      "pred_interval": {
        "start": 1124.2,
        "end": 1139.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.0,
        "end": 32.799999999999955,
        "average": 26.399999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.23059552907943726,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the speaker mentions 'making time for dinner' while the 'After school' slide is displayed, but it omits the precise event labels and timestamps (E1/E2 and 1070.8\u20131172.0 with the target at 1104.2\u20131107.0) given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes being consistent, when does she mention that parents might sometimes feel like 'the heavy'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1140.4,
        "end": 1145.7
      },
      "pred_interval": {
        "start": 1179.4,
        "end": 1200.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 54.299999999999955,
        "average": 46.64999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320754,
        "text_similarity": 0.12771978974342346,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that the comment comes after the emphasis but omits the crucial timing/segment details (1140.4\u20131145.7s and relation to E1 at 1139.8s) provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes discussing how consistency helps with sibling rivalry, when is the 'ACCOUNTABILITY' slide fully displayed?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1246.0,
        "end": 1247.5
      },
      "pred_interval": {
        "start": 1230.4,
        "end": 1259.8
      },
      "iou": 0.05102040816326554,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.599999999999909,
        "end": 12.299999999999955,
        "average": 13.949999999999932
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.6650434136390686,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the qualitative relation (the slide appears after the discussion) but omits the key factual details\u2014the exact timestamps (fully displayed at 1246.0s and shown until ~1247.5s) required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker emphasizes the importance of repeatedly stressing accountability, when does the second panel describing accountability appear on the slide?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1285.7,
        "end": 1286.2
      },
      "pred_interval": {
        "start": 1267.6,
        "end": 1284.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.100000000000136,
        "end": 1.7999999999999545,
        "average": 9.950000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367346,
        "text_similarity": 0.4776357114315033,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates a second panel appears after the emphasis, but it omits the essential timing details (start at 1285.7s, fully animated by 1286.2s and the reference event at 1272.0s), so it's incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that accountability is the baseline foundation for a school community, when does she mention 'due dates for homework assignments'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1329.7,
        "end": 1331.9
      },
      "pred_interval": {
        "start": 1296.0,
        "end": 1309.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.700000000000045,
        "end": 22.700000000000045,
        "average": 28.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.5459257960319519,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies that the phrase appears on a slide element (first bullet) but fails to answer the temporal question: it omits the 'after' relation and the specific timing given in the reference, so it is largely incomplete and not aligned with the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"If there's one thing you take away to put in your toolbox tonight, I hope it is this\", when does she explain what students had to write if they said something negative?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1442.41,
        "end": 1454.99
      },
      "pred_interval": {
        "start": 92.5,
        "end": 94.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1349.91,
        "end": 1360.29,
        "average": 1355.1
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307691,
        "text_similarity": 0.2115185707807541,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the explanation occurs after the quoted line but incorrectly asserts it begins 'immediately after' and omits the timestamps and duration; the correct answer shows the explanation starts ~8.4s later (1442.41s) and continues to 1454.99s, so the timing is misrepresented."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes talking about reminding themselves of positive thoughts, when does she introduce the topic of 'Restorative practice when community has been broken'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1486.37,
        "end": 1488.95
      },
      "pred_interval": {
        "start": 139.6,
        "end": 143.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1346.77,
        "end": 1345.65,
        "average": 1346.21
      },
      "rationale_metrics": {
        "rouge_l": 0.22535211267605634,
        "text_similarity": 0.44554322957992554,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the trigger for the topic introduction, tying it to a slide appearance rather than the speaker finishing her positive-thoughts remark and gives no timing; it adds an unverified detail and fails to match the reference relation."
      }
    },
    {
      "question_id": "003",
      "question": "While the green slide titled \"Holding everyone accountable for their own choices and responsibilities\" is displayed, when does the speaker give the example of parents getting a dog for their kids?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1524.93,
        "end": 1577.73
      },
      "pred_interval": {
        "start": 149.6,
        "end": 151.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1375.3300000000002,
        "end": 1426.03,
        "average": 1400.68
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814814,
        "text_similarity": 0.40872347354888916,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys that the dog example occurs while the green accountability slide is displayed (the main relation), but it omits the precise start/end timestamps and duration provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states that 'we have to equip them with their ability to be able to overcome obstacles', when does she explain what saying 'no' does?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1785.657,
        "end": 1788.202
      },
      "pred_interval": {
        "start": 214.6,
        "end": 223.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1571.057,
        "end": 1564.402,
        "average": 1567.7295
      },
      "rationale_metrics": {
        "rouge_l": 0.0625,
        "text_similarity": -0.03342663496732712,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer merely restates the question and provides no timestamps or the 'once_finished' relationship given in the reference, so it fails to match the correct, detailed response."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to 'help and not hinder their development', when does she suggest brainstorming for an essay instead of writing it for them?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1881.94,
        "end": 1883.282
      },
      "pred_interval": {
        "start": 267.6,
        "end": 281.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1614.3400000000001,
        "end": 1601.882,
        "average": 1608.111
      },
      "rationale_metrics": {
        "rouge_l": 0.0784313725490196,
        "text_similarity": -0.0730753242969513,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the semantic relation that the brainstorming suggestion comes after the 'help and not hinder' advice, but it omits the key factual details (the precise anchor/target timestamps and explicit 'after' annotation) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide transitions to 'Collaboration Form Two', when does the speaker say that teachers want to work with parents and guardians?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1934.726,
        "end": 1943.0
      },
      "pred_interval": {
        "start": 293.4,
        "end": 298.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1641.326,
        "end": 1644.6,
        "average": 1642.963
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307691,
        "text_similarity": 0.11633194983005524,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is overly vague and omits the key temporal details (exact timestamps and the explicit 'after' relationship) given in the correct answer, so it fails to provide the required specific timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"It is so important so that we can get a hold of you when we need to be able to talk,\" when do the bullet points on the slide disappear?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2163.0,
        "end": 2163.5
      },
      "pred_interval": {
        "start": 230.0,
        "end": 239.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1933.0,
        "end": 1924.1,
        "average": 1928.55
      },
      "rationale_metrics": {
        "rouge_l": 0.06451612903225808,
        "text_similarity": 0.35216784477233887,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction links the disappearance to that utterance but asserts it happens as the line is spoken, whereas the reference states the bullets disappear immediately after the speech ends (starts 2163.0s, completes 2163.5s) and provides timestamps; the prediction omits these details and slightly contradicts the timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker describes a harmonious journey with unicorns and rainbows, when does she say, \"It's not always going to be perfect. And there's going to be times where we are going to continue to butt heads\"?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2176.5,
        "end": 2181.0
      },
      "pred_interval": {
        "start": 227.6,
        "end": 235.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1948.9,
        "end": 1946.0,
        "average": 1947.45
      },
      "rationale_metrics": {
        "rouge_l": 0.039999999999999994,
        "text_similarity": 0.1803814023733139,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction describes scheduling a phone call and not the temporal/timestamp relation given in the correct answer; it fails to identify the specified timestamps and the 'once_finished' relation, so it is wholly incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker suggests saying, \"I don't think this is going the way that either of us intended,\" when does she suggest scheduling time later in the week for a phone call?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2219.5,
        "end": 2226.5
      },
      "pred_interval": {
        "start": 229.6,
        "end": 235.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1989.9,
        "end": 1991.5,
        "average": 1990.7
      },
      "rationale_metrics": {
        "rouge_l": 0.03846153846153846,
        "text_similarity": 0.2365027666091919,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction reverses the temporal order (saying the quote occurs after mentioning scheduling), contradicting the correct relation that scheduling happens after the quote (once_finished at 2219.5\u20132226.5) and provides no timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that most classrooms will have a homework board, when does she suggest that students should come to school equipped with a planner?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2495.0,
        "end": 2500.0
      },
      "pred_interval": {
        "start": 259.3,
        "end": 264.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2235.7,
        "end": 2235.3,
        "average": 2235.5
      },
      "rationale_metrics": {
        "rouge_l": 0.24691358024691354,
        "text_similarity": 0.2596336603164673,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the planner comment comes after the homework board), but it omits the key factual detail that students should be equipped 'by third grade and beyond' and provides none of the timing specifics from the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker suggests having accessible snacks that can be accessed independently at home, when does she mention tasking students with making their own lunch or breakfast?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2538.8,
        "end": 2542.8
      },
      "pred_interval": {
        "start": 269.4,
        "end": 271.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2269.4,
        "end": 2271.8,
        "average": 2270.6000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.26315789473684215,
        "text_similarity": 0.09363184124231339,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the event occurs after the accessible-snacks comment, but it omits the required timestamps and adds an unsupported detail ('once they are done packing it up in the morning'), which is a hallucination relative to the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker suggests having students set out their clothes the night before, when does she mention that these actions will help ease up on hectic morning routines?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2604.5,
        "end": 2608.0
      },
      "pred_interval": {
        "start": 271.0,
        "end": 273.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2333.5,
        "end": 2334.2,
        "average": 2333.85
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.40390318632125854,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the semantic content (setting out clothes helps ease hectic mornings) but gives a vastly incorrect timestamp (\u2248271s vs the correct \u22482604.5s), so it fails on the key temporal accuracy required."
      }
    },
    {
      "question_id": "001",
      "question": "After Meredith asks Angela if there are any questions, when does Angela respond about pushing her buttons?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2698.0,
        "end": 2701.0
      },
      "pred_interval": {
        "start": 2675.8,
        "end": 2689.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.199999999999818,
        "end": 11.699999999999818,
        "average": 16.949999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.13043478260869568,
        "text_similarity": 0.4744405150413513,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that Angela responds after Meredith, matching the relation, but it omits the specific timing details (Angela starts at 2698.0s and ends at 2701.0s) given in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once Angela finishes her question about kindergartener and eighth grader interactions on cell phones, when does Meredith begin to answer?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2771.5,
        "end": 2773.5
      },
      "pred_interval": {
        "start": 2714.0,
        "end": 2726.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.5,
        "end": 46.69999999999982,
        "average": 52.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.2173913043478261,
        "text_similarity": 0.35014885663986206,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relational timing (Meredith answers after Angela finishes) but omits the key factual timestamps (2770.5s, 2771.5s\u20132773.5s) and duration details present in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After Meredith encourages parents to follow their students on social media, when does she explain how to approach conversations offline?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2717.3,
        "end": 2729.9
      },
      "pred_interval": {
        "start": 2732.5,
        "end": 2745.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.199999999999818,
        "end": 15.299999999999727,
        "average": 15.249999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.6215566396713257,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly gives the start time as 2732.5s, which contradicts the reference (actual start 2717.3s, finish 2729.9s) and also omits the end time; the timing error makes it factually incorrect despite keeping the 'after' relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker talks about establishing very baseline questions to begin with around social media with kids, when does she mention having family meetings around responsibility?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2893.0,
        "end": 2896.0
      },
      "pred_interval": {
        "start": 2854.9,
        "end": 2976.3
      },
      "iou": 0.02471169686985171,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.09999999999991,
        "end": 80.30000000000018,
        "average": 59.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.06779661016949153,
        "text_similarity": 0.08153805136680603,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a single, incorrect timestamp (~29s) and omits the anchor interval; it fails to match the correct absolute times (2893\u20132896s) and lacks the specified anchor (2873\u20132878s), though it loosely implies the event follows the prior topic."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having to change how you talk in terms of voice projection for different age groups in the classroom, when does she advise being careful about the words you're choosing to use?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2921.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2976.3,
        "end": 3016.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.30000000000018,
        "end": 93.40000000000009,
        "average": 74.35000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.04761904761904762,
        "text_similarity": 0.09740810841321945,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly gives timing (3:00\u20133:30 vs. 2912\u20132923s) and changes the content to \u2018vulnerability,\u2019 so it does not match the correct timestamps or precise topic; it only vaguely preserves that a subsequent piece of advice follows."
      }
    },
    {
      "question_id": "001",
      "question": "After Meredith discusses students possibly feeling social anxiety and insecurity when re-entering school, when does she suggest getting them together with friends and classmates ahead of time?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3092.1,
        "end": 3098.5
      },
      "pred_interval": {
        "start": 2369.7,
        "end": 2458.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 722.4000000000001,
        "end": 639.5999999999999,
        "average": 681.0
      },
      "rationale_metrics": {
        "rouge_l": 0.29729729729729726,
        "text_similarity": 0.574112594127655,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the main content and relative ordering (she suggests getting students together after discussing anxiety) but omits the precise timing, timestamps, and the explicit 'once_finished/immediately after' relation given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After Meredith Esau states that social and emotional learning doesn't have to exist in its own silo, when does she talk about teachers weaving social-emotional learning into debate?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3227.397,
        "end": 3232.508
      },
      "pred_interval": {
        "start": 3258.4,
        "end": 3279.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.003000000000156,
        "end": 47.0920000000001,
        "average": 39.04750000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.2941176470588235,
        "text_similarity": 0.4470657706260681,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the weaving occurs after the prior remark, but it omits the required precise timing (start/end timestamps) given in the correct answer, failing to provide the key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "During Meredith Esau's explanation about enabling students to see their unique talents, when does she mention students wanting to code instead of playing football?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3269.041,
        "end": 3312.931
      },
      "pred_interval": {
        "start": 3324.0,
        "end": 3345.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.95899999999983,
        "end": 32.26899999999978,
        "average": 43.613999999999805
      },
      "rationale_metrics": {
        "rouge_l": 0.14705882352941177,
        "text_similarity": 0.4430277943611145,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly paraphrases the content (that she mentions coding vs. football) but fails to provide the requested timing details (the specific timestamps), omitting the key factual elements of the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela finishes asking about parents in conflict regarding screen time, when does Meredith start her response by saying \"Absolutely\"?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3400.93,
        "end": 3402.12
      },
      "pred_interval": {
        "start": 342.5,
        "end": 346.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3058.43,
        "end": 3055.3199999999997,
        "average": 3056.875
      },
      "rationale_metrics": {
        "rouge_l": 0.1,
        "text_similarity": 0.5142465233802795,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but fails to provide the requested timing detail (the start timestamp 3400.93s) and omits the explicit time interval, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After Meredith states that you should \"never put your student in the middle\", when does she suggest helping them develop their own sense of compromise?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3462.72,
        "end": 3469.49
      },
      "pred_interval": {
        "start": 357.8,
        "end": 360.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3104.9199999999996,
        "end": 3109.29,
        "average": 3107.1049999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.3098591549295775,
        "text_similarity": 0.7383992671966553,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly indicates the event occurs 'after' but gives timestamps that are vastly incorrect (\u2248357.8\u2013360.2s vs. the true \u22483462.7\u20133469.5s), so it fails to provide the correct timing."
      }
    },
    {
      "question_id": "003",
      "question": "After Angela lists several places where Meredith's book is available, when does she specifically mention Green Apple Books?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3556.06,
        "end": 3559.12
      },
      "pred_interval": {
        "start": 358.3,
        "end": 360.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3197.7599999999998,
        "end": 3198.92,
        "average": 3198.34
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.5546966195106506,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and lacks the specific timestamps/sequence given in the correct answer, and it adds an unsupported claim about Meredith discussing libraries buying digital books; thus it does not match the precise reference."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela asks if librarians buy digital books, when does Anissa confirm they do?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3595.925,
        "end": 3600.567
      },
      "pred_interval": {
        "start": 3574.8,
        "end": 3629.8
      },
      "iou": 0.08439999999999682,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.125,
        "end": 29.233000000000175,
        "average": 25.179000000000087
      },
      "rationale_metrics": {
        "rouge_l": 0.08888888888888888,
        "text_similarity": 0.42660483717918396,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that Anissa confirms after Angela asks, but it omits the required precise timing (start/end timestamps and the 'once_finished' anchor) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once Anissa finishes asking Angela if she wants to take the YouTube viewer's question, when does Angela say 'Sure, yeah'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3617.561,
        "end": 3621.102
      },
      "pred_interval": {
        "start": 3630.9,
        "end": 3670.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.338999999999942,
        "end": 49.79800000000023,
        "average": 31.568500000000085
      },
      "rationale_metrics": {
        "rouge_l": 0.17391304347826086,
        "text_similarity": 0.3706092834472656,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly implies Angela responds after the question, but it omits the precise timing/ immediacy given in the reference, is ambiguous about who finished asking, and adds an unsupported detail about 'buying digital books.'"
      }
    },
    {
      "question_id": "003",
      "question": "After Meredith begins answering the question about schools helping children cope with COVID deaths, when does Angela next speak?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3720.052,
        "end": 3723.137
      },
      "pred_interval": {
        "start": 3671.0,
        "end": 3681.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.052000000000135,
        "end": 42.13700000000017,
        "average": 45.59450000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.12500000000000003,
        "text_similarity": 0.6544318199157715,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and misleading: Angela does not speak right after Meredith begins but after Meredith finishes her answer (Angela speaks at 3720.052s saying 'Thank you so much'). It omits the precise timing and key detail about Angela's utterance."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela finishes stating that they need to pick one more winner who will get a digital code, when does she clarify that it's an actual digital ebook?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3778.3,
        "end": 3780.3
      },
      "pred_interval": {
        "start": 3796.0,
        "end": 3825.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.699999999999818,
        "end": 44.69999999999982,
        "average": 31.199999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.22535211267605632,
        "text_similarity": 0.4637388586997986,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is largely incorrect: it cites a different anchor event (putting her email in the chat) rather than the correct event (picking one more winner) and omits the precise timestamps; it therefore contradicts and omits key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "Once Angela finishes stating her intention to put her email in the chat, when do her fingers come into view as she appears to type?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3833.5,
        "end": 3840.4
      },
      "pred_interval": {
        "start": 3825.0,
        "end": 3845.0
      },
      "iou": 0.3450000000000045,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.5,
        "end": 4.599999999999909,
        "average": 6.5499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.27848101265822783,
        "text_similarity": 0.5949561595916748,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (her fingers appear once she finishes), but it omits the key timestamp details and duration provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman at the bottom finishes describing the usefulness of the book for specific tips, when does she start reading the quote about teaching children?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3930.0,
        "end": 3989.9829999999997
      },
      "gt_interval": {
        "start": 3945.123,
        "end": 3950.606
      },
      "pred_interval": {
        "start": 3946.5,
        "end": 3987.2
      },
      "iou": 0.09758300259049467,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3769999999999527,
        "end": 36.593999999999596,
        "average": 18.985499999999774
      },
      "rationale_metrics": {
        "rouge_l": 0.1923076923076923,
        "text_similarity": 0.22630158066749573,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the relative ordering ('after') but omits the key factual details and precise timestamps given in the correct answer, making it incomplete. It also lacks the specified start and end times and the minor precision adjustment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'we want to be your allies', when does she talk about parents and teachers wanting the best for the kids?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1953.971,
        "end": 1964.847
      },
      "pred_interval": {
        "start": 5.7,
        "end": 8.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1948.271,
        "end": 1956.647,
        "average": 1952.4589999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.41379310344827586,
        "text_similarity": 0.6035048365592957,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states the temporal relation (the remark about parents and teachers occurs after 'we want to be your allies'), matching the reference despite omitting exact timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes discussing the scaffolding teachers have in place, when does she mention bringing students to meetings?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.427,
        "end": 2061.512
      },
      "pred_interval": {
        "start": 43.6,
        "end": 45.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2014.8270000000002,
        "end": 2016.5120000000002,
        "average": 2015.6695000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1791044776119403,
        "text_similarity": 0.5762537717819214,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the temporal relation that she mentions bringing students to meetings after finishing the scaffolding discussion; it omits the exact timestamps and the quoted wording ('whenever possible'), hence not a perfect match."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes her parents attending a parent-teacher conference without her, when does she explain how her presence could have helped?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2110.911,
        "end": 2135.889
      },
      "pred_interval": {
        "start": 151.0,
        "end": 152.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1959.911,
        "end": 1983.2890000000002,
        "average": 1971.6000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.5589919090270996,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the topic but misrepresents the timing\u2014it says the explanation occurs during the conference, whereas the reference states the explanation happens afterward\u2014and omits the timestamp details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining how collaborating with parents increases involvement on a holistic level in the academic environment, when does she start talking about identifying unique talents and abilities?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2340.0,
        "end": 2348.835
      },
      "pred_interval": {
        "start": 2374.9,
        "end": 2425.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.90000000000009,
        "end": 76.96500000000015,
        "average": 55.93250000000012
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.06381571292877197,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the target follows the anchor (identifying talents begins after the collaboration point) but omits the key factual timestamps and precise timing information requested in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says it's our duty to instill independence, resilience, and self-reliance in students, when does she state that 'autonomy is action when we...'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2407.49,
        "end": 2412.5
      },
      "pred_interval": {
        "start": 2426.1,
        "end": 2457.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.610000000000127,
        "end": 44.69999999999982,
        "average": 31.654999999999973
      },
      "rationale_metrics": {
        "rouge_l": 0.09375,
        "text_similarity": 0.04108300060033798,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the target follows the anchor, but it omits the specific timing information and incorrectly implies immediate continuation rather than the brief (~2.2s) pause indicated in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions students experiencing a gamut of emotions within a calendar day, when does she begin discussing their ability to be allies and advocates for others?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2429.86,
        "end": 2438.809
      },
      "pred_interval": {
        "start": 2458.3,
        "end": 2519.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.440000000000055,
        "end": 80.1909999999998,
        "average": 54.31549999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.16339099407196045,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (\u224824:58\u201325:20) are completely inconsistent with the reference (start at 2429.86s \u2248 40:29.86, end 2438.809s), so the prediction is incorrect. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating that this is 'practice dialogue number one', when does the English speaker (teacher) begin her first segment?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 81.412,
        "end": 86.516
      },
      "pred_interval": {
        "start": 7.8,
        "end": 9.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.61200000000001,
        "end": 77.316,
        "average": 75.464
      },
      "rationale_metrics": {
        "rouge_l": 0.17777777777777778,
        "text_similarity": 0.3758641183376312,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction claims the speaker begins immediately after 'number one', but the reference shows the English segment actually starts much later (at 81.412s after E1 ends at 28.373s), so the answer contradicts the correct timing and omits key timestamp details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes reading the English segment for Segment 5, when does she start reading the Telugu segment for Segment 6?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 150.0,
        "end": 233.917
      },
      "gt_interval": {
        "start": 158.981,
        "end": 170.016
      },
      "pred_interval": {
        "start": 152.4,
        "end": 168.9
      },
      "iou": 0.5630676657584025,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.580999999999989,
        "end": 1.1159999999999854,
        "average": 3.848499999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.5550490617752075,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that the Telugu segment follows the English one, correctly conveying the temporal relation, but it omits the precise timestamps, the end time, and the noted beep between segments, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes reading the English segment for Segment 7, when does she start reading the Telugu segment for Segment 8?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 150.0,
        "end": 233.917
      },
      "gt_interval": {
        "start": 187.957,
        "end": 202.515
      },
      "pred_interval": {
        "start": 217.3,
        "end": 233.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.343000000000018,
        "end": 31.38500000000002,
        "average": 30.36400000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.548778235912323,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the temporal relation (that the Telugu segment follows the English one) but omits all key factual details from the reference\u2014no start/end timestamps, no mention of the beep, and no absolute-to-relative timing information."
      }
    },
    {
      "question_id": "003",
      "question": "While the 'Thank You!' screen is displayed, when does the speaker begin her concluding remarks about the dialogue?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 150.0,
        "end": 233.917
      },
      "gt_interval": {
        "start": 209.544,
        "end": 233.917
      },
      "pred_interval": {
        "start": 233.9,
        "end": 233.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.355999999999995,
        "end": 0.016999999999995907,
        "average": 12.186499999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.25531914893617014,
        "text_similarity": 0.3538062572479248,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the concluding remarks occur while the 'Thank You!' screen is displayed (the relation), but it omits the key factual timing details (start at 209.544s, end at 233.917s) required to answer 'when'."
      }
    },
    {
      "question_id": "001",
      "question": "After the introductory speaker says, 'And I will turn it over to you,' when does Megan start speaking her introductory remarks?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 88.123,
        "end": 97.103
      },
      "pred_interval": {
        "start": 28.9,
        "end": 34.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.223000000000006,
        "end": 62.40299999999999,
        "average": 60.813
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.5314268469810486,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that Megan speaks after the handover, but it omits the key factual details from the reference\u2014specifically the precise timestamps for E1 and for Megan's remarks (start 88.123, end 97.103)."
      }
    },
    {
      "question_id": "002",
      "question": "After Megan displays the 'Pandemic Parenting Principles' slide, when does she first mention graduating from Fairfield in 2010?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 101.112,
        "end": 102.697
      },
      "pred_interval": {
        "start": 56.2,
        "end": 63.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.91199999999999,
        "end": 39.097,
        "average": 42.00449999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.17543859649122806,
        "text_similarity": 0.6893551349639893,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the mention occurs later during her discussion of teaching/education (i.e., after the slide), but it omits the precise timing/timestamps and the explicit 'after' relationship details provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions she got her master's in early childhood from BC, when does she start talking about teaching in Newton and Wellesley?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.6,
        "end": 174.5
      },
      "pred_interval": {
        "start": 248.5,
        "end": 257.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.9,
        "end": 82.80000000000001,
        "average": 81.35000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.04444444444444444,
        "text_similarity": 0.01692650094628334,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mentions the content (teaching in Newton and Wellesley) but fails to answer the timing question and omits the crucial timestamps; it does not provide when she starts talking as the correct answer specifies. "
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is talking about the Jesuit ideals instilled during her time at Fairfield, when does she mention the ability to reflect on where she was and wanted to go?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 352.0,
        "end": 355.5
      },
      "pred_interval": {
        "start": 267.5,
        "end": 281.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 84.5,
        "end": 73.89999999999998,
        "average": 79.19999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.11594202898550725,
        "text_similarity": 0.40472596883773804,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures that a reflection follows the discussion of Jesuit ideals, but it fails to provide the requested timing (specific timestamps/segment info) and thus omits key factual details from the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions offering strategies to help motivate your child, when does she introduce the topic of handwriting?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 351.8,
        "end": 361.0
      },
      "pred_interval": {
        "start": 38.9,
        "end": 47.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 312.90000000000003,
        "end": 313.8,
        "average": 313.35
      },
      "rationale_metrics": {
        "rouge_l": 0.16393442622950818,
        "text_similarity": 0.32779407501220703,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the relation ('after') but fails to provide the requested timing details (the timestamps 351.8s\u2013361.0s and the initial reference at 340.0s), so it is largely incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide displays '2-5 minutes of handwriting practice adds up!', when does the speaker explain the importance of modeling numbers for children?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 396.0,
        "end": 413.0
      },
      "pred_interval": {
        "start": 254.6,
        "end": 257.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 141.4,
        "end": 155.5,
        "average": 148.45
      },
      "rationale_metrics": {
        "rouge_l": 0.15151515151515152,
        "text_similarity": 0.2981342077255249,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is incorrect and off-topic: it ties the explanation to talking about magnetic letters/word building rather than the actual timing (396\u2013413s) when the speaker models numbers during the slide display, and it omits the correct temporal relation."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes talking about using magnetic letters for word building, when does she start discussing ordering numbers?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 455.216,
        "end": 464.045
      },
      "pred_interval": {
        "start": 476.1,
        "end": 491.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.884000000000015,
        "end": 27.254999999999995,
        "average": 24.069500000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2105263157894737,
        "text_similarity": 0.547833263874054,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the temporal sequence (ordering numbers follows the magnetic letters segment) but omits the requested timestamps and adds an unsupported detail about a poster board; it also uses the wrong pronoun."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker describes the specific elements a child included on their glowfish poster, when does she start to explain the general benefits of using big poster boards?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 532.8,
        "end": 542.0
      },
      "pred_interval": {
        "start": 234.8,
        "end": 256.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 297.99999999999994,
        "end": 285.1,
        "average": 291.54999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.24000000000000005,
        "text_similarity": 0.5046769380569458,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately paraphrases the correct relation\u2014she begins explaining the general benefits after describing the specific example\u2014preserving the original meaning without adding or omitting key details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes showing the second poster example about the solar system, when does she explicitly list the general benefits of posters?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 576.835,
        "end": 593.004
      },
      "pred_interval": {
        "start": 279.4,
        "end": 294.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 297.43500000000006,
        "end": 298.704,
        "average": 298.06950000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814817,
        "text_similarity": 0.40288013219833374,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the benefits are listed after an example, but it omits the precise timestamps and refers vaguely to a 'drawing' example instead of the solar system poster, failing to match the specific timing and context given in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker makes a general statement about children hesitating to write about things they can't draw, when does she provide a personal example of her nephew?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 672.0,
        "end": 690.0
      },
      "pred_interval": {
        "start": 305.5,
        "end": 329.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 366.5,
        "end": 360.6,
        "average": 363.55
      },
      "rationale_metrics": {
        "rouge_l": 0.2631578947368421,
        "text_similarity": 0.43421924114227295,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that she follows the general statement with a nephew example, but it contradicts a key fact by saying 'can draw' instead of 'can't draw' and omits the provided timestamps."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions a 'how-to drawing type book', when does she explain that drawing is a big piece of practice in addition to writing?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.375,
        "end": 704.155
      },
      "pred_interval": {
        "start": 275.6,
        "end": 324.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 423.775,
        "end": 379.255,
        "average": 401.515
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.5591820478439331,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly captures the key relation \u2014 that the speaker explains the drawing comment after mentioning the 'how-to drawing type book'; omission of timestamps does not change the meaning."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker transitions to the 'MAKE YOUR OWN MATH GAMES' slide, when does she specifically describe making green and pink number cards?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 744.49,
        "end": 748.575
      },
      "pred_interval": {
        "start": 385.8,
        "end": 410.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 358.69,
        "end": 338.475,
        "average": 348.5825
      },
      "rationale_metrics": {
        "rouge_l": 0.39344262295081966,
        "text_similarity": 0.5620741248130798,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the description occurs after the slide transition and mentions the green/pink cards, but it omits the specific timing details (timestamps and interval) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that a collection of 'just right' books is key to helping children learn to read, when does she show an example of a Scholastic reader?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 911.4,
        "end": 915.0
      },
      "pred_interval": {
        "start": 973.4,
        "end": 982.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.0,
        "end": 67.5,
        "average": 64.75
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.41949760913848877,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the Scholastic reader appears after the mention, but incorrectly asserts it occurs \"immediately after\" and omits the actual timing (there is a ~16.4s gap between 895.0s and 911.4s), so it is misleading and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the explanation of the '5 Finger Test', when does the speaker describe what constitutes a 'just right' book?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 986.5,
        "end": 970.0
      },
      "pred_interval": {
        "start": 929.6,
        "end": 938.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.89999999999998,
        "end": 31.200000000000045,
        "average": 44.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.10666666666666667,
        "text_similarity": 0.49537283182144165,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the general idea that the speaker explains what makes a book 'just right' during the demonstration, but it omits the key factual detail that she specifies 2\u20133 words as 'just right' and adds an unverified sequencing detail about the image/hand, failing to match the precise timing given."
      }
    },
    {
      "question_id": "001",
      "question": "While the images of the cardboard clocks are displayed, when does the speaker mention a child drawing a puppy on one of them?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1058.2,
        "end": 1060.95
      },
      "pred_interval": {
        "start": 96.4,
        "end": 102.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 961.8000000000001,
        "end": 958.6500000000001,
        "average": 960.2250000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5254759192466736,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly links the puppy mention to the cardboard clock images, but it incorrectly states the timing ('after showing') whereas the reference specifies the mention occurs during the clocks' display; this factual contradiction warrants a low score."
      }
    },
    {
      "question_id": "002",
      "question": "While the 'Weekend News' template is shown on the screen, when does the speaker say that kids would be excited to share their news?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1131.3,
        "end": 1138.0
      },
      "pred_interval": {
        "start": 105.7,
        "end": 111.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1025.6,
        "end": 1026.7,
        "average": 1026.15
      },
      "rationale_metrics": {
        "rouge_l": 0.1846153846153846,
        "text_similarity": 0.44148385524749756,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that the speaker mentions kids being excited while the 'Weekend News' template is displayed, but it omits the specific timestamps given in the reference and adds an unverified visual detail (lined paper and pencil)."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the 'Hide & Go Seek' sight word game, when does she start explaining the 'Memory' sight word game?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1204.2,
        "end": 1205.5
      },
      "pred_interval": {
        "start": 113.5,
        "end": 118.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1090.7,
        "end": 1086.6,
        "average": 1088.65
      },
      "rationale_metrics": {
        "rouge_l": 0.21875,
        "text_similarity": 0.5555636882781982,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction vaguely notes she begins a memory activity after Hide & Go Seek, but it omits the required timestamp (1204.2s) and adds an unsupported detail ('top right side'), so it fails to answer when precisely."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes recommending non-fiction books if the home collection is mostly storybooks, when does she start talking about having visuals to practice multiplication?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1250.14,
        "end": 1251.01
      },
      "pred_interval": {
        "start": 769.0,
        "end": 834.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 481.1400000000001,
        "end": 417.01,
        "average": 449.07500000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.6683855056762695,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp is wildly incorrect and nonsensical (7 minutes 69 seconds) compared to the reference (~1250s \u2248 20:50), and it fails to provide the correct separate start/end event timings; key factual timing information is missing/incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes explaining that dry erase boards help with handwriting consistency, when does she start talking about having math tools for exploration?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1322.321,
        "end": 1324.997
      },
      "pred_interval": {
        "start": 854.0,
        "end": 882.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 468.3209999999999,
        "end": 442.99700000000007,
        "average": 455.659
      },
      "rationale_metrics": {
        "rouge_l": 0.2040816326530612,
        "text_similarity": 0.3412405848503113,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the correct chronology by claiming dry erase boards come after math tools and provides no timestamps; it therefore fails to match the referenced timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes mentioning having sharpened pencils around for home setup, when does she display and introduce the word wall for visual reinforcement?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1425.637,
        "end": 1450.0
      },
      "pred_interval": {
        "start": 899.0,
        "end": 939.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 526.637,
        "end": 511.0,
        "average": 518.8185
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.30901721119880676,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction vaguely says the word wall appears near the segment end but gives an incorrect/meaningless timestamp (\"9 minutes, 99 seconds\") and omits the precise times and relation provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions having an alphabet chart or number line for easy accessibility, when does she introduce the word wall?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1425.2,
        "end": 1427.5
      },
      "pred_interval": {
        "start": 1473.8,
        "end": 1529.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.59999999999991,
        "end": 102.09999999999991,
        "average": 75.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367346,
        "text_similarity": 0.34615546464920044,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits the key factual details (the specific timestamps for E1 and E2 and the exact interval when the word wall is introduced), making it incomplete for the asked 'when' question."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker suggests parents type the words for a book while the child illustrates, when does she suggest having the child practice typing?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1506.0,
        "end": 1508.0
      },
      "pred_interval": {
        "start": 1529.6,
        "end": 1555.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.59999999999991,
        "end": 47.59999999999991,
        "average": 35.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571433,
        "text_similarity": 0.28559747338294983,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the practice suggestion follows the parent-typing/child-illustrating suggestion, but it fails to provide the specific timing (1506\u20131508s) and omits the precise next-event relation given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that games help build skills, when does she mention 'problem solving'?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1617.701,
        "end": 1618.281
      },
      "pred_interval": {
        "start": 96.8,
        "end": 97.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1520.901,
        "end": 1521.081,
        "average": 1520.991
      },
      "rationale_metrics": {
        "rouge_l": 0.2553191489361702,
        "text_similarity": 0.3902808427810669,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the mention occurs 'after', but it omits the required anchor and precise timestamps and introduces a vague context ('comparing the benefits of games') that doesn't match the detailed reference, so key factual elements are missing."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker compares reading less than a minute a day to 20 minutes a day, when does she state that 1.8 million words are exposed per year?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1683.016,
        "end": 1684.426
      },
      "pred_interval": {
        "start": 143.5,
        "end": 145.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1539.516,
        "end": 1539.126,
        "average": 1539.321
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290322,
        "text_similarity": 0.399599552154541,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and does not provide the requested timing; it fails to give the specific timestamp or clear relative location (it only says 'right before concluding'), omitting the key factual element present in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the 'Q&A' slide is displayed, when does the slide asking 'COVID and religious education?' appear?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.8,
        "end": 1803.9
      },
      "pred_interval": {
        "start": 182.9,
        "end": 183.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1614.8999999999999,
        "end": 1620.3000000000002,
        "average": 1617.6
      },
      "rationale_metrics": {
        "rouge_l": 0.32727272727272727,
        "text_similarity": 0.35341426730155945,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates that a question/slide about COVID and religious education follows the Q&A slide, but it omits all precise timing, the exact transition moment (1797.8s), display durations, and the 'once_finished' relation, making it incomplete for the asked question."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker concludes her statement about music being important for religious education, when does she start talking about children learning about saints?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1840.4,
        "end": 1844.9
      },
      "pred_interval": {
        "start": 184.7,
        "end": 185.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1655.7,
        "end": 1659.1000000000001,
        "average": 1657.4
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.42432701587677,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates that she starts discussing saints after the music comment, but it omits the requested precise timing (start at 1840.4s, end at 1844.9s) and other key timestamp details, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes asking how schools can assist with the transition to in-person learning, when does the slide listing 'clear expectations' appear?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1879.3,
        "end": 1940.0
      },
      "pred_interval": {
        "start": 187.6,
        "end": 188.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1691.7,
        "end": 1751.8,
        "average": 1721.75
      },
      "rationale_metrics": {
        "rouge_l": 0.1724137931034483,
        "text_similarity": 0.3511201739311218,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that the slide appears 'after' the speaker's question and gives no timestamps or the crucial detail that E2 appears at 1879.3s and continues past the anchor completion at 1976.7s, omitting key factual information from the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks, 'How to ensure children are not being distracted by non-school work when online?', when does she start listing tips?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.342,
        "end": 1963.495
      },
      "pred_interval": {
        "start": 48.7,
        "end": 56.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1910.642,
        "end": 1907.195,
        "average": 1908.9185
      },
      "rationale_metrics": {
        "rouge_l": 0.1724137931034483,
        "text_similarity": 0.20481637120246887,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the tips come after the question (the main relation), but it omits the precise timing and quoted start phrase provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes giving tips on staying on task, when does she offer to answer questions?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1997.897,
        "end": 2003.182
      },
      "pred_interval": {
        "start": 189.9,
        "end": 190.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1807.9969999999998,
        "end": 1813.082,
        "average": 1810.5394999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.16901408450704225,
        "text_similarity": 0.24063700437545776,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly and succinctly conveys that she offers to answer questions immediately after finishing the tips, matching the reference's 'once finished'/immediate timing without adding or contradicting details."
      }
    },
    {
      "question_id": "003",
      "question": "After the host says 'Great. I have two more. Thank you for that.', when does she ask the question about kindergarten?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2083.534,
        "end": 2093.534
      },
      "pred_interval": {
        "start": 191.9,
        "end": 204.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1891.634,
        "end": 1888.9340000000002,
        "average": 1890.284
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962262,
        "text_similarity": 0.3570933938026428,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly locates the question at ~20 seconds, which strongly contradicts the correct timestamp (~2083.534s start); it also omits the precise start/end times and relation, so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the female speaker on the right finishes asking the question about the emotional side of entering a new grade, when does the female speaker on the left begin to respond?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2297.683
      },
      "gt_interval": {
        "start": 2181.936,
        "end": 2182.54
      },
      "pred_interval": {
        "start": 237.4,
        "end": 245.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1944.536,
        "end": 1936.6399999999999,
        "average": 1940.588
      },
      "rationale_metrics": {
        "rouge_l": 0.13043478260869562,
        "text_similarity": 0.25265800952911377,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the left speaker responds after the question, but it is vague and omits the precise timing and relation details (start at 2181.936s, completion at 2182.54s and the 'once_finished' relation), so it's incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "When is the next time the female speaker on the left mentions a way students are socializing online after she describes a student's weekly Zoom calls?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2297.683
      },
      "gt_interval": {
        "start": 2204.249,
        "end": 2210.952
      },
      "pred_interval": {
        "start": 255.6,
        "end": 263.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1948.649,
        "end": 1947.2520000000002,
        "average": 1947.9505
      },
      "rationale_metrics": {
        "rouge_l": 0.10344827586206896,
        "text_similarity": 0.22162026166915894,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only vaguely restates that she mentions another way after the Zoom calls but omits the precise timestamps, event identifiers (E1/E2), and the 'next' relation specified in the correct answer, thus missing key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "After the female speaker on the left finishes talking about an online newspaper, when does she begin to introduce the 'Outschool' platform?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2297.683
      },
      "gt_interval": {
        "start": 2227.882,
        "end": 2232.043
      },
      "pred_interval": {
        "start": 270.9,
        "end": 281.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1956.982,
        "end": 1950.4430000000002,
        "average": 1953.7125
      },
      "rationale_metrics": {
        "rouge_l": 0.06349206349206349,
        "text_similarity": 0.29732847213745117,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly implies the 'Outschool' mention comes after the online newspaper segment, but it is vague (no timestamps) and introduces an unfounded detail about \"how they use technology in their classes\" instead of stating the core offering (online courses), omitting key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'Number four', when does the text 'Parents don't get trained' appear on screen?",
      "video_id": "J-upF-lwWvg",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 46.400000000000006
      },
      "gt_interval": {
        "start": 2.02,
        "end": 3.73
      },
      "pred_interval": {
        "start": 23.4,
        "end": 27.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.38,
        "end": 24.169999999999998,
        "average": 22.775
      },
      "rationale_metrics": {
        "rouge_l": 0.42553191489361697,
        "text_similarity": 0.6674764752388,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the text appears after the speaker, but incorrectly claims it appears immediately; the ground truth shows a 1.44s delay (starts at 2.02s after the 0.58s cue) and includes duration until 3.73s, which the prediction omits and misstates."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'communicating at the IEP table', when does she continue her explanation about parents at the IEP table?",
      "video_id": "J-upF-lwWvg",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 46.400000000000006
      },
      "gt_interval": {
        "start": 9.85,
        "end": 12.35
      },
      "pred_interval": {
        "start": 35.6,
        "end": 38.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.75,
        "end": 26.15,
        "average": 25.95
      },
      "rationale_metrics": {
        "rouge_l": 0.3666666666666667,
        "text_similarity": 0.7448557019233704,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates the relation but provides no temporal details\u2014omitting the key timestamps (9.3s, 9.85s\u201312.35s) included in the correct answer\u2014so it is largely incomplete despite not contradicting the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'And number five', when does the text 'you don't have the playbook' appear?",
      "video_id": "J-upF-lwWvg",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 46.400000000000006
      },
      "gt_interval": {
        "start": 24.8,
        "end": 26.0
      },
      "pred_interval": {
        "start": 40.1,
        "end": 43.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.3,
        "end": 17.1,
        "average": 16.200000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.5416666666666666,
        "text_similarity": 0.6705895662307739,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the text appears after the speaker says the line) and is not contradictory, but it omits the key timing details provided in the reference (the exact start/end times and the speaker timestamp)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions they have three presentations, when does she introduce the first presenter, Khadija Mohamed?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 40.767,
        "end": 45.473
      },
      "pred_interval": {
        "start": 65.7,
        "end": 83.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.933,
        "end": 37.727000000000004,
        "average": 31.330000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1951219512195122,
        "text_similarity": 0.6188275814056396,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') between the mention of three presentations and the introduction of Khadija Mohamed, but it omits the specific timestamps and finer timing details provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions revealing the hidden curriculum, when does the slide change to display 'Teaching Scotland's Future'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.8,
        "end": 202.8
      },
      "pred_interval": {
        "start": 264.3,
        "end": 278.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.5,
        "end": 76.09999999999997,
        "average": 69.29999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.15686274509803924,
        "text_similarity": 0.3284185528755188,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction asserts the slide changes at the moment the speaker mentions the hidden curriculum, which contradicts the reference stating the slide appears much later (around 201.8\u2013202.8s) after the anchor (166.5\u2013169.8s); it also omits the timestamp details."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing teacher educators, when does a blue speech bubble with the question 'Is the team all right?' appear on the screen?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 245.5,
        "end": 258.7
      },
      "pred_interval": {
        "start": 329.2,
        "end": 330.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.69999999999999,
        "end": 71.40000000000003,
        "average": 77.55000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.3948381543159485,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the blue speech bubble appears during the discussion of teacher educators, preserving the main semantic point, but it omits the specific onset/offset timestamps (245.5s\u2013258.7s and related anchor times) given in the reference, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing the challenges faced by collectivist teachers, when does she state the research question about how minority ethnic teachers use their cultural, religious, and linguistic skills?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 390.6,
        "end": 394.78
      },
      "pred_interval": {
        "start": 256.4,
        "end": 267.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 134.20000000000005,
        "end": 127.47999999999996,
        "average": 130.84
      },
      "rationale_metrics": {
        "rouge_l": 0.0784313725490196,
        "text_similarity": 0.08802879601716995,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes that the speaker states the research question, but it fails to provide the required timing details (the precise timestamps and the 'after' relation), so it is largely incomplete. "
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker quotes Ladson-Billings about Critical Race Theory, when does she explain what Critical Race Theory helps to do?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 420.0,
        "end": 427.3
      },
      "pred_interval": {
        "start": 458.4,
        "end": 473.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.39999999999998,
        "end": 46.599999999999966,
        "average": 42.49999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.13311496376991272,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes that she explains the purpose of CRT after the quote and paraphrases the content, but it fails to provide the requested timing information (the specific start/end timestamps and precise 'after' relation) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the 'racial microaggression framework', when does she mention the time period 'the early 1970s to the 1990s'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 517.1,
        "end": 519.1
      },
      "pred_interval": {
        "start": 579.2,
        "end": 648.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.10000000000002,
        "end": 129.19999999999993,
        "average": 95.64999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.326530612244898,
        "text_similarity": 0.5503845810890198,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that the mention of 'the early 1970s to the 1990s' occurs after the discussion of the 'racial microaggression framework,' matching the reference's relative ordering."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker shares discussions from her study, when does the first speech bubble graphic appear on the 'Cultural and Linguistic experiences' slide?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 574.2,
        "end": 574.9
      },
      "pred_interval": {
        "start": 579.2,
        "end": 580.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 5.2000000000000455,
        "average": 5.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.57349693775177,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the bubble appears while the discussion is happening, but it omits the precise timing (first bubble at ~574.2s) and implies it appears immediately as the discussion starts, making it imprecise and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions a teacher in Edinburgh trying to talk about the slave trade issue with her class, when does the speaker state that the discussion 'went terribly wrong'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 721.0,
        "end": 722.451
      },
      "pred_interval": {
        "start": 84.6,
        "end": 92.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 636.4,
        "end": 629.751,
        "average": 633.0754999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333334,
        "text_similarity": 0.5026407241821289,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys that the 'went terribly wrong' remark occurs after the Edinburgh teacher mention (immediately following it), matching the reference relation and timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the teacher asks Muslim children to draw an image of what they think God looks like, when does the speaker describe the Muslim kids just sitting there and staring?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 746.761,
        "end": 793.029
      },
      "pred_interval": {
        "start": 85.3,
        "end": 92.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 661.461,
        "end": 700.429,
        "average": 680.9449999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.6305950880050659,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time interval (85.3s\u201392.6s) does not match the reference interval (746.761s\u2013793.029s); the predicted timestamps are completely incorrect and contradict the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the teacher asks what's happening in Burma, when do the children ask why it's not in the news?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 897.0,
        "end": 899.8
      },
      "pred_interval": {
        "start": 387.2,
        "end": 406.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 509.8,
        "end": 492.9,
        "average": 501.35
      },
      "rationale_metrics": {
        "rouge_l": 0.16,
        "text_similarity": 0.48634862899780273,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction vaguely references the teacher and a student but gives an invalid/incorrect timestamp and says a student replies 'Burma' about a minute later, which contradicts the correct short delay and the children asking why it's not in the news, so it fails on timing and event accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stella finishes inviting Jacqueline to introduce herself, when does Jacqueline begin speaking?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1145.3,
        "end": 1146.2
      },
      "pred_interval": {
        "start": 108.2,
        "end": 126.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1037.1,
        "end": 1019.5,
        "average": 1028.3
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.43961599469184875,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and contradictory: it says Jacqueline speaks after Khadija's presentation rather than immediately after Stella's invitation, and it omits the timing details given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After Khadija finishes her presentation and apology, when does Stella begin thanking her?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1119.9,
        "end": 1121.2
      },
      "pred_interval": {
        "start": 124.3,
        "end": 125.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 995.6000000000001,
        "end": 995.7,
        "average": 995.6500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981134,
        "text_similarity": 0.4687685966491699,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the reference: it mentions Jacqueline and slide display instead of Khadija finishing, gives no timing, and introduces unrelated details, so it does not match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After Jacqueline says, 'Let me just see if I can share these slides with you', when does her presentation's title slide appear in full screen?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1177.8,
        "end": 1182.0
      },
      "pred_interval": {
        "start": 125.6,
        "end": 126.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1052.2,
        "end": 1055.3,
        "average": 1053.75
      },
      "rationale_metrics": {
        "rouge_l": 0.17721518987341772,
        "text_similarity": 0.46853381395339966,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction wrongly claims the slide appears immediately after the phrase; the reference specifies a ~23s delay (anchor at 1154.7s, slide full screen at 1177.8s) and notes how long it remains, so the prediction omits and contradicts key timing details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes talking about how students of color were feeling left out at the secondary school, when does she transition to the slide about 'Race in Scotland'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1260.0,
        "end": 1269.32
      },
      "pred_interval": {
        "start": 965.3,
        "end": 978.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 294.70000000000005,
        "end": 291.1199999999999,
        "average": 292.90999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.3125,
        "text_similarity": 0.5331622362136841,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the slide changes to 'Race in Scotland' but fails to provide the required timing details (1259s\u21921260s and the subsequent speech ending at 1269.32s), omitting key factual elements from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that only 40% of Scottish people surveyed agreed that immigrants make Scotland a better place, when does she mention the number of hate crimes reported in Scotland?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1312.001,
        "end": 1323.455
      },
      "pred_interval": {
        "start": 1247.7,
        "end": 1261.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.30099999999993,
        "end": 62.35500000000002,
        "average": 63.327999999999975
      },
      "rationale_metrics": {
        "rouge_l": 0.1875,
        "text_similarity": 0.5045695304870605,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that she mentions the number of hate crimes but omits the required timing details (1312.001s\u20131323.455s) and the relation to the 40% statement, so it fails to answer the question fully."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker explains that colourblind racism leads to the omission and avoidance of race issues in the classroom, when does she mention that teachers fear talking about race?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1376.326,
        "end": 1379.45
      },
      "pred_interval": {
        "start": 1304.0,
        "end": 1312.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.32600000000002,
        "end": 66.75,
        "average": 69.53800000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.4193548387096774,
        "text_similarity": 0.6598453521728516,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the sequence and main idea (that teachers fear discussing race) but omits the precise timestamps given in the reference and weakens the assertion from 'do fear' to 'may fear,' losing factual specificity."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says that Critical Race Theory \"really underpins everything that I do when it comes to research\", when does she start discussing the \"Methods\" of their research?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1453.971,
        "end": 1486.746
      },
      "pred_interval": {
        "start": 1482.9,
        "end": 1503.7
      },
      "iou": 0.0773391783466388,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.929000000000087,
        "end": 16.95399999999995,
        "average": 22.94150000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.12698412698412698,
        "text_similarity": 0.17543606460094452,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the key temporal relation that the Methods discussion occurs after the Critical Race Theory remark, but it omits the precise timestamps and specific quoted utterances ('We did our research...' and 'Scottish city') given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker describes the first tenet of Critical Race Theory as the assertion that \"racism is normal, it's ordinary, it's systemic\", when does she describe the next tenet?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1440.328,
        "end": 1450.256
      },
      "pred_interval": {
        "start": 1503.7,
        "end": 1516.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.37200000000007,
        "end": 66.54399999999987,
        "average": 64.95799999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.1714285714285714,
        "text_similarity": 0.21061256527900696,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to answer the asked timing (timestamps) and instead supplies an unsupported description of the next tenet, introducing likely hallucinated content and omitting the key temporal details from the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that students wholeheartedly disagreed with the idea of equal chance regardless of race/ethnicity, when does she introduce Omar's quote about teachers trying to motivate them?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.0,
        "end": 1618.0
      },
      "pred_interval": {
        "start": 6.7,
        "end": 8.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1606.3,
        "end": 1609.8,
        "average": 1608.05
      },
      "rationale_metrics": {
        "rouge_l": 0.2142857142857143,
        "text_similarity": 0.498099684715271,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that Omar's quote is introduced immediately after the prior statement (matching the 'after' relation), but it omits the specific timestamps (1611.0s end and 1613.0\u20131618.0 interval) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says she emailed 31 schools, when does she state how many responses she received?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1782.3,
        "end": 1783.5
      },
      "pred_interval": {
        "start": 239.6,
        "end": 258.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1542.7,
        "end": 1524.8,
        "average": 1533.75
      },
      "rationale_metrics": {
        "rouge_l": 0.08,
        "text_similarity": 0.14453616738319397,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer only restates that the responses are mentioned afterward and lacks the required anchor/target timestamps and explicit temporal relation provided in the correct answer, so it is insufficiently specific."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that one of the secured schools dropped out before recruiting, when does she mention that the second school dropped out a day before the focus groups began?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1818.0,
        "end": 1825.4
      },
      "pred_interval": {
        "start": 482.2,
        "end": 496.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1335.8,
        "end": 1328.5,
        "average": 1332.15
      },
      "rationale_metrics": {
        "rouge_l": 0.14705882352941177,
        "text_similarity": 0.34876516461372375,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the second school dropped out a day before the focus groups began, but it omits the requested timing anchors/timestamps and the note that this mention occurs immediately after the first dropout, so it is incomplete relative to the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker describes the gatekeeper's reason for not including Black students, when does she state that the gatekeeper didn't ask them to participate?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1907.394,
        "end": 1909.8
      },
      "pred_interval": {
        "start": 638.9,
        "end": 652.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1268.4940000000001,
        "end": 1257.0,
        "average": 1262.747
      },
      "rationale_metrics": {
        "rouge_l": 0.1492537313432836,
        "text_similarity": 0.3294629156589508,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction conveys the core fact that the gatekeeper didn't ask the Black students to participate, but it omits the key temporal details (the provided timestamps) and the explicit note that the statement immediately follows as a direct consequence, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says teachers avoided the topic because they didn't want to be seen as racist, when does she explain that a lack of interest convergence led to inaction?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.768,
        "end": 1967.955
      },
      "pred_interval": {
        "start": 745.6,
        "end": 832.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1214.1680000000001,
        "end": 1135.0549999999998,
        "average": 1174.6115
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.6743341684341431,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that the lack-of-interest-convergence explanation occurs after the comment about teachers fearing being seen as racist, but it omits the specific timestamps and event labels provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide titled 'The Normalcy of Racism', when does the speaker explain why whiteness is considered neutral?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1991.32,
        "end": 2002.951
      },
      "pred_interval": {
        "start": 1025.6,
        "end": 1034.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 965.72,
        "end": 968.5509999999999,
        "average": 967.1355
      },
      "rationale_metrics": {
        "rouge_l": 0.16393442622950818,
        "text_similarity": 0.42000389099121094,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect: it references Rashida's hijab reasoning rather than the speaker explaining whiteness as neutral, gives nonsensical/reversed timestamps (start after end), and does not match the reference time interval."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining Rashida's reasoning for not wearing a hijab, when does she mention Omar's comment about jokes hurting?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2082.096,
        "end": 2085.039
      },
      "pred_interval": {
        "start": 1351.4,
        "end": 1363.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 730.6959999999999,
        "end": 721.4390000000003,
        "average": 726.0675000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.44421491026878357,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys that Omar's comment comes after Rashida's point, but it gives incorrect timestamps (13:51.4\u201313:53.6 rather than the correct ~34:42.1\u201334:45.0) and omits the E1 timing, so the answer is factually inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker discusses students internalizing their experience of 'othering' and exclusion, when does she mention that teachers would mostly ignore comments or engage in biased language?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2148.8,
        "end": 2166.4
      },
      "pred_interval": {
        "start": 1245.8,
        "end": 1317.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 903.0000000000002,
        "end": 848.5,
        "average": 875.7500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.27118644067796605,
        "text_similarity": 0.5842580199241638,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mentions both topics but misrepresents their relationship (implying students' internalization leads to teachers' biased language), omits the timing/timestamps and the 'after' relation, and thus contradicts key details in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker states she is glad to have been part of the study, when does she say that the students did not feel heard or supported?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2205.5,
        "end": 2210.0
      },
      "pred_interval": {
        "start": 1655.2,
        "end": 1667.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 550.3,
        "end": 542.8,
        "average": 546.55
      },
      "rationale_metrics": {
        "rouge_l": 0.32432432432432434,
        "text_similarity": 0.41860446333885193,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the main claim that students felt unheard and unsupported after the speaker's remark, but it fails to provide the required timing relation/timestamps and introduces an unverified detail ('by teachers'), making it incomplete and slightly hallucinatory."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes her statement about acknowledging bias being scary but important, when does the slide transition to show the 'Schools can:' recommendations?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2333.0,
        "end": 2333.5
      },
      "pred_interval": {
        "start": 2125.9,
        "end": 2228.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 207.0999999999999,
        "end": 104.90000000000009,
        "average": 156.0
      },
      "rationale_metrics": {
        "rouge_l": 0.14457831325301204,
        "text_similarity": 0.3353429138660431,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer lists the slide's recommendations but fails to provide the requested timing (2333.0\u20132333.5s) or the moment the speaker finished, so it does not answer the 'when' question."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces implementing curriculum that explicitly includes race talk and counter narratives, when does she explain how teachers can learn to put this into practice?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2345.1,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 249.7,
        "end": 253.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2095.4,
        "end": 2115.7,
        "average": 2105.55
      },
      "rationale_metrics": {
        "rouge_l": 0.06779661016949153,
        "text_similarity": 0.1587679386138916,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer merely restates the question and provides no timing information or the anchor/target timestamps given in the correct answer, so it fails to answer 'when'."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker mentions that the racial equality framework from a couple of years ago is 'very general,' when does she suggest specific, practical training would be more helpful?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2453.2,
        "end": 2458.5
      },
      "pred_interval": {
        "start": 253.8,
        "end": 263.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2199.3999999999996,
        "end": 2194.9,
        "average": 2197.1499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.11267605633802817,
        "text_similarity": 0.08838917315006256,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the main idea that specific, practical training would be more helpful, but it omits the required anchor/target timestamps and precise transcript details provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker says 'Thank you', when does the title slide for the presentation appear on screen and is acknowledged?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2535.7,
        "end": 2536.7
      },
      "pred_interval": {
        "start": 2493.8,
        "end": 2567.4
      },
      "iou": 0.013586956521739147,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.899999999999636,
        "end": 30.700000000000273,
        "average": 36.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.2745098039215686,
        "text_similarity": 0.3831245005130768,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the coarse relation (the slide appears after 'Thank you') but omits all required temporal specifics (start/end times) and the acknowledgement detail ('Yes, we can see it'), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Outline' slide, when does Dr. Nighet Riaz state that racism is normalized in everyday interactions?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2593.7,
        "end": 2602.4
      },
      "pred_interval": {
        "start": 2594.0,
        "end": 2639.2
      },
      "iou": 0.18461538461538662,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3000000000001819,
        "end": 36.79999999999973,
        "average": 18.549999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.08,
        "text_similarity": 0.12398873269557953,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the event occurs during the 'Outline' slide but omits the precise temporal intervals (2581.9\u20132627.0 and 2593.7\u20132602.4) and the contained \u2018during\u2019 relation detail required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After Dr. Nighet Riaz states her name, when does she explain her roles at the University of the West of Scotland and Advance HE?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2550.6,
        "end": 2567.6
      },
      "pred_interval": {
        "start": 2642.4,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 91.80000000000018,
        "end": 132.4000000000001,
        "average": 112.10000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.11940298507462685,
        "text_similarity": 0.24199792742729187,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys that she explains her roles after stating her name, but it omits the key timing details and specific timestamps provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions disrupting the narrative, when does she start discussing global citizenship through the lens of the beneficent other?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2700.74,
        "end": 2707.407
      },
      "pred_interval": {
        "start": 273.0,
        "end": 284.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2427.74,
        "end": 2423.407,
        "average": 2425.5735
      },
      "rationale_metrics": {
        "rouge_l": 0.21818181818181817,
        "text_similarity": 0.3403083086013794,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and only restates that the discussion occurs 'after this' without providing the timestamps or segment boundaries given in the correct answer. It omits the key temporal details (start/end times and exact phrasing) required by the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing global citizenship and Scotland's curricular intention to imbricate it through the curriculum, when does she specifically mention it presenting a cross-curricular and whole school approach?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2790.853,
        "end": 2797.969
      },
      "pred_interval": {
        "start": 259.0,
        "end": 265.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2531.853,
        "end": 2532.969,
        "average": 2532.411
      },
      "rationale_metrics": {
        "rouge_l": 0.2580645161290323,
        "text_similarity": 0.3761249780654907,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that she describes it as a cross-curricular, whole-school approach, but it omits the key temporal details (the specific E1/E2 timestamps and when this occurs) required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Decolonising the Curriculum', when does the speaker begin talking about that specific term?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2851.15,
        "end": 2854.233
      },
      "pred_interval": {
        "start": 278.0,
        "end": 281.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2573.15,
        "end": 2573.233,
        "average": 2573.1915
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.5629271864891052,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the speaker begins speaking about the term immediately after the slide change, but it omits the precise timing details and span (2851.150s to 2854.233s) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that decolonisation moves out of a western framework, when does she start mentioning Sophia Kell?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2904.8,
        "end": 2905.4
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 3060.0
      },
      "iou": 0.002857142857142424,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.80000000000018,
        "end": 154.5999999999999,
        "average": 104.70000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.27118644067796616,
        "text_similarity": 0.41476455330848694,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction merely restates that Sophia Kell is mentioned and provides no timing information or the specified timestamps/relative timing (immediately after), thus omitting key factual details from the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker describes her journey from compulsory to higher education, when does she identify internalized racism as a large part of her imposter syndrome?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3077.4,
        "end": 3085.5
      },
      "pred_interval": {
        "start": 2578.6,
        "end": 2594.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 498.8000000000002,
        "end": 491.3000000000002,
        "average": 495.0500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.31881317496299744,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states that she identifies internalized racism as a large part of her imposter syndrome after describing her impostor feelings in an academic context; it omits the specific framing of the journey from compulsory to higher education (and the precise timestamps) but preserves the core relation and meaning."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker recounts a SAMI colleague advising her to channel frustration into something positive, when does she mention the planning of the project called Humari Pehchan?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3060.6,
        "end": 3064.5
      },
      "pred_interval": {
        "start": 2723.8,
        "end": 2745.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 336.7999999999997,
        "end": 319.5,
        "average": 328.14999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.2580645161290323,
        "text_similarity": 0.35952457785606384,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the project mention follows the colleague's advice and names 'Humari Pehchan', but it fails to provide the required precise timestamps/temporal offsets (3060.6\u20133064.5) and omits the exact timing detail requested."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker outlines the project's aim to bring families, schools, and community organizations together for storytelling, when does she state that the project is a call for action and a provocation?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3121.9,
        "end": 3125.0
      },
      "pred_interval": {
        "start": 2849.0,
        "end": 2864.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 272.9000000000001,
        "end": 260.4000000000001,
        "average": 266.6500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.46527817845344543,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly reports that she calls the project 'a call to action' and 'a provocation' and that this occurs after prior remarks, but it omits the specific timestamps and mischaracterizes the immediate preceding content (project aims vs. colleague advice), making it imprecise and partially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining the research methodology's approach to power imbalances, when does she introduce the project's aim for children and parents?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.427,
        "end": 3304.244
      },
      "pred_interval": {
        "start": 3284.9,
        "end": 3307.5
      },
      "iou": 0.6998672566371713,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5270000000000437,
        "end": 3.255999999999858,
        "average": 3.391499999999951
      },
      "rationale_metrics": {
        "rouge_l": 0.2807017543859649,
        "text_similarity": 0.2830961346626282,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the aim is introduced after the methodology, but it omits all required timing details (start/end timestamps and the explicit temporal relation), so it fails to answer the 'when' precisely."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker concludes the description of story development using heritage language, when does she start listing the project participants?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3305.525,
        "end": 3316.596
      },
      "pred_interval": {
        "start": 3308.0,
        "end": 3360.3
      },
      "iou": 0.1569329073482426,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.474999999999909,
        "end": 43.70400000000018,
        "average": 23.089500000000044
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.5176727175712585,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the qualitative relation (participants are listed after she finishes), but it omits the key factual details\u2014the exact start (3305.525s) and end (3316.596s) timestamps and the referenced finish time (3304.2s)\u2014so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the project was postponed to September, when does she state the duration of the project and its output?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3369.8,
        "end": 3378.21
      },
      "pred_interval": {
        "start": 3360.5,
        "end": 3374.0
      },
      "iou": 0.2371541501976177,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.300000000000182,
        "end": 4.210000000000036,
        "average": 6.755000000000109
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.663061261177063,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes that the duration and output are mentioned after the September postponement but fails to provide the key timestamps and explicit relation details specified in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker (Niget) finishes saying 'thank you', when does the other speaker (Katerina) start thanking her?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3413.516,
        "end": 3415.117
      },
      "pred_interval": {
        "start": 342.7,
        "end": 346.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3070.8160000000003,
        "end": 3068.617,
        "average": 3069.7165000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.13953488372093023,
        "text_similarity": 0.4573144018650055,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the key relation that Katerina begins thanking immediately after Niget, but it omits the crucial timing details (start at 3413.516s, end at 3415.117s) provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker in the bottom left talks about extreme prevent agendas, when does she talk about overt acts of racism in schools?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3579.7,
        "end": 3585.6
      },
      "pred_interval": {
        "start": 234.0,
        "end": 259.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3345.7,
        "end": 3326.6,
        "average": 3336.1499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.2898550724637681,
        "text_similarity": 0.41760337352752686,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the sequence (the bottom-left speaker first discusses prevent agendas and then mentions overt racism in schools) but fails to provide the requested timing information (the specific timestamps), omitting key factual detail."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker in the bottom right discusses the concept of 'racism without racists', when does she explain that the system itself is inherently racist?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3628.4,
        "end": 3675.8
      },
      "pred_interval": {
        "start": 356.0,
        "end": 373.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3272.4,
        "end": 3302.8,
        "average": 3287.6000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.19444444444444445,
        "text_similarity": 0.42611026763916016,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures that the explanation comes after the initial discussion, but it misstates the content\u2014claiming she discusses 'strategies to push back' rather than explaining the system itself is inherently racist\u2014and omits the timestamps, so it ignores key factual elements and adds unsupported detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the host thanks the speakers, when does she introduce a question for Jackie?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3771.2,
        "end": 3772.9
      },
      "pred_interval": {
        "start": 3759.2,
        "end": 3846.6
      },
      "iou": 0.01945080091533491,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.0,
        "end": 73.69999999999982,
        "average": 42.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.31578947368421045,
        "text_similarity": 0.4766460061073303,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect: it says the host thanks Jackie (not \u2018speakers\u2019), gives wildly wrong and inconsistent timestamps (38s to just after 3 minutes), and thus does not match the correct timing or facts."
      }
    },
    {
      "question_id": "002",
      "question": "After Jackie states that the US has been using CRT in anti-discrimination training, when does she mention that it hasn't been implemented in Scotland?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3861.8,
        "end": 3866.4
      },
      "pred_interval": {
        "start": 3847.1,
        "end": 3913.9
      },
      "iou": 0.06886227544910024,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.700000000000273,
        "end": 47.5,
        "average": 31.100000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.4774467349052429,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies the speaker pronoun and gives a completely incorrect time window (3:47\u20133:51 vs. ~64:22\u201364:26), so it fails to match the correct temporal answer despite noting the sequence."
      }
    },
    {
      "question_id": "003",
      "question": "After Jackie concludes her answer about diversity being everyone's issue, when does the host pick up on Greg's statement and question?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3918.884,
        "end": 3925.172
      },
      "pred_interval": {
        "start": 3914.2,
        "end": 3960.0
      },
      "iou": 0.13729257641921366,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.6840000000001965,
        "end": 34.827999999999975,
        "average": 19.756000000000085
      },
      "rationale_metrics": {
        "rouge_l": 0.2153846153846154,
        "text_similarity": 0.5073878765106201,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a much earlier and imprecise time window (3:51\u20133:55) and fails to match the correct timestamps (Jackie ~3897\u20133898s; host ~3919\u20133925s), so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman in the top-right finishes her sentence about normalising provocation, when does the woman in the top-left start speaking about a national campaign?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3954.0,
        "end": 4036.3
      },
      "pred_interval": {
        "start": 3985.6,
        "end": 4002.7
      },
      "iou": 0.20777642770352214,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.59999999999991,
        "end": 33.600000000000364,
        "average": 32.600000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.10344827586206898,
        "text_similarity": 0.1548401415348053,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only states a vague 'after' relation and is ambiguous, omitting the precise start time (3954.0s), end time, and quoted wording from the correct answer; it therefore lacks the key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman in the top-right finishes saying they have 10 minutes before wrapping up, when does the woman in the bottom-left start speaking?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4129.3,
        "end": 4130.2
      },
      "pred_interval": {
        "start": 1584.6,
        "end": 1672.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2544.7000000000003,
        "end": 2457.8999999999996,
        "average": 2501.3
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.42145344614982605,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the reference: it claims the bottom-left starts speaking after 'Lisa' finishes asking a question (self-referential and hallucinated), whereas the ground truth specifies the bottom-left starts after the top-right finishes at 4126.3s (E2 at 4129.3s); timestamps and actors are incorrect or missing."
      }
    },
    {
      "question_id": "002",
      "question": "After Lisa (woman in bottom-left) asks if anyone would like to put their hand up, when is the next time an unidentified woman speaks to assist her?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4214.2,
        "end": 4215.3
      },
      "pred_interval": {
        "start": 1673.0,
        "end": 1688.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2541.2,
        "end": 2526.9,
        "average": 2534.05
      },
      "rationale_metrics": {
        "rouge_l": 0.1935483870967742,
        "text_similarity": 0.5299752950668335,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives completely different timestamps and the wrong context ('You have the floor' vs asking people to raise hands), so it contradicts the correct answer; only a minimal match is that an unidentified woman speaks, hence very low credit."
      }
    },
    {
      "question_id": "003",
      "question": "After Lisa (woman in bottom-left) says 'You have the floor' to Ken, when does Ken (man in bottom-right) start asking his question?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4227.7,
        "end": 4304.7
      },
      "pred_interval": {
        "start": 1701.1,
        "end": 1727.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2526.6,
        "end": 2576.8999999999996,
        "average": 2551.75
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.43935734033584595,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and largely incorrect: it omits the precise timestamps (4220.4s, 4227.7s, 4304.7s), introduces an unfounded 'woman assists' event, and fails to state when Ken starts and finishes his question, only vaguely saying 'shortly after.'"
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker (top right) says she was hoping to be told who the next Education Minister was, when does the speaker (top left) say she was excited for an announcement about a new education minister?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4405.248,
        "end": 4411.436
      },
      "pred_interval": {
        "start": 237.4,
        "end": 249.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4167.848,
        "end": 4161.6359999999995,
        "average": 4164.742
      },
      "rationale_metrics": {
        "rouge_l": 0.0689655172413793,
        "text_similarity": 0.11299002170562744,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a different anchor utterance (about 'many voices missing') rather than the specified line about who the next Education Minister was, and provides no timing information; it therefore fails to match the correct temporal relation and content."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker (top right) says there are many voices missing within policy construction, when does the speaker (top left) start talking about Kokab Stewart?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4411.577,
        "end": 4421.13
      },
      "pred_interval": {
        "start": 269.6,
        "end": 284.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4141.977,
        "end": 4136.93,
        "average": 4139.4535
      },
      "rationale_metrics": {
        "rouge_l": 0.208955223880597,
        "text_similarity": 0.3466147184371948,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives completely different timestamps and temporal ordering (269.6s/284.2s) that contradict the reference (target starts at 4411.577s after anchor finishes at 4345.617s), so it fails to match the correct timing despite mentioning Kokab Stewart."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker (bottom left) says 'I am a lowly teacher more so than a policy expert', when does she start talking about mandated teacher training in anti-racism?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4463.676,
        "end": 4476.028
      },
      "pred_interval": {
        "start": 285.4,
        "end": 313.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4178.276000000001,
        "end": 4162.828,
        "average": 4170.552000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.05714285714285715,
        "text_similarity": 0.2467406988143921,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted start time (285.4s) is entirely inconsistent with the correct start time (4463.676s) and it omits the end time; the timestamps do not match, so the prediction is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that a policy won't translate into practice without teacher buy-in, when does she start talking about specific and mandated training for teachers?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4487.6,
        "end": 4494.5
      },
      "pred_interval": {
        "start": 4627.5,
        "end": 4638.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 139.89999999999964,
        "end": 143.5,
        "average": 141.69999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.0727209746837616,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the core relation that the speaker begins discussing mandated training after finishing the policy point, but it omits key factual details from the reference\u2014specifically the exact timestamps and the fact that the target starts immediately after the anchor\u2014so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After David finishes asking if it's appropriate to apply critical race theory to Irish racism in Scotland, when does Jackie respond?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4674.198,
        "end": 4676.359
      },
      "pred_interval": {
        "start": 4648.5,
        "end": 4662.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.69800000000032,
        "end": 14.359000000000378,
        "average": 20.02850000000035
      },
      "rationale_metrics": {
        "rouge_l": 0.09090909090909091,
        "text_similarity": 0.20948028564453125,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates Jackie responds after David, but the timestamp is significantly incorrect (predicts ~4648.5s vs the correct start at 4674.198s) and it omits the precise timing and content details given in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once Jackie finishes saying she will stop before making a political boo-boo, when does the speaker (top right) begin to discuss critical race theory's applicability beyond color racial issues?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4576.21,
        "end": 4586.726
      },
      "pred_interval": {
        "start": 4673.5,
        "end": 4695.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.28999999999996,
        "end": 108.27400000000034,
        "average": 102.78200000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.03571428571428572,
        "text_similarity": 0.19880974292755127,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly states the speaker begins after Jackie, but the timestamp is off by ~100s (4673.5s vs. the correct ~4576.2s) and omits the target end time; thus it is factually inaccurate and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the top-left female speaker finishes stating she is looking forward to inviting Nicola to present her work, when does she explain the reason for the invitation?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4663.9,
        "end": 4672.2
      },
      "pred_interval": {
        "start": 5.2,
        "end": 6.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4658.7,
        "end": 4665.9,
        "average": 4662.299999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1875,
        "text_similarity": 0.5181419849395752,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that she moves from the initial remark into explaining the reason, but it omits the precise timestamp bounds and the explicit statement that the target immediately follows the anchor."
      }
    },
    {
      "question_id": "002",
      "question": "After the top-left female speaker asks if there are any more questions, when does the top-right female speaker begin to answer a question from 'Sarah Khan'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4697.9,
        "end": 4703.6
      },
      "pred_interval": {
        "start": 48.7,
        "end": 50.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4649.2,
        "end": 4653.6,
        "average": 4651.4
      },
      "rationale_metrics": {
        "rouge_l": 0.29850746268656714,
        "text_similarity": 0.46616533398628235,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the top-right speaker begins answering Sarah Khan's question and implies it happens after a brief pause, but it omits the precise timing/relative-event detail (timestamps and explicit anchor\u2192target relation) given in the reference and adds an unnecessary inference about intent."
      }
    },
    {
      "question_id": "003",
      "question": "After the top-right female speaker mentions that UWS has included a clear statement in placement handbooks, when does she describe the challenge of students having the confidence to speak up about discrimination?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4738.4,
        "end": 4750.8
      },
      "pred_interval": {
        "start": 48.0,
        "end": 51.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4690.4,
        "end": 4699.2,
        "average": 4694.799999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.4094622731208801,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer captures the order (anchor then target) and the content (students needing confidence), but the timestamps are wildly incorrect (48.0s/51.6s vs. 4730.4\u20134750.8s), so it fails to match the key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "After the top-left woman finishes speaking about BAME students experiencing racism and leaving, when does the bottom-right woman begin speaking about the important message?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4841.8,
        "end": 4845.0
      },
      "pred_interval": {
        "start": 397.0,
        "end": 402.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4444.8,
        "end": 4443.0,
        "average": 4443.9
      },
      "rationale_metrics": {
        "rouge_l": 0.21276595744680848,
        "text_similarity": 0.5161561965942383,
        "llm_judge_score": 6,
        "llm_judge_justification": "The predicted answer correctly captures the temporal relation (that the bottom-right woman speaks after the top-left woman), but it omits the key factual details of the exact start and end timestamps provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the bottom-right woman states that including an explicit statement in handbooks can make a difference in a student's life, when does she mention that they only have four minutes left?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4880.8,
        "end": 4897.0
      },
      "pred_interval": {
        "start": 501.0,
        "end": 504.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4379.8,
        "end": 4393.0,
        "average": 4386.4
      },
      "rationale_metrics": {
        "rouge_l": 0.0392156862745098,
        "text_similarity": 0.4717160761356354,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction states she mentions it 'right before this point,' which directly contradicts the ground truth that she mentions it afterward (with specific timestamps); it is vague and factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the bottom-right woman finishes describing the story from the book 'Whistling Vivaldi', when does she mention that there are many other examples in that book?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4986.36,
        "end": 4989.384
      },
      "pred_interval": {
        "start": 496.0,
        "end": 500.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4490.36,
        "end": 4489.384,
        "average": 4489.871999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.07142857142857144,
        "text_similarity": 0.4212014377117157,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction notes that she mentions there are many examples, but it incorrectly states this occurs when she starts describing the story rather than immediately after she finishes; it also omits the precise timing details from the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker expresses her upset about the schools' reluctance to participate, when does she mention Negat having difficulties with recruitment?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 5023.8,
        "end": 5035.8
      },
      "pred_interval": {
        "start": 8.7,
        "end": 9.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5015.1,
        "end": 5026.400000000001,
        "average": 5020.75
      },
      "rationale_metrics": {
        "rouge_l": 0.19672131147540983,
        "text_similarity": 0.3328588604927063,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (that the Negat mention comes after the upset) but omits the required precise timestamps (5023.8\u20135035.8 and the prior event times), making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'there is no neutral position' for the first time following Jackie's quote, when does she say it again?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 5084.475,
        "end": 5085.8
      },
      "pred_interval": {
        "start": 34.6,
        "end": 35.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5049.875,
        "end": 5050.400000000001,
        "average": 5050.137500000001
      },
      "rationale_metrics": {
        "rouge_l": 0.17857142857142858,
        "text_similarity": 0.351732462644577,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and provides no timestamps (key factual elements) and even misattributes the quote to Martin Luther King rather than following Jackie's quote, so it fails to match the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes quoting the first Martin Luther King line, when does she start quoting the second one about accepting evil?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 5105.5,
        "end": 5114.1
      },
      "pred_interval": {
        "start": 40.5,
        "end": 42.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5065.0,
        "end": 5071.700000000001,
        "average": 5068.35
      },
      "rationale_metrics": {
        "rouge_l": 0.20289855072463772,
        "text_similarity": 0.39706724882125854,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction conveys the general relation (the second quote follows the first) but omits all required timestamps and even misgenders the speaker, failing to provide the key factual details in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says that the team is going to do a quick introduction, when does Ashley Satri introduce herself?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 84.156,
        "end": 102.754
      },
      "pred_interval": {
        "start": 28.7,
        "end": 36.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.456,
        "end": 65.85400000000001,
        "average": 60.65500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.5782163739204407,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates Ashley introduces herself after the speaker (relative order), but it fails to provide the requested timing (timestamps) and even misgenders the speaker, lacking the specific details given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Next, after Ashley Satri finishes introducing herself, when does Carly Thibodeau introduce herself?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 106.54,
        "end": 116.471
      },
      "pred_interval": {
        "start": 42.5,
        "end": 50.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.04,
        "end": 65.771,
        "average": 64.9055
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.410480260848999,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction omits the required timestamps and provides only a vague sequencing; it also uses the incorrect pronoun 'his' for Ashley, failing to match the factual details in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning the \"IDEA Supervision, Monitoring, and Support team\", when does she begin listing other teams within that department?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.641,
        "end": 188.788
      },
      "pred_interval": {
        "start": 238.6,
        "end": 245.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.959,
        "end": 56.91199999999998,
        "average": 55.43549999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320754,
        "text_similarity": 0.29848694801330566,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the listing begins immediately after the mention, but it omits the precise start/end timestamps and the minor timing adjustment provided in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining the purpose of an IEP, when does she highlight the phrase \"prepare them\" on the slide?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.569,
        "end": 304.375
      },
      "pred_interval": {
        "start": 269.3,
        "end": 270.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.269000000000005,
        "end": 33.47500000000002,
        "average": 24.872000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.24137931034482757,
        "text_similarity": 0.5412739515304565,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the highlight occurs during the speaker's explanation, but it omits the specific timing details (start and end timestamps) and the explicit anchor/target framing provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes saying \"So please feel free to reach out\", when does the slide transition to \"The IEP Decision Making Process\"?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 324.55,
        "end": 326.4
      },
      "pred_interval": {
        "start": 311.5,
        "end": 312.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.050000000000011,
        "end": 13.599999999999966,
        "average": 13.324999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981132,
        "text_similarity": 0.1834283471107483,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction claims the slide transitions immediately when the speaker says the phrase, which contradicts the ground truth timing (transition starts at 324.55s and fully displays by 326.4s, well after the speech ended at 254.65s)."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks what the IEP meeting is, when does she define it as a communication vehicle?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 348.721,
        "end": 354.0
      },
      "pred_interval": {
        "start": 358.9,
        "end": 426.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.178999999999974,
        "end": 72.69999999999999,
        "average": 41.43949999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.6496373414993286,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction states the speaker defines the IEP meeting, but gives completely incorrect timestamps (\u22483:59\u20134:26 / 239\u2013266s) versus the reference (\u22485:43\u20135:54 / 343\u2013354s); while it captures the existence of the definition, the key factual timing is wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker explains that the SAU has the ultimate responsibility for FAPE, when does she mention that they will discuss disagreement on the next slide?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 404.242,
        "end": 409.428
      },
      "pred_interval": {
        "start": 449.6,
        "end": 463.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.358000000000004,
        "end": 53.77199999999999,
        "average": 49.565
      },
      "rationale_metrics": {
        "rouge_l": 0.3492063492063492,
        "text_similarity": 0.6774328947067261,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly preserves the temporal relation (the mention occurs after the explanation) but gives incorrect and inconsistent timestamps (e.g., invalid '4:63' and times that do not match the referenced 400\u2013409s range), so it fails to accurately match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Recap' slide appears, when does the speaker state that the IEP meeting serves as a communication vehicle?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 529.94,
        "end": 533.504
      },
      "pred_interval": {
        "start": 473.9,
        "end": 483.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.04000000000008,
        "end": 50.30400000000003,
        "average": 53.172000000000054
      },
      "rationale_metrics": {
        "rouge_l": 0.39344262295081966,
        "text_similarity": 0.7558582425117493,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that the statement occurs after the 'Recap' slide but gives an invalid and incorrect timestamp (\"4:74\") and fails to reflect the precise timing/range (529.94\u2013533.504s), so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that the SAU has ultimate responsibility for FAPE, when does she mention that dispute resolution options are available?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 544.0,
        "end": 547.0
      },
      "pred_interval": {
        "start": 564.7,
        "end": 583.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.700000000000045,
        "end": 36.89999999999998,
        "average": 28.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.6287529468536377,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the mention of dispute resolution comes after the SAU responsibility remark, but it omits the specific timing (544.0s\u2013547.0s) requested in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Required Participants for IEP Meetings' slide, when does the speaker describe the qualifications of a representative from the SAU?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 584.0,
        "end": 600.0
      },
      "pred_interval": {
        "start": 610.0,
        "end": 628.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.0,
        "end": 28.200000000000045,
        "average": 27.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.10526315789473685,
        "text_similarity": 0.5249110460281372,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timing (\u2248610\u2013628s) does not match the reference (584\u2013600s) and does not overlap the correct interval, so it mislocates the described segment; it is only correct that both are during the slide display but the times are substantially off."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the special education director, IP coordinator, and assistant principal as part of the team, when does she state that the child must be invited?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 700.0,
        "end": 713.5
      },
      "pred_interval": {
        "start": 759.2,
        "end": 834.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.200000000000045,
        "end": 121.10000000000002,
        "average": 90.15000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.11538461538461539,
        "text_similarity": 0.2418249547481537,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not answer when the child must be invited and merely repeats part of the question; it omits the timing and quoted phrase ('whenever applicable, the child') provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the conditions for when a team member's attendance is not necessary, when does she begin discussing the conditions for an excusal?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.0,
        "end": 776.0
      },
      "pred_interval": {
        "start": 836.0,
        "end": 866.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.0,
        "end": 90.60000000000002,
        "average": 78.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1917808219178082,
        "text_similarity": 0.40637320280075073,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer merely restates the question and provides no timestamps or specific phrasing as in the correct answer, omitting the key details (769.0s start, 776.0s end and quoted phrase). It therefore fails to match the factual specifics required."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'What if the parent can't attend the IEP meeting?', when does she begin explaining the requirements for public agencies?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 909.0,
        "end": 924.0
      },
      "pred_interval": {
        "start": 874.5,
        "end": 926.3
      },
      "iou": 0.28957528957528983,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.5,
        "end": 2.2999999999999545,
        "average": 18.399999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.3742346465587616,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the explanation begins after the question) but omits the key factual details and exact timestamps provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses offering other methods for parents to attend IEP meetings, when does she explain that a meeting might be conducted without a parent?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 950.0,
        "end": 965.0
      },
      "pred_interval": {
        "start": 1008.0,
        "end": 1039.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.0,
        "end": 74.20000000000005,
        "average": 66.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.4403579831123352,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (10:08\u201310:39) do not match the reference segment (950\u2013965s \u2248 15:50\u201316:05) and therefore fail to identify the correct timing of the speaker's explanation."
      }
    },
    {
      "question_id": "001",
      "question": "After Ashley suggests recording attempts to contact parents in the written notice, when does Carly agree with this recommendation?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1076.3,
        "end": 1077.4
      },
      "pred_interval": {
        "start": 1235.4,
        "end": 1249.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 159.10000000000014,
        "end": 172.29999999999995,
        "average": 165.70000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.13636363636363635,
        "text_similarity": 0.48603954911231995,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (Carly agrees after Ashley's suggestion) but omits the key factual details of the precise timestamps and start/end times provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once Ashley finishes posing the question about holding an IEP meeting with only an 18-year-old student, when does Carly offer her initial thought on the matter?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1117.7,
        "end": 1122.7
      },
      "pred_interval": {
        "start": 1252.6,
        "end": 1260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 134.89999999999986,
        "end": 137.29999999999995,
        "average": 136.0999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.17543859649122806,
        "text_similarity": 0.6135560274124146,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relational timing (Carly speaks after Ashley finishes) but omits the key factual details\u2014the specific start and end timestamps (1117.7s\u20131122.7s) and the referenced finish time (1068.7s)\u2014requested in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'determining those present levels', when does she mention the 'Office Hours Archives \u2013 Data Collection Modules' link?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1233.32,
        "end": 1234.36
      },
      "pred_interval": {
        "start": 394.8,
        "end": 407.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 838.52,
        "end": 827.1599999999999,
        "average": 832.8399999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.32142857142857145,
        "text_similarity": 0.622305691242218,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states the temporal relation: the link is mentioned after the phrase 'determining those present levels,' matching the reference's relative ordering without adding or contradicting details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'determining modifications and/or accommodations', when does she mention the 'MTSS office'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1291.054,
        "end": 1294.278
      },
      "pred_interval": {
        "start": 564.8,
        "end": 584.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 726.2540000000001,
        "end": 710.078,
        "average": 718.166
      },
      "rationale_metrics": {
        "rouge_l": 0.163265306122449,
        "text_similarity": 0.5782026052474976,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer contradicts the reference: the MTSS office is mentioned after 'determining modifications and/or accommodations' per the timestamps, not right before; it also omits the provided timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'This is an IEP checklist that I think Carly developed', when does she describe what the checklist tells you to do?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1366.516,
        "end": 1375.503
      },
      "pred_interval": {
        "start": 683.2,
        "end": 732.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 683.316,
        "end": 642.703,
        "average": 663.0095
      },
      "rationale_metrics": {
        "rouge_l": 0.3888888888888889,
        "text_similarity": 0.6949529647827148,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the ground truth ordering and provides no matching timestamps: it implies the checklist description occurs before or at the quoted timestamp rather than after (1366.516s), so it is incorrect and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"number five\", when does the \"Amendments\" slide fully appear on screen?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1443.918,
        "end": 1444.018
      },
      "pred_interval": {
        "start": 253.0,
        "end": 268.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1190.918,
        "end": 1176.018,
        "average": 1183.4679999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.391304347826087,
        "text_similarity": 0.656550407409668,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction claims the slide appears immediately when the speaker finishes, but the reference gives precise times showing the slide fully appears about 4.57 seconds later (and stable by 4.67s), so the prediction contradicts the timing and omits the timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "After the \"IEP Meeting Timelines\" slide appears on screen, when does the speaker state that timelines can be a little bit confusing?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1517.804,
        "end": 1519.454
      },
      "pred_interval": {
        "start": 475.0,
        "end": 482.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1042.804,
        "end": 1037.454,
        "average": 1040.129
      },
      "rationale_metrics": {
        "rouge_l": 0.41791044776119407,
        "text_similarity": 0.7427481412887573,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the speaker speaks after the slide appears, but it inaccurately claims a ~7s pause; the actual gap is about 2s (speaker starts at 1517.804s vs slide ~1515.318\u20131515.748s) and it omits the precise timestamps."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker explains that an advanced written notice needs to go out seven days prior to the IEP meeting, when do they state that parents must sign to waive this 7-day advanced written notice?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1560.813,
        "end": 1570.038
      },
      "pred_interval": {
        "start": 621.0,
        "end": 628.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 939.8130000000001,
        "end": 942.038,
        "average": 940.9255
      },
      "rationale_metrics": {
        "rouge_l": 0.22950819672131148,
        "text_similarity": 0.625693142414093,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives an incorrect timestamp (\u2248621s) and misrepresents the sequence; the correct statement about parents signing occurs around 1560.8\u20131570.0s, so the predicted answer is factually wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker explains the 60-calendar-day and 45-school-day evaluation timelines, when does she explain that evaluation reports must be provided to the parent at least three days prior to the IEP meeting?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1633.362,
        "end": 1641.913
      },
      "pred_interval": {
        "start": 74.8,
        "end": 92.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1558.5620000000001,
        "end": 1549.613,
        "average": 1554.0875
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307691,
        "text_similarity": 0.20807237923145294,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction merely restates the content of the requirement and omits all required temporal details (anchor/target timestamps and the 'after' relation), failing to answer when the explanation occurs."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide changes to 'Requirement that Program be in Effect', when does the speaker clarify that the 30-day timeline applies to both IEP development and implementation?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1719.674,
        "end": 1731.971
      },
      "pred_interval": {
        "start": 265.9,
        "end": 281.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1453.774,
        "end": 1450.671,
        "average": 1452.2224999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.3444727063179016,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the clarification occurs after the slide change and captures the content, but it omits the crucial temporal details (anchor and target timestamps and the start/end times) specified in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the annual meeting date for the student as January 6th, 2022, when does she state when the next annual meeting must be held?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1785.48,
        "end": 1793.83
      },
      "pred_interval": {
        "start": 297.2,
        "end": 307.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1488.28,
        "end": 1486.1299999999999,
        "average": 1487.205
      },
      "rationale_metrics": {
        "rouge_l": 0.09836065573770493,
        "text_similarity": 0.3548077344894409,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that she later mentions the next meeting (capturing the general sequential relation) but omits the required timestamps, explicit 'once_finished' relation label, and the absolute\u2192relative judgment, so key factual details are missing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the annual meeting date of January 6, 2022, when does she mention that the duration of the IEP begins on January 16?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.116,
        "end": 1878.561
      },
      "pred_interval": {
        "start": 652.7,
        "end": 689.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1220.416,
        "end": 1189.261,
        "average": 1204.8384999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3934426229508197,
        "text_similarity": 0.7330145835876465,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the annual meeting date and that the IEP begins on Jan 16, but it gives a highly incorrect timestamp for the annual meeting (6:52.7s vs 1778.79s) and omits the correct IEP mention timestamps (1873.116s\u20131878.561s), so it's inaccurate and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Annual IEP & Duration of IEP' diagram, when does the speaker explain the 7-day notice period?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1901.094,
        "end": 1909.493
      },
      "pred_interval": {
        "start": 1430.0,
        "end": 1440.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 471.09400000000005,
        "end": 469.49299999999994,
        "average": 470.2935
      },
      "rationale_metrics": {
        "rouge_l": 0.2641509433962264,
        "text_similarity": 0.5198768377304077,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the explanation occurs during the diagram display, but the timestamp is far off (predicts ~14:30 / 870s versus the correct ~1901\u20131909s) and it omits the precise start/end times, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says that there are two sets of 364-day timelines, when does she next discuss parents waiving the 7-day notice?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1896.915,
        "end": 1901.942
      },
      "pred_interval": {
        "start": 1687.6,
        "end": 1697.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 209.31500000000005,
        "end": 204.3420000000001,
        "average": 206.82850000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.3380281690140845,
        "text_similarity": 0.6344878673553467,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that discussion of waiving the 7-day notice comes next, but it gives an invalid/incorrect timestamp ('16:87.6s') and omits the precise start (1901.942s) and end (1980.0s) times, so it is largely inaccurate and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if there are any other questions about timelines, when does she say they are 'good for now'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2192.362,
        "end": 2131.025
      },
      "pred_interval": {
        "start": 2145.9,
        "end": 2168.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.46199999999999,
        "end": 37.67499999999973,
        "average": 42.06849999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5950318574905396,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that she says 'good for now' after the question), but it omits the essential timing details/timestamps required by the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the procedural manual, when does she introduce the Maine Unified Special Education Regulations (MUSER)?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2219.043,
        "end": 2229.826
      },
      "pred_interval": {
        "start": 2318.4,
        "end": 2333.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 99.35699999999997,
        "end": 103.77399999999989,
        "average": 101.56549999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.12244897959183673,
        "text_similarity": 0.5083518624305725,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (2318.4\u20132333.6s) are about 99\u2013104 seconds later than the correct MUSER interval (2219.043\u20132229.826s), so despite matching the 'once finished' relation the timing is factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the 'Special Education Laws and Regulations', when does the '2024-25 Professional Development Schedule' slide appear?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2361.5,
        "end": 2421.5
      },
      "pred_interval": {
        "start": 2485.6,
        "end": 2509.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 124.09999999999991,
        "end": 87.80000000000018,
        "average": 105.95000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.7611820101737976,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') between the mention and the slide, but it omits the key timing details (the specific start/end timestamps and durations) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes encouraging viewers to reach out to them, when does the speaker say, 'I think that is it'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2490.0,
        "end": 2538.75
      },
      "gt_interval": {
        "start": 2514.0,
        "end": 2516.5
      },
      "pred_interval": {
        "start": 2498.5,
        "end": 2536.7
      },
      "iou": 0.06544502617801078,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.5,
        "end": 20.199999999999818,
        "average": 17.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.28125,
        "text_similarity": 0.3263999819755554,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the phrase occurs after the encouragement), but it omits the specific timing details (start/end timestamps) provided in the reference, making it incomplete for the question asked."
      }
    },
    {
      "question_id": "002",
      "question": "After the host introduces Stephen McKinney, when does Stephen McKinney start talking about the dramatic impact of the pandemic?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 101.9,
        "end": 107.8
      },
      "pred_interval": {
        "start": 83.7,
        "end": 84.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.200000000000003,
        "end": 23.39999999999999,
        "average": 20.799999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.09999999999999999,
        "text_similarity": 0.25495922565460205,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not identify when McKinney begins discussing the pandemic and instead references unrelated content (the Carers Scotland Act and pre-existing social problems), contradicting and omitting the precise timestamps and quoted pandemic line given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states the Carers Scotland Act 2016 was published in 2018 by the Scottish Government, when does he state that the Act applies to adult and young carers?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.5,
        "end": 171.0
      },
      "pred_interval": {
        "start": 245.8,
        "end": 263.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.30000000000001,
        "end": 92.89999999999998,
        "average": 85.1
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666669,
        "text_similarity": 0.09803464263677597,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes that the speaker states the Act applies to adult and young carers and that this follows the earlier remark, but it omits the required timing details (specific start/end timestamps and immediate adjacency) from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker defines a young carer as a person under 18 with caring responsibilities, when does he provide an additional condition for defining a young carer?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 217.0,
        "end": 222.5
      },
      "pred_interval": {
        "start": 271.1,
        "end": 275.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.10000000000002,
        "end": 53.30000000000001,
        "average": 53.70000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2077922077922078,
        "text_similarity": 0.37093374133110046,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies an additional condition but omits the required timestamps and asserts a specific phrasing ('up to age sixteen') not provided in the reference, making it incomplete and potentially incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker cites the 2011 census data about the age distribution of young carers in the UK, when does he mention that Scottish Government guidance acknowledges very young carers?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 236.0,
        "end": 244.5
      },
      "pred_interval": {
        "start": 276.9,
        "end": 280.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.89999999999998,
        "end": 36.0,
        "average": 38.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2077922077922078,
        "text_similarity": 0.18114319443702698,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction describes the content (ages five or six) rather than answering when the mention occurs; it omits the required timing/temporal relation (target starts at 236.0s immediately after the anchor) and introduces an unverified age detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker says he just wanted to introduce the topic, when does he refer to 'invisible children'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 424.5,
        "end": 426.1
      },
      "pred_interval": {
        "start": 25.9,
        "end": 31.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 398.6,
        "end": 394.70000000000005,
        "average": 396.65000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.15,
        "text_similarity": 0.03507743403315544,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the mention occurs after the introduction, but it is vague and omits the precise timestamps and exact temporal relation given in the reference (anchor 415.7\u2013418.5s; target 424.5\u2013426.1s), and 'right after' may be misleading."
      }
    },
    {
      "question_id": "002",
      "question": "After John says 'Many thanks, Stephen', when is the next time he speaks to introduce the next presentation?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 461.0,
        "end": 465.0
      },
      "pred_interval": {
        "start": 106.7,
        "end": 110.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 354.3,
        "end": 354.9,
        "average": 354.6
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666669,
        "text_similarity": 0.4552260637283325,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that John next speaks to introduce Katie's presentation, but it omits the specific timing information given in the reference and introduces an unsupported detail about \"studies conducted in Scotland.\""
      }
    },
    {
      "question_id": "003",
      "question": "While Katie's first slide 'Widening the gap? The challenges for equitable music education in Scotland' is displayed, when does she mention Leo Moscardini?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 490.7,
        "end": 504.0
      },
      "pred_interval": {
        "start": 285.3,
        "end": 290.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 205.39999999999998,
        "end": 213.7,
        "average": 209.54999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.07017543859649124,
        "text_similarity": 0.16951659321784973,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that Katie mentions Leo Moscardini during her presentation on equitable music education, but it omits the required temporal information (the specific timestamp range when the mention occurs) and thus fails to answer the question."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes listing what the presentation will cover, when does she say 'Okay'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 526.04,
        "end": 527.9
      },
      "pred_interval": {
        "start": 529.3,
        "end": 530.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.259999999999991,
        "end": 2.5,
        "average": 2.8799999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.20512820512820512,
        "text_similarity": 0.37350916862487793,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys that 'Okay' occurs immediately after the listing, but it omits the precise timestamps and interval (start 526.04s\u2013527.9s) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing Case Study B, when does she begin describing Case Study C?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 561.5,
        "end": 567.5
      },
      "pred_interval": {
        "start": 568.7,
        "end": 570.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.2000000000000455,
        "end": 3.3999999999999773,
        "average": 5.300000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307693,
        "text_similarity": 0.6051572561264038,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a start time of ~569s, which contradicts the correct start at 561.5s (and even lies after the correct end at 567.5s), so the timing is incorrect despite addressing the next case study."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the number of pupils taking Advanced Higher music in Case Study A, when does she mention the number of pupils taking qualifications in Case Study B?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 627.5,
        "end": 634.2
      },
      "pred_interval": {
        "start": 638.4,
        "end": 646.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.899999999999977,
        "end": 12.099999999999909,
        "average": 11.499999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.32352941176470584,
        "text_similarity": 0.5013981461524963,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes Case Study B is discussed next but gives an incorrect start time (~638s vs the correct 627.5s) and omits the end time (634.2s), so the timing is substantially wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that inequality in music education was beginning in primary schools and persisting, when does she explain that the focus on performance privileges middle-class pupils?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 728.2,
        "end": 740.8
      },
      "pred_interval": {
        "start": 285.6,
        "end": 310.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 442.6,
        "end": 430.4,
        "average": 436.5
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.39778411388397217,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer does not address the question about when the speaker explains the performance focus; it merely restates the inequality claim and omits the required timing/relative relation and timestamps, so it fails to match the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'What this means?' is displayed, when does the speaker state that working-class, poorer households, disabled children, and those with additional support needs are effectively excluded?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 763.3,
        "end": 771.2
      },
      "pred_interval": {
        "start": 775.0,
        "end": 803.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.700000000000045,
        "end": 32.0,
        "average": 21.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.17142857142857143,
        "text_similarity": 0.5200721025466919,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that the speaker's remark about exclusion occurs while the 'What this means?' slide is displayed, but it omits the specific timestamps (742.0\u2013789.2 for the slide and 763.3\u2013771.2 for the remark) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once Katie finishes saying 'Thanks very much', when does John begin thanking her?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 882.288,
        "end": 883.549
      },
      "pred_interval": {
        "start": 435.9,
        "end": 447.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 446.38800000000003,
        "end": 435.94899999999996,
        "average": 441.1685
      },
      "rationale_metrics": {
        "rouge_l": 0.18604651162790697,
        "text_similarity": 0.6023503541946411,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly captures the temporal relation (John speaks after Katie finishes) but gives an incorrect timestamp (\u2248436s vs 881.508s) and omits John's actual start time (~882.288s), thus containing factual errors and a hallucinated time."
      }
    },
    {
      "question_id": "002",
      "question": "After the first slide of Lindsay's presentation appears on screen, when does Lindsay begin to introduce her project?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 921.97,
        "end": 989.732
      },
      "pred_interval": {
        "start": 876.2,
        "end": 914.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.76999999999998,
        "end": 75.13199999999995,
        "average": 60.450999999999965
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.5323288440704346,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction's start time (876\u2013881s) contradicts the reference start at 921.97s and ties the introduction to a different slide; it also omits the end time and misaligns the relation, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "During the 'Background to study' slide, when does Lindsay state that poverty is detrimental to academic attainment?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 964.634,
        "end": 969.402
      },
      "pred_interval": {
        "start": 870.2,
        "end": 893.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 94.43399999999997,
        "end": 75.80200000000002,
        "average": 85.118
      },
      "rationale_metrics": {
        "rouge_l": 0.12307692307692307,
        "text_similarity": 0.3979586064815521,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the remark occurs during the slide segment but is vague and inaccurate about timing ('first few seconds' vs ~12.8s in) and adds an unsupported detail about a preceding mention of policy drive, so it is partially but not substantially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining the 'Study design' slide, when does she start discussing the 'Research Participants and School Profiles'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1085.64,
        "end": 1103.0
      },
      "pred_interval": {
        "start": 65.8,
        "end": 74.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1019.8400000000001,
        "end": 1028.8,
        "average": 1024.3200000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.33898305084745767,
        "text_similarity": 0.6002705097198486,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the relative relation ('after') but omits the key factual timestamps and duration provided in the correct answer, so it is incomplete. "
      }
    },
    {
      "question_id": "001",
      "question": "After the female presenter finishes speaking about the previous research, when does she transition to the 'Reflective questions' slide?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1249.4,
        "end": 1250.5
      },
      "pred_interval": {
        "start": 295.7,
        "end": 316.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 953.7,
        "end": 933.7,
        "average": 943.7
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.5489492416381836,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the slide appears after she finishes speaking) but omits the key factual details and timestamps (1242.8s, 1249.4s, 1250.5s) given in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the female presenter finishes talking about the reflective questions, when does the male presenter start speaking?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1272.5,
        "end": 1273.0
      },
      "pred_interval": {
        "start": 343.8,
        "end": 361.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 928.7,
        "end": 912.0,
        "average": 920.35
      },
      "rationale_metrics": {
        "rouge_l": 0.1739130434782609,
        "text_similarity": 0.45742252469062805,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the causal/order relation (male speaks after the female), but it omits the precise timing provided in the correct answer (1271.0s and 1272.5s/1273.0s) and is vague about 'transition' versus the female finishing."
      }
    },
    {
      "question_id": "003",
      "question": "While the first male presenter is speaking about digital exclusion, when does he mention the conditions that education systems need to meet to be successful?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1343.9,
        "end": 1346.5
      },
      "pred_interval": {
        "start": 452.6,
        "end": 473.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 891.3000000000001,
        "end": 872.8,
        "average": 882.05
      },
      "rationale_metrics": {
        "rouge_l": 0.1724137931034483,
        "text_similarity": 0.3186645805835724,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly states he mentions conditions during the discussion but gives completely wrong timestamps (~452.6\u2013473.7s vs actual 1343.9\u20131346.5s) and omits the presenter's speech start, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker says 'There you go', when does the screen transition to the presentation slide with the second speaker in a small window?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1426.2,
        "end": 1426.5
      },
      "pred_interval": {
        "start": 161.8,
        "end": 1620.0
      },
      "iou": 0.00020573309559728057,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1264.4,
        "end": 193.5,
        "average": 728.95
      },
      "rationale_metrics": {
        "rouge_l": 0.03508771929824561,
        "text_similarity": 0.1838424801826477,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not address the screen-transition timing or provide the specified timestamps; it gives a different content event and an incorrect time (~15:51 vs. 1426s), so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker states that online lessons could be quite useful, when does he discuss gaining insights into pupils' lives and building better relationships with parents?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1637.5,
        "end": 1645.0
      },
      "pred_interval": {
        "start": 24.8,
        "end": 57.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1612.7,
        "end": 1587.1,
        "average": 1599.9
      },
      "rationale_metrics": {
        "rouge_l": 0.1791044776119403,
        "text_similarity": 0.3259052634239197,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not answer when the discussion of pupils' lives and parent relationships occurs, instead introducing incorrect content about providing technology to young people and omitting the timestamps and 'after' relation from the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker finishes asking Kevin to pick up some stuff, when does Kevin begin to talk about the work being done to provide technology to young people?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1660.0,
        "end": 1676.0
      },
      "pred_interval": {
        "start": 136.3,
        "end": 143.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1523.7,
        "end": 1532.6,
        "average": 1528.15
      },
      "rationale_metrics": {
        "rouge_l": 0.47761194029850756,
        "text_similarity": 0.57354736328125,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the general temporal relation that Kevin speaks after the first speaker finishes, but it omits the crucial factual details present in the correct answer (the specific start/end timestamps and the 'once_finished' relation mapping)."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning digital inclusion, when does she begin discussing finances and support?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1787.8,
        "end": 1790.0
      },
      "pred_interval": {
        "start": 97.6,
        "end": 128.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1690.2,
        "end": 1661.6,
        "average": 1675.9
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.45359838008880615,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives completely different and incorrect timecodes (\u224897.6\u2013128.4s) that do not match the reference timings (starts at ~1787.8s and completes by 1790.0s), so it fails to answer when the discussion begins."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces the 'Key findings' section, when does she mention parents on low incomes being more concerned about money?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1815.4,
        "end": 1829.0
      },
      "pred_interval": {
        "start": 135.8,
        "end": 150.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1679.6000000000001,
        "end": 1678.4,
        "average": 1679.0
      },
      "rationale_metrics": {
        "rouge_l": 0.36111111111111105,
        "text_similarity": 0.3886675238609314,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time window (\u2248135.8\u2013150.6s) is completely inconsistent with the reference (starts at 1815.4s\u20131829.0s), so the answer is factually incorrect regarding timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that 'progress clearly being made' regarding digital inclusion, when does she mention that children on free meals are more likely to share devices?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1952.9,
        "end": 1958.5
      },
      "pred_interval": {
        "start": 13.8,
        "end": 16.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1939.1000000000001,
        "end": 1941.6,
        "average": 1940.35
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.394643098115921,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the children-sharing-devices remark occurs after the 'progress being made' comment) but omits the specific timestamps provided in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces 'Free meal replacements', when does she discuss the importance of choice and dignity in food provision?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2003.8,
        "end": 2010.5
      },
      "pred_interval": {
        "start": 74.8,
        "end": 75.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1929.0,
        "end": 1935.1,
        "average": 1932.05
      },
      "rationale_metrics": {
        "rouge_l": 0.19607843137254902,
        "text_similarity": 0.5618048906326294,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives a completely different timestamp (\u224874.8s) and implies the discussion is immediate, whereas the reference places the discussion much later (after the 'Free meal replacements' mention at ~2003.8s); the timing and relation contradict the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the female speaker mentions \"cash first approaches\", when does the male speaker begin speaking?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2167.9,
        "end": 2172.6
      },
      "pred_interval": {
        "start": 235.4,
        "end": 248.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1932.5,
        "end": 1923.8999999999999,
        "average": 1928.1999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454545,
        "text_similarity": 0.31723305583000183,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction asserts the male starts immediately after the mention, which contradicts the transcript-based timestamps and the correct answer that he begins after the previous presenter finishes; it omits the precise timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker asks Angela Japp's question about creative approaches, when does Katie start her answer by mentioning 'the digital'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.835,
        "end": 2259.242
      },
      "pred_interval": {
        "start": 265.5,
        "end": 282.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1970.335,
        "end": 1976.4420000000002,
        "average": 1973.3885
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.5666557550430298,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted start time (~265.5s) is far from the referenced start (2235.835s) when Katie says 'And the second point about the digital', so the prediction is incorrect and inconsistent with the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once Katie finishes discussing culturally valued aspects in schools, when does the male speaker thank her?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2297.355,
        "end": 2298.476
      },
      "pred_interval": {
        "start": 288.3,
        "end": 293.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2009.055,
        "end": 2005.276,
        "average": 2007.1655
      },
      "rationale_metrics": {
        "rouge_l": 0.15151515151515152,
        "text_similarity": 0.5468232035636902,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that the male speaker thanks Katie immediately after she finishes and gives the corresponding (relative) timestamp of just under 288.3s, matching the converted time from the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After John asks whether initiatives like 'Big Noise' would impact music provision generally if targeted at deprived areas, when does Alistair start speaking?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2390.458,
        "end": 2391.922
      },
      "pred_interval": {
        "start": 2458.7,
        "end": 2469.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 68.24199999999973,
        "end": 77.37800000000016,
        "average": 72.80999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.5761582851409912,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and asserts Alistair speaks 'after John asks', whereas the reference gives precise timing and indicates Alistair speaks following a short Katie\u2013John exchange (with specific timestamps); the predicted answer omits timestamps and misstates the temporal relation. "
      }
    },
    {
      "question_id": "002",
      "question": "After Alistair says that some programs are 'hugely expensive', when does he advise treating them with caution?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2406.7,
        "end": 2414.2
      },
      "pred_interval": {
        "start": 2469.3,
        "end": 2471.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.600000000000364,
        "end": 57.5,
        "average": 60.05000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.5820820331573486,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly claims the caution is advised immediately upon mentioning 'hugely expensive', while the reference shows he warns later (about 2406.7\u20132414.2s) and completes the point regarding multinational companies; the timing and context are misaligned."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker states that recovery plans were produced by the Scottish and English governments, when does he explain what those recovery plans are about?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2499.117,
        "end": 2513.724
      },
      "pred_interval": {
        "start": 625.0,
        "end": 739.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1874.1170000000002,
        "end": 1774.7240000000002,
        "average": 1824.4205000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.3695332109928131,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives incorrect timestamps and adds a hallucinatory detail (digital literacy) not in the reference; it only partially matches by mentioning parents, so it largely fails to align with the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After Sarah mentions that digital literacy for parents wasn't something they specifically looked at, when does she explain the challenges parents faced with remote learning?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2558.855,
        "end": 2578.0
      },
      "pred_interval": {
        "start": 741.0,
        "end": 802.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1817.855,
        "end": 1776.0,
        "average": 1796.9275
      },
      "rationale_metrics": {
        "rouge_l": 0.14705882352941174,
        "text_similarity": 0.16471320390701294,
        "llm_judge_score": 1,
        "llm_judge_justification": "While the prediction notes Sarah discusses parental challenges after mentioning digital literacy, the provided timestamps are drastically incorrect (\u22487:41\u20138:02 vs. the correct \u224842:38.9\u201342:58.0), so it fails to match the reference timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the male host mentions a question from Katharine Reid, when does Sarah laugh?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.86,
        "end": 2741.43
      },
      "pred_interval": {
        "start": 274.9,
        "end": 285.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2465.96,
        "end": 2456.1299999999997,
        "average": 2461.045
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.572515606880188,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the temporal relation (Sarah laughs after the host mentions Katharine Reid's question) but omits the precise timing details provided in the correct answer (the specific timestamps)."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes saying 'Yes', when does she begin to explain how more money for families leads to better outcomes for children?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.15,
        "end": 2772.16
      },
      "pred_interval": {
        "start": 286.5,
        "end": 295.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2457.65,
        "end": 2476.56,
        "average": 2467.105
      },
      "rationale_metrics": {
        "rouge_l": 0.2413793103448276,
        "text_similarity": 0.45022618770599365,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives start/end times that are radically different from the ground-truth timestamps (286.5\u2013295.6s vs. 2744.15\u20132772.16s), so despite matching the 'once_finished' relation it is factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the male host mentions people working in rural areas, when does he ask Lindsay for her thoughts?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2828.315,
        "end": 2829.617
      },
      "pred_interval": {
        "start": 296.6,
        "end": 300.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2531.715,
        "end": 2529.317,
        "average": 2530.516
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.49554407596588135,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation right (he asks Lindsay once he mentions rural workers) but gives a completely incorrect timestamp (~296.6s vs ~2828s in the ground truth) and omits the precise end time, making it factually inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman states that all schools must be very mindful to poverty-proof themselves, when does she mention that teaching pedagogies and strategies should be transparent and inclusive?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2858.72,
        "end": 2868.63
      },
      "pred_interval": {
        "start": 2854.6,
        "end": 2913.7
      },
      "iou": 0.1676818950930681,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.119999999999891,
        "end": 45.06999999999971,
        "average": 24.5949999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.07017543859649124,
        "text_similarity": 0.02000991627573967,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly paraphrases the content but fails to provide the requested timing/temporal information (anchor and target timestamps and their immediate succession), omitting key factual details required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman suggests giving probationers and undergraduates more practical tools before they go into probation, when does she say that a lot can be learned from autism education?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2896.13,
        "end": 2901.89
      },
      "pred_interval": {
        "start": 2915.5,
        "end": 2932.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.36999999999989,
        "end": 30.91000000000031,
        "average": 25.1400000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.058823529411764705,
        "text_similarity": -0.009206229820847511,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction paraphrases the content but fails to provide the requested timing details (specific timestamps and precise relative timing); it only vaguely implies 'after' rather than giving the anchor/target times as in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man reminds people about the PACT project launch, when does he describe it as a professional learning project funded by the Scottish Government?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2951.199,
        "end": 2960.769
      },
      "pred_interval": {
        "start": 2934.7,
        "end": 2962.5
      },
      "iou": 0.34424460431653403,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.49900000000025,
        "end": 1.731000000000222,
        "average": 9.115000000000236
      },
      "rationale_metrics": {
        "rouge_l": 0.04166666666666667,
        "text_similarity": 0.01689986325800419,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that the PACT was described as a professional learning project funded by the Scottish Government, but it fails to answer the question's required timing (the specific timestamps) and misidentifies or ambiguously names the speaker, omitting key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the first speaker puts in an advert for John McKendrick, when does he praise the work of the Caledonian Club?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3049.4,
        "end": 3053.3
      },
      "pred_interval": {
        "start": 245.7,
        "end": 263.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2803.7000000000003,
        "end": 2789.4,
        "average": 2796.55
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.6752785444259644,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the praise follows the advert, but the reported timestamps are substantially incorrect and do not match the reference (predicted ~165.7\u2013174.9s vs correct 3049.4\u20133053.3s), so the answer is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker finishes asking Mary a question, when does the second speaker (John) appear and begin to speak?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3079.0,
        "end": 3082.0
      },
      "pred_interval": {
        "start": 266.0,
        "end": 272.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2813.0,
        "end": 2810.0,
        "average": 2811.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2962962962962963,
        "text_similarity": 0.47476768493652344,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a single relative timestamp (2:54.9) that does not match the correct timing (John begins at 3079.0s) and omits the end time and relation; thus it is essentially incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After Mary finishes discussing how to best support students, when does John appear on screen and comment on her questions?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3152.3,
        "end": 3159.5
      },
      "pred_interval": {
        "start": 272.1,
        "end": 281.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2880.2000000000003,
        "end": 2878.0,
        "average": 2879.1000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.13157894736842105,
        "text_similarity": 0.5137008428573608,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly preserves the order (John speaks after Mary) but the timestamps are fundamentally inconsistent with the reference (uses 2:54.9 vs correct 3146.4/3152.3s), omits the end time of John's comment, and therefore is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the first speaker asks if something happened and how it is going, when does he state that he will put the question to the Glasgow team first?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3213.51,
        "end": 3214.09
      },
      "pred_interval": {
        "start": 3268.7,
        "end": 3295.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.1899999999996,
        "end": 81.30999999999995,
        "average": 68.24999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.10526315789473685,
        "text_similarity": 0.16617988049983978,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction paraphrases the content but omits the key factual details (exact timestamps and the 'once_finished' relation) required by the correct answer, so it fails to answer the \"when\" precisely."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker with the beard begins speaking, when does he mention the rollout of 50,000 plus iPads?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3232.12,
        "end": 3237.0
      },
      "pred_interval": {
        "start": 3355.9,
        "end": 3377.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 123.7800000000002,
        "end": 140.30000000000018,
        "average": 132.0400000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.03636363636363636,
        "text_similarity": 0.008463893085718155,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly captures the topic (mentioning iPads in the context of education) but fails to provide the required temporal information or timestamps and does not state the 'after' relation, so it is largely incomplete for the question asked."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman states that getting information out to all families about support is available, when does she finish her statement that this is really critical?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3390.0,
        "end": 3482.1099999999997
      },
      "gt_interval": {
        "start": 3396.5,
        "end": 3398.0
      },
      "pred_interval": {
        "start": 3426.9,
        "end": 3478.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.40000000000009,
        "end": 80.5,
        "average": 55.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.21874999999999997,
        "text_similarity": 0.3694744110107422,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and circular, merely restating that she finishes after saying it's critical and provides no timestamps or timing details as in the reference, so it fails to answer the question."
      }
    },
    {
      "question_id": "002",
      "question": "After the man states that the presenters were exemplary in their timekeeping, when does he continue to say he will be exemplary in his timekeeping?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3390.0,
        "end": 3482.1099999999997
      },
      "gt_interval": {
        "start": 3427.0,
        "end": 3431.0
      },
      "pred_interval": {
        "start": 3478.5,
        "end": 3482.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.5,
        "end": 51.09999999999991,
        "average": 51.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.06896551724137931,
        "text_similarity": 0.43410366773605347,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the intent that he will be exemplary in timekeeping but fails to provide the exact timestamps and wrongly frames the timing as 'once his current session ends,' which is not supported by the ground truth; key factual details are omitted."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks to virtually clap, when does he physically clap his hands?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3390.0,
        "end": 3482.1099999999997
      },
      "gt_interval": {
        "start": 3476.0,
        "end": 3478.0
      },
      "pred_interval": {
        "start": 3482.1,
        "end": 3482.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.099999999999909,
        "end": 4.099999999999909,
        "average": 5.099999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.1754385964912281,
        "text_similarity": 0.4046632647514343,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only generically says the clap follows his speech but omits the precise timestamps and incorrectly implies it was immediate; the ground truth specifies the clap occurred about 32 seconds later (3476\u20133478s), so the timing claim is misleading and key details are missing."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the 'Strategic Priority 3' slide is displayed, when does the speaker mention the Alliance's 2021 to 2025 strategy?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.0,
        "end": 27.7
      },
      "pred_interval": {
        "start": 74.6,
        "end": 82.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.599999999999994,
        "end": 54.599999999999994,
        "average": 53.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.3977468013763428,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the mention occurs while the 'Strategic Priority 3' slide is displayed, but it omits the specific timestamps (22.0\u201327.7s within the slide display 0.0\u2013115.5s) and is vaguer than the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the NFDHR logo and name are fully displayed, when does the text indicating its establishment appear?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 165.0,
        "end": 168.0
      },
      "pred_interval": {
        "start": 204.8,
        "end": 205.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.80000000000001,
        "end": 37.599999999999994,
        "average": 38.7
      },
      "rationale_metrics": {
        "rouge_l": 0.20833333333333334,
        "text_similarity": 0.6813967823982239,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the establishment text appears after the logo/name are fully displayed, but it omits the precise timestamps (logo/name 159.0\u2013162.0s; establishment 165.0\u2013168.0s) given in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the statistics for Education, Food Security, and Health & Nutrition programs are fully displayed, when do the statistics for WASH, Peace Building, Protection & Gender, and Shelter & CCCM programs appear?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 211.0
      },
      "pred_interval": {
        "start": 275.3,
        "end": 282.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 68.30000000000001,
        "end": 71.39999999999998,
        "average": 69.85
      },
      "rationale_metrics": {
        "rouge_l": 0.12307692307692308,
        "text_similarity": 0.34638267755508423,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the sequential/once-finished relation, but it omits the key timing details (E1: 196.0s\u2192200.0s and E2: 207.0s\u2192211.0s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the main descriptive text for the 'Education Overview 2022' slide, when do the icons and numerical statistics appear?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 237.0,
        "end": 243.0
      },
      "pred_interval": {
        "start": 284.0,
        "end": 284.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.0,
        "end": 41.89999999999998,
        "average": 44.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.17241379310344826,
        "text_similarity": 0.5998896360397339,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the core relation that the icons/numbers appear during the main text, but it omits the key timing details (start/fully displayed timestamps) present in the reference, so it's incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that the Syrian crisis created a fragmented society unable to benefit from its expertise, when does she mention that they started working together from 2018?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 351.3,
        "end": 364.9
      },
      "pred_interval": {
        "start": 354.7,
        "end": 362.9
      },
      "iou": 0.6029411764705889,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.3999999999999773,
        "end": 2.0,
        "average": 2.6999999999999886
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.3082311153411865,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer merely restates the question and provides no timestamps or explicit timing information; it fails to answer when the speaker mentions they started working together (2018) as given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that 2 million Syrian children are out of education and tens of thousands are in North Syrian camps, when does she begin to list the specific numbers of camps and schools?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 418.5,
        "end": 427.8
      },
      "pred_interval": {
        "start": 363.4,
        "end": 409.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.10000000000002,
        "end": 18.69999999999999,
        "average": 36.900000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.3384615384615384,
        "text_similarity": 0.4958515763282776,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer merely restates that she begins listing the numbers but gives no timestamps; it omits the key factual details (418.0s, 418.5s\u2013427.8s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that IRC has invested a lot in research and social and emotional learning, when does she explain how these learnings can be used for out-of-school and in-school children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.0,
        "end": 568.9
      },
      "pred_interval": {
        "start": 195.8,
        "end": 236.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 355.2,
        "end": 332.5,
        "average": 343.85
      },
      "rationale_metrics": {
        "rouge_l": 0.19753086419753088,
        "text_similarity": 0.36020728945732117,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the correct sequence (mention followed by an explanation about use for out-of-school and in-school children) but omits the key required timestamps and the precise start/end timing details present in the correct answer, making it incomplete for the 'when' question."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces the PRIEST project as one of IRC's flagship programs, when does she state the countries where it is implemented?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.9,
        "end": 627.597
      },
      "pred_interval": {
        "start": 278.8,
        "end": 311.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 344.09999999999997,
        "end": 315.99699999999996,
        "average": 330.0485
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322035,
        "text_similarity": 0.44161662459373474,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives the countries named but fails to provide the required timing details and temporal relation (timestamps and that the event immediately follows the anchor), omitting key factual elements from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces Ahlam Ahmed as the Education Programme Manager, when does Ahlam Ahmed greet the speaker?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 777.178,
        "end": 778.34
      },
      "pred_interval": {
        "start": 756.8,
        "end": 781.8
      },
      "iou": 0.04648000000000138,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.378000000000043,
        "end": 3.4599999999999227,
        "average": 11.918999999999983
      },
      "rationale_metrics": {
        "rouge_l": 0.09523809523809525,
        "text_similarity": 0.2782030999660492,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction describes a slide change and a request for the next slide, which is unrelated to when Ahlam Ahmed greets the speaker; it fails to mention the greeting that occurs immediately after the introduction."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker asks to move to the next slide, when does the slide visually change?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 962.9,
        "end": 963.4
      },
      "pred_interval": {
        "start": 1042.4,
        "end": 1050.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.50000000000011,
        "end": 86.60000000000002,
        "average": 83.05000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.09090909090909091,
        "text_similarity": 0.13830849528312683,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is irrelevant and does not address the timing or visual change of the slide described in the correct answer; it provides a repeated phrase rather than the requested timing information, so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions 'with ALP classrooms', when does she begin to introduce 'the second activity or the second intervention'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1104.5,
        "end": 1109.5
      },
      "pred_interval": {
        "start": 82.7,
        "end": 94.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1021.8,
        "end": 1015.2,
        "average": 1018.5
      },
      "rationale_metrics": {
        "rouge_l": 0.05,
        "text_similarity": 0.14399772882461548,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation ('after') but omits the key factual details required by the ground truth (the anchor end at 1054.5s and the target start/end at 1104.5s\u20131109.5s), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes talking about 'on the safe school protocols', when does she describe how 'Temporary learning spaces will also be provided with wash facilities and essential cleaning hygiene materials'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1138.5,
        "end": 1148.0
      },
      "pred_interval": {
        "start": 115.6,
        "end": 120.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1022.9,
        "end": 1027.5,
        "average": 1025.2
      },
      "rationale_metrics": {
        "rouge_l": 0.37500000000000006,
        "text_similarity": 0.3369424343109131,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the segment occurs after the safe school protocols, but it omits the crucial start/end timestamps and specific segment labeling provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions community sensitization, when does she describe the creation of a community-based support system for children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1246.823,
        "end": 1274.838
      },
      "pred_interval": {
        "start": 763.9,
        "end": 854.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 482.9230000000001,
        "end": 420.6379999999999,
        "average": 451.7805
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.21796143054962158,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys that the community-based support system is described after the discussion of sensitization, but it omits the precise timing/timestamps and the explicit 'once_finished' anchor-to-target relation provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning integration into the formal learning system, when does she state the overall objective of the program?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1339.066,
        "end": 1350.221
      },
      "pred_interval": {
        "start": 1194.9,
        "end": 1226.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 144.16599999999994,
        "end": 123.82099999999991,
        "average": 133.99349999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307693,
        "text_similarity": 0.28253352642059326,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that the speaker states the program's overall objective immediately afterwards, preserving the main temporal relation and meaning, but it omits the specific start/end timestamps and precise timing details given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing school referrals and observation capacity, when does she mention that guidelines for pathways and referral will be revised?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1389.248,
        "end": 1400.984
      },
      "pred_interval": {
        "start": 1282.7,
        "end": 1303.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 106.548,
        "end": 97.18399999999997,
        "average": 101.86599999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.12903225806451613,
        "text_similarity": 0.3961586654186249,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys that the revision is mentioned after discussing school referrals and observation capacity, but it omits the precise timestamps and event-boundary details given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker finishes mentioning case management and referral pathways, when does she start listing additional skills training in the capacity building package?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1471.0,
        "end": 1480.5
      },
      "pred_interval": {
        "start": 228.4,
        "end": 249.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1242.6,
        "end": 1231.2,
        "average": 1236.9
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.2541259229183197,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction describes a different speaker and event (introducing 'Sundas') with timestamps (~148\u2013169s) that do not match the correct event or its timestamps (~1470.8\u20131480.5s); it is therefore incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker says \"Yeah, next slide, please\" for the first time, when does the green box with the English text for the \"Commitment indicator\" appear on screen?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1634.9,
        "end": 1720.9
      },
      "pred_interval": {
        "start": 23.8,
        "end": 24.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1611.1000000000001,
        "end": 1696.3000000000002,
        "average": 1653.7000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324328,
        "text_similarity": 0.6784716844558716,
        "llm_judge_score": 0,
        "llm_judge_justification": "Error parsing LLM response: Expecting ',' delimiter: line 3 column 221 (char 236)"
      }
    },
    {
      "question_id": "001",
      "question": "Once the male speaker finishes asking to move to the next slide, when does the slide actually change?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1785.53,
        "end": 1785.6
      },
      "pred_interval": {
        "start": 2.5,
        "end": 4.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1783.03,
        "end": 1781.3,
        "average": 1782.165
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367344,
        "text_similarity": 0.592954158782959,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the slide changes after the speaker's request but incorrectly asserts it happens immediately; the ground truth shows a ~3.2s delay (speaker at 1782.3s, slide change ~1785.53\u20131785.6s), so the timing is wrong and key timing details are omitted."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the child's achievement in the first case study, when does she ask for the next slide?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1909.926,
        "end": 1911.04
      },
      "pred_interval": {
        "start": 75.8,
        "end": 76.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1834.126,
        "end": 1834.1399999999999,
        "average": 1834.1329999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3773584905660377,
        "text_similarity": 0.5896589159965515,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly conveys the 'asks right away' (once_finished) relation and matches the timing implication, but it omits the precise timestamps given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks for the next slide, when does the slide transition to the domestic violence case study?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1915.72,
        "end": 1921.8
      },
      "pred_interval": {
        "start": 168.9,
        "end": 169.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1746.82,
        "end": 1751.8999999999999,
        "average": 1749.36
      },
      "rationale_metrics": {
        "rouge_l": 0.38596491228070173,
        "text_similarity": 0.5860506296157837,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the slide changes to the domestic violence case study after the speaker's request, but it omits the precise timestamps (start at 1915.72s, completion by 1921.8s) and incorrectly implies an immediate/direct transition rather than the documented slight delay and completion interval."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes her detailed explanation of how they help children facing domestic violence, when does she say 'Next slide'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2003.389,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 208.4,
        "end": 210.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1794.9889999999998,
        "end": 1793.5,
        "average": 1794.2444999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.20512820512820515,
        "text_similarity": 0.51237952709198,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer correctly conveys the temporal relation (the speaker says 'Next slide' immediately after finishing the explanation), matching the ground-truth 'once_finished' relation and timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "Once the Arabic speaker (Sundus) finishes her conclusion about the link between protection and education, when does the English speaker thank her?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2072.045,
        "end": 2076.5
      },
      "pred_interval": {
        "start": 216.3,
        "end": 217.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1855.7450000000001,
        "end": 1858.6,
        "average": 1857.1725000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.46987754106521606,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the English speaker thanks Sundus after her conclusion, but it omits the precise timing, incorrectly asserts exact utterances for Sundus, and fails to mention that the English speaker also thanks Sahar, making it incomplete and partially inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the PEACE project as a multi-country project in Nigeria, Cameroon, and Niger, when does he specify the states in Nigeria where it is implemented?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2211.28,
        "end": 2223.708
      },
      "pred_interval": {
        "start": 2358.7,
        "end": 2409.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 147.41999999999962,
        "end": 185.89199999999983,
        "average": 166.65599999999972
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290325,
        "text_similarity": 0.5468922257423401,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that the states are specified after the project introduction (relative order), but it omits key details provided in the reference\u2014namely the specific timestamps and the named Nigerian states (Borno, Adamawa, Yobe)."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker states that the project has three main results, when does he begin describing the first result, 'Access'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2250.478,
        "end": 2262.09
      },
      "pred_interval": {
        "start": 2409.6,
        "end": 2457.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 159.12199999999984,
        "end": 195.60999999999967,
        "average": 177.36599999999976
      },
      "rationale_metrics": {
        "rouge_l": 0.17543859649122806,
        "text_similarity": 0.4183993935585022,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and lacks the required timing details (timestamps) and instead references 'Nigerian states' as an anchor, which contradicts the ground-truth anchor; it only partially matches the fact that the description follows immediately."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the 'Accelerated Learning Program' for children who are out of school, when does he specify the age range of these children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2337.405,
        "end": 2348.025
      },
      "pred_interval": {
        "start": 2457.7,
        "end": 2505.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 120.29499999999962,
        "end": 157.7750000000001,
        "average": 139.03499999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.1492537313432836,
        "text_similarity": 0.6884069442749023,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the age range is mentioned after the program description, but it omits the specific timing/segment details (the precise interval 2337.405\u20132348.025s) and is too vague to fully match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker transitions to discussing Result 2, when does he mention 'Parenting Sessions'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.824,
        "end": 2369.824
      },
      "pred_interval": {
        "start": 2485.9,
        "end": 2513.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 117.07600000000002,
        "end": 143.77599999999984,
        "average": 130.42599999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.15,
        "text_similarity": 0.18970292806625366,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relative timing (that 'Parenting Sessions' occurs after the Result 2 discussion) but omits the key factual details\u2014the specific timestamps and explicit anchor/target interval\u2014which are required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"Next slide,\" when does he begin asking about integrating child protection and education activities?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2755.7,
        "end": 2766.6
      },
      "pred_interval": {
        "start": 275.6,
        "end": 279.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2480.1,
        "end": 2487.2,
        "average": 2483.6499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.45684099197387695,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the speaker asks about integration after saying 'Next slide,' but it omits the key factual details (the precise start/end timestamps and the once_finished relation) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker (Kunja) finishes explaining that child protection activities require more funding, when does Amanda thank him?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2899.8,
        "end": 2900.8
      },
      "pred_interval": {
        "start": 2945.3,
        "end": 2986.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.5,
        "end": 85.89999999999964,
        "average": 65.69999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.1951219512195122,
        "text_similarity": 0.45309585332870483,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after')\u2014Amanda thanks Kunja after he finishes\u2014but it omits the precise timestamps provided in the reference (start/end times)."
      }
    },
    {
      "question_id": "002",
      "question": "Once Amanda finishes introducing Mike and hands over to him, when does Mike thank Amanda?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2938.9,
        "end": 2940.5
      },
      "pred_interval": {
        "start": 3032.0,
        "end": 3039.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 93.09999999999991,
        "end": 99.0,
        "average": 96.04999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.5202906727790833,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that Mike thanks Amanda after she hands over, preserving the main relation, but it omits the timestamps and adds an unsupported/inaccurate claim that the handover occurs just before the end of his introduction."
      }
    },
    {
      "question_id": "001",
      "question": "While the male speaker introduces the first question about project findings, when does he ask the panelists to be brief?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3039.0,
        "end": 3046.5
      },
      "pred_interval": {
        "start": 15.8,
        "end": 16.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3023.2,
        "end": 3030.3,
        "average": 3026.75
      },
      "rationale_metrics": {
        "rouge_l": 0.09523809523809523,
        "text_similarity": 0.22428648173809052,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction notes that the speaker asks panelists to be brief but gives no timing or timestamp details as required; it omits the key factual elements (the provided timestamps and event positioning) from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker thanks Ahlam for her input, when does he introduce Sundus?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3153.0,
        "end": 3159.0
      },
      "pred_interval": {
        "start": 27.3,
        "end": 28.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3125.7,
        "end": 3130.9,
        "average": 3128.3
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981131,
        "text_similarity": 0.49246692657470703,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that Sundus is introduced after thanking Ahlam, but it fails to provide the key temporal details (the specific timestamps) given in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After Sundus finishes speaking in Arabic, when does Paul ask 'Can you say that again?'",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3234.7,
        "end": 3235.7
      },
      "pred_interval": {
        "start": 28.7,
        "end": 29.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3206.0,
        "end": 3206.2999999999997,
        "average": 3206.1499999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.13559322033898305,
        "text_similarity": 0.36123067140579224,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates Paul asks after an introduction (relative timing), but it is ambiguous and omits that Sundus had finished speaking in Arabic and who spoke in Arabic; it also lacks the precise timing given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After Sundus finishes speaking, when does Mike thank her for her input?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3217.7,
        "end": 3221.9
      },
      "pred_interval": {
        "start": 3289.4,
        "end": 3315.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.70000000000027,
        "end": 93.79999999999973,
        "average": 82.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2631578947368421,
        "text_similarity": 0.3848274350166321,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') between events but omits the key factual details (the exact start/end timestamps for both events and the temporal span for Mike's thanks), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After Mike asks Paul to share a main finding from his project, when does Paul ask Mike to repeat the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3234.3,
        "end": 3235.5
      },
      "pred_interval": {
        "start": 3362.3,
        "end": 3386.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 128.0,
        "end": 150.80000000000018,
        "average": 139.4000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1923076923076923,
        "text_similarity": 0.41182941198349,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction omits the key event that Paul asks Mike to repeat the question and instead says Paul answers and continues speaking, which contradicts and fails to capture the referenced temporal relation and details."
      }
    },
    {
      "question_id": "003",
      "question": "Once Paul finishes explaining how the integrated approach helps children, when does Mike thank him for his insights?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3306.5,
        "end": 3307.4
      },
      "pred_interval": {
        "start": 3428.0,
        "end": 3445.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 121.5,
        "end": 138.29999999999973,
        "average": 129.89999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.1724137931034483,
        "text_similarity": 0.304132342338562,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation that Mike thanks Paul immediately after he finishes, but it omits the key factual details (the specific timestamps 3304.8s and 3306.5\u20133307.4s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After Ahlam states that the first lesson involves integrating child protection with educational activities, when does she explain how child protection creates a safe environment for children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3626.1,
        "end": 3634.8
      },
      "pred_interval": {
        "start": 358.2,
        "end": 364.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3267.9,
        "end": 3269.9,
        "average": 3268.9
      },
      "rationale_metrics": {
        "rouge_l": 0.20338983050847456,
        "text_similarity": 0.5133153796195984,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only repeats the content of E1 and omits all required timing information and the 'after' relation to E2, so it captures a small portion of the correct answer but misses key factual elements."
      }
    },
    {
      "question_id": "002",
      "question": "Once Ahlam finishes speaking and says 'Thanks Mike. Over to you.', when does the host thank Ahlam for her insights?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3679.3,
        "end": 3687.5
      },
      "pred_interval": {
        "start": 373.0,
        "end": 376.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3306.3,
        "end": 3311.3,
        "average": 3308.8
      },
      "rationale_metrics": {
        "rouge_l": 0.16326530612244897,
        "text_similarity": 0.36318981647491455,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction merely restates Ahlam finishing her turn and omits all required timing information and the host's thanking event/relation; it fails to answer when the host thanks Ahlam."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks Sundus about the lessons learned from the monitoring system in Northern Syria, when does Sundus provide her initial lessons learned?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3704.2,
        "end": 3724.0
      },
      "pred_interval": {
        "start": 378.0,
        "end": 383.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3326.2,
        "end": 3340.3,
        "average": 3333.25
      },
      "rationale_metrics": {
        "rouge_l": 0.19444444444444445,
        "text_similarity": 0.36620140075683594,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction merely restates that Sundus speaks after the host but fails to provide the required precise timestamps and relation details from the reference, omitting key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sundus finishes asking Mike to repeat the question, when does Mike start repeating the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3785.8,
        "end": 3796.2
      },
      "pred_interval": {
        "start": 385.6,
        "end": 429.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3400.2000000000003,
        "end": 3366.5,
        "average": 3383.3500000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.6764392852783203,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates that Mike repeats the question after Sundus asks for repetition, but it is vague and omits all key details (exact timing, when Mike starts at 3785.8s, and that only the first part is repeated)."
      }
    },
    {
      "question_id": "002",
      "question": "After Sundus finishes providing her answer, when does Mike thank her for her input?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3851.7,
        "end": 3853.6
      },
      "pred_interval": {
        "start": 429.7,
        "end": 444.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3422.0,
        "end": 3409.1,
        "average": 3415.55
      },
      "rationale_metrics": {
        "rouge_l": 0.2608695652173913,
        "text_similarity": 0.6103411316871643,
        "llm_judge_score": 6,
        "llm_judge_justification": "The predicted answer correctly conveys that Mike thanks Sundus after she finishes, but it omits the key factual timestamps and precise timing details (3851.7s\u20133853.6s) given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After Mike says he will ask Ahlam the same question, when does Ahlam ask for clarification on the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3864.0,
        "end": 3872.7
      },
      "pred_interval": {
        "start": 444.5,
        "end": 460.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3419.5,
        "end": 3412.7,
        "average": 3416.1
      },
      "rationale_metrics": {
        "rouge_l": 0.35294117647058826,
        "text_similarity": 0.6842367649078369,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that Ahlam asks for clarification after Mike's statement, but it omits the crucial timing details (specific timestamps and completion time) provided in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman in the bottom left finishes explaining how all staff were working together, when does the male host in the top left thank Ahlam?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3937.666,
        "end": 3939.047
      },
      "pred_interval": {
        "start": 4073.8,
        "end": 4125.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 136.13400000000001,
        "end": 186.55300000000034,
        "average": 161.34350000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.1568627450980392,
        "text_similarity": 0.42777276039123535,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that the male host thanks Ahlam after she finishes her explanation, matching the correct answer's relative timing (the thank-you occurs after the anchor completes)."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male host finishes asking what type of evidence ECHO asked for, when does the female speaker (Sarah) in the top middle-right start to respond?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3981.063,
        "end": 3984.022
      },
      "pred_interval": {
        "start": 4006.2,
        "end": 4050.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.136999999999716,
        "end": 66.77800000000025,
        "average": 45.95749999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.17857142857142858,
        "text_similarity": 0.4363664984703064,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that Sarah responds after the male host's question but omits the precise timestamps and the note that the response starts immediately after the anchor, so it is incomplete relative to the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once Paul finishes explaining how learning is put into action and fits into different contexts, when does he say 'Thank you'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 4068.612,
        "end": 4069.152
      },
      "pred_interval": {
        "start": 4043.6,
        "end": 4064.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.01200000000017,
        "end": 4.9520000000002256,
        "average": 14.982000000000198
      },
      "rationale_metrics": {
        "rouge_l": 0.19607843137254904,
        "text_similarity": 0.4559306502342224,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that Paul says 'Thank you' after finishing the explanation, but it omits the precise timing details and timestamps (and the explicit note that it occurs immediately after the anchor), which are present in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host says \"go ahead Paul, sorry\", when does Paul begin his response?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4123.162,
        "end": 4123.743
      },
      "pred_interval": {
        "start": 246.3,
        "end": 259.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3876.862,
        "end": 3864.0430000000006,
        "average": 3870.4525000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.14545454545454545,
        "text_similarity": 0.42559120059013367,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the correct high-level relation (Paul speaks immediately after the host) but omits the key factual details\u2014exact timestamps, intervals, and the once_finished relation\u2014present in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once Paul finishes his feedback and says \"Thank you\", when does the host respond?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4179.089,
        "end": 4183.52
      },
      "pred_interval": {
        "start": 263.1,
        "end": 270.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3915.989,
        "end": 3912.6200000000003,
        "average": 3914.3045
      },
      "rationale_metrics": {
        "rouge_l": 0.17391304347826086,
        "text_similarity": 0.45420360565185547,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly states that the host responds immediately, matching the key conclusion; it omits the specific timestamps and explicit note that the host says 'thank you,' so it is not a fully detailed match."
      }
    },
    {
      "question_id": "003",
      "question": "Once the host explicitly says \"So thank you for that\" to Kunja, when does she transition to Lynn's question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4298.586,
        "end": 4300.0
      },
      "pred_interval": {
        "start": 272.0,
        "end": 284.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4026.5860000000002,
        "end": 4015.7,
        "average": 4021.143
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.35825878381729126,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly implies the transition follows the host's thank-you, but it omits the precise timing/timestamps and even misattributes the transition to Kunja rather than the host, so key factual details are missing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker thanks the previous participant, when does he introduce a question from Lynn?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4296.586,
        "end": 4299.158
      },
      "pred_interval": {
        "start": 4297.8,
        "end": 4356.4
      },
      "iou": 0.02270371484936952,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2139999999999418,
        "end": 57.24199999999928,
        "average": 29.22799999999961
      },
      "rationale_metrics": {
        "rouge_l": 0.20512820512820512,
        "text_similarity": 0.3799097239971161,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation ('after') that Lynn's question is introduced, but it omits the specific timing details (the provided start/end timestamps) included in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes reading Lynn's question, when does he ask Sundus for her opinion?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4324.216,
        "end": 4328.945
      },
      "pred_interval": {
        "start": 4357.8,
        "end": 4396.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.58399999999983,
        "end": 67.45499999999993,
        "average": 50.51949999999988
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.40561193227767944,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that Sundus speaks after Lynn's question, but it omits the precise timing and implies an immediate start, whereas the reference specifies a ~4.12s delay (start at 4324.216s)."
      }
    },
    {
      "question_id": "003",
      "question": "After Sundus finishes stating that violence is not the only challenge, when does the speaker confirm that she answered part of the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4415.375,
        "end": 4425.293
      },
      "pred_interval": {
        "start": 4397.8,
        "end": 4456.4
      },
      "iou": 0.16924914675767505,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.574999999999818,
        "end": 31.10699999999997,
        "average": 24.340999999999894
      },
      "rationale_metrics": {
        "rouge_l": 0.04761904761904762,
        "text_similarity": 0.37471652030944824,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the ground truth: the correct timestamps show the confirmation occurs after Sundus finishes (4415.375\u20134425.293s), whereas the prediction says it occurs before Sundus begins answering."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host asks if the panelist agrees with his statement, when does Ahlam reply with 'Yes, yes, Mike'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4479.36,
        "end": 4480.3
      },
      "pred_interval": {
        "start": 459.7,
        "end": 462.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4019.66,
        "end": 4017.5,
        "average": 4018.58
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.4974481761455536,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that Ahlam replies immediately after the host (matching the 'once_finished' relation) and contains no contradictions, but it omits the precise start/end timestamps provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the host finishes asking who would like to answer the question, when does Paul Bagambe begin to speak?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4707.194,
        "end": 4709.296
      },
      "pred_interval": {
        "start": 47.3,
        "end": 52.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4659.894,
        "end": 4656.696,
        "average": 4658.295
      },
      "rationale_metrics": {
        "rouge_l": 0.16,
        "text_similarity": 0.3019201457500458,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the relative timing: Paul begins speaking immediately/shortly after the host finishes asking who would like to answer, matching the reference's timing relation (no incorrect details or omissions)."
      }
    },
    {
      "question_id": "002",
      "question": "Once Paul Bagambe mentions 'praise singers', when does he elaborate on what they do?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4717.127,
        "end": 4732.251
      },
      "pred_interval": {
        "start": 58.2,
        "end": 62.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4658.927000000001,
        "end": 4669.751,
        "average": 4664.339
      },
      "rationale_metrics": {
        "rouge_l": 0.18461538461538457,
        "text_similarity": 0.659988522529602,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction identifies an elaboration window but the timestamps are drastically different from the reference (58\u201362s vs. 4717\u20134732s) and thus do not match the correct timing or the stated relation that the explanation begins immediately after the mention."
      }
    },
    {
      "question_id": "003",
      "question": "After the host thanks Paul, when does Sindus (woman in bottom-left video) start speaking?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4827.512,
        "end": 4830.216
      },
      "pred_interval": {
        "start": 70.6,
        "end": 72.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4756.911999999999,
        "end": 4758.0160000000005,
        "average": 4757.464
      },
      "rationale_metrics": {
        "rouge_l": 0.2413793103448276,
        "text_similarity": 0.5317218899726868,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly indicates Sindus speaks after the host's thanks and the start time (\u224870.6s relative) aligns closely with the correct start (4827.512s) after converting absolutes to relatives; the only minor issue is the predicted end time is slightly earlier and the duration is shorter than the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker (Sundus) finishes her concluding remarks in Arabic, when does the moderator thank her and explain the fast wrap-up session?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4897.7,
        "end": 4916.5
      },
      "pred_interval": {
        "start": 4932.8,
        "end": 5040.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.100000000000364,
        "end": 123.5,
        "average": 79.30000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.20833333333333334,
        "text_similarity": 0.28604793548583984,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the moderator thanks the speaker and announces a fast wrap-up, but it omits the required timing information (start/end timestamps and the 'once_finished' relation), so it is incomplete for the 'when' question."
      }
    },
    {
      "question_id": "002",
      "question": "During Sarah's key message, when does she mention strengthening the existing system and training teachers?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4936.0,
        "end": 4942.9
      },
      "pred_interval": {
        "start": 4976.0,
        "end": 4998.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.0,
        "end": 55.100000000000364,
        "average": 47.55000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.41567090153694153,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly places both mentions within Sarah's key message period, but the reported times are significantly later than the ground truth (4936.0\u20134942.9) and it alters the timing/order of the two mentions; thus it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the host asks Sundus for her key takeaway message, when does Sundus begin speaking in Arabic?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 4985.7,
        "end": 5026.77
      },
      "pred_interval": {
        "start": 5.2,
        "end": 6.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4980.5,
        "end": 5020.47,
        "average": 5000.485000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.25531914893617025,
        "text_similarity": 0.4264599084854126,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that Sundus begins speaking in Arabic, but it omits the crucial timestamp details and the 'after' relation specified in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the host thanks Paul, when does Amanda, the next speaker, start speaking?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5190.0,
        "end": 5356.2699999999995
      },
      "gt_interval": {
        "start": 5251.699,
        "end": 5254.524
      },
      "pred_interval": {
        "start": 258.9,
        "end": 364.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4992.799,
        "end": 4889.8240000000005,
        "average": 4941.3115
      },
      "rationale_metrics": {
        "rouge_l": 0.2564102564102564,
        "text_similarity": 0.5125803351402283,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that Amanda speaks after the host thanks Paul, but it omits the requested timing details (the specific timestamps and duration), so it is incomplete relative to the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once Amanda says 'Over to you, David', when does David start speaking?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5190.0,
        "end": 5356.2699999999995
      },
      "gt_interval": {
        "start": 5287.087,
        "end": 5288.53
      },
      "pred_interval": {
        "start": 364.7,
        "end": 374.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4922.387000000001,
        "end": 4914.33,
        "average": 4918.3585
      },
      "rationale_metrics": {
        "rouge_l": 0.13953488372093023,
        "text_similarity": 0.4740581512451172,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the core idea that David speaks after Amanda says 'Over to you,' but it omits the precise timing details (David starts ~0.28s after Amanda's finish and the exact timestamps) and the note that he begins almost immediately and when his turn ends."
      }
    },
    {
      "question_id": "003",
      "question": "After David finishes explaining about the feedback form, when does he start giving instructions about the FILO page and WELO coffee lounge?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5190.0,
        "end": 5356.2699999999995
      },
      "gt_interval": {
        "start": 5309.965,
        "end": 5315.734
      },
      "pred_interval": {
        "start": 374.2,
        "end": 462.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4935.765,
        "end": 4853.134,
        "average": 4894.449500000001
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714288,
        "text_similarity": 0.6027094721794128,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the FILO/WELO instructions follow the feedback-form explanation, but it omits the precise timing information (start/end timestamps) given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes describing the expectations for IRC Child Protection Team Members, when does he finish describing the expectations for IRC Education Team Members?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2490.27,
        "end": 2535.335
      },
      "pred_interval": {
        "start": 846.2,
        "end": 935.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1644.07,
        "end": 1600.135,
        "average": 1622.1025
      },
      "rationale_metrics": {
        "rouge_l": 0.1917808219178082,
        "text_similarity": 0.3839029371738434,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction vaguely references content ('Capacity Strengthening' and training) that may relate to the education-team segment but fails to provide the required timestamps or indicate the event span; it omits key factual timing details from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says that 'cross-sector collaboration is really needed to achieve peace expectation', when does he start talking about the integration across the four education models?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2555.112,
        "end": 2569.771
      },
      "pred_interval": {
        "start": 1752.9,
        "end": 1802.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 802.212,
        "end": 766.8710000000001,
        "average": 784.5415
      },
      "rationale_metrics": {
        "rouge_l": 0.07272727272727274,
        "text_similarity": 0.285819411277771,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives a start time (1752.9s) that is far off from the correct start time (~2555.112s) and omits the end time and precise relation details, so it is largely incorrect."
      }
    }
  ]
}