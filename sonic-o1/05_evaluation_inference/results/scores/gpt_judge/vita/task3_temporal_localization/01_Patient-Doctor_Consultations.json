{
  "topic_id": 1,
  "topic_name": "Patient-Doctor Consultations",
  "num_evaluated": 266,
  "aggregated_metrics": {
    "mean_iou": 0.0348162671671364,
    "std_iou": 0.12600695599104955,
    "median_iou": 0.0,
    "R@0.3": {
      "recall": 0.041353383458646614,
      "count": 11,
      "total": 266
    },
    "R@0.5": {
      "recall": 0.03759398496240601,
      "count": 10,
      "total": 266
    },
    "R@0.7": {
      "recall": 0.007518796992481203,
      "count": 2,
      "total": 266
    },
    "mae": {
      "start_mean": 169.81368796992484,
      "end_mean": 3685.539533834586,
      "average_mean": 1927.6766109022556
    },
    "rationale": {
      "rouge_l_mean": 0.24669788793451727,
      "rouge_l_std": 0.1138268626444423,
      "text_similarity_mean": 0.44953603665099334,
      "text_similarity_std": 0.19231654538664766,
      "llm_judge_score_mean": 3.5601503759398496,
      "llm_judge_score_std": 2.7307340126903186
    },
    "rationale_cider": 0.31449686067022425
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "After the speaker welcomes viewers and introduces himself as 'Karma Medic', when does he state that he is a 'final year medical student'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 35.0,
        "end": 36.62
      },
      "pred_interval": {
        "start": 25.0,
        "end": 36.6
      },
      "iou": 0.13769363166953544,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 0.01999999999999602,
        "average": 5.009999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.8918918918918919,
        "text_similarity": 0.97123122215271,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the target segment and the 'after' relationship, but it mislocates the anchor start time (25.0s vs the correct 3.54s), which is a significant factual error."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'Now with that lovely disclaimer out of the way, let's get right into it', when does the text 'before the history' appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.06,
        "end": 57.06
      },
      "pred_interval": {
        "start": 40.0,
        "end": 41.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.060000000000002,
        "end": 16.060000000000002,
        "average": 16.060000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.7881146669387817,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect: it gives entirely different timestamps (40.0\u201341.0s vs ~56.03\u201357.06s) and the temporal relation is wrong ('at' vs the correct 'once_finished' immediate appearance)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'So before starting the history, there's generally two things that I try and keep in mind', when does he begin describing 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 206.36,
        "end": 207.36
      },
      "pred_interval": {
        "start": 70.0,
        "end": 71.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 136.36,
        "end": 136.36,
        "average": 136.36
      },
      "rationale_metrics": {
        "rouge_l": 0.5352112676056339,
        "text_similarity": 0.8949118852615356,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer has almost entirely incorrect timestamps and misidentifies the anchor span; although it labels the relationship 'after' (matching the ground truth), the reported start/end times for both events are far from the correct values and the spans/content are inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the acronym 'ICE', when does he explain what it stands for?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 155.7,
        "end": 158.7
      },
      "pred_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.30000000000001,
        "end": 81.30000000000001,
        "average": 80.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.391304347826087,
        "text_similarity": 0.5542612075805664,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the temporal relation right (explains immediately after), but the absolute timestamp is incorrect (235.0s vs 155.7s) and it omits the explanation's end time (158.7s), so it fails on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the components of the WIPER acronym, when does he start elaborating on 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 212.0
      },
      "pred_interval": {
        "start": 260.0,
        "end": 265.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.0,
        "end": 53.0,
        "average": 53.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3846153846153846,
        "text_similarity": 0.6323070526123047,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the correct temporal relation (elaboration occurs after finishing) but gives a greatly incorrect start time (260.0s vs. 207.0s) and omits the end time, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what brought the patient in, when does he explain what the 'history of presenting complaint' is about?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 346.0,
        "end": 351.0
      },
      "pred_interval": {
        "start": 345.0,
        "end": 352.0
      },
      "iou": 0.7142857142857143,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.0,
        "end": 1.0,
        "average": 1.0
      },
      "rationale_metrics": {
        "rouge_l": 0.27450980392156865,
        "text_similarity": 0.4463384747505188,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits the key factual details (the specific start/end timestamps for E1 and E2) given in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "How long after the speaker says he'll put a picture of all possible questions does the \"REVIEW OF SYSTEMS\" checklist first appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 539.8,
        "end": 543.7
      },
      "pred_interval": {
        "start": 512.0,
        "end": 513.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.799999999999955,
        "end": 30.700000000000045,
        "average": 29.25
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.3535599410533905,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction (512.0s) contradicts the reference timings \u2014 the checklist actually appears at 29.8\u201333.7s (with the speaker anchor at 534.817s) \u2014 and omits the relative \"after\" relation; the answer is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is giving examples of systems review questions, when does he ask about \"tummy pain\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 565.74,
        "end": 566.422
      },
      "pred_interval": {
        "start": 546.0,
        "end": 547.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.74000000000001,
        "end": 19.422000000000025,
        "average": 19.581000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.23255813953488372,
        "text_similarity": 0.3937072157859802,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted time (546.0s) is within the overall examples window but does not match the correct interval (555.740\u2013556.422s) and is about 9.7s off; it also omits the precise interval and relation."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the \"JAM THREADS\" mnemonic, when does he say the name \"Sketchy Medical\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 696.0,
        "end": 699.531
      },
      "pred_interval": {
        "start": 598.0,
        "end": 599.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 98.0,
        "end": 100.53099999999995,
        "average": 99.26549999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2631578947368421,
        "text_similarity": 0.3637385666370392,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted time (598.0s) contradicts the reference (696.0\u2013699.531s) and is not after the JAM THREADS mention at 635.0s, so the timing and relation are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker describes Sketchy Medical, when does he mention drugs' mechanism of action and side effects?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 701.0,
        "end": 703.982
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.0,
        "end": 26.01800000000003,
        "average": 25.009000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.3829787234042553,
        "text_similarity": 0.44992440938949585,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamp (725.0s) does not match the correct interval (701.0s\u2013703.982s) when the speaker mentions mechanism and side effects, so it is factually incorrect and omits the correct timing context."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks a general question about family health, when does he suggest being specific about asthma, diabetes, and hypertension?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 742.914,
        "end": 745.914
      },
      "pred_interval": {
        "start": 740.0,
        "end": 745.0
      },
      "iou": 0.3527223537368984,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.9139999999999873,
        "end": 0.9139999999999873,
        "average": 1.9139999999999873
      },
      "rationale_metrics": {
        "rouge_l": 0.10714285714285714,
        "text_similarity": 0.2940372824668884,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gives 740.0s which is outside the correct interval (742.914\u2013745.914s) and omits the relation that this specificity occurs after the general family-health question, so it's close but factually inaccurate and incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the importance of signposting, when does he ask if the patient uses any recreational drugs?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 811.123,
        "end": 812.664
      },
      "pred_interval": {
        "start": 800.0,
        "end": 805.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.123000000000047,
        "end": 7.663999999999987,
        "average": 9.393500000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.163265306122449,
        "text_similarity": 0.46812865138053894,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted time (800.0s) is far from the correct question window (811.123\u2013812.664s) and wrongly places the question during the signposting explanation (800.851\u2013802.575s), so it is essentially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"concerns from ICE\", when does he start saying \"Just generally, if you're feeling stuck\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 880.187,
        "end": 883.471
      },
      "pred_interval": {
        "start": 905.0,
        "end": 908.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.812999999999988,
        "end": 24.528999999999996,
        "average": 24.670999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.42857142857142855,
        "text_similarity": 0.43965640664100647,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a start time of 905.0s which is substantially later than the correct start at 880.187s (\u224825s off), so the timing is incorrect even though it preserves the 'after' relation; it fails to match the annotated span."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"golden rulebook\", when does he open both hands outwards in a gesture?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 895.8,
        "end": 897.5
      },
      "pred_interval": {
        "start": 913.0,
        "end": 914.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.200000000000045,
        "end": 16.5,
        "average": 16.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.25531914893617014,
        "text_similarity": 0.6028452515602112,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the gesture occurs after 'golden rulebook', but gives a single timestamp (913.0s) that is far from the correct interval (895.8\u2013897.5s) and omits the target's proper time span, so the timing is inaccurate and incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying \"I hope you find this video useful\", when does he say \"Peace\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 910.148,
        "end": 910.609
      },
      "pred_interval": {
        "start": 921.0,
        "end": 922.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.851999999999975,
        "end": 11.390999999999963,
        "average": 11.121499999999969
      },
      "rationale_metrics": {
        "rouge_l": 0.41509433962264153,
        "text_similarity": 0.5136780738830566,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that 'Peace' follows the prior line, but the timestamp is significantly off (predicted 921.0s vs. actual start ~910.148s) and it omits the correct interval; thus it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying he has an appointment at 10 am, when does the green text 'Sure, what's your name?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 6.1,
        "end": 8.2
      },
      "pred_interval": {
        "start": 12.6,
        "end": 13.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 5.200000000000001,
        "average": 5.8500000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.3736817240715027,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the text appears immediately after he finishes), but it omits key factual details from the reference\u2014specifically the exact timestamps (appears 6.1s\u20138.2s, anchor ends at 5.9s)."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes stating his name, when does the green text 'Thank you, Lucas. Please take a seat...' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 11.9,
        "end": 19.0
      },
      "pred_interval": {
        "start": 15.9,
        "end": 16.7
      },
      "iou": 0.11267605633802802,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 2.3000000000000007,
        "average": 3.1500000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.09302325581395349,
        "text_similarity": 0.13472488522529602,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys that the text appears after he finishes, but it omits the precise timing (anchor ends at 10.6s; target appears from 11.9s to 19.0s) and thus lacks the key factual details required."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'How long is the wait?', when does the green text 'About 10 minutes. Would you like some water while you wait?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 22.1,
        "end": 25.3
      },
      "pred_interval": {
        "start": 20.8,
        "end": 21.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3000000000000007,
        "end": 3.6999999999999993,
        "average": 2.5
      },
      "rationale_metrics": {
        "rouge_l": 0.10526315789473684,
        "text_similarity": 0.2035963237285614,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the text appears shortly after the question (matching the 'after' relation), but it omits the precise timing (22.1\u201325.3s) and the slight pause specified in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the video explains the 'we're a team' approach with animated graphics, when does the speaker appear at his desk looking at a computer?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 34.6,
        "end": 36.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.5,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3999999999999986,
        "end": 0.6000000000000014,
        "average": 0.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1951219512195122,
        "text_similarity": 0.6496872305870056,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely misaligns timings and content: E1 is placed much later and described with wrong audio, E2 is shifted significantly later than the ground truth, and the stated 'after' relationship contradicts the actual overlap; it only partially matches that the speaker eventually looks at a computer."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker says 'take that extra bit of time to listen', when does the 'OK' hand gesture emoji appear?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 44.0,
        "end": 45.5
      },
      "pred_interval": {
        "start": 49.0,
        "end": 49.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 3.5,
        "average": 4.25
      },
      "rationale_metrics": {
        "rouge_l": 0.4810126582278481,
        "text_similarity": 0.7597021460533142,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it places both events at ~49.0s (with E2 instantaneous) rather than E1 at 42.8\u201344.5s and E2 at 44.0\u201345.5s, so the timing and duration/overlap are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After Nurse Kim mentions graduating as a registered nurse, when does she talk about working for many different pharmaceutical companies?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 43.0,
        "end": 50.475
      },
      "pred_interval": {
        "start": 25.0,
        "end": 36.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.0,
        "end": 14.475000000000001,
        "average": 16.2375
      },
      "rationale_metrics": {
        "rouge_l": 0.1904761904761905,
        "text_similarity": 0.30737924575805664,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the temporal relation (that the pharmaceutical companies mention occurs after the nursing graduation), but it omits the specific start/end timestamps given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once Nurse Kim finishes describing her background as an 'incredible journey', when does she mention training side-by-side with Dr. Jugenberg for five years?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 149.87,
        "end": 153.25
      },
      "pred_interval": {
        "start": 107.0,
        "end": 118.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.870000000000005,
        "end": 35.25,
        "average": 39.06
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.267652690410614,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the five-year training is mentioned after the 'incredible journey'), but it omits all required precise timestamps and event boundaries provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "While Nurse Kim explains options and possible outcomes, when does she begin examining the patient's stomach?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 157.5,
        "end": 160.5
      },
      "pred_interval": {
        "start": 152.0,
        "end": 163.0
      },
      "iou": 0.2727272727272727,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.5,
        "end": 2.5,
        "average": 4.0
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428564,
        "text_similarity": 0.6403543949127197,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives an earlier start time (152.0s) and ties the action to talking about asymmetry, but the reference locates the speech at 156.8s and the stomach exam from 157.5\u2013160.5s during that speech, so the timing and description are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After Nurse Kim finishes discussing the benefits, risks, and possible complications of the procedure, when does she start talking about asymmetry?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 169.7,
        "end": 172.0
      },
      "pred_interval": {
        "start": 194.0,
        "end": 207.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.30000000000001,
        "end": 35.0,
        "average": 29.650000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.2686567164179105,
        "text_similarity": 0.5751062631607056,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives 194.0s which is far from the correct 169.7s (immediately after the 169.5s anchor), so it contradicts the correct timing and omits the key detail that the target occurs immediately after the anchor."
      }
    },
    {
      "question_id": "003",
      "question": "Once Nurse Kim finishes explaining that the one-hour consultation cannot provide everything you need to know, when does she mention that they are always available?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 201.5,
        "end": 203.71
      },
      "pred_interval": {
        "start": 218.0,
        "end": 225.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.5,
        "end": 21.289999999999992,
        "average": 18.894999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.48417770862579346,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct utterance but gives an incorrect timestamp (218.0s vs the correct 201.5s) and fails to reflect the immediate transition; thus the key factual timing is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces himself and the topic, when does the slide change to 'Objectives for today's lesson'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 24.379,
        "end": 24.5
      },
      "pred_interval": {
        "start": 0.0,
        "end": 35.0
      },
      "iou": 0.003457142857142819,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.379,
        "end": 10.5,
        "average": 17.439500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.48434481024742126,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the slide change occurs after the introduction but fails to provide the correct timestamps and incorrectly places the introduction at 0.0s instead of 4.014\u201314.567s and omits the slide change time of 24.379s, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the objectives for the lesson, when does the slide change to 'Brain storming time'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 46.529,
        "end": 47.0
      },
      "pred_interval": {
        "start": 40.0,
        "end": 41.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5290000000000035,
        "end": 6.0,
        "average": 6.264500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.23255813953488372,
        "text_similarity": 0.6523020267486572,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the causal relation right (slide changes after the speaker finishes) but is factually incorrect about timing\u2014it states 40.0s versus the reference times of 45.800s and 46.529s\u2014thus it omits and contradicts key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes defining communication as the successful passage of a message from one person to another, when does he start explaining how good communication manifests in medical practice by informing patients of their diagnosis?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 153.0,
        "end": 177.0
      },
      "pred_interval": {
        "start": 150.0,
        "end": 153.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 24.0,
        "average": 13.5
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818185,
        "text_similarity": 0.08042553812265396,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly identifies the anchor ending at 153.0s and the target starting at 153.0s, matching the reference timing and sequence exactly."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the 'Importance of communication' slide, when does he begin discussing that good doctor-patient communication has been linked to improved patient satisfaction?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 190.0,
        "end": 198.0
      },
      "pred_interval": {
        "start": 160.0,
        "end": 163.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.0,
        "end": 35.0,
        "average": 32.5
      },
      "rationale_metrics": {
        "rouge_l": 0.0967741935483871,
        "text_similarity": 0.13790470361709595,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction preserves the order (target follows anchor) but the reported times are substantially incorrect compared to the reference (predicted 160s/163s vs. ground truth 177.5\u2013179.5s and 190.0\u2013198.0s), so it fails to match the key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker starts talking about how a lot of malpractice lawsuits have been documented, when does he explicitly advise being aware of communication's importance to avoid lawsuits?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 226.0,
        "end": 271.0
      },
      "pred_interval": {
        "start": 170.0,
        "end": 173.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.0,
        "end": 98.0,
        "average": 77.0
      },
      "rationale_metrics": {
        "rouge_l": 0.125,
        "text_similarity": 0.372012197971344,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives timestamps (170s\u2013173s) that conflict with the reference (anchor 198\u2013212s, target 226\u2013271s) and misplaces the advice sequence; it therefore fails to match the correct timings and sequence despite touching the same topic."
      }
    },
    {
      "question_id": "001",
      "question": "After the initial slide 'Communication is not just talking' is displayed, when does the speaker mention that physicians can improve health outcomes?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 339.28,
        "end": 346.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 340.0
      },
      "iou": 0.045000000000001705,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.279999999999973,
        "end": 6.0,
        "average": 7.639999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.29629629629629634,
        "text_similarity": 0.37426504492759705,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the event occurs after the slide (matching the key temporal relation) but fails to provide the specific timing details given in the reference (start/end timestamps 339.28s\u2013346.0s), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide showing two images (bored girl vs. smiling doctor/patient), when does the speaker describe the first image as depicting a 'horribly bored' lady?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.8,
        "end": 359.0
      },
      "pred_interval": {
        "start": 360.0,
        "end": 370.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.199999999999989,
        "end": 11.0,
        "average": 8.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.3492063492063492,
        "text_similarity": 0.5824224948883057,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the 'horribly bored' description occurs while the slide is displayed, but it omits the specific timing details (E1 347.8\u2013410.7s; E2 354.8\u2013359.0s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker defines verbal communication as 'using spoken words', when is the next time they define non-verbal communication?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 428.87,
        "end": 433.596
      },
      "pred_interval": {
        "start": 400.0,
        "end": 410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.870000000000005,
        "end": 23.596000000000004,
        "average": 26.233000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.16,
        "text_similarity": 0.3938060998916626,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that the non-verbal definition occurs after the verbal one, but it omits the specific timing/timestamps and immediacy details given in the correct answer, so it's incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the 'golden minute', when does he describe the patient's hypothetical response?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 613.818,
        "end": 630.0
      },
      "pred_interval": {
        "start": 512.0,
        "end": 513.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 101.81799999999998,
        "end": 117.0,
        "average": 109.40899999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.39344262295081966,
        "text_similarity": 0.5535075664520264,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (512.0s and 513.0s) do not match the ground-truth anchor (568.746\u2013569.929s) or target (613.818\u2013629.974s); it is therefore factually incorrect about when the patient's hypothetical response occurs."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions 'Checking facts', when does he mention the next essential element of listening?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 641.157,
        "end": 642.461
      },
      "pred_interval": {
        "start": 546.0,
        "end": 547.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 95.15700000000004,
        "end": 95.46100000000001,
        "average": 95.30900000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.45390480756759644,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives wrong timestamps and fails to identify 'Checking feelings' as the next element after 'Checking facts', only vaguely claiming the next item occurs one second later, which contradicts the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Before the speaker says 'So, for example, we have three main types of reflective listening', when does he explain what reflective listening involves?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 667.457,
        "end": 687.051
      },
      "pred_interval": {
        "start": 559.0,
        "end": 560.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 108.457,
        "end": 127.05100000000004,
        "average": 117.75400000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.17857142857142855,
        "text_similarity": 0.4996286630630493,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (559.0s) is incorrect and contradicts the ground truth, which locates the definition at 667.457\u2013672.051s before the examples; thus it fails to align with the correct timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the three main types of reflective listening, when does he start explaining the 'Repeating' example?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 710.0,
        "end": 737.0
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.18518518518518517,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.0,
        "end": 7.0,
        "average": 11.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367344,
        "text_similarity": 0.5007836818695068,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the 'Repeating' example occurs after the three types are mentioned) but omits the key factual details\u2014specific start/end timestamps and exact timing\u2014provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the 'Repeating' example, when does he introduce 'Rephrasing'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 720.0,
        "end": 720.4
      },
      "pred_interval": {
        "start": 740.0,
        "end": 745.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.0,
        "end": 24.600000000000023,
        "average": 22.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.6480039358139038,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relation that 'Rephrasing' follows the end of 'Repeating', but it omits the key factual details (the specific timestamps 698.0s and 720.0s and the quoted phrase) required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing 'Reflection of feeling by showing empathy', when does the 'Non-verbal' slide appear?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 780.0,
        "end": 821.5
      },
      "pred_interval": {
        "start": 800.0,
        "end": 805.0
      },
      "iou": 0.12048192771084337,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.0,
        "end": 16.5,
        "average": 18.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3255813953488372,
        "text_similarity": 0.6095125675201416,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relation that the 'Non-verbal' slide appears once the speaker finishes discussing empathy, but it omits the specific timestamps (778.5s and 780.0s) given in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises to smile, when does he mention checking for signs of pain?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.045,
        "end": 882.0
      },
      "pred_interval": {
        "start": 925.0,
        "end": 926.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.95500000000004,
        "end": 44.0,
        "average": 47.97750000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.6295635104179382,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the check for pain occurs after the smile instruction, but it is vague and omits the specific timing details (starts at ~873.045s and runs until ~882.0s) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the cultural interpretations of folding arms, when does he advise to avoid folding arms?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 932.0,
        "end": 936009.0
      },
      "pred_interval": {
        "start": 947.0,
        "end": 948.0
      },
      "iou": 1.0694306458184727e-06,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.0,
        "end": 935061.0,
        "average": 467538.0
      },
      "rationale_metrics": {
        "rouge_l": 0.23809523809523808,
        "text_similarity": 0.5675935745239258,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the advice comes after the cultural discussion but omits the required timing information (932.0s\u2013936.009s) and other specific timestamps, so key factual details are missing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker instructs to introduce yourself to the patient, when does he advise to explain your role as a student or intern?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 985.0,
        "end": 990.853
      },
      "pred_interval": {
        "start": 952.0,
        "end": 953.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.0,
        "end": 37.85299999999995,
        "average": 35.426499999999976
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.4328717291355133,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the advice comes after the introduction (relative order) but fails to provide the specific timing (985.0\u2013990.1s) and omits the key detail about explaining the role to gain consent, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"if you're in the hospital\", when does he refer to \"inpatient patients\"?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1059.6,
        "end": 1059.8
      },
      "pred_interval": {
        "start": 1056.0,
        "end": 1057.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.599999999999909,
        "end": 2.7999999999999545,
        "average": 3.199999999999932
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": -0.009292570874094963,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the phrase occurs after the anchor remark, but it omits the precise timestamps and imprecisely claims it happens 'right after' when the target is a few seconds later (1059.6s vs 1055.5\u20131056.8s)."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining how to start a consultation, when does he give the example \"how can I help you today?\"",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1069.0,
        "end": 1070.0
      },
      "pred_interval": {
        "start": 1084.0,
        "end": 1086.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.0,
        "end": 16.0,
        "average": 15.5
      },
      "rationale_metrics": {
        "rouge_l": 0.07142857142857142,
        "text_similarity": 0.11140402406454086,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the example occurs while explaining how to start a consultation, but it fails to provide the requested timing (1064.5\u20131067.5 and 1069.0\u20131070.0) and anchor/target details, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes explaining the 'golden minute', when does he announce the end of the lecture?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1090.0,
        "end": 1094.0
      },
      "pred_interval": {
        "start": 1119.0,
        "end": 1120.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.0,
        "end": 26.0,
        "average": 27.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.23168691992759705,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the announcement occurs after the 'golden minute' explanation, but it omits the key factual details and timestamps (anchor at 1089.0s and target at 1090.0\u20131094.0s) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "While Raquel is talking about the hospital providing opportunities for nurses, when is she shown smiling and opening a package?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 2.0,
        "end": 4.5
      },
      "pred_interval": {
        "start": 2.0,
        "end": 4.0
      },
      "iou": 0.8,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.0,
        "end": 0.5,
        "average": 0.25
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307693,
        "text_similarity": 0.2517625093460083,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted time 0:02\u20130:04 (2\u20134s) falls within the reference visual event window (2.0\u20134.5s) and correctly indicates it occurs during her speech, matching the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria finishes saying that new nurses will be nudged to become lifelong learners, when does Precious state that the teamwork is strong?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 14.321,
        "end": 16.486
      },
      "pred_interval": {
        "start": 35.0,
        "end": 37.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.679000000000002,
        "end": 20.514,
        "average": 20.5965
      },
      "rationale_metrics": {
        "rouge_l": 0.1379310344827586,
        "text_similarity": 0.3139212727546692,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (0:35\u20130:37) are far off from the ground-truth times (~14.301\u201316.486s), so the answer is essentially incorrect about when Precious speaks; formats differ and key timing details are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After Reny states that the hospital does things up to a magnet level, when does Raquel say her values align with the hospital's values?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 42.854,
        "end": 50.692
      },
      "pred_interval": {
        "start": 51.0,
        "end": 52.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.146,
        "end": 1.3079999999999998,
        "average": 4.727
      },
      "rationale_metrics": {
        "rouge_l": 0.14084507042253522,
        "text_similarity": 0.3268352150917053,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamps (0:51\u20130:52) do not match the correct times (Reny ends at 42.473s; Raquel 42.854\u201350.692s) and incorrectly collapses both events into the same one-second interval, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that healthcare in Siem Reap is not the best, when is the Royal Angkor International Hospital first shown on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 94.0,
        "end": 99.1
      },
      "pred_interval": {
        "start": 125.0,
        "end": 130.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.0,
        "end": 30.900000000000006,
        "average": 30.950000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.253968253968254,
        "text_similarity": 0.5122820734977722,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the hospital appears after the speaker's remark, but it omits the key quantitative details (visual start at 94.0s and description start at 99.100s) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he visited a clinic for chest congestion, when does he mention the Paschern Dental Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 209.8,
        "end": 211.4
      },
      "pred_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.19999999999999,
        "end": 28.599999999999994,
        "average": 26.89999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705885,
        "text_similarity": 0.5844614505767822,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the Paschern Dental Clinic is mentioned after the chest-congestion clinic) but omits the precise time intervals and event labels provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he introduce the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.0,
        "end": 184.8
      },
      "pred_interval": {
        "start": 240.0,
        "end": 245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.0,
        "end": 60.19999999999999,
        "average": 58.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.474398136138916,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the clinic is introduced immediately after the hospital) but omits the specific timestamps and interval details (182.0s and 184.0\u2013184.8s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker introduces the Cigna International Health Policy, when is the insurance quote form displayed with personal information?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 265.0,
        "end": 270.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 86.0,
        "end": 90.0,
        "average": 88.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307692,
        "text_similarity": 0.6136257648468018,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the required timestamps; it also asserts a simple 'introduction before form' ordering that contradicts the detailed temporal information in the reference (which specifies exact times and the relation), so it is largely incomplete/incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the voiceover states that the Cigna policy is \"fairly typical of policies of this type\", when does the Cigna website display the form for inputting personal details to get a quote?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 352.9,
        "end": 358.0
      },
      "pred_interval": {
        "start": 345.0,
        "end": 346.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.899999999999977,
        "end": 12.0,
        "average": 9.949999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290322,
        "text_similarity": 0.4891699552536011,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the form appears after the voiceover (matching the relative order) but omits the key timing details and duration (352.9s\u2013358.0s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the voiceover mentions \"evacuation service, also part of Cigna plan\", when is the Global Rescue website displayed on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 384.0,
        "end": 431.0
      },
      "pred_interval": {
        "start": 417.0,
        "end": 418.0
      },
      "iou": 0.02127659574468085,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.0,
        "end": 13.0,
        "average": 23.0
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413793,
        "text_similarity": 0.6910871863365173,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the website appears after the voiceover but omits key factual details from the reference (specific timestamps 379.0s, 384.0s, and display until 431.0s and anchor/target relation), so it's incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the host concludes his introduction about the fight in modern healthcare, when does he introduce Sarah?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 19.4,
        "end": 22.0
      },
      "pred_interval": {
        "start": 19.0,
        "end": 20.0
      },
      "iou": 0.20000000000000048,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3999999999999986,
        "end": 2.0,
        "average": 1.1999999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.34615384615384615,
        "text_similarity": 0.6235535144805908,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (Sarah is introduced after the host's remark) and gives approximate times, but the timestamps are inaccurate (18.0s vs 19.0s and 19.4s vs 20.0s) and it omits Sarah's end time, so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "While Sarah is introducing herself and her genetic condition, when does she mention having her very first surgery?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.08,
        "end": 108.8
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 69.08,
        "end": 72.19999999999999,
        "average": 70.63999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1875,
        "text_similarity": 0.4681076109409332,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect: it places the first-surgery mention at 35.0s and cites a line about being born with the condition, whereas the ground truth locates the first-surgery mention at 104.08\u2013108.08s, contradicting the correct timing and content."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sarah finishes describing her role as a volunteer patient representative for a non-profit organization, when does the static image showing her behind a 'CHILDREN'S TUMOR FOUNDATION' table appear?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 185.0,
        "end": 190.0
      },
      "pred_interval": {
        "start": 150.0,
        "end": 162.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.0,
        "end": 28.0,
        "average": 31.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.4903714060783386,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states the static image appears immediately after Sarah finishes speaking, matching the reference's relative timing (the target follows the anchor); no incorrect details or hallucinations are introduced."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes explaining the purpose of the 'Shine a Light Walk' to raise money and awareness, when does the video clip showing children running at an outdoor event play?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 189.0,
        "end": 192.0
      },
      "pred_interval": {
        "start": 162.0,
        "end": 174.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.0,
        "end": 18.0,
        "average": 22.5
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.5547777414321899,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction omits the provided timestamps and asserts the clip plays immediately when Sarah finishes, which contradicts the ground truth timeline (Sarah at 179.0s; clip at 189.0\u2013192.0s) and thus lacks key factual detail."
      }
    },
    {
      "question_id": "003",
      "question": "Once Steve asks if the 'Shine a Light Walk' goes throughout the world, when does Sarah begin to explain that the walks do not?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 253.2,
        "end": 258.88
      },
      "pred_interval": {
        "start": 174.0,
        "end": 186.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.19999999999999,
        "end": 72.88,
        "average": 76.03999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1090909090909091,
        "text_similarity": 0.325182169675827,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that Sarah responds immediately to Steve's question, but it omits the key factual timing details (Steve at 252.5s; Sarah from 253.2s to 258.88s) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes asking Sarah what things in miscommunication can lead to delays or misdiagnosis, when does the woman start responding?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 362.48,
        "end": 365.44
      },
      "pred_interval": {
        "start": 330.0,
        "end": 342.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.48000000000002,
        "end": 23.439999999999998,
        "average": 27.960000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5550012588500977,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that the woman speaks immediately after the man, but it gives a wrong absolute timestamp (330.0s vs ~361.9s\u2192362.48s) and thus contradicts the reference's precise timing."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman gives the example of writing 'hyperthyroid instead of hypothyroid', when does the man respond with 'That that's pretty bad'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 389.2,
        "end": 432.5
      },
      "pred_interval": {
        "start": 342.0,
        "end": 346.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.19999999999999,
        "end": 86.5,
        "average": 66.85
      },
      "rationale_metrics": {
        "rouge_l": 0.15625,
        "text_similarity": 0.36997997760772705,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (342.0s) contradicts the ground-truth timing (man speaks at ~389.2s after the woman's example at 385.28\u2013388.44s); it misplaces the event and is therefore incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the man says he tried researching miscommunication problems, when does he state his finding about thousands of preventable deaths?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 446.56,
        "end": 535.68
      },
      "pred_interval": {
        "start": 375.0,
        "end": 380.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.56,
        "end": 155.67999999999995,
        "average": 113.61999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.3902602791786194,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (375.0s) is completely inconsistent with the reference (446.56s\u2013451.68s); it contradicts the correct timing and omits the noted temporal separation between the two statements."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks, \"What's in my budget to fix it?\", when does she start asking, \"How important is it to me to fix this issue?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 518.66,
        "end": 522.26
      },
      "pred_interval": {
        "start": 512.0,
        "end": 513.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.659999999999968,
        "end": 9.259999999999991,
        "average": 7.9599999999999795
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814814,
        "text_similarity": 0.09410473704338074,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction provides no timestamps and fails to state when the target question begins; it also nonsensically restates the same budget question rather than indicating that the target question occurs after the anchor as in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the man finishes saying, \"not continuing medical bills,\" when does he start asking, \"So, what does successful self-advocacy look like?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 643.04,
        "end": 646.32
      },
      "pred_interval": {
        "start": 647.0,
        "end": 648.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.9600000000000364,
        "end": 1.67999999999995,
        "average": 2.819999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.12244897959183673,
        "text_similarity": 0.2121324986219406,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and does not provide the requested timestamps; it introduces 'follow-up process' (a detail not in the reference) and fails to match the correct timing information and key facts."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining what a doctor's follow-up might entail, when does the woman start asking, \"Or will I actually be able to get into your office in two weeks?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 679.0,
        "end": 683.92
      },
      "pred_interval": {
        "start": 695.0,
        "end": 696.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.0,
        "end": 12.080000000000041,
        "average": 14.04000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.19230769230769232,
        "text_similarity": 0.1671600043773651,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the woman asks after the man finishes, but it omits the key factual details (the specific timestamps 679.00\u2013683.92s and the end time 677.92s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Immediately after the woman asks if she should follow up if she is still experiencing symptoms, when does the man ask what if the symptoms go away?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.38,
        "end": 707.15
      },
      "pred_interval": {
        "start": 70.0,
        "end": 72.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 629.38,
        "end": 635.15,
        "average": 632.265
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.42288315296173096,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that the man's question immediately follows the woman's, but it omits the specific timing details (start/end timestamps and seconds) provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying to voice symptoms and concerns clearly, when does he give an example about shoulder pain?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 734.59,
        "end": 737.0
      },
      "pred_interval": {
        "start": 165.0,
        "end": 168.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 569.59,
        "end": 569.0,
        "average": 569.2950000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2181818181818182,
        "text_similarity": 0.3920268416404724,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the shoulder-pain example follows the man's instruction, but it omits the precise timestamps and duration given in the reference and does not state that the target immediately follows the anchor."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes warning not to try putting a hand in an electrical outlet, when does the woman agree and say not to try that?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 810.0,
        "end": 812.0
      },
      "pred_interval": {
        "start": 240.0,
        "end": 242.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 570.0,
        "end": 570.0,
        "average": 570.0
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.2417798638343811,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the woman agrees after the man finishes, but it omits the required specific timing (E1 ends at 808s; E2 810.0\u2013812.0s) and thus lacks the key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes saying to assume benevolence of your doctor, when does the man begin to speak?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.9,
        "end": 879.1
      },
      "pred_interval": {
        "start": 870.0,
        "end": 872.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.899999999999977,
        "end": 7.100000000000023,
        "average": 8.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2978723404255319,
        "text_similarity": 0.5196412205696106,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the man speaks immediately after the woman, but it omits the precise timing (878.0s and 878.9s) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks about trying non-surgical options first, when does the woman reply 'Yes'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 899.7,
        "end": 900.1
      },
      "pred_interval": {
        "start": 945.0,
        "end": 946.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.299999999999955,
        "end": 45.89999999999998,
        "average": 45.599999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.21818181818181814,
        "text_similarity": 0.5067092180252075,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation\u2014the woman says 'Yes' immediately after the man asks\u2014matching the reference's 'once finished' timing (899.7s vs 899.5s). It is a faithful paraphrase without adding or contradicting details."
      }
    },
    {
      "question_id": "003",
      "question": "After the man concludes his statement about how to ask for another opinion, when does the woman respond that asking for another opinion is definitely valid?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 982.0,
        "end": 988.72
      },
      "pred_interval": {
        "start": 1065.0,
        "end": 1066.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.0,
        "end": 77.27999999999997,
        "average": 80.13999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.16129032258064516,
        "text_similarity": 0.31446248292922974,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the woman responds after the man), but it omits the key factual details required by the correct answer\u2014specific event labels and timestamps (E1 at 976.0s and E2 at ~982s)."
      }
    },
    {
      "question_id": "001",
      "question": "After the man suggests bringing someone along if you're not feeling safe, when does the woman agree that it's advisable?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1127.0,
        "end": 1130.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1060.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.0,
        "end": 70.0,
        "average": 73.5
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814817,
        "text_similarity": 0.39667391777038574,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (1050.0s) does not match the correct event time (woman's agreement at 1127.0s); it is factually incorrect and misses the target event."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman talks about a doctor not trusting a patient's pain because they don't act like they're in pain, when does she give an example of a loved one vouching for the patient?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1167.68,
        "end": 1174.48
      },
      "pred_interval": {
        "start": 1070.0,
        "end": 1080.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.68000000000006,
        "end": 94.48000000000002,
        "average": 96.08000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.26229508196721313,
        "text_similarity": 0.5296047925949097,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (1070.0s) contradicts the reference, which places the example at ~1167.68\u20131174.48s; the prediction is incorrect and does not match the event timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks if it is legal to be given your own medical records, when does the woman confirm that it is?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1268.6,
        "end": 1270.7
      },
      "pred_interval": {
        "start": 1345.0,
        "end": 1350.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.40000000000009,
        "end": 79.29999999999995,
        "average": 77.85000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.17857142857142855,
        "text_similarity": 0.07954246550798416,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the woman's confirmation follows the man's question, but it omits the specific timing information (the provided start/end timestamps and the absolute\u2192relative judgement) required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman mentions that things have changed a lot with electronic medical records, when does the man state that bureaucracy reminds him of common barriers?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1333.0,
        "end": 1339.5
      },
      "pred_interval": {
        "start": 1395.0,
        "end": 1400.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.0,
        "end": 60.5,
        "average": 61.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454545,
        "text_similarity": 0.2983708381652832,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the man's remark occurs after the woman's comment, but it omits the key detail that this occurs significantly later and provides no timing information as given in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks about common barriers and how to overcome them, when does the woman share her fear of ants?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.36,
        "end": 1383.7
      },
      "pred_interval": {
        "start": 1425.0,
        "end": 1430.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.6400000000001,
        "end": 46.299999999999955,
        "average": 46.97000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.326530612244898,
        "text_similarity": 0.2614273428916931,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly and concisely states that the woman shares her fear after the man\u2019s question about barriers, matching the reference's relative timing despite omitting exact timestamps."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says to write things down on paper and give it to the doctor, when does he mention a doctor refusing to look at the paper?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1484.96,
        "end": 1490.0
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 105.03999999999996,
        "end": 110.0,
        "average": 107.51999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.3300743103027344,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the key temporal relation that the doctor\u2019s refusal is mentioned after the instruction to write and give the paper, but it omits the specific timestamps and precise timing nuance provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the woman discusses prioritizing cognition, when does she state that she would rather be in pain than have her mental capacity harmed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1534.64,
        "end": 1542.24
      },
      "pred_interval": {
        "start": 1570.0,
        "end": 1580.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.3599999999999,
        "end": 37.75999999999999,
        "average": 36.559999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.3846153846153847,
        "text_similarity": 0.6740221977233887,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that she makes the remark during a discussion of prioritizing cognition, but it fails to provide the required timing/segment details and specific quote (anchor/target timestamps), omitting key factual elements. "
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'Nord, what is that?', when does the woman state what NORD stands for?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.4,
        "end": 1615.4
      },
      "pred_interval": {
        "start": 1625.0,
        "end": 1630.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.599999999999909,
        "end": 14.599999999999909,
        "average": 13.099999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222218,
        "text_similarity": 0.6175254583358765,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately conveys the key relation \u2014 the woman states what NORD stands for immediately after the man asks \u2014 matching the correct answer's relative timing; no factual elements are contradicted or added."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says 'I read that I need to start this at 30', when does she explain why she needs the doctor to order it?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1692.24,
        "end": 1711.28
      },
      "pred_interval": {
        "start": 1745.0,
        "end": 1750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.75999999999999,
        "end": 38.72000000000003,
        "average": 45.74000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2702702702702703,
        "text_similarity": 0.4213162064552307,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately captures the correct answer's meaning that she explains why she needs the doctor to order it immediately after saying 'I read that I need to start this at 30,' matching the direct continuation described."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman explains how to mirror a planned course of action, when does she suggest asking the doctor what they heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.0,
        "end": 1799.8
      },
      "pred_interval": {
        "start": 178.0,
        "end": 182.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1619.0,
        "end": 1617.8,
        "average": 1618.4
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.07396456599235535,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction only restates that the suggestion comes after the explanation, but fails to provide the requested timing/relative detail (the target follows after a brief note about miscommunication at ~1797\u20131799.8s) and is therefore incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the man advises to 'just dig' and not use a medical dictionary, when does he ask if medical language can be 'dumbed down'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1836.56,
        "end": 1841.52
      },
      "pred_interval": {
        "start": 205.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1631.56,
        "end": 1631.52,
        "average": 1631.54
      },
      "rationale_metrics": {
        "rouge_l": 0.07142857142857142,
        "text_similarity": -0.06307554990053177,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the event occurs after the 'just dig' advice, but it omits the key factual elements from the reference (the specific anchor/target timestamps and the note about following discussion of complex terminology), so it's incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks what to do when doctors look rushed, when does the woman describe slowing down and capturing their attention?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1965.6,
        "end": 1973.5
      },
      "pred_interval": {
        "start": 24.0,
        "end": 35.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1941.6,
        "end": 1938.5,
        "average": 1940.05
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.2742837965488434,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the temporal relation that the woman\u2019s description occurs after the man\u2019s question, but it omits the precise timestamps and event boundaries (1953.8s anchor; 1965.6\u20131973.5s target) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes suggesting a doctor might be having a bad day, when does the man humorously ask if doctors have bad days?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2002.5,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 69.0,
        "end": 70.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1933.5,
        "end": 1934.0,
        "average": 1933.75
      },
      "rationale_metrics": {
        "rouge_l": 0.16393442622950816,
        "text_similarity": 0.38186219334602356,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that the man's question follows the woman's suggestion, but it omits the crucial timing details (the specific start/end times and that the target directly follows the anchor), so it is incomplete relative to the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the man introduces the 'five practical tips to advocate for yourself', when does the woman begin talking about writing down questions?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2195.28,
        "end": 2199.7
      },
      "pred_interval": {
        "start": 2340.0,
        "end": 2340.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 144.7199999999998,
        "end": 140.30000000000018,
        "average": 142.51
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.06357695162296295,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the woman speaks after the man (right order) but incorrectly claims it was 'immediately after'; the reference timestamps show the target occurs about 15\u201325 seconds later, so the timing is wrong."
      }
    },
    {
      "question_id": "002",
      "question": "During the man's explanation about preparing beforehand, when does he demonstrate by pointing to his neck?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.0,
        "end": 2237.0
      },
      "pred_interval": {
        "start": 2340.0,
        "end": 2340.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 105.0,
        "end": 103.0,
        "average": 104.0
      },
      "rationale_metrics": {
        "rouge_l": 0.25000000000000006,
        "text_similarity": 0.3723754286766052,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the pointing occurs during his explanation but is vague and implies it happens immediately when he starts, omitting the key timing (pointing at 2235\u20132237, about 10s after the speech start) and thus lacks necessary precision."
      }
    },
    {
      "question_id": "001",
      "question": "After the man describes getting dizzy when walking up and down stairs, when does the woman mention repeating back what was heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2316.0,
        "end": 2317.0
      },
      "pred_interval": {
        "start": 2345.0,
        "end": 2360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.0,
        "end": 43.0,
        "average": 36.0
      },
      "rationale_metrics": {
        "rouge_l": 0.1724137931034483,
        "text_similarity": 0.5041871070861816,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') between the two events, but it omits the specific timestamps and event labels provided in the correct answer, which are key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman expresses her inability to distract herself from the pain, when does the man advise her to be specific?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.7,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2470.0,
        "end": 2480.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 101.30000000000018,
        "end": 110.5,
        "average": 105.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.16,
        "text_similarity": 0.5041208863258362,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') between the two events, but it omits the specific event timestamps and event identifiers provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says 'document everything', when does the woman affirm the advice and tell viewers to take notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2504.5,
        "end": 2506.0
      },
      "pred_interval": {
        "start": 2536.0,
        "end": 2540.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.5,
        "end": 34.0,
        "average": 32.75
      },
      "rationale_metrics": {
        "rouge_l": 0.12,
        "text_similarity": 0.28470826148986816,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect on both timing (2536.0s vs correct 2504.5\u20132506.0s) and content (wrong quote and omits the 'please do take notes' instruction), so it does not match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes asking if one should ask permission before recording their doctor, when does the woman respond?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2531.6,
        "end": 2533.5
      },
      "pred_interval": {
        "start": 2540.0,
        "end": 2541.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.400000000000091,
        "end": 7.5,
        "average": 7.9500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.4849562644958496,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states she responds immediately after but gives a timestamp (2540.0s) that is ~8.4 seconds later than the correct start time (2531.6s) and omits the response end time, so it is factually inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman begins explaining the hope that doctors will focus more on patients with AI recording, when does she explain why she almost always checks her online appointment notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.0,
        "end": 2579.0
      },
      "pred_interval": {
        "start": 2541.0,
        "end": 2547.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.0,
        "end": 32.0,
        "average": 28.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23880597014925373,
        "text_similarity": 0.42325663566589355,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives a much earlier timestamp (2541.0s) and a different utterance about electronic forms, not the woman's explanation about checking online appointment notes which occurs at 2566.0\u20132579.0s."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks if one should be assertive, when does he introduce the topic of emotional intelligence?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2701.0,
        "end": 2710.0
      },
      "pred_interval": {
        "start": 2765.0,
        "end": 2768.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.0,
        "end": 58.0,
        "average": 61.0
      },
      "rationale_metrics": {
        "rouge_l": 0.38596491228070173,
        "text_similarity": 0.7168939113616943,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the topic is introduced immediately after the question, but it gives an incorrect timestamp for the question (2765.0s vs 2696.0s) and omits the E2 interval (2701.0\u20132710.0)."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man says 'You wanna learn some breathing control', when does he start describing box breathing?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.0,
        "end": 2747.0
      },
      "pred_interval": {
        "start": 2793.0,
        "end": 2794.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.0,
        "end": 47.0,
        "average": 50.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4067796610169492,
        "text_similarity": 0.751072883605957,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (description follows the prompt) but gives substantially incorrect timestamps (off by ~50\u201360 seconds) and the timing relation (1s delay vs. the reference's specified start at 2740s) is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "While the man is saying 'If you want, share your story in the comments', when is the 'COMMENT BELOW' graphic displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2976.0,
        "end": 2976.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.0,
        "end": 53.0,
        "average": 54.5
      },
      "rationale_metrics": {
        "rouge_l": 0.19444444444444445,
        "text_similarity": 0.21015381813049316,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly asserts the graphic coincides with the man's utterance but wrongly describes it as an instantaneous moment and omits the precise timing and continuous display during the speech (2920.0\u20132923.0s), so it is incomplete/misleading."
      }
    },
    {
      "question_id": "003",
      "question": "After the thumbs up icon appears on screen, when is the next graphic ('COMMENT BELOW') displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2985.0,
        "end": 2985.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.0,
        "end": 62.0,
        "average": 63.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3448275862068966,
        "text_similarity": 0.7364129424095154,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is incorrect and contradictory: it misstates the thumbs-up time (2985s vs correct 2862s) and falsely claims the 'COMMENT BELOW' appears immediately after, whereas the correct next graphic appears at 2920.0s (not immediately)."
      }
    },
    {
      "question_id": "001",
      "question": "After Marissa Fourie introduces herself, when does she mention cross-cultural communication?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 34.2,
        "end": 36.5
      },
      "pred_interval": {
        "start": 25.0,
        "end": 26.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.200000000000003,
        "end": 10.5,
        "average": 9.850000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.4102564102564103,
        "text_similarity": 0.6051294207572937,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the relation (after the introduction) but gives an incorrect timestamp (25.0s) and omits the actual interval (34.2s\u201336.5s), so it is factually inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After mentioning cross-cultural communication, when does Marissa Fourie next mention personality-specific communication skills?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 37.0,
        "end": 39.0
      },
      "pred_interval": {
        "start": 37.0,
        "end": 38.0
      },
      "iou": 0.5,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.0,
        "end": 1.0,
        "average": 0.5
      },
      "rationale_metrics": {
        "rouge_l": 0.5217391304347827,
        "text_similarity": 0.5978027582168579,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer correctly identifies the next mention of personality-specific communication skills at 37.0s, matching the reference start time and relation; it omits ancillary end and prior-start details but captures the required information."
      }
    },
    {
      "question_id": "003",
      "question": "After encouraging viewers to join PhysioPlus, when does Marissa Fourie say 'See you there!'?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 62.9,
        "end": 63.7
      },
      "pred_interval": {
        "start": 49.0,
        "end": 50.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.899999999999999,
        "end": 13.700000000000003,
        "average": 13.8
      },
      "rationale_metrics": {
        "rouge_l": 0.30434782608695654,
        "text_similarity": 0.48667779564857483,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a substantially incorrect timestamp (49.0s) for 'See you there!' whereas the correct timing is 62.9\u201363.7s; it also omits the end time. It correctly implies the phrase occurs after the encouragement but is factually wrong on timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes mentioning \"the dosage in each area\", when does the woman in blue gloves point to the glabella area of the patient's forehead?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 4.469,
        "end": 4.8
      },
      "pred_interval": {
        "start": 3.6,
        "end": 4.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8690000000000002,
        "end": 0.5999999999999996,
        "average": 0.7344999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.3778718113899231,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') but omits all precise timing details and pointer visibility durations provided in the ground truth, making it incomplete for a video-timestamp question."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the dosage for the brow lift, when does the woman in blue gloves point to the patient's upper lip?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 12.121,
        "end": 12.5
      },
      "pred_interval": {
        "start": 10.9,
        "end": 11.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.221,
        "end": 1.0,
        "average": 1.1105
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454546,
        "text_similarity": 0.4368361234664917,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (pointing occurs once the speaker finishes), but it omits the key factual timestamps and the pointer visibility duration (12.080s, 12.121s, visible until 12.500s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the dosage for the lip flip, when does the text \"TIME TO INJECT!\" appear on screen?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 18.291,
        "end": 21.0
      },
      "pred_interval": {
        "start": 17.8,
        "end": 18.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.49099999999999966,
        "end": 3.0,
        "average": 1.7454999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.163265306122449,
        "text_similarity": 0.44668594002723694,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relation that the text appears once the speaker finishes, but it omits the key factual details of the precise timestamps (E1 at 15.067s, E2 at 18.291s) and that the text remains until the end, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host welcomes Rich, when does Rich begin his response?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 33.015,
        "end": 34.078
      },
      "pred_interval": {
        "start": 21.0,
        "end": 23.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.015,
        "end": 11.078000000000003,
        "average": 11.546500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.21621621621621623,
        "text_similarity": 0.5638200640678406,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that Rich begins immediately after the host welcomes him, matching the key relation, but it omits the precise timestamps (31.333s and 33.015s) provided in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While Rich is explaining how medicine may have let relationships with patients deteriorate, when does he say that scientific facts will protect us?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 89.0,
        "end": 93.76
      },
      "pred_interval": {
        "start": 59.0,
        "end": 61.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.0,
        "end": 32.760000000000005,
        "average": 31.380000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.043478260869565216,
        "text_similarity": 0.1742752194404602,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that he mentions scientific facts during that explanation but omits the requested timing details (start at 73.611s and the phrase at 89.0\u201393.760s), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks what trust looks like in the future with intermediaries, when does Rich first discuss the stethoscope in relation to technology in medicine?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 112.0,
        "end": 113.0
      },
      "pred_interval": {
        "start": 107.0,
        "end": 108.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 5.0,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.3404194414615631,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that Rich's stethoscope discussion occurs after the host's question, but it fails to provide the specific timestamps (106.718s and 112.700s) requested, omitting key factual details about when it occurs."
      }
    },
    {
      "question_id": "001",
      "question": "After the man in glasses finishes describing the giant TV screen in a new hospital exam room, when does the video show a patient interacting with a screen in a hospital bed?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 167.6,
        "end": 177.6
      },
      "pred_interval": {
        "start": 152.0,
        "end": 163.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.599999999999994,
        "end": 14.599999999999994,
        "average": 15.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.4540618062019348,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the relative order (the patient appears after the man finishes), but it omits the key factual details from the ground truth\u2014specific start/end timestamps (167.6s\u2013177.6s and 152.8s anchor end) and precise timing information required by the question."
      }
    },
    {
      "question_id": "002",
      "question": "While the interviewer asks if technology can bring doctors and patients closer together, when is he holding a small white 'Trust tv' card?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 178.0,
        "end": 183.5
      },
      "pred_interval": {
        "start": 194.0,
        "end": 200.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.0,
        "end": 16.5,
        "average": 16.25
      },
      "rationale_metrics": {
        "rouge_l": 0.12903225806451615,
        "text_similarity": 0.33096495270729065,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the interviewer is holding the 'Trust tv' card while asking that question, but it omits the key temporal details (the 178.0s\u2013183.5s interval and that the card is held throughout that speech segment) present in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the interviewer thanks Rich and says viewers learned a lot, when does Rich respond 'It's really a pleasure'?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 210.3,
        "end": 212.1
      },
      "pred_interval": {
        "start": 220.0,
        "end": 228.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.699999999999989,
        "end": 15.900000000000006,
        "average": 12.799999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290322,
        "text_similarity": 0.4567953050136566,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction merely restates that Rich replies after the interviewer thanks him but gives no timing or segment details (timestamps/relative boundaries) from the ground truth, omitting key factual information."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions learning about 'patient rapport', when does he discuss charting and interacting with other healthcare providers?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 2.075,
        "end": 9.55
      },
      "pred_interval": {
        "start": 0.0,
        "end": 12.0
      },
      "iou": 0.6229166666666667,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.075,
        "end": 2.4499999999999993,
        "average": 2.2624999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.4193548387096775,
        "text_similarity": 0.6470878720283508,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that the discussion of charting and interacting with other providers follows the mention of patient rapport (shortly after/at the beginning), but it omits the precise timestamps and the explicit 'once_finished' relation given in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker talks about developing skills like putting an IV, when does he mention getting a patient discharged?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 15.42,
        "end": 24.583
      },
      "pred_interval": {
        "start": 12.0,
        "end": 24.0
      },
      "iou": 0.6818723674799333,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.42,
        "end": 0.5829999999999984,
        "average": 2.001499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.26086956521739124,
        "text_similarity": 0.4481467008590698,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly states the discharge occurs at ~12.0s, whereas the reference places the discharge at 15.420\u201324.583s immediately after the IV segment (9.689\u201315.441s); this is a factual timing error."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Make their problem, your problem', when does he introduce the importance of self-care?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 45.009,
        "end": 48.396
      },
      "pred_interval": {
        "start": 24.0,
        "end": 36.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.009,
        "end": 12.396,
        "average": 16.7025
      },
      "rationale_metrics": {
        "rouge_l": 0.2898550724637681,
        "text_similarity": 0.5927910208702087,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (~24.0s) contradicts the reference, which places the self-care remark at ~45.0s after the 'Make their problem' statement, so the prediction is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker's introduction of herself, when does she mention specializing in wounds?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.605,
        "end": 26.329
      },
      "pred_interval": {
        "start": 0.0,
        "end": 2.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.605,
        "end": 24.329,
        "average": 23.467
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.32426372170448303,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes a self-introduction occurs early, but it is vague and omits the key factual details\u2014the speaker's name, the specific mention of specializing in wounds, and the timestamps provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of 'getting the most out of your GP consultation', when does she mention that GP practices are getting a huge injection of funding?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.82,
        "end": 75.533
      },
      "pred_interval": {
        "start": 15.0,
        "end": 17.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.81999999999999,
        "end": 58.533,
        "average": 55.6765
      },
      "rationale_metrics": {
        "rouge_l": 0.1509433962264151,
        "text_similarity": 0.5392276048660278,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is incorrect and contradicts the reference: it states the funding is mentioned at 15s, whereas the correct timestamps place the funding mention at 67.82\u201375.53s (after the topic introduction)."
      }
    },
    {
      "question_id": "003",
      "question": "While the slide titled 'Appointments are precious' is on screen, when does the speaker mention that GP practices are moving back towards face-to-face appointments?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 123.0,
        "end": 129.0
      },
      "pred_interval": {
        "start": 19.0,
        "end": 21.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 104.0,
        "end": 108.0,
        "average": 106.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307692,
        "text_similarity": 0.5463191270828247,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is factually incorrect: it states 19s whereas the speaker actually mentions moving back to face-to-face appointments between ~123.0\u2013129.0 while the slide (appearing at ~100.74s) is on screen, so the timing contradicts the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that GP practices are very different places now, when does she begin listing the specific roles in a GP practice?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.0,
        "end": 204.0
      },
      "pred_interval": {
        "start": 150.0,
        "end": 152.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.0,
        "end": 52.0,
        "average": 52.5
      },
      "rationale_metrics": {
        "rouge_l": 0.375,
        "text_similarity": 0.48647594451904297,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation (the listing occurs after the remark) but gives an incorrect timestamp (150.0s vs 185.8s) and is vague about the start of the listing (should be 203.0s), so it is factually inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide displays the question 'Does it need to be a GP?', when does the speaker mention that paramedics work in primary care?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "pred_interval": {
        "start": 180.0,
        "end": 182.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.0,
        "end": 58.0,
        "average": 56.5
      },
      "rationale_metrics": {
        "rouge_l": 0.5230769230769231,
        "text_similarity": 0.6462957859039307,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly implies the remark comes after the slide but severely misstates the timing: it places the speaker's line at 181.0s whereas the reference is 235.0\u2013240.0s, a large and consequential temporal error."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker talks about paramedics working in primary care, when does she begin to explain the role of Advanced Clinical Practitioners?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 241.0,
        "end": 249.0
      },
      "pred_interval": {
        "start": 182.0,
        "end": 184.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.0,
        "end": 65.0,
        "average": 62.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2641509433962264,
        "text_similarity": 0.5522121787071228,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the simple 'after' relation but the timestamps are far off and contradict the correct intervals (238.5s vs 182.0s and 241.0s\u2013249.0s vs 183.0s), so it is largely incorrect on the key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the problem of a wound on your foot, when does she strongly advise mentioning if you are diabetic?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 337.875,
        "end": 343.0
      },
      "pred_interval": {
        "start": 336.0,
        "end": 342.0
      },
      "iou": 0.5892857142857143,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.875,
        "end": 1.0,
        "average": 1.4375
      },
      "rationale_metrics": {
        "rouge_l": 0.1090909090909091,
        "text_similarity": -0.04741675406694412,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately captures the correct answer's key point that the advice to mention diabetes comes immediately when the wound-on-foot problem is introduced, matching the intended timing information."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having a new wound on your leg, when does she suggest going to a local pharmacist for simple dressings?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 363.968,
        "end": 366.552
      },
      "pred_interval": {
        "start": 357.0,
        "end": 363.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.968000000000018,
        "end": 3.552000000000021,
        "average": 5.260000000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.10344827586206896,
        "text_similarity": 0.20916146039962769,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the suggestion to visit a pharmacist for simple dressings, but it omits the required timestamps and misstates the temporal context (the correct answer specifies it follows discussion of nurse appointments, not immediately after the new-wound mention)."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker explains that a nurse's appointment is needed for long-standing wounds, when does she advise to clearly state how long the wound has been there?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 409.579,
        "end": 439.62
      },
      "pred_interval": {
        "start": 389.0,
        "end": 395.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.579000000000008,
        "end": 44.620000000000005,
        "average": 32.599500000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.03125,
        "text_similarity": 0.2894238531589508,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that the advice occurs when she explains the need for a nurse but omits the key timing detail (the specific timestamps and that the advice follows immediately), so it is incomplete. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if you feel more short of breath, when does she state that a GP or nurse practitioner might be needed the same day?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 522.783,
        "end": 525.113
      },
      "pred_interval": {
        "start": 564.0,
        "end": 572.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.216999999999985,
        "end": 46.886999999999944,
        "average": 44.051999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.06451612903225806,
        "text_similarity": 0.026063144207000732,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the basic content (that a GP/nurse may be needed same day) but omits the crucial timing details and segment alignment (the anchor/target timestamps and that the target follows discussion of new leg swelling), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to measure your ankle and calf, when does she give an example of a calf measurement that would 'perk up more interest'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.623,
        "end": 586.297
      },
      "pred_interval": {
        "start": 609.0,
        "end": 613.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.376999999999953,
        "end": 26.702999999999975,
        "average": 26.039999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.11111111111111112,
        "text_similarity": 0.17092680931091309,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction merely restates that an example is given and fails to provide the required timing details or the specific timestamps from the correct answer, thus omitting key factual elements."
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Photography', when does the speaker advise to 'expect to be asked for a photo'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 670.384,
        "end": 672.807
      },
      "pred_interval": {
        "start": 680.0,
        "end": 684.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.615999999999985,
        "end": 11.192999999999984,
        "average": 10.404499999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814817,
        "text_similarity": 0.2403181493282318,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction restates the advice but omits the required timing details (the slide transition at 650.676s and the target speech from 670.384s\u2013672.807s), so it fails to answer 'when'."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions some GP practices use video consultations, when does she state that a good quality photograph is better than a video?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.278,
        "end": 717.251
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.72199999999998,
        "end": 12.749000000000024,
        "average": 11.735500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.5491148233413696,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the photograph comment comes after the video consultations remark) but fails to provide the requested timing details (the specific timestamps), omitting key factual information."
      }
    },
    {
      "question_id": "002",
      "question": "Once the slide changes to 'Photography tips', when does the speaker begin discussing taking a close-up and further-away picture?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 738.601,
        "end": 740.91
      },
      "pred_interval": {
        "start": 740.0,
        "end": 745.0
      },
      "iou": 0.142209720268787,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.399000000000001,
        "end": 4.090000000000032,
        "average": 2.7445000000000164
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.6129405498504639,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the general link between the slide and the discussion but omits the required timestamps and incorrectly implies the discussion starts immediately at the slide change rather than after it (speaker starts at 738.601s, slide at 736.057s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide changes to 'General top tips- face to face appointments', when does the speaker advise to 'Go suitably dressed'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 860.136,
        "end": 860.846
      },
      "pred_interval": {
        "start": 805.0,
        "end": 810.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.13599999999997,
        "end": 50.846000000000004,
        "average": 52.990999999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.4810628294944763,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits key factual details required by the reference\u2014specifically the timestamps (slide at 805.957s and advice at 860.136s) and the note that other tips are given first."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises not to wear tight socks, trousers, or wellies, when does she suggest wearing something with quick access to lower limbs?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.0,
        "end": 877.5
      },
      "pred_interval": {
        "start": 925.0,
        "end": 930.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.0,
        "end": 52.5,
        "average": 52.25
      },
      "rationale_metrics": {
        "rouge_l": 0.1568627450980392,
        "text_similarity": 0.3120317757129669,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (that the suggestion occurs after the advice not to wear tight socks, trousers, or wellies) and preserves the original meaning without adding or contradicting details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes advising not to make chit-chat about the weather, when does she advise not to dodge the real problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 893.0,
        "end": 894.5
      },
      "pred_interval": {
        "start": 940.0,
        "end": 945.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.0,
        "end": 50.5,
        "average": 48.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3571428571428571,
        "text_similarity": 0.45302796363830566,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (once she finishes advising about the weather) but fails to provide the requested timing details (the timestamps 893.0\u2013894.5s), thus omitting key factual information."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker advises to take a list of the medications you are actually taking, when does she advise against describing tablets by their appearance?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 948.0,
        "end": 969.0
      },
      "pred_interval": {
        "start": 965.0,
        "end": 970.0
      },
      "iou": 0.18181818181818182,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.0,
        "end": 1.0,
        "average": 9.0
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.5267667770385742,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') between the two statements, but it omits the specific timestamps and interval details provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker advises speaking to the practice in advance about a relative, when does she explain the reason for this advance arrangement due to confidentiality?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1065.0,
        "end": 1095.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1060.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.0,
        "end": 35.0,
        "average": 25.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2580645161290323,
        "text_similarity": 0.5604442358016968,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives incorrect timings and is vague about the advice (saying 'beginning of the segment') and wrongly places the confidentiality explanation at 1050s, which contradicts the correct start time of 1065s and the 'once_finished' relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker suggests writing things down before an appointment to help structure what you say, when does she first ask 'How did it start?' regarding the leg problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1130.415,
        "end": 1131.738
      },
      "pred_interval": {
        "start": 1090.0,
        "end": 1100.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.414999999999964,
        "end": 31.738000000000056,
        "average": 36.07650000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.34375,
        "text_similarity": 0.35418134927749634,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect: it gives 1090.0s whereas the correct E2 start is 1130.415s (immediately after E1 ends at 1130.0s), so the timing and relation do not match."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes advising to ask to be referred to a specialist service, when does she start introducing the referrals examples?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.105,
        "end": 1249.385
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1235.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.105000000000018,
        "end": 14.384999999999991,
        "average": 16.245000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.19230769230769232,
        "text_similarity": 0.28962254524230957,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the 'after' relation but both timestamps are substantially incorrect (finish 1236.741s vs predicted 1230.0s; start 1248.105s vs predicted 1235.0s) and it omits the correct E2 time range, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that lymphoedema services can be patchy, when does she first advise writing to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.0,
        "end": 1378.0
      },
      "pred_interval": {
        "start": 1340.0,
        "end": 1345.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.0,
        "end": 33.0,
        "average": 35.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4313725490196078,
        "text_similarity": 0.5827499628067017,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the 'after' relation but gives incorrect timestamps: the speaker's advice occurs at ~1377s (not 1345s), and the mention time is also off (~1335s vs 1340s), so it is factually inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions that a GP will assess new leg swelling for onward referral, when does she explain there are many different causes?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1429.846,
        "end": 1432.0
      },
      "pred_interval": {
        "start": 1360.0,
        "end": 1365.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 69.846,
        "end": 67.0,
        "average": 68.423
      },
      "rationale_metrics": {
        "rouge_l": 0.3098591549295775,
        "text_similarity": 0.7562231421470642,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the 'after' relation but gives incorrect timestamps (1360/1365s) that conflict with the correct times (1405s and 1429.846\u20131432.0s), so it is factually inaccurate despite matching the order."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what information you could take with you, when does she suggest looking up the National Wound Care Strategy Lower Limb Recommendations?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1465.0,
        "end": 1469.5
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.0,
        "end": 49.5,
        "average": 49.75
      },
      "rationale_metrics": {
        "rouge_l": 0.13559322033898302,
        "text_similarity": 0.1924286186695099,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction reverses the temporal order: it claims the question comes after the recommendation, whereas the correct answer states the recommendation occurs after the question (1465.0\u20131469.5s vs 1450.2s); thus it contradicts the reference and omits timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions escalating concerns to the practice manager, when does she mention escalating concerns to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.6,
        "end": 1525.7
      },
      "pred_interval": {
        "start": 1490.0,
        "end": 1495.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.59999999999991,
        "end": 30.700000000000045,
        "average": 32.14999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.4892898201942444,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the sequence (practice manager then MP) but omits the required timestamps and relation details, and adds an unsupported claim of \u201cimmediately,\u201d which is a factual/hallucinated detail."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'I'll stop sharing', when does she start reading the first question from a viewer?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1574.5,
        "end": 1578.5
      },
      "pred_interval": {
        "start": 1560.0,
        "end": 1565.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.5,
        "end": 13.5,
        "average": 14.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.5767827033996582,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the speaker begins reading immediately after saying 'I'll stop sharing,' but it omits the precise timestamps and exact timing details provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially suggests the mum needs compression hosiery, when does she mention asking for an appointment with the nurse for stronger compression?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1654.942,
        "end": 1664.2
      },
      "pred_interval": {
        "start": 165.0,
        "end": 167.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1489.942,
        "end": 1497.2,
        "average": 1493.571
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.5497390627861023,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the nurse appointment is mentioned after the initial suggestion, but it omits the required precise timing (the specific start/end timestamps and relation detail) present in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'That is such a good question', when does she state that self-diagnosis via the internet is never a good idea?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1757.815,
        "end": 1762.821
      },
      "pred_interval": {
        "start": 183.0,
        "end": 184.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1574.815,
        "end": 1578.821,
        "average": 1576.818
      },
      "rationale_metrics": {
        "rouge_l": 0.2622950819672131,
        "text_similarity": 0.44433796405792236,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the relation ('after') and repeats the content, but it omits the required precise timing (start/end timestamps and anchor time) given in the correct answer, so it's incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes that approaching a GP is about framing the conversation, when does she tell the viewer not to worry about being labeled a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1795.335,
        "end": 1798.383
      },
      "pred_interval": {
        "start": 190.0,
        "end": 191.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1605.335,
        "end": 1607.383,
        "average": 1606.359
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.19866721332073212,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly captures the key temporal relation that the reassurance comes after the comment about framing the conversation; it preserves the original meaning despite omitting timestamps and exact phrasing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker first says, 'Please don't worry about things like that', when does she next advise not to worry about being labelled as a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1827.66,
        "end": 1831.19
      },
      "pred_interval": {
        "start": 182.5,
        "end": 183.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1645.16,
        "end": 1647.5900000000001,
        "average": 1646.375
      },
      "rationale_metrics": {
        "rouge_l": 0.07017543859649122,
        "text_similarity": 0.1476060152053833,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps do not match the reference: the first occurrence is given at 182.5s instead of ~1787s (major discrepancy), and the second 183.6s falls outside the correct 1827.66\u20131831.19s window, so the answer is essentially incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks, 'What can I do to maintain healthy legs or feet so I don't get any problems?', when does she start listing actions like 'walk' and 'legs up'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1865.412,
        "end": 1883.383
      },
      "pred_interval": {
        "start": 194.7,
        "end": 195.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1670.712,
        "end": 1687.7830000000001,
        "average": 1679.2475
      },
      "rationale_metrics": {
        "rouge_l": 0.14084507042253522,
        "text_similarity": 0.3509664535522461,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer correctly identifies the time the speaker begins listing actions (195.6s), which corresponds to the correct E2 start (1865.412s) after the absolute\u2192relative conversion, and thus answers the question as asked."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks how much is in the GP curriculum, when does she say 'I don't know'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1983.7,
        "end": 1984.201
      },
      "pred_interval": {
        "start": 205.0,
        "end": 206.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1778.7,
        "end": 1778.201,
        "average": 1778.4505
      },
      "rationale_metrics": {
        "rouge_l": 0.07999999999999999,
        "text_similarity": 0.18911640346050262,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (205.0s \u2192 206.0s) do not match the correct times (1981.797\u20131984.201s) and are off by a large margin, so the prediction is incorrect despite claiming immediacy."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'I think it is something that Legs Matter can help with', when does she discuss Legs Matter influencing GP curriculums?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2004.063,
        "end": 2009.063
      },
      "pred_interval": {
        "start": 207.0,
        "end": 208.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1797.063,
        "end": 1801.063,
        "average": 1799.063
      },
      "rationale_metrics": {
        "rouge_l": 0.07272727272727272,
        "text_similarity": 0.0980430468916893,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the target occurs after the anchor, but the provided timestamps (207s \u2192 208s) are nowhere near the ground-truth times (~1991.45s \u2192 ~2004.06s) and omits the precise intervals, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks if seeing a nurse practitioner is appropriate, when does she state that nurse practitioners are 'extremely experienced clinicians'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2062.584,
        "end": 2066.851
      },
      "pred_interval": {
        "start": 209.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1853.5839999999998,
        "end": 1856.851,
        "average": 1855.2175
      },
      "rationale_metrics": {
        "rouge_l": 0.07142857142857144,
        "text_similarity": 0.038039445877075195,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction preserves the sequence but the timestamps are wildly inaccurate\u2014the correct target occurs at ~2062.6\u20132066.9s (anchor ~2058.9\u20132060.8s), whereas the prediction gives 209s/210s, so it is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I understand the issue of smartphones and taking pictures too\", when does she first ask \"is there somebody who can help you?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2174.0,
        "end": 2176.0
      },
      "pred_interval": {
        "start": 2135.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 36.0,
        "average": 37.5
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.013435274362564087,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the question is asked right after the prior remark, matching the ground truth that the target follows the anchor, but it omits the precise timestamps and event labels provided in the correct answer, making it incomplete for the asked 'when'."
      }
    },
    {
      "question_id": "002",
      "question": "During the period when the speaker discusses the importance of planning phone calls to the GP, when does she ask, \"What am I feeling?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2197.721,
        "end": 2198.663
      },
      "pred_interval": {
        "start": 2195.0,
        "end": 2200.0
      },
      "iou": 0.18840000000000146,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.7210000000000036,
        "end": 1.336999999999989,
        "average": 2.0289999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352942,
        "text_similarity": 0.0721021443605423,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that the question is asked while discussing planning calls to the GP (semantic match) but omits the key factual details from the reference\u2014specifically the anchor/target labels and precise timestamps showing the event occurs at 2197.721\u20132198.663s within the anchor span."
      }
    },
    {
      "question_id": "001",
      "question": "Once Dr. Angelos finishes introducing Dr. Tolchin, when does Dr. Tolchin begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.128,
        "end": 109.393
      },
      "pred_interval": {
        "start": 210.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 104.872,
        "end": 100.607,
        "average": 102.73949999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.05,
        "text_similarity": 0.271392285823822,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated and incorrect \u2014 it gives the video end time instead of the requested timestamps and relation (Dr. Tolchin beginning at ~105.128s after the 100.128s introduction), omitting key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After Dr. Angelos describes Dr. Tolchin's research on crisis standards of care, when does he describe his research on functional neurological disorders and epilepsy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.426,
        "end": 116.456
      },
      "pred_interval": {
        "start": 210.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 153.574,
        "end": 93.544,
        "average": 123.559
      },
      "rationale_metrics": {
        "rouge_l": 0.09756097560975609,
        "text_similarity": 0.29252758622169495,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely unrelated and incorrect: it gives the video end time instead of the requested start/end timestamps for the functional neurological disorders research and omits the correct segment times."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating the second learning objective, when does he start explaining the third learning objective?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 181.0
      },
      "pred_interval": {
        "start": 153.0,
        "end": 162.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 19.0,
        "average": 16.5
      },
      "rationale_metrics": {
        "rouge_l": 0.28,
        "text_similarity": 0.5736672878265381,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the relation 'after' but gives a wildly incorrect timestamp (153.0s) and omits the correct start time (17.0s) and span (17.0\u201331.0s), contradicting the ground-truth timings."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'Why conduct clinical ethics consultations?' is displayed, when does the speaker discuss moral distress among clinicians and staff?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.4,
        "end": 304.0
      },
      "pred_interval": {
        "start": 198.0,
        "end": 207.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 87.39999999999998,
        "end": 97.0,
        "average": 92.19999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.28070175438596484,
        "text_similarity": 0.7108269929885864,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the discussion occurs while that slide is displayed, but gives an incorrect time (198.0s) and omits the actual discussion interval (285.4\u2013304.0s), so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that clinical ethics consultations were helpful, when does he state that they were more likely to achieve consensus in clinical decisions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 350.2,
        "end": 357.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 340.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.19999999999999,
        "end": 17.0,
        "average": 18.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.09090909090909091,
        "text_similarity": -0.018986620008945465,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the required timestamps and explicit temporal relation; it fails to match the ground-truth specification that E2 starts at 350.2s (after E1 ending at 337.0s)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of resource utilization, when does he specifically state that there was a reduced length of stay?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 438.9,
        "end": 450.3
      },
      "pred_interval": {
        "start": 360.0,
        "end": 370.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.89999999999998,
        "end": 80.30000000000001,
        "average": 79.6
      },
      "rationale_metrics": {
        "rouge_l": 0.08695652173913043,
        "text_similarity": 0.12706850469112396,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the relative ordering ('after') but omits the required specific timestamps and span (E1 end 369.0s; E2 438.9\u2013450.3), so it lacks key factual details. "
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'to look at disparities', when does he begin to introduce Ellen Fox's team and their survey?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 493.5,
        "end": 499.0
      },
      "pred_interval": {
        "start": 380.0,
        "end": 390.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 113.5,
        "end": 109.0,
        "average": 111.25
      },
      "rationale_metrics": {
        "rouge_l": 0.08163265306122448,
        "text_similarity": 0.13201496005058289,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that the introduction occurs after 'to look at disparities' and thus captures the coarse ordering, but it omits the crucial timing details (E1 ends at 393.0s; E2 starts at 493.5s and ends at 499.0s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'hospitals with less than 400 beds', when does he mention 'little or no growth over that two decade period'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 527.809,
        "end": 530.91
      },
      "pred_interval": {
        "start": 516.0,
        "end": 520.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.808999999999969,
        "end": 10.909999999999968,
        "average": 11.359499999999969
      },
      "rationale_metrics": {
        "rouge_l": 0.34375000000000006,
        "text_similarity": 0.6774289608001709,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that the mention occurs immediately after the 'hospitals with less than 400 beds' phrase, matching the reference's relative timing (target immediately follows the anchor)."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide titled 'Prior Healthcare System Ethics Committees' is fully displayed, when do the images of the six hospitals with their bed counts appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.7,
        "end": 552.0
      },
      "pred_interval": {
        "start": 537.0,
        "end": 540.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.700000000000045,
        "end": 12.0,
        "average": 13.350000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.3225806451612903,
        "text_similarity": 0.40529710054397583,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the images appear after the slide title, but incorrectly claims they appear immediately; the ground truth specifies a ~15.5s delay with exact timestamps (551.7s\u2013552.0s), which the prediction omits and contradicts."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the number of ethics consults at Yale New Haven Hospital increased from 50 to 239, when does he describe this as 'approximately a five-fold increase in consult volume'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.7,
        "end": 624.7
      },
      "pred_interval": {
        "start": 598.0,
        "end": 600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.700000000000045,
        "end": 24.700000000000045,
        "average": 24.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.2972972972972973,
        "text_similarity": 0.5169864892959595,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys that the 'five-fold' remark immediately follows the statement of 50 to 239, but it omits the specific timestamps (E1 614.8\u2013621.0s and E2 622.7\u2013624.7s) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially mentions the 'Community Bioethics Forum', when does he start describing its community members?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 887.216,
        "end": 905.918
      },
      "pred_interval": {
        "start": 870.0,
        "end": 872.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.216000000000008,
        "end": 33.918000000000006,
        "average": 25.567000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.2641509433962264,
        "text_similarity": 0.5499835014343262,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the description occurs after the mention, but it omits the required timestamps and asserts it happens 'immediately after,' which is misleading given the correct answer specifies the description begins about 2.1 seconds later (887.216s)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that the primary focus of the Center for Clinical Ethics has been ethics education, when does he start listing 'Systemwide Ethics Forum and Newsletter'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1055.54,
        "end": 1069.28
      },
      "pred_interval": {
        "start": 872.0,
        "end": 874.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 183.53999999999996,
        "end": 195.27999999999997,
        "average": 189.40999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.401404470205307,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly ties the mention to 'Community Bioethics Forum' and implies it occurs 'right away' rather than the documented later timestamp; it also omits the required absolute times (1055.54s\u20131069.28s) and misidentifies the anchor (ethics education at 938\u2013948s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker lists 'ICU Walk Rounds', when does he mention 'HEC-C Certification'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1048.0,
        "end": 1052.0
      },
      "pred_interval": {
        "start": 874.0,
        "end": 876.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 174.0,
        "end": 176.0,
        "average": 175.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.4372738003730774,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies that 'HEC-C Certification' is mentioned shortly after another item, but it incorrectly names the preceding item ('Systemwide Ethics Forum and Newsletter' instead of 'ICU Walk Rounds'), and it omits the precise timing and 'next' relation details from the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"ethics consultation services,\" when does he start talking about collecting feedback?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.8,
        "end": 1249.8
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1235.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.799999999999955,
        "end": 14.799999999999955,
        "average": 12.799999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.4186046511627907,
        "text_similarity": 0.6630761623382568,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction hallucinates the finish time (1230.0s vs 1238.9s) and omits the correct start timestamp (1240.8s), incorrectly stating the speaker begins 'immediately after' rather than ~1.9s later, so it contradicts the ground truth timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that participant satisfaction is not the \"be-all and end-all,\" when does he say they have begun the survey process with clinicians?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.3,
        "end": 1282.8
      },
      "pred_interval": {
        "start": 1240.0,
        "end": 1245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.299999999999955,
        "end": 37.799999999999955,
        "average": 38.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.4482758620689655,
        "text_similarity": 0.6114506125450134,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer identifies the correct event but gives a substantially incorrect timestamp (1240.0s vs. the reference 1278.3s, a 38.3s discrepancy), so it fails to match the ground truth timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes describing the first pie chart about helpful advice/guidance, when does the second pie chart about communication appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1367.5,
        "end": 1367.9
      },
      "pred_interval": {
        "start": 1250.0,
        "end": 1255.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 117.5,
        "end": 112.90000000000009,
        "average": 115.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.35999999999999993,
        "text_similarity": 0.5804005861282349,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly preserves the relation that the second chart appears after the first is finished, but it provides an incorrect timestamp (1250.0s) that contradicts the ground-truth finish at 1356.0s and appearance at 1376.5s, so it is largely factually wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he wants to turn to some of the organizational ethics consultation work, when does the slide showing the 'Organizational ethics consultations' table appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1472.0,
        "end": 1472.5
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.0,
        "end": 62.5,
        "average": 62.25
      },
      "rationale_metrics": {
        "rouge_l": 0.196078431372549,
        "text_similarity": 0.4184037446975708,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the slide appears after the speaker introduces the topic but incorrectly claims it appears 'immediately'\u2014the ground truth shows a ~35s gap and provides exact timestamps, which the prediction omits."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining that organizational ethics work is new to them, when do they state that it began during the COVID pandemic?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1469.5,
        "end": 1472.0
      },
      "pred_interval": {
        "start": 1560.0,
        "end": 1560.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.5,
        "end": 88.0,
        "average": 89.25
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.49924442172050476,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the COVID-start statement occurs immediately after the remark about newness, but it omits the specific timestamps and duration (E1 at 1469.3s; E2 1469.5\u20131472.0s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the 'Organizational ethics consultations' table, when does the speaker mention the 'Blood products scarcity protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1510.0,
        "end": 1513.0
      },
      "pred_interval": {
        "start": 1560.0,
        "end": 1560.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.0,
        "end": 47.0,
        "average": 48.5
      },
      "rationale_metrics": {
        "rouge_l": 0.36,
        "text_similarity": 0.6760534048080444,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the mention occurs while the table is displayed, but it omits the key factual timestamps (the table 1474\u20131573s and the mention at 1510\u20131513s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the 'sequential organ failure assessment or SOFA score', when does he begin to explain what it is?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1647.6,
        "end": 1697.0
      },
      "pred_interval": {
        "start": 159.0,
        "end": 162.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1488.6,
        "end": 1535.0,
        "average": 1511.8
      },
      "rationale_metrics": {
        "rouge_l": 0.09677419354838708,
        "text_similarity": 0.22615838050842285,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (159.0s) is far from the correct anchor (1621.0s) and it fails to provide the required explanation timestamps; overall it is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that '70% of publicly available crisis standards of care used either the SOFA score or a modified version', when does he mention the SOFA score being used in Alaska?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1726.0,
        "end": 1733.0
      },
      "pred_interval": {
        "start": 174.0,
        "end": 178.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1552.0,
        "end": 1555.0,
        "average": 1553.5
      },
      "rationale_metrics": {
        "rouge_l": 0.06779661016949153,
        "text_similarity": 0.26737406849861145,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamp (174.0s) is far from the correct intervals (anchor 1705.0\u20131712.0 and target 1726.0\u20131733.0) and omits the anchor/target pairing; it therefore contradicts the ground truth and is essentially incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the 'SOFA Disparities' slide appears, when does the speaker begin discussing concerns about the score's accuracy and contributions to disparities?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1770.0,
        "end": 1776.606
      },
      "pred_interval": {
        "start": 180.0,
        "end": 182.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1590.0,
        "end": 1594.606,
        "average": 1592.3029999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1568627450980392,
        "text_similarity": 0.3427892029285431,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (180.0s) is completely inconsistent with the reference (discussion begins at 1770.0\u20131776.606s); it contradicts the correct timing and is therefore incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that the center was able to test the triage protocol before it was used, when does he state that they developed a SOFA calculation system?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1799.553,
        "end": 1807.997
      },
      "pred_interval": {
        "start": 178.0,
        "end": 182.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1621.553,
        "end": 1625.997,
        "average": 1623.775
      },
      "rationale_metrics": {
        "rouge_l": 0.29090909090909095,
        "text_similarity": 0.6850931644439697,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the relative ordering (SOFA mention occurs after the triage-protocol remark) but omits the precise timing details given in the reference (start 1799.553s, end 1807.997s)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the retrospective cohort study, when does he detail the demographic breakdown of the patients?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1846.122,
        "end": 1858.077
      },
      "pred_interval": {
        "start": 205.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1641.122,
        "end": 1648.077,
        "average": 1644.5995
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307692,
        "text_similarity": 0.5261509418487549,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the demographics are presented after the cohort introduction, but it omits the key factual timestamps provided in the reference (E1 end 1787.983s; E2 1846.122\u20131858.077), making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker highlights that non-Hispanic Black patients had greater odds of an elevated SOFA score, when does he state that no significant difference by race in mortality was found when controlling for other factors?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.642,
        "end": 1879.694
      },
      "pred_interval": {
        "start": 214.0,
        "end": 219.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1659.642,
        "end": 1660.694,
        "average": 1660.1680000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.18918918918918917,
        "text_similarity": 0.6600839495658875,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relative order (that the mortality finding follows the SOFA finding) but omits the key temporal details given in the reference (specific start/end timestamps and that it was the next key finding), making it incomplete for the asked 'when' question."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the early small cohort out of Wuhan, China, when does he state that subsequent larger cohorts in the United States did not show such high accuracy rates?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.0,
        "end": 1966.5
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2030.0
      },
      "iou": 0.09375,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.0,
        "end": 63.5,
        "average": 36.25
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.33995091915130615,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly identifies the anchor/target ordering but gives inaccurate timestamps: the anchor is off by ~4s and the target is far from the correct 1959.0\u20131966.5s window (predicted 2030.0s), so the answer is largely incorrect on timings."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'This graph here is a calibration curve', when does he explain that the diagonal line shows a perfectly calibrated predictor of mortality?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2014.0,
        "end": 2020.0
      },
      "pred_interval": {
        "start": 2060.0,
        "end": 2100.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.0,
        "end": 80.0,
        "average": 63.0
      },
      "rationale_metrics": {
        "rouge_l": 0.17500000000000004,
        "text_similarity": 0.43829354643821716,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (2060s/2100s) are far from the reference intervals (~2009.9s for the anchor and 2014\u20132020s for the explanation) and misrepresent the timing relationship\u2014the explanation should directly follow the graph, so the prediction is essentially incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that SOFA predicted mortality with less accuracy than age in their own COVID cohort, when does he mention that SOFA predicted mortality with better accuracy than age in the pre-COVID eICU cohort?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2066.0,
        "end": 2069.0
      },
      "pred_interval": {
        "start": 2120.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.0,
        "end": 71.0,
        "average": 62.5
      },
      "rationale_metrics": {
        "rouge_l": 0.20930232558139536,
        "text_similarity": 0.35248512029647827,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (2120s/2140s) do not match the reference anchor (1998.1\u20132000.8s) and target (2066.0\u20132069.0s), and it fails to reproduce the referenced contrast phrase, so the answer is essentially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the Omicron surge increasing, when does he talk about working with the healthcare system's legal team?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2153.6,
        "end": 2174.93
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.59999999999991,
        "end": 34.929999999999836,
        "average": 29.264999999999873
      },
      "rationale_metrics": {
        "rouge_l": 0.3703703703703704,
        "text_similarity": 0.6943883299827576,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly preserves the event order and roughly matches the first timestamp, but it omits the precise time range (2153.6s\u20132174.93s) for when the speaker discusses the legal team and is therefore incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the policy was active until late February of 2022, when does the first 'Scope of protocol' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2194.0,
        "end": 2234.0
      },
      "pred_interval": {
        "start": 2150.0,
        "end": 2160.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.0,
        "end": 74.0,
        "average": 59.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4285714285714286,
        "text_similarity": 0.8163237571716309,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps substantially contradict the ground truth: the speaker event is at 2192.0s (predicted 2150.0s) and the slide appears from 2194.0\u20132234.0s (predicted 2160.0s), and the prediction also omits the slide's duration."
      }
    },
    {
      "question_id": "003",
      "question": "After the second 'Scope of protocol' slide appears, when does the speaker mention 'renal replacement therapy'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2263.679,
        "end": 2254.733
      },
      "pred_interval": {
        "start": 2170.0,
        "end": 2180.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 93.67900000000009,
        "end": 74.73300000000017,
        "average": 84.20600000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.4406779661016949,
        "text_similarity": 0.7851909399032593,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are far off from the reference (E1: 2170s vs 2230s; E2: 2180s vs ~2255\u20132264s), so it contradicts the correct timing and fails to match the event interval."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that goals of care discussions significantly changed, when does the speaker mention that patients were more likely to choose limited life-sustaining interventions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2320.0,
        "end": 2327.0
      },
      "pred_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.0,
        "end": 73.0,
        "average": 74.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3555555555555555,
        "text_similarity": 0.5238620042800903,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to provide the requested times or the temporal relation between the two events and instead asserts an unrelated cause (COVID-19); it omits the second event (patients choosing limited interventions) and thus does not match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I'll stop and take questions,\" when does an audience member begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2541.6,
        "end": 2544.0
      },
      "pred_interval": {
        "start": 2500.0,
        "end": 2503.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.59999999999991,
        "end": 41.0,
        "average": 41.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.3137254901960784,
        "text_similarity": 0.6484807133674622,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the audience speaks after the speaker, but it omits the precise timestamps and misleadingly says 'right after' when the audience actually begins ~23.7 seconds later (and the answer omits the end time)."
      }
    },
    {
      "question_id": "002",
      "question": "Once the audience member finishes complimenting the center, when does he ask a specific question about local hospital ethics committees?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2571.5,
        "end": 2580.5
      },
      "pred_interval": {
        "start": 2510.0,
        "end": 2514.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.5,
        "end": 66.5,
        "average": 64.0
      },
      "rationale_metrics": {
        "rouge_l": 0.32653061224489793,
        "text_similarity": 0.5368368029594421,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the causal relation (the question is asked once the compliment finishes) but fails to provide the requested timing details (the specific start and end timestamps), omitting key factual elements."
      }
    },
    {
      "question_id": "003",
      "question": "After the audience member mentions the low numbers of ethics consultations, when does the speaker begin to answer the question?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2624.0,
        "end": 2634.8
      },
      "pred_interval": {
        "start": 2516.0,
        "end": 2518.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 108.0,
        "end": 116.80000000000018,
        "average": 112.40000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.25925925925925924,
        "text_similarity": 0.5213232040405273,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the speaker responds after the audience comment, but it omits the key factual timing details (speaker start at 2624.0s and end at 2634.8s) required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the listener asks about assessing the quality of care across the system, when does the speaker respond by calling it a 'great question'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.1,
        "end": 2745.7
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2671.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.09999999999991,
        "end": 74.69999999999982,
        "average": 74.39999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.25925925925925924,
        "text_similarity": 0.7558164000511169,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the speaker responds by calling it a 'great question' after the listener's query, but it omits the key factual detail of the precise timestamp (2744.1s) and the exact timing window given in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions starting to survey clinicians for feedback, when does he mention planning to survey patients and families?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2807.8,
        "end": 2821.6
      },
      "pred_interval": {
        "start": 2675.0,
        "end": 2676.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 132.80000000000018,
        "end": 145.5999999999999,
        "average": 139.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2933333333333334,
        "text_similarity": 0.7627969980239868,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the plan to survey patients and families but gives a clearly incorrect timestamp (2675.0s) and thus misstates the timing/sequence relative to the clinicians mention (~2807.8\u20132821.6s), so it is largely factually wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that hospitals in the healthcare system can join together, when does he state that they will preferentially present cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2854.49,
        "end": 2856.13
      },
      "pred_interval": {
        "start": 2856.0,
        "end": 2873.0
      },
      "iou": 0.007023230686121426,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5100000000002183,
        "end": 16.86999999999989,
        "average": 9.190000000000055
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.29988741874694824,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly indicates the statement occurs after the mention (preserving the relative order), but it omits the specific timing details/timestamps provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces 'a third method of feedback', when does he describe it as 'formal needs assessments'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2877.53,
        "end": 2879.53
      },
      "pred_interval": {
        "start": 2940.0,
        "end": 2950.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.4699999999998,
        "end": 70.4699999999998,
        "average": 66.4699999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.35294117647058826,
        "text_similarity": 0.5468023419380188,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the key relation that the phrase 'formal needs assessments' occurs after the anchor 'a third method of feedback'; it omits the exact timestamps given in the reference, so it is not fully complete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'the overwhelming response was number one', when does he specify the first response as 'a lack of ethics education'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2901.56,
        "end": 2903.46
      },
      "pred_interval": {
        "start": 2950.0,
        "end": 2960.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.440000000000055,
        "end": 56.539999999999964,
        "average": 52.49000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.43333333333333335,
        "text_similarity": 0.7104110717773438,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the speaker names 'a lack of ethics education' after the anchor, but it omits the required timing details (absolute timestamps and the relative relation), making it incomplete for the question asked."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"The more medically complex cases tend to transfer,\" when does he start listing examples of such cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3044.3,
        "end": 3048.2
      },
      "pred_interval": {
        "start": 3030.0,
        "end": 3045.0
      },
      "iou": 0.03846153846152885,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.300000000000182,
        "end": 3.199999999999818,
        "average": 8.75
      },
      "rationale_metrics": {
        "rouge_l": 0.19230769230769232,
        "text_similarity": 0.3441726565361023,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states that the examples begin immediately after the mention, matching the key temporal relationship, but it omits the specific timestamps (3044.3s start) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the questioner asks about the 'escalation of care policy', when does the slide titled 'Escalation of Care Protocol' appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3114.8,
        "end": 3117.8
      },
      "pred_interval": {
        "start": 3060.0,
        "end": 3065.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.80000000000018,
        "end": 52.80000000000018,
        "average": 53.80000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454545,
        "text_similarity": 0.69392329454422,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the slide appears after the question (indeed immediately after), but it omits the precise timestamps and duration provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions \"boarding 190 patients in the emergency department\", when does he discuss concerns about the level of care?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3154.983,
        "end": 3143.945
      },
      "pred_interval": {
        "start": 3090.0,
        "end": 3105.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.98300000000017,
        "end": 38.945000000000164,
        "average": 51.96400000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.5145831108093262,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states that concerns are discussed immediately after the 'boarding 190 patients' remark, matching the core relation, but it omits the precise timing information (the specific timestamps/relative timing) given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker mentions 'in all 26 of those cases', when does he then talk about 'many more cases'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3214.9,
        "end": 3215.4
      },
      "pred_interval": {
        "start": 3254.0,
        "end": 3260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.09999999999991,
        "end": 44.59999999999991,
        "average": 41.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.392156862745098,
        "text_similarity": 0.3741784691810608,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly implies the 'many more cases' remark comes after, but is factually wrong about timing \u2014 it claims it occurs immediately while the reference shows a ~4.7s gap and provides precise timestamps that the prediction omits."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker states that the 'escalation of care protocol' was nice, when does he mention a 'SOFA-based protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3246.0,
        "end": 3249.0
      },
      "pred_interval": {
        "start": 3379.0,
        "end": 3385.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 133.0,
        "end": 136.0,
        "average": 134.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1724137931034483,
        "text_similarity": 0.40561312437057495,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the SOFA-based protocol is mentioned after the escalation protocol but omits the required timestamps and wrongly implies it occurs immediately ('right after') when the reference shows a 13-second gap (E1 3231\u20133233s, E2 3246\u20133249s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the second speaker says 'SOFA is horrendous', when does he mention 'SOFA's AUC goes up'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3322.32,
        "end": 3324.71
      },
      "pred_interval": {
        "start": 3405.0,
        "end": 3410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 82.67999999999984,
        "end": 85.28999999999996,
        "average": 83.9849999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.5959460139274597,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relative ordering (the mention occurs shortly after 'SOFA is horrendous') but omits all precise timestamps and interval details provided in the correct answer, making it incomplete for the asked timing information."
      }
    },
    {
      "question_id": "001",
      "question": "After the question about equity monitoring is asked, when does the speaker begin explaining the logging process for patient cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3401.583,
        "end": 3406.09
      },
      "pred_interval": {
        "start": 3495.0,
        "end": 3502.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 93.41699999999992,
        "end": 95.90999999999985,
        "average": 94.66349999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.3018867924528302,
        "text_similarity": 0.6322259306907654,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction directly contradicts the ground truth temporal relation: the ground truth shows the explanation occurred before the question (starts at 3401.583s and ends at 3406.090s, question at 3406.535s), whereas the prediction claims it began after the question."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the 'Escalation of Care Protocol', when does the 'Conscientious Practice Policy' slide appear on screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3429.8,
        "end": 3430.5
      },
      "pred_interval": {
        "start": 3507.0,
        "end": 3516.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.19999999999982,
        "end": 85.5,
        "average": 81.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.3448275862068966,
        "text_similarity": 0.7154971957206726,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the slide appears once the speaker finishes), but it omits the key factual details of the exact timestamps (E1=3424.0s, E2=3429.8s) and the absolute\u2192relative timing mapping provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Conscientious Practice Policy' slide appears, when does the speaker mention tracking outcomes and looking back retrospectively for this policy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3444.0,
        "end": 3492.0
      },
      "pred_interval": {
        "start": 3518.0,
        "end": 3525.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.0,
        "end": 33.0,
        "average": 53.5
      },
      "rationale_metrics": {
        "rouge_l": 0.39999999999999997,
        "text_similarity": 0.7345436811447144,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the speaker mentions tracking outcomes after the slide appears, but it omits the crucial timing information (3444.0s\u20133492.0s and the slide at 3434.0s) given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions an increasing disparity over time, when does he discuss how they can provide support to all hospitals?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 707.399,
        "end": 742.972
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.14055603969302569,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.601,
        "end": 12.97199999999998,
        "average": 15.28649999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.2898653745651245,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the main relation that the discussion of support occurs after the mention of increasing disparity, but it omits the specific timestamps and the precise once-finished temporal boundary provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the organizational chart for the Center for Clinical Ethics is displayed, when does the speaker describe the Ethics Education program?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.177,
        "end": 786.763
      },
      "pred_interval": {
        "start": 740.0,
        "end": 745.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.17700000000002,
        "end": 41.763000000000034,
        "average": 35.47000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3137254901960784,
        "text_similarity": 0.6617908477783203,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that the Ethics Education description occurs while the organizational chart is displayed, but it omits the specific timestamps and duration given in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says he will go into depth on the programs, when does he first mention the Yale Interdisciplinary Center for Bioethics?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 837.605,
        "end": 845.26
      },
      "pred_interval": {
        "start": 760.0,
        "end": 765.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.60500000000002,
        "end": 80.25999999999999,
        "average": 78.9325
      },
      "rationale_metrics": {
        "rouge_l": 0.4657534246575342,
        "text_similarity": 0.6903854608535767,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the Yale Interdisciplinary Center for Bioethics is mentioned after the 'go into depth' remark, but it omits the requested specific timing (timestamps) and is therefore incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the title 'Systemwide Ethics Forum and Newsletter', when does he describe it as a hybrid meeting?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1070.5,
        "end": 1076.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1052.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.5,
        "end": 24.5,
        "average": 22.5
      },
      "rationale_metrics": {
        "rouge_l": 0.37681159420289856,
        "text_similarity": 0.6460483074188232,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly notes the hybrid remark follows the title, but it gives an incorrect timestamp and wrongly claims it occurred \"immediately after\" rather than several seconds later, so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining that they looked through the 26 specific patient cases individually, when does the slide transition to 'Scope of protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3425.8,
        "end": 3429.0
      },
      "pred_interval": {
        "start": 3495.2,
        "end": 3506.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 69.39999999999964,
        "end": 77.19999999999982,
        "average": 73.29999999999973
      },
      "rationale_metrics": {
        "rouge_l": 0.19230769230769232,
        "text_similarity": 0.6084357500076294,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') between the speaker finishing and the slide transition but omits the key timing details (3417.5s, 3425.8s, 3429.0s) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the 'Scope of protocol' slide finishes being displayed, when does the 'Conscientious Practice Policy' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3429.0,
        "end": 3519.5
      },
      "pred_interval": {
        "start": 3506.2,
        "end": 3517.2
      },
      "iou": 0.12154696132596685,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.19999999999982,
        "end": 2.300000000000182,
        "average": 39.75
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.6740158796310425,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the relation that the 'Conscientious Practice Policy' slide appears once the 'Scope of protocol' slide finishes, but it omits the key temporal details (start at 3429.0s and end at 3519.5s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes discussing the tracking of equity, socioeconomic status, and other demographic characteristics, when is the presentation window minimized?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3530.0,
        "end": 3531.0
      },
      "pred_interval": {
        "start": 3517.2,
        "end": 3528.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.800000000000182,
        "end": 2.800000000000182,
        "average": 7.800000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.32653061224489793,
        "text_similarity": 0.5391203165054321,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation ('after') but omits the specific timestamps and interval (E1 at 3508.5s; E2 3530.0\u20133531.0) included in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the audience will be on mute, when does he mention that the live event can be paused?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 38.524,
        "end": 43.729
      },
      "pred_interval": {
        "start": 19.0,
        "end": 20.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.524,
        "end": 23.729,
        "average": 21.6265
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.5770566463470459,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits the key factual details\u2014the specific timestamps and target span\u2014required by the question, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses changing the speed of presentations and speakers, when does he advise on what to do if Wi-Fi or connection is lost?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 55.563,
        "end": 59.787
      },
      "pred_interval": {
        "start": 135.0,
        "end": 136.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.437,
        "end": 76.213,
        "average": 77.82499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454546,
        "text_similarity": 0.46143850684165955,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the 'after' relation (that advice comes after the speed discussion) but omits the key factual details\u2014the specific timestamps/target span (55.563s\u201359.787s) and exact timing\u2014so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the presenter mentions Tom Gardner in the background, when does he mention Stephanie Fraser joining in place of Jane Preston?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.258,
        "end": 171.201
      },
      "pred_interval": {
        "start": 150.0,
        "end": 152.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.25800000000001,
        "end": 19.200999999999993,
        "average": 18.7295
      },
      "rationale_metrics": {
        "rouge_l": 0.1923076923076923,
        "text_similarity": 0.7558684945106506,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and contradictory: it mislabels events, gives a wrong timestamp (150.0s vs 12.30s/18.80s), swaps who is mentioned, and includes unfounded assumptions rather than the correct 'after' relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male presenter finishes introducing Stephanie Fraser, when does Stephanie Fraser begin speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 223.86,
        "end": 224.8
      },
      "pred_interval": {
        "start": 152.0,
        "end": 153.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.86000000000001,
        "end": 71.80000000000001,
        "average": 71.83000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.13186813186813184,
        "text_similarity": 0.6062197089195251,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction misidentifies both the anchor and target events, offers no timestamps or relation, and hallucinates details\u2014failing to match the precise timing and content in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker is discussing the recent research undertaken by the Neurological Alliance of Scotland, when does she state that 57% of respondents reported not being able to access a face-to-face appointment?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 433.0,
        "end": 434.9
      },
      "pred_interval": {
        "start": 365.0,
        "end": 370.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 68.0,
        "end": 64.89999999999998,
        "average": 66.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.14084507042253522,
        "text_similarity": 0.2685508131980896,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (365\u2013370s) does not overlap with the correct interval (spoken phrase at 433.0\u2013434.9s within a broader 383.3\u2013443.3s discussion) and is therefore incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that nearly two-thirds of respondents had not had a video appointment, when does she state that telephone appointments were the most common way to access care?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.8,
        "end": 452.9
      },
      "pred_interval": {
        "start": 405.0,
        "end": 410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.80000000000001,
        "end": 42.89999999999998,
        "average": 42.849999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.14925373134328357,
        "text_similarity": 0.35605889558792114,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives a time window (405.0\u2013410.0s) that does not match the correct timing (447.8\u2013452.9s) and thus contradicts the reference; it is factually incorrect about when the telephone-appointments statement occurs."
      }
    },
    {
      "question_id": "003",
      "question": "After the blue slide with the speaker's title disappears, when does the speaker begin to mention what factors clinicians should consider for appointment formats?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 479.3,
        "end": 480.3
      },
      "pred_interval": {
        "start": 415.0,
        "end": 420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.30000000000001,
        "end": 60.30000000000001,
        "average": 62.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.12698412698412698,
        "text_similarity": 0.4031849503517151,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction places the start around 415\u2013420s, which directly contradicts the correct times (anchor 476.3s, target 479.3s); it omits the correct timestamps and mislocates the event by roughly 60 seconds."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stephanie finishes speaking and hands over to Mark, when does Mark begin to speak?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 606.5,
        "end": 607.0
      },
      "pred_interval": {
        "start": 510.0,
        "end": 510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 96.5,
        "end": 97.0,
        "average": 96.75
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.42748868465423584,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction fails to answer the timing question\u2014it gives no timestamps and instead states unrelated/incorrect information about the video start/end, omitting the key fact that Mark begins speaking at ~606.5\u2013607.0s."
      }
    },
    {
      "question_id": "002",
      "question": "Once Mark finishes introducing Calum Duncan, when does Calum Duncan start speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 638.3,
        "end": 639.3
      },
      "pred_interval": {
        "start": 510.0,
        "end": 510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 128.29999999999995,
        "end": 129.29999999999995,
        "average": 128.79999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.15789473684210528,
        "text_similarity": 0.38490086793899536,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is incorrect and unrelated: it references Stephanie and Mark instead of when Calum Duncan starts speaking and provides no timing information, contradicting the ground truth timestamps."
      }
    },
    {
      "question_id": "003",
      "question": "Once Calum Duncan says 'Next slide please', when does the second presentation slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 685.7,
        "end": 686.0
      },
      "pred_interval": {
        "start": 510.0,
        "end": 510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 175.70000000000005,
        "end": 176.0,
        "average": 175.85000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.0975609756097561,
        "text_similarity": 0.3174012303352356,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is unrelated to the question about when the second slide appears: it discusses when Calum starts speaking relative to Mark and omits the timing and the 'once_finished' relation given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 'near me is what we're going to focus on today', when does he describe it as 'internet-based'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 702.7,
        "end": 703.5
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.299999999999955,
        "end": 26.5,
        "average": 24.399999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.3143109679222107,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the relation (the description occurs after the anchor) but the anchor timestamp is incorrect (725.0s vs 699.8s) and the target time (702.7s) is not provided\u2014only a vague 'shortly after'\u2014so it fails to match the correct timings."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states there were '330 consultations per week' before the pandemic, when does he mention it went up to '10,000'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 737.0,
        "end": 739.0
      },
      "pred_interval": {
        "start": 745.0,
        "end": 750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.0,
        "end": 11.0,
        "average": 9.5
      },
      "rationale_metrics": {
        "rouge_l": 0.16326530612244897,
        "text_similarity": 0.053668051958084106,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer preserves the correct temporal order (the 10,000 figure occurs after the 330 figure) but gives incorrect absolute timestamps that differ substantially from the ground truth, so it is largely inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' for the first time, when does he point to the map on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.0,
        "end": 767.5
      },
      "pred_interval": {
        "start": 765.0,
        "end": 770.0
      },
      "iou": 0.1,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 2.5,
        "average": 2.25
      },
      "rationale_metrics": {
        "rouge_l": 0.20833333333333334,
        "text_similarity": 0.33907392621040344,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the 'after' relation and gives a pointing time close to the reference (770.0s vs 767.0s), but the anchor time is substantially off (765.0s vs 756.0s), so it's only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'go back to the next slide', when does the slide titled 'Video consulting using near me via attend anywhere platform' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 874.0,
        "end": 874.1
      },
      "pred_interval": {
        "start": 870.0,
        "end": 872.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 2.1000000000000227,
        "average": 3.0500000000000114
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.5432845950126648,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the slide appears immediately after the instruction, but it gives an incorrect anchor timestamp (870.0s vs 873.91s) and fails to report the exact slide appearance time (874.0s), so it is only partially accurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that 'Stephanie Fraser has talked about' the survey, when does he then say 'Back to next slide, Mark, please'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 884.0
      },
      "pred_interval": {
        "start": 930.0,
        "end": 932.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.0,
        "end": 48.0,
        "average": 47.5
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.4071081876754761,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (anchor before target) but gives times (930.0s \u2192 932.0s) that are far off from the reference (\u2248882.5s \u2192 883.0\u2013884.0s), so it is factually incorrect on the key timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'Next slide, please' at the 42-second mark, when does the slide titled 'Clinician and patient experience - Scotland' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 913.0,
        "end": 913.1
      },
      "pred_interval": {
        "start": 960.0,
        "end": 962.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.0,
        "end": 48.89999999999998,
        "average": 47.94999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.31818181818181823,
        "text_similarity": 0.47572964429855347,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the slide appears immediately after the instruction, but it gives the wrong absolute timestamp (960.0s vs the correct 912.0s for the cue and 913.0s for the slide), so key factual timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "During the discussion of what works well with video calls, when does the speaker express finding it much easier to interact with groups on a video call than on the telephone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1053.0,
        "end": 1062.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1060.0
      },
      "iou": 0.56,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 2.5,
        "average": 2.75
      },
      "rationale_metrics": {
        "rouge_l": 0.22950819672131145,
        "text_similarity": 0.4115975797176361,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the main semantic point (it's easier to interact with groups on video calls) but omits the crucial timestamped annotations (E1, E2 timing and 'during' relation) required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions technical issues with patient bandwidth, when does he advise to choose patients correctly to avoid those difficulties?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1134.0,
        "end": 1135.5
      },
      "pred_interval": {
        "start": 1070.0,
        "end": 1080.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.0,
        "end": 55.5,
        "average": 59.75
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705885,
        "text_similarity": 0.6376736164093018,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the causal/temporal relation that the advice comes after the mention of bandwidth issues, but it omits the specific timestamps and time-range details provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' to introduce the smart phone camera, when does he specifically point out his wife's iPhone on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1213.0,
        "end": 1215.0
      },
      "pred_interval": {
        "start": 1100.0,
        "end": 1110.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 113.0,
        "end": 105.0,
        "average": 109.0
      },
      "rationale_metrics": {
        "rouge_l": 0.28,
        "text_similarity": 0.6980141401290894,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits the key factual details (the specific timestamps for 'Next slide, please' and the wife's iPhone mention), making it incomplete compared to the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying 'Next slide please', when does the 'Sharing content' slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.574,
        "end": 1249.574
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1235.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.57400000000007,
        "end": 14.57400000000007,
        "average": 16.57400000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666669,
        "text_similarity": 0.6128249764442444,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only vaguely notes the speaker utters the phrase but provides no timing or the moment the 'Sharing content' slide appears (key facts in the reference), so it largely fails to answer the question."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'You can share things', when does he point towards the screen showing the brain scan?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1252.25,
        "end": 1252.85
      },
      "pred_interval": {
        "start": 1240.0,
        "end": 1245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.25,
        "end": 7.849999999999909,
        "average": 10.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.543122410774231,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states he points after saying the phrase but fails to provide the required timing details (the specific timestamps 1252.250s\u20131252.850s) and thus omits key factual elements of the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "During the discussion about poor picture quality, when does the speaker suggest clearing browser history?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1313.823,
        "end": 1315.286
      },
      "pred_interval": {
        "start": 1300.0,
        "end": 1305.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.823000000000093,
        "end": 10.286000000000058,
        "average": 12.054500000000075
      },
      "rationale_metrics": {
        "rouge_l": 0.45833333333333337,
        "text_similarity": 0.7036491632461548,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that the speaker suggests clearing browser history during the discussion, but it omits the precise timestamps and temporal boundaries given in the correct answer, which are key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying \"Thank you very much for that\", when does he state he is handing over to Jane?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.837,
        "end": 1430.682
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.836999999999989,
        "end": 10.682000000000016,
        "average": 12.259500000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705885,
        "text_similarity": 0.5153257846832275,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that he hands over to Jane after saying 'thank you very much for that', but it omits the key specifics (the exact timestamps and interval) given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that using 'Near Me' felt quite adventurous, when does she state that its use became vital to their whole service?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1636.0,
        "end": 1643.0
      },
      "pred_interval": {
        "start": 165.0,
        "end": 172.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1471.0,
        "end": 1471.0,
        "average": 1471.0
      },
      "rationale_metrics": {
        "rouge_l": 0.43478260869565216,
        "text_similarity": 0.6766100525856018,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes that she later says it became vital, but it gives an incorrect timestamp (165.0s vs. the correct ~1636.0s / target span 1646.0\u20131653.0s) and omits the original 'adventurous' timestamp, so key temporal details are wrong or missing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes asking Mark to go back to the previous slide, when does she say 'Thank you'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1676.54,
        "end": 1678.02
      },
      "pred_interval": {
        "start": 180.0,
        "end": 180.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1496.54,
        "end": 1498.02,
        "average": 1497.28
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454546,
        "text_similarity": 0.7036593556404114,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly implies the 'Thank you' occurs after the request to go back, but the timestamp is substantially incorrect (predicts 180.0s vs the reference 126.5s and does not match the target span 1676.54\u20131678.02). This significant timing mismatch makes the answer largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the 'Training and preparation' slide appears, when does the speaker mention the 'Level 1' training?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1791.0,
        "end": 1791.5
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1820.0
      },
      "iou": 0.01,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.0,
        "end": 28.5,
        "average": 24.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5974239110946655,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the temporal relation (the mention occurs after the slide), but it omits the key factual details\u2014the specific timestamps and explicit relation labeling\u2014present in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing tele-swallowing partners as 'our eyes and our hands and our ears', when does she start talking about preparing the clinical room?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1897.0,
        "end": 1901.0
      },
      "pred_interval": {
        "start": 1820.0,
        "end": 1900.0
      },
      "iou": 0.037037037037037035,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.0,
        "end": 1.0,
        "average": 39.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3793103448275862,
        "text_similarity": 0.5000450611114502,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted start time (1820.0s) contradicts the reference (1897.0\u20131901.0s) and thus is factually incorrect; it also fails to match the referenced end time (1895.0s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses tele-swallowing partners preparing the clinical room, when does she next talk about them providing reassurance to patients?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1906.0,
        "end": 1910.0
      },
      "pred_interval": {
        "start": 1900.0,
        "end": 1960.0
      },
      "iou": 0.06666666666666667,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 50.0,
        "average": 28.0
      },
      "rationale_metrics": {
        "rouge_l": 0.32142857142857145,
        "text_similarity": 0.502483606338501,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a single incorrect timestamp (1900.0s) that contradicts the correct event interval (1906.0\u20131910.0s) and omits the event intervals and 'next' relation; it is therefore largely incorrect though roughly in the same vicinity."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning emergency procedures in place onsite, when does the slide change to 'Technology/equipment'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1971.6,
        "end": 1972.0
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 1960.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.59999999999991,
        "end": 12.0,
        "average": 16.799999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.2641509433962264,
        "text_similarity": 0.30353623628616333,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('once finished') but omits all required timing details (anchor/target intervals and exact timestamps) specified in the ground truth, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the time the 'Technology/equipment' slide is displayed, when does the speaker discuss the need for a device with a webcam and microphone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2024.079,
        "end": 2026.579
      },
      "pred_interval": {
        "start": 1960.0,
        "end": 1970.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.07899999999995,
        "end": 56.57899999999995,
        "average": 60.32899999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.14925373134328357,
        "text_similarity": 0.35333308577537537,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that the mention occurs while the 'Technology/equipment' slide is displayed, but it omits the key factual timestamps and the specific E1/E2 timing relation provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the general category of 'certain resources' for teleswallow sessions, when does she mention 'appropriate diet and fluid consistencies'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.952,
        "end": 2061.952
      },
      "pred_interval": {
        "start": 1970.0,
        "end": 1980.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 88.95200000000023,
        "end": 81.95200000000023,
        "average": 85.45200000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.11356988549232483,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (that the mention occurs after the introduction) but omits the precise timestamps, the specific target event timing, and the note that it followed other listed resources, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that remote swallowing assessments are not intended to fully replace face-to-face assessments, when does she mention that they are a very useful addition?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2159.677,
        "end": 2162.619
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.677000000000135,
        "end": 22.619000000000142,
        "average": 26.14800000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322035,
        "text_similarity": 0.4066958427429199,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer accurately conveys that the 'very useful addition' remark occurs immediately after the comment about not replacing face-to-face assessments; it preserves the correct temporal relation though it omits the specific timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning gathering feedback from those who completed the training, when does she start talking about evaluating quantitative data?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2164.643,
        "end": 2186.427
      },
      "pred_interval": {
        "start": 2140.0,
        "end": 2150.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.64300000000003,
        "end": 36.427000000000135,
        "average": 30.535000000000082
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5282459855079651,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the qualitative order (the quantitative-data remark follows the feedback remark) but omits the key factual details in the reference\u2014explicit timestamps and that the target immediately follows the anchor's speech."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes her presentation by saying 'thank you very much for listening', when does the video visually transition to the male presenter?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2257.0,
        "end": 2258.0
      },
      "pred_interval": {
        "start": 2160.0,
        "end": 2170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.0,
        "end": 88.0,
        "average": 92.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307693,
        "text_similarity": 0.6446053981781006,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the video transitions to the male presenter after she says 'thank you very much for listening,' but it omits the key factual details in the reference\u2014specifically the precise timestamps (2256.0s and 2257.0s) and that the transition immediately follows her speech."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that picking up cues is difficult, when does she start talking about 'points to consider' for virtual technology?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2491.8,
        "end": 2498.2
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2500.0
      },
      "iou": 0.6399999999999636,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.800000000000182,
        "end": 1.800000000000182,
        "average": 1.800000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.37485364079475403,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction references the right events but gives significantly incorrect times (2490.0 vs 2491.8 for the end, and 2500.0 vs 2491.8 for the start) and contradicts the immediate continuation ('once_finished'), so it misaligns key factual time points."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions conducting a 'sprint audit' with patients, when does she state that 'most were very satisfied' with the virtual appointments?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2515.0,
        "end": 2516.0
      },
      "pred_interval": {
        "start": 2500.0,
        "end": 2510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.0,
        "end": 6.0,
        "average": 10.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3728813559322034,
        "text_similarity": 0.6119023561477661,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives an incorrect timestamp (2500.0s) for the quote\u2014actual timing is 2515.0\u20132516.0s\u2014and thus contradicts the event order (sprint audit at 2509.5s); it loosely notes 'after' but the timing is wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that patients found virtual technology 'more acceptable', when does she say 'So moving on to the next slide'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2638.0,
        "end": 2639.3
      },
      "pred_interval": {
        "start": 2510.0,
        "end": 2520.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 128.0,
        "end": 119.30000000000018,
        "average": 123.65000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.4444444444444445,
        "text_similarity": 0.48001691699028015,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted time (2510.0s) is substantially different from the correct timing (~2638.0\u20132639.3s) and contradicts the reference; it therefore fails to identify the correct moment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing confidentiality, when does she begin to mention the subtlety of the therapeutic relationship?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2693.583,
        "end": 2697.126
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2680.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.583000000000084,
        "end": 17.126000000000204,
        "average": 20.354500000000144
      },
      "rationale_metrics": {
        "rouge_l": 0.14634146341463414,
        "text_similarity": 0.5955920219421387,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the relationship (the mention occurs after confidentiality) but omits the key factual details from the reference\u2014no specific timing (start at 2693.583s, span to 2697.126s, and the 5.0s offset) is provided, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'It all comes down to Wi-Fi', when does she state that 'delivery of remote therapy is very, very difficult'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.0,
        "end": 2729.0
      },
      "pred_interval": {
        "start": 2750.0,
        "end": 2760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.0,
        "end": 31.0,
        "average": 27.0
      },
      "rationale_metrics": {
        "rouge_l": 0.5573770491803278,
        "text_similarity": 0.6052371263504028,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states the temporal relation (the quoted line occurs after the anchor), matching the reference, but it omits the precise timestamps given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'So next slide', when does the slide visually change to 'Practical considerations'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2884.0,
        "end": 2884.2
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 2851.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 33.19999999999982,
        "average": 33.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.29166666666666663,
        "text_similarity": 0.7365052700042725,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that the slide changes immediately after the verbal cue, but it omits the key factual details\u2014the specific timestamps (2883.0s and 2884.0s) given in the correct answer\u2014so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing 'Practical considerations', when does she first mention 'increasing reflective feedback'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2913.483,
        "end": 2916.268
      },
      "pred_interval": {
        "start": 2854.0,
        "end": 2856.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.483000000000175,
        "end": 60.26800000000003,
        "average": 59.8755000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7580217719078064,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the mention occurs during 'Practical considerations' but omits the key factual timestamps (2850.0 and 2913.483s) required by the question, so it's incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"for the patients\", when does the slide change to \"WHERE WE ARE NOW\"?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3067.769,
        "end": 3068.2
      },
      "pred_interval": {
        "start": 3035.0,
        "end": 3040.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.76899999999978,
        "end": 28.199999999999818,
        "average": 30.484499999999798
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.6264362931251526,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits the precise timestamps and the detail about when the slide is fully visible, so it is incomplete compared to the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says \"open up for some discussion\", when does the discussion slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3163.435,
        "end": 3163.7
      },
      "pred_interval": {
        "start": 3195.0,
        "end": 3200.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.565000000000055,
        "end": 36.30000000000018,
        "average": 33.93250000000012
      },
      "rationale_metrics": {
        "rouge_l": 0.35000000000000003,
        "text_similarity": 0.6271111965179443,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the temporal relation (the slide appears after the utterance) but omits the precise timestamps and completeness details (appearance at 3163.435s and fully visible by 3163.705s) given in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the first male speaker asks about attendees' experience with Near Me, when does the second male speaker begin talking about starting to use NearMe?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.9,
        "end": 3312.0
      },
      "pred_interval": {
        "start": 3256.0,
        "end": 3304.0
      },
      "iou": 0.6267857142857126,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.900000000000091,
        "end": 8.0,
        "average": 10.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.4528301886792452,
        "text_similarity": 0.48769280314445496,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gives times for both events but they deviate notably from the reference (first is ~7.2s later and second is ~35.1s later), so the answer is only partially correct and the second timestamp is significantly off."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second male speaker finishes stating the advantages and utility of NearMe, when does he mention supplementing normal activities?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.4,
        "end": 3293.32
      },
      "pred_interval": {
        "start": 3304.0,
        "end": 3317.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.599999999999909,
        "end": 23.679999999999836,
        "average": 19.639999999999873
      },
      "rationale_metrics": {
        "rouge_l": 0.3673469387755102,
        "text_similarity": 0.36593592166900635,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the relative order ('once finished') but gives substantially different timestamps (3304.0 vs 3283.40 and 3317.0 vs 3288.40), so it is factually incorrect on the key timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the first man finishes reading Jenny's chat message, when does he ask the audience if they would find guidance helpful?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3411.0,
        "end": 3415.0
      },
      "pred_interval": {
        "start": 3495.0,
        "end": 3500.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 84.0,
        "end": 85.0,
        "average": 84.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.4472731351852417,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (that he asks after reading the chat) but omits all required timestamps and the target span information, so it is incomplete relative to the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first man finishes reading John Hogan's comment about clinical interviewing, when does he state he was quite skeptical?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3434.9,
        "end": 3437.7
      },
      "pred_interval": {
        "start": 3505.0,
        "end": 3510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.09999999999991,
        "end": 72.30000000000018,
        "average": 71.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.39285714285714285,
        "text_similarity": 0.4440957009792328,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that he says he was skeptical but omits the key temporal details (the 44.9s start / 3434.9\u20133437.7s target span) and the timing relation specified in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the second woman mentions neuropsychology bringing out guidance, when is the next time a woman speaks about professional guidance?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3511.043,
        "end": 3528.447
      },
      "pred_interval": {
        "start": 3515.0,
        "end": 3520.0
      },
      "iou": 0.28729027809698926,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.95699999999988,
        "end": 8.447000000000116,
        "average": 6.201999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.32727272727272727,
        "text_similarity": 0.6760638952255249,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer contradicts the reference by claiming the second woman is the next to speak about professional guidance; the correct answer identifies the third woman speaking at 3500.0 (target span 3511.043\u20133528.447) and provides timing, which the prediction omits."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 36 people joined the session, when does he talk about taking the next steps with Richard and the team?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3574.7,
        "end": 3576.5
      },
      "pred_interval": {
        "start": 3605.0,
        "end": 3608.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.300000000000182,
        "end": 31.5,
        "average": 30.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.2537001371383667,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the target occurs after the mention (saying it happens immediately after), but it omits the precise timestamps and temporal details provided in the correct answer, so it's incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker makes a plea to fill in the survey, when does he ask if listeners would like to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3592.9,
        "end": 3594.1
      },
      "pred_interval": {
        "start": 3610.0,
        "end": 3614.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.09999999999991,
        "end": 19.90000000000009,
        "average": 18.5
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.20576655864715576,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the sequence (the question about engaging with the advisory committee occurs after the plea) but omits the key factual details\u2014specific anchor/target timestamps and intervals\u2014required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes thanking everyone for joining the session today, when does he mention that the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3599.8,
        "end": 3603.2
      },
      "pred_interval": {
        "start": 3615.0,
        "end": 3617.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.199999999999818,
        "end": 13.800000000000182,
        "average": 14.5
      },
      "rationale_metrics": {
        "rouge_l": 0.14925373134328357,
        "text_similarity": 0.21801424026489258,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the speaker mentions the session will be recorded and resources provided, but it omits the key factual details from the reference (the exact timestamps and the anchor/target timing and quote), making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'where did we start?', when does she mention considering moving to Near Me for patient contacts?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2332.719,
        "end": 2336.344
      },
      "pred_interval": {
        "start": 2315.0,
        "end": 2320.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.71900000000005,
        "end": 16.34400000000005,
        "average": 17.03150000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.1266292929649353,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the mention occurs after the question but omits the key factual details (the precise anchor and target timestamps and that the target is a direct follow-up), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says the pandemic came along, when does she mention adopting Near Me as their default for routine people?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2367.217,
        "end": 2412.045
      },
      "pred_interval": {
        "start": 2340.0,
        "end": 2345.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.2170000000001,
        "end": 67.04500000000007,
        "average": 47.131000000000085
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.208543062210083,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the relative order (the adoption was mentioned after the pandemic comment) but omits the required timing details and specific timestamps/segments provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the results of the focus groups for the qualitative study, when does she introduce the quotes from the participants?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2511.0,
        "end": 2512.0
      },
      "pred_interval": {
        "start": 2360.0,
        "end": 2370.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 151.0,
        "end": 142.0,
        "average": 146.5
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.3291301131248474,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the quotes are introduced after the results, but it omits the key factual details about the exact event boundaries/timestamps (E1 ending ~2469.0s; E2 starting at 2511.0s and finishing at 2512.0s), so it is too vague for the required answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks to fill in the survey, when does he ask if listeners want to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3591.7,
        "end": 3595.8
      },
      "pred_interval": {
        "start": 3605.0,
        "end": 3608.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.300000000000182,
        "end": 12.199999999999818,
        "average": 12.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2985074626865672,
        "text_similarity": 0.3609151244163513,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly captures the required temporal relation that the advisory-committee question occurs after the request to fill in the survey; although it omits absolute timestamps, the reference asked for a relative judgment."
      }
    },
    {
      "question_id": "002",
      "question": "Before the speaker thanks the speakers for their expertise, when does he mention the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3599.9,
        "end": 3603.7
      },
      "pred_interval": {
        "start": 3609.0,
        "end": 3611.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.099999999999909,
        "end": 7.300000000000182,
        "average": 8.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.3880597014925373,
        "text_similarity": 0.33829838037490845,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the key temporal relation that the mention of recording/resources occurs before the speaker thanks the speakers, preserving the meaning with no incorrect details (omitting timestamps is acceptable)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker initially thanks the audience for joining, when does he deliver his final 'thank you very much' for the session?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3614.6,
        "end": 3615.4
      },
      "pred_interval": {
        "start": 3612.0,
        "end": 3617.0
      },
      "iou": 0.1600000000000364,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.599999999999909,
        "end": 1.599999999999909,
        "average": 2.099999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.28947368421052627,
        "text_similarity": 0.44067007303237915,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relative order (the final 'thank you' occurs after the initial thanks) but omits the specific timestamps and precise timing details provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After Mark introduces Dr. John Mckeown and Dr. Naomi Dow, when does he ask Dr. Dow to describe how they've been using Near Me?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.48,
        "end": 34.4
      },
      "pred_interval": {
        "start": 21.0,
        "end": 23.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.48,
        "end": 11.399999999999999,
        "average": 10.94
      },
      "rationale_metrics": {
        "rouge_l": 0.32786885245901637,
        "text_similarity": 0.4402393698692322,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gets the sequence right but the timestamps are substantially incorrect (23.0s vs correct 31.48\u201334.4s and 21.0s vs correct 15.72s) and it omits the end time, so it fails to match the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once Dr. Naomi Dow finishes explaining how students take part in consultations, when does Mark ask Dr. Mckeown about the impact on the teaching team?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.96,
        "end": 124.4
      },
      "pred_interval": {
        "start": 195.0,
        "end": 196.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.04,
        "end": 71.6,
        "average": 73.82
      },
      "rationale_metrics": {
        "rouge_l": 0.4375,
        "text_similarity": 0.6375109553337097,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction preserves the event order but gives completely incorrect timestamps (195.0s/196.0s vs 117.60s/118.96\u2013124.4s) and omits the correct end time and specified 'once_finished' relation, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker introduces the concept of emotions in the session, when does the female speaker first mention 'real patients'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.9,
        "end": 202.6
      },
      "pred_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.099999999999994,
        "end": 37.400000000000006,
        "average": 35.25
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5439592599868774,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the temporal relation (female mentions 'real patients' after the male introduces emotions) but omits the specific timestamps (150.0s and 201.9\u2013202.6s) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the interviewer finishes asking the question about comparing models, when does the female speaker finish explaining the advantages of 'Near Me' regarding real patients and capacity?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 198.7,
        "end": 306.9
      },
      "pred_interval": {
        "start": 345.0,
        "end": 360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 146.3,
        "end": 53.10000000000002,
        "average": 99.70000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.17857142857142855,
        "text_similarity": 0.36413565278053284,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the reference: the correct answer specifies the female speaker finishes at 306.9s (well after the interviewer at 186.4s), whereas the prediction incorrectly states she finishes when the interviewer finishes."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the man is speaking on screen, when does he mention 'Near Me'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 342.0,
        "end": 344.0
      },
      "pred_interval": {
        "start": 356.0,
        "end": 357.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 13.0,
        "average": 13.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2272727272727273,
        "text_similarity": 0.44522660970687866,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (356.0s) contradicts the ground truth (342.0\u2013344.0s) and falls outside the man's speaking interval (337.0\u2013350.7s), so it is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying 'Thank you and goodbye', when do the 'NHS Scotland' and 'Near Me' logos appear with text links?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 360.0,
        "end": 361.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.0,
        "end": 1.0,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2181818181818182,
        "text_similarity": 0.1985648274421692,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the logos but gives the wrong time (360.0s) \u2014 the correct onset is ~351.0s and they last until 360.0s, so the timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the initial voiceover concludes with 'patient that day', when does the man on screen begin to say 'Thanks very much John and Amy'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 336.4,
        "end": 341.6
      },
      "pred_interval": {
        "start": 358.0,
        "end": 359.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.600000000000023,
        "end": 17.399999999999977,
        "average": 19.5
      },
      "rationale_metrics": {
        "rouge_l": 0.35294117647058826,
        "text_similarity": 0.5149280428886414,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted start time (358.0s) is substantially incorrect compared to the reference (336.40s start, 341.6s end) and omits the end time; it therefore fails to match the correct timing relation."
      }
    }
  ]
}