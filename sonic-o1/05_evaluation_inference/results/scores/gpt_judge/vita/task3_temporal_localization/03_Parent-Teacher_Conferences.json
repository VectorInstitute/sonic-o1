{
  "topic_id": 3,
  "topic_name": "Parent-Teacher Conferences",
  "num_evaluated": 530,
  "aggregated_metrics": {
    "mean_iou": 0.023133479771761153,
    "std_iou": 0.09257947283068967,
    "median_iou": 0.0,
    "R@0.3": {
      "recall": 0.03207547169811321,
      "count": 17,
      "total": 530
    },
    "R@0.5": {
      "recall": 0.013207547169811321,
      "count": 7,
      "total": 530
    },
    "R@0.7": {
      "recall": 0.0018867924528301887,
      "count": 1,
      "total": 530
    },
    "mae": {
      "start_mean": 175.6921679245283,
      "end_mean": 176.91987924528303,
      "average_mean": 176.30602358490563
    },
    "rationale": {
      "rouge_l_mean": 0.21384367291248413,
      "rouge_l_std": 0.09755577512617385,
      "text_similarity_mean": 0.4187140709773268,
      "text_similarity_std": 0.18346345936512104,
      "llm_judge_score_mean": 3.550943396226415,
      "llm_judge_score_std": 2.640441832774907
    },
    "rationale_cider": 0.26636397893073654
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "Once the speaker states he used to be a teacher, when does he explain why he would be called upon to interpret?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 25.699,
        "end": 29.902
      },
      "pred_interval": {
        "start": 0.0,
        "end": 12.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.699,
        "end": 17.902,
        "average": 21.8005
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367344,
        "text_similarity": 0.4341288208961487,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence (he mentions being a teacher and then explains why), but it fails to provide the requested timing details (the specific timestamps and the 'once_finished' relation) present in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker announces the opening poll, when does he start explaining how to format the name for the certificate?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 71.748,
        "end": 78.603
      },
      "pred_interval": {
        "start": 12.0,
        "end": 21.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.748000000000005,
        "end": 57.602999999999994,
        "average": 58.6755
      },
      "rationale_metrics": {
        "rouge_l": 0.15,
        "text_similarity": 0.3884968161582947,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect: it refers to explaining the poll setup at 12.0s rather than the name-formatting explanation at ~71.75s, and it misidentifies the event queried, contradicting the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Next, after the speaker states that those who don't need a certificate can ignore the poll, when does he start explaining what to do if the pop-up doesn't appear?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 83.778,
        "end": 88.445
      },
      "pred_interval": {
        "start": 21.0,
        "end": 24.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.778000000000006,
        "end": 64.445,
        "average": 63.6115
      },
      "rationale_metrics": {
        "rouge_l": 0.14084507042253522,
        "text_similarity": 0.413152277469635,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives an incorrect timestamp and only repeats the ignore-poll remark, failing to identify when the speaker begins explaining the pop-up issue; it contradicts the reference timings (52.445\u201355.487s and 83.778\u201388.445s) and omits the subsequent instruction."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker mentions not leaving the webinar by 'X-ing out', when does he instruct to use the 'red button' to close out?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 172.8,
        "end": 174.7
      },
      "pred_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.19999999999999,
        "end": 65.30000000000001,
        "average": 63.75
      },
      "rationale_metrics": {
        "rouge_l": 0.1568627450980392,
        "text_similarity": 0.2467881441116333,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the key temporal relation\u2014that the 'red button' instruction occurs after the 'X-ing out' remark\u2014but it omits the precise timestamps and event labels given in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker says he will leave up the poll, when does he mention sharing links in the chat?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 193.9,
        "end": 195.4
      },
      "pred_interval": {
        "start": 240.0,
        "end": 245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.099999999999994,
        "end": 49.599999999999994,
        "average": 47.849999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.31814509630203247,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the temporal order (sharing links occurs after he says he'll leave the poll) but omits the precise timestamps and the detail that the target speech follows a pause after the poll discussion."
      }
    },
    {
      "question_id": "003",
      "question": "After the male speaker discusses the second link, a webinar called 'Translation for Teachers', when does he introduce the third link for the Refugee Services of Texas charity?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 231.5,
        "end": 236.0
      },
      "pred_interval": {
        "start": 245.0,
        "end": 250.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.5,
        "end": 14.0,
        "average": 13.75
      },
      "rationale_metrics": {
        "rouge_l": 0.16,
        "text_similarity": 0.38945549726486206,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the third link is introduced after the second, but it omits the key factual details (the exact anchor and target time ranges: 213.5\u2013218.5s and 231.5\u2013236.0s) and thus lacks the specificity required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once Graciela finishes asking the participants to unmute and then mute themselves, when does she say \"Perfect\"?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 380.807,
        "end": 381.3
      },
      "pred_interval": {
        "start": 345.0,
        "end": 346.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.807000000000016,
        "end": 35.30000000000001,
        "average": 35.553500000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.3692307692307692,
        "text_similarity": 0.6076885461807251,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are far from the reference (off by ~29\u201335 seconds) and it wrongly claims the two events are simultaneous, contradicting the ground truth that 'Perfect' occurs after the mute/unmute instruction; thus it fails to match key factual elements."
      }
    },
    {
      "question_id": "002",
      "question": "Once Graciela finishes explaining how questions will be handled, when does she mention the glossary of terms?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 425.281,
        "end": 429.266
      },
      "pred_interval": {
        "start": 375.0,
        "end": 376.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.281000000000006,
        "end": 53.26600000000002,
        "average": 51.77350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.29729729729729726,
        "text_similarity": 0.6643069982528687,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is factually incorrect: it gives entirely different timestamps (375s vs ~425s) and incorrectly states the glossary coincides with the questions-handling segment, contradicting the reference which shows an immediate sequential transition."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the modes of interpretation used in educational settings, when does the slide transition to 'Educational Settings'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 560.8,
        "end": 560.9
      },
      "pred_interval": {
        "start": 510.0,
        "end": 512.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.799999999999955,
        "end": 48.89999999999998,
        "average": 49.849999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.28125000000000006,
        "text_similarity": 0.4624558687210083,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the slide transition happens after the speaker's mention (capturing the relative ordering), but it omits the precise timestamps and may misleadingly imply an immediate transition rather than the ~11-second gap given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker defines an educational setting, when does she list the types of institutions that can be included?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 575.0,
        "end": 585.8
      },
      "pred_interval": {
        "start": 512.0,
        "end": 514.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.0,
        "end": 71.79999999999995,
        "average": 67.39999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.2661604881286621,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that the listing occurs immediately after the definition, but it omits the precise timestamps and explicit E1/E2 mapping provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining where interpreters are mostly called, when does the slide change to an image with a diploma and US flag?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 628.0,
        "end": 628.1
      },
      "pred_interval": {
        "start": 514.0,
        "end": 516.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 114.0,
        "end": 112.10000000000002,
        "average": 113.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3142857142857143,
        "text_similarity": 0.633663535118103,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states that the slide changes immediately after the speaker finishes (matching the reference's relative timing), but it omits the precise timestamps and event labels (E1/E2) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the mandatory schooling age in the United States, when do they state the mandatory schooling age in Mexico?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 749.416,
        "end": 751.6
      },
      "pred_interval": {
        "start": 695.0,
        "end": 700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.416000000000054,
        "end": 51.60000000000002,
        "average": 53.00800000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.4983891546726227,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (Mexico stated after the US) but the timestamps are far off from the ground truth (predicted 695\u2013700s vs. actual ~744.5\u2013751.6s) and thus factually incorrect about timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker describes the grades for middle school or junior high in the United States, when do they describe the equivalent 'secundaria' grades in Mexico?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 804.2,
        "end": 809.5
      },
      "pred_interval": {
        "start": 705.0,
        "end": 710.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 99.20000000000005,
        "end": 99.5,
        "average": 99.35000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.6288396120071411,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives timestamps (705.0s \u2192 710.0s) that are drastically different from the reference (799.0\u2013803.6s \u2192 804.2\u2013809.5s); while both state the Mexico segment follows the U.S. segment, the timing is incorrect and thus fails to match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning the number of public schools in the U.S. in 2021, when does she state the average number of students per public school?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.167,
        "end": 877.377
      },
      "pred_interval": {
        "start": 874.0,
        "end": 875.0
      },
      "iou": 0.2375296912114058,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.83299999999997,
        "end": 2.3769999999999527,
        "average": 1.6049999999999613
      },
      "rationale_metrics": {
        "rouge_l": 0.30000000000000004,
        "text_similarity": 0.5989259481430054,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures that the average is stated immediately after the school-count, but it gives an incorrect timestamp for the school-count (874.0s vs the correct span ending at 873.167s) and omits the precise interval for the average-students utterance."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states the total allocation for K-12 schools, when does she mention the average amount per student?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 920.147,
        "end": 925.432
      },
      "pred_interval": {
        "start": 906.0,
        "end": 907.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.147000000000048,
        "end": 18.432000000000016,
        "average": 16.289500000000032
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.5448111295700073,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a time (906.0s) that contradicts the reference (about 920.1s) and is before the stated total allocation, so it is essentially incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning 'disciplinary meetings', when does she mention 'classroom instruction'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1191.5,
        "end": 1192.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1060.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 141.5,
        "end": 132.5,
        "average": 137.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367344,
        "text_similarity": 0.6021515727043152,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction notes both phrases are mentioned but fails to provide the timing or the immediate 'once finished' relation, and it mischaracterizes 'classroom instruction' as a participant rather than the subsequent item\u2014omitting key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker is listing the participants of ARD Meetings, when does she specifically mention the 'District Representative'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1240.5,
        "end": 1245.0
      },
      "pred_interval": {
        "start": 1070.0,
        "end": 1080.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 170.5,
        "end": 165.0,
        "average": 167.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2909090909090909,
        "text_similarity": 0.5160293579101562,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the 'District Representative' is mentioned during the participant list and near the end of that segment, but it omits the precise timestamps and specific timing detail given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes listing the participants of an ARD meeting, when does she begin discussing the purpose of the meeting?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1249.5,
        "end": 1252.8
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.5,
        "end": 7.7999999999999545,
        "average": 13.649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.30188679245283023,
        "text_similarity": 0.551777720451355,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamps conflict with the ground truth: listing ends at 1248.0s (not 1230.0s) and purpose begins at 1249.5s (not 1245.0s). The prediction is therefore substantially incorrect and omits the correct interval."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker asks about the reasons for an ARD meeting, when does she state the first reason?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1294.4,
        "end": 1296.1
      },
      "pred_interval": {
        "start": 1245.0,
        "end": 1250.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.40000000000009,
        "end": 46.09999999999991,
        "average": 47.75
      },
      "rationale_metrics": {
        "rouge_l": 0.18867924528301885,
        "text_similarity": 0.4654615521430969,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamp (1245.0s) is about 49 seconds earlier than the correct interval (1294.4\u20131296.1s) when the first reason is stated, so it does not match the correct moment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks about the different purposes of the ARD meeting, when does she start listing the initial purposes?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1445.358,
        "end": 1450.41
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.35799999999995,
        "end": 30.410000000000082,
        "average": 32.884000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.23255813953488377,
        "text_similarity": 0.3275219202041626,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and does not provide the requested timing or sequence (it fails to state when she starts listing the purposes and omits the timestamps), so it does not match the precise correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide fully displays the 'Review Assessment' section, when does the speaker specifically mention the 'full individual evaluation'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.092,
        "end": 1432.125
      },
      "pred_interval": {
        "start": 1530.0,
        "end": 1540.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 101.9079999999999,
        "end": 107.875,
        "average": 104.89149999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2439024390243903,
        "text_similarity": 0.5461414456367493,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relation that the speaker mentions the full individual evaluation after the Review Assessment, but it omits the precise timestamps and timing details provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing parental input, when does the text for 'Review PLAAFP' appear on the slide?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1531.58,
        "end": 1532.59
      },
      "pred_interval": {
        "start": 1600.0,
        "end": 1610.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 68.42000000000007,
        "end": 77.41000000000008,
        "average": 72.91500000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.2978723404255319,
        "text_similarity": 0.6843791604042053,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the text appears after the speaker finishes), but it omits the precise timestamps and the detail about when the text becomes fully visible, which are key elements of the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions being 'completely clueless' about the ARD meetings, when does she state that the terminology was 'so scary'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1602.75,
        "end": 1607.38
      },
      "pred_interval": {
        "start": 1625.0,
        "end": 1630.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.25,
        "end": 22.61999999999989,
        "average": 22.434999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.12307692307692307,
        "text_similarity": 0.08202657848596573,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a wildly incorrect timestamp (1625.0s vs ~0:06 and ~0:12) and only vaguely says 'right after,' failing to match the precise anchor/target timings and introducing hallucinated timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker states 'I am an interpreter', when does she recount the other interpreter responding 'I have to interpret'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1656.82,
        "end": 1658.744
      },
      "pred_interval": {
        "start": 1640.0,
        "end": 1645.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.819999999999936,
        "end": 13.743999999999915,
        "average": 15.281999999999925
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320754,
        "text_similarity": 0.28244516253471375,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies both events but gives timestamps that are ~15 seconds earlier than the ground truth and does not reflect that the target immediately follows the anchor; thus it is largely temporally incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker reviews the IEP goals and objectives, when does she begin to review accommodations?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1758.266,
        "end": 1760.028
      },
      "pred_interval": {
        "start": 1700.0,
        "end": 1705.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.266000000000076,
        "end": 55.02800000000002,
        "average": 56.64700000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.39597222208976746,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives much earlier timestamps (1695.0s \u2192 1700.0s) that contradict the reference times (anchor finishes at 1757.865s; target starts at 1758.266s), so it fails to match the key factual timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes discussing the previous assessment, when does she mention the proposal of the STAAR assessment?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1783.7,
        "end": 1791.4
      },
      "pred_interval": {
        "start": 178.0,
        "end": 182.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1605.7,
        "end": 1609.4,
        "average": 1607.5500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.08888888888888889,
        "text_similarity": 0.12692634761333466,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the STAAR proposal occurs after the previous assessment) but omits all key factual details from the correct answer\u2014no anchor/target timestamps, span durations, or the absolute\u2192relative judge mapping\u2014making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker concludes the topic of district-wide assessments and accommodations, when does she introduce the least restrictive environment?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1810.5,
        "end": 1815.2
      },
      "pred_interval": {
        "start": 195.0,
        "end": 198.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1615.5,
        "end": 1617.2,
        "average": 1616.35
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.25444304943084717,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the topic is introduced after concluding district-wide assessments), but it omits key details from the reference such as exact timestamps and that the introduction begins immediately at 1810.5s."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing the potential harmful effects of an instruction setting, when does she question if the benefits outweigh the harm?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1854.7,
        "end": 1857.3
      },
      "pred_interval": {
        "start": 204.0,
        "end": 206.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1650.7,
        "end": 1651.3,
        "average": 1651.0
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.08636412024497986,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relation that the question is asked after discussing harmful effects, but it omits the key factual details (exact timestamps and the target utterance) provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says she will send glossaries to Marco, when does she introduce disciplinary action meetings?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1969.3,
        "end": 1975.0
      },
      "pred_interval": {
        "start": 195.0,
        "end": 204.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1774.3,
        "end": 1771.0,
        "average": 1772.65
      },
      "rationale_metrics": {
        "rouge_l": 0.36666666666666664,
        "text_similarity": 0.5369879007339478,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly states the sequence (glossaries then disciplinary meetings) but gives a completely incorrect timestamp (195.0s vs the correct start at 1969.3s) and omits the end times and explicit 'after' relation, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining when disciplinary actions happen, when does the slide transition to 'Potential disciplinary outcomes'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2006.4,
        "end": 2007.1
      },
      "pred_interval": {
        "start": 204.0,
        "end": 208.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1802.4,
        "end": 1799.1,
        "average": 1800.75
      },
      "rationale_metrics": {
        "rouge_l": 0.4313725490196078,
        "text_similarity": 0.6874141693115234,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction preserves the 'once_finished' relation but gives a wildly incorrect timestamp (204.0s vs ~2006.4\u20132007.1s) and omits the settling time, so it is essentially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what skills are needed to interpret in an educational setting, when does she define the interpreter's role?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2161.0,
        "end": 2168.0
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.0,
        "end": 28.0,
        "average": 29.5
      },
      "rationale_metrics": {
        "rouge_l": 0.12000000000000001,
        "text_similarity": 0.3299179673194885,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction does not provide the requested timing or the after-relation; it merely restates a sequencing unrelated to when the interpreter's role is defined and therefore fails to match the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker stops sharing the slides, when does the video switch to the gallery view of the participants?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2465.33,
        "end": 2475.337
      },
      "pred_interval": {
        "start": 2435.0,
        "end": 2436.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.329999999999927,
        "end": 39.33699999999999,
        "average": 34.83349999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.18461538461538457,
        "text_similarity": 0.5785179734230042,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that the switch occurs after the speaker stops sharing, preserving the core relation, but it omits the precise timing (2465.33s switch and completion by 2475.337s) provided in the reference, so it's incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the 'Simultaneous Interpreting' slide is displayed, when does the speaker mention ARD meetings as a use case?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2409.449,
        "end": 2418.605
      },
      "pred_interval": {
        "start": 2447.0,
        "end": 2448.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.55099999999993,
        "end": 29.394999999999982,
        "average": 33.472999999999956
      },
      "rationale_metrics": {
        "rouge_l": 0.14634146341463417,
        "text_similarity": 0.6691794395446777,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that ARD meetings are mentioned after the 'Simultaneous Interpreting' slide, but it omits the precise timing information (start and end timestamps) provided in the correct answer, making it incomplete for the asked 'when' question."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker asks if everyone is still awake, when does she begin to explain the practice method?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2490.175,
        "end": 2497.855
      },
      "pred_interval": {
        "start": 2495.0,
        "end": 2496.0
      },
      "iou": 0.13020833333333612,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.824999999999818,
        "end": 1.8550000000000182,
        "average": 3.339999999999918
      },
      "rationale_metrics": {
        "rouge_l": 0.1724137931034483,
        "text_similarity": 0.40610092878341675,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the explanation comes after the question) but omits the key factual details from the reference\u2014specifically the precise start/end timestamps and timing offsets."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states that everyone at home will be interpreting, when does she ask if everyone is good with the plan?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2513.9,
        "end": 2515.1
      },
      "pred_interval": {
        "start": 2536.0,
        "end": 2540.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.09999999999991,
        "end": 24.90000000000009,
        "average": 23.5
      },
      "rationale_metrics": {
        "rouge_l": 0.27397260273972607,
        "text_similarity": 0.45345306396484375,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence (asks after stating the plan) but fails to provide the requested timing details or the specific relative/absolute timestamps given in the correct answer, omitting key factual elements."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks to discuss a classroom concern about Peter, when does she describe Peter as a sweet boy who enjoys stacking blocks?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2558.467,
        "end": 2564.21
      },
      "pred_interval": {
        "start": 2547.0,
        "end": 2550.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.467000000000098,
        "end": 14.210000000000036,
        "average": 12.838500000000067
      },
      "rationale_metrics": {
        "rouge_l": 0.22535211267605632,
        "text_similarity": 0.3920133113861084,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys that the speaker describes Peter as a sweet boy after asking about a classroom concern, but it omits the precise timestamp details and minor timing adjustments provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions Peter may benefit from special education services, when does she discuss the social worker's assessment and concerns at home?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2595.389,
        "end": 2610.228
      },
      "pred_interval": {
        "start": 2558.0,
        "end": 2560.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.389000000000124,
        "end": 50.228000000000065,
        "average": 43.808500000000095
      },
      "rationale_metrics": {
        "rouge_l": 0.3855421686746988,
        "text_similarity": 0.7503416538238525,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the social worker's assessment is discussed after the special education mention, but it omits the specific timestamps and explicit detail that the latter event builds on the former."
      }
    },
    {
      "question_id": "001",
      "question": "During the main speaker's instructions for showing thumbs up, sideways, or down, when do multiple participants start showing their reactions?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2731.0,
        "end": 2736.0
      },
      "pred_interval": {
        "start": 2675.0,
        "end": 2680.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.0,
        "end": 56.0,
        "average": 56.0
      },
      "rationale_metrics": {
        "rouge_l": 0.28,
        "text_similarity": 0.4473041296005249,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly states reactions occur after the speaker's instructions and omits the precise timings; the correct answer indicates multiple participants begin reacting during the instructions (2731\u20132736s) and provides anchor event timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "After the main speaker asks Marco if he has anything to say, when does Marco start talking about the link he shared?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2760.32,
        "end": 2763.065
      },
      "pred_interval": {
        "start": 2730.0,
        "end": 2740.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.320000000000164,
        "end": 23.065000000000055,
        "average": 26.69250000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.25925925925925924,
        "text_similarity": 0.4454428553581238,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the core relation that Marco begins talking about the link after the main speaker's question, matching the reference's temporal ordering; no factual errors or contradictions are present."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Okay' to transition, when does she start talking about questions related to a child's behavior for a rating scale?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2838.512,
        "end": 2846.226
      },
      "pred_interval": {
        "start": 2790.0,
        "end": 2800.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.51200000000017,
        "end": 46.22600000000011,
        "average": 47.36900000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.39593231678009033,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the topic occurs after the speaker says 'Okay,' but it omits the key timing details and the specific next-topic interval provided in the reference, so it is incomplete. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes instructing to write 'DK' if the answer is unknown, when does she start reading the first child-related question?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2867.07,
        "end": 2872.84
      },
      "pred_interval": {
        "start": 2856.0,
        "end": 2857.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.070000000000164,
        "end": 15.840000000000146,
        "average": 13.455000000000155
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.12120020389556885,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the question occurs after the instruction but wrongly claims it starts \"immediately after\"; the ground truth gives specific timestamps showing a ~7.2s delay (target starts at 2867.07s), which the prediction omits and contradicts."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'My child often argues with adults', when does she start reading the next child-related question?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2888.82,
        "end": 2892.66
      },
      "pred_interval": {
        "start": 2904.0,
        "end": 2905.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.179999999999836,
        "end": 12.340000000000146,
        "average": 13.759999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.16393442622950818,
        "text_similarity": 0.11821074783802032,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly states the next question begins 'right away,' whereas the correct answer shows a ~6-second gap (next starts at 2888.82s after 2882.78s) and provides precise timestamps; the prediction omits these key timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the video screen changes to a black view displaying names, when does the speaker read the question about the child blurring out answers?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2930.0,
        "end": 2934.78
      },
      "pred_interval": {
        "start": 2920.0,
        "end": 2921.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 13.7800000000002,
        "average": 11.8900000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1016949152542373,
        "text_similarity": 0.33039402961730957,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the question is read after the screen changes, but it omits the precise timestamps and the detail that the target audio occurs during the black-screen interval, thus missing key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker describes a child having difficulty waiting for their turn, when does she describe a child being constantly on the go?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3036.8,
        "end": 3044.7
      },
      "pred_interval": {
        "start": 3125.0,
        "end": 3140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 88.19999999999982,
        "end": 95.30000000000018,
        "average": 91.75
      },
      "rationale_metrics": {
        "rouge_l": 0.09090909090909093,
        "text_similarity": 0.24731135368347168,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer identifies the correct event but gives substantially incorrect timestamps (3125\u20133140s vs. the correct 3036.8\u20133044.7s) and thus fails the immediate-following temporal relation; timing error invalidates the response."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing a child being often forgetful in daily activities, when does she ask the audience how they did?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3099.8,
        "end": 3101.4
      },
      "pred_interval": {
        "start": 3165.0,
        "end": 3170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.19999999999982,
        "end": 68.59999999999991,
        "average": 66.89999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.06779661016949153,
        "text_similarity": 0.15085864067077637,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timing (3165.0\u20133170.0s) is far from the correct event (3099.8\u20133101.4s) and thus contradicts the reference; it also omits the anchor/target relation noted in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks about the remaining time, when does Marco start responding?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3134.1,
        "end": 3139.2
      },
      "pred_interval": {
        "start": 3185.0,
        "end": 3190.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.90000000000009,
        "end": 50.80000000000018,
        "average": 50.850000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.07272727272727272,
        "text_similarity": 0.37401309609413147,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted times (3185.0\u20133190.0s) contradict the reference (3134.1\u20133139.2s) and do not reflect that Marco's response directly follows the question, so the answer is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once Frank finishes asking if the 504 plan is inside the subject of special education, when does the woman in green confirm that it is?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3235.829,
        "end": 3239.914
      },
      "pred_interval": {
        "start": 3245.0,
        "end": 3250.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.170999999999822,
        "end": 10.085999999999785,
        "average": 9.628499999999804
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.6424102783203125,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamps deviate substantially from the reference (\u224810\u201315s later) and only give start times, omitting the correct finish time and the relation; therefore it fails to match the key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "Once Frank finishes stating that he thinks 504 is federal language, when does another woman ask for confirmation?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.61,
        "end": 3269.733
      },
      "pred_interval": {
        "start": 3260.0,
        "end": 3265.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.610000000000127,
        "end": 4.733000000000175,
        "average": 6.671500000000151
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.6499027013778687,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the ordering (woman asks after Frank) but the timestamps differ substantially (E1 is 7.59s early and E2 start is 3.61s early), and it omits E2's end time and the required relative relation mapping."
      }
    },
    {
      "question_id": "003",
      "question": "Once Jesse Thompson finishes asking how interpreters can stand up for themselves, when does the woman in green explain what interpreters have control over?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3361.672,
        "end": 3367.782
      },
      "pred_interval": {
        "start": 3300.0,
        "end": 3305.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.672000000000025,
        "end": 62.78200000000015,
        "average": 62.22700000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.35087719298245607,
        "text_similarity": 0.6016325950622559,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (E2 after E1) but the timestamps are substantially incorrect (off by ~56\u201361 seconds) and it omits the E2 end time and the explicit relation, so it is largely factually inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying she doesn't like being 'used' as an interpreter, when does she begin explaining what she needs for a successful encounter?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3404.5,
        "end": 3411.6
      },
      "pred_interval": {
        "start": 3495.0,
        "end": 3500.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.5,
        "end": 88.40000000000009,
        "average": 89.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.08219178082191782,
        "text_similarity": 0.14113125205039978,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (explanation follows the statement) but the timestamps are substantially incorrect and do not match the anchor/target intervals or the immediacy described in the correct answer, so it fails to align with the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that rules can be set ahead of time for pre-sessions, when does she explain what raising a hand means?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3433.1,
        "end": 3436.5
      },
      "pred_interval": {
        "start": 3500.0,
        "end": 3505.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.90000000000009,
        "end": 68.5,
        "average": 67.70000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.09836065573770493,
        "text_similarity": 0.20198191702365875,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the correct temporal relation (target after anchor) but the provided timestamps are far off from the reference intervals, omitting the correct event boundaries and thus giving incorrect factual timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the female speaker replies 'Yes' to the question about doing work on Zoom, when does she explain how consecutive interpreting works on Zoom?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3471.0,
        "end": 3493.0
      },
      "pred_interval": {
        "start": 3505.0,
        "end": 3510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 17.0,
        "average": 25.5
      },
      "rationale_metrics": {
        "rouge_l": 0.17721518987341772,
        "text_similarity": 0.2890194356441498,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly places the explanation shortly after the 'Yes' reply (matches the judge-adjusted start at 3510.0s), but it omits the target event's duration/end time and slightly shifts the anchor timing, so it is only partially complete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"And then you as the interpreter will go into that room as well,\" when does she explain what the attendees can hear?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3584.889,
        "end": 3595.545
      },
      "pred_interval": {
        "start": 3625.0,
        "end": 3630.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.110999999999876,
        "end": 34.45499999999993,
        "average": 37.2829999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3611111111111111,
        "text_similarity": 0.6506069898605347,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a substantially different timestamp and claims the explanation occurs immediately after, whereas the reference specifies the explanation occurs about 5 seconds later (once_finished) after a brief pause; thus it is factually misaligned."
      }
    },
    {
      "question_id": "002",
      "question": "After Martha Rosenbaum mentions that schools receive a lot of funding from the government, when does she ask how to change the use of teachers as translators?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3629.646,
        "end": 3632.125
      },
      "pred_interval": {
        "start": 3745.0,
        "end": 3750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 115.35399999999981,
        "end": 117.875,
        "average": 116.61449999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.18461538461538463,
        "text_similarity": 0.3182443678379059,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the question occurs immediately after the funding remark, but it gives a wrong/unsupported timestamp (3745.0s) and omits the precise E1/E2 intervals from the reference, so it is largely inaccurate on timing and detail."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker first mentions \"Executive Order 13166,\" when does she expand on its details, including its signing by President Clinton?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3669.853,
        "end": 3689.291
      },
      "pred_interval": {
        "start": 3765.0,
        "end": 3770.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 95.14699999999993,
        "end": 80.70899999999983,
        "average": 87.92799999999988
      },
      "rationale_metrics": {
        "rouge_l": 0.2121212121212121,
        "text_similarity": 0.624262273311615,
        "llm_judge_score": 0,
        "llm_judge_justification": "Error parsing LLM response: Expecting ',' delimiter: line 3 column 296 (char 311)"
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that organizations receiving federal funds must provide meaningful language access, when does she suggest starting those conversations?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3762.0,
        "end": 3764.7
      },
      "pred_interval": {
        "start": 3750.0,
        "end": 3760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.0,
        "end": 4.699999999999818,
        "average": 8.349999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.18867924528301888,
        "text_similarity": 0.1286875158548355,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the main point that conversations should start immediately after, but it gives an incorrect anchor timestamp (3750.0s vs 3762.0s) and omits the target end time, so it is factually imprecise."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male speaker jokes about Google Translate replacing human interpreters, when does Maria E. Mendoza respond with 'Exactly!'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3789.6,
        "end": 3790.5
      },
      "pred_interval": {
        "start": 3840.0,
        "end": 3845.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.40000000000009,
        "end": 54.5,
        "average": 52.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.04081632653061224,
        "text_similarity": 0.1654122769832611,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the response occurs immediately after the joke, but gives a significantly incorrect timestamp (3840.0s vs the actual ~3789.6\u20133790.5s), so the timing is wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once Susanna finishes asking if the Zoom environment for interpreting school meetings is common in other states, when does Maria E. Mendoza begin to respond?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3933.2,
        "end": 3934.2
      },
      "pred_interval": {
        "start": 3930.0,
        "end": 3940.0
      },
      "iou": 0.1,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.199999999999818,
        "end": 5.800000000000182,
        "average": 4.5
      },
      "rationale_metrics": {
        "rouge_l": 0.0784313725490196,
        "text_similarity": 0.2646828591823578,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that Maria responds soon after Susanna, but it gives incorrect and inconsistent timestamps (both at 3930.0s) rather than the reference times where the anchor ends at 3923.2\u20133932.2s and the target begins at 3933.2s, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once Maria E. Mendosa finishes saying people are getting more comfortable with in-person meetings, when does the next speaker begin to add her point?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3956.6,
        "end": 3957.8
      },
      "pred_interval": {
        "start": 4035.0,
        "end": 4036.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.40000000000009,
        "end": 78.19999999999982,
        "average": 78.29999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.21212121212121213,
        "text_similarity": 0.5439550876617432,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys that the next speaker speaks after Maria, but it omits the crucial timing details (start at 3956.6s and end at 3957.8s) and is imprecise by only saying 'immediately after.'"
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria E. Mendosa interrupts to say 'This is gonna help you feel better', when does she start talking about her conversation with a school district client?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 4002.0,
        "end": 4007.6
      },
      "pred_interval": {
        "start": 4036.0,
        "end": 4037.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 29.40000000000009,
        "average": 31.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.22535211267605634,
        "text_similarity": 0.32131922245025635,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the key timing\u2014that she begins discussing the school-district conversation immediately after saying 'This is gonna help you feel better'\u2014which matches the reference (start at 4002.0s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks to hear from Alejandra Mendez, when does Alejandra Mendez start speaking?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 4096.7,
        "end": 4098.5
      },
      "pred_interval": {
        "start": 4037.0,
        "end": 4038.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.69999999999982,
        "end": 60.5,
        "average": 60.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.37089264392852783,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction contradicts the ground truth by saying she starts immediately, whereas the reference specifies a ~4.7s delay (start at 4096.7s) and notes a short pause; it therefore omits key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says that the meetings are emotionally exhausting, when does Maria ask if the volume of meetings for Spanish-speaking families has increased?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4154.13,
        "end": 4166.78
      },
      "pred_interval": {
        "start": 4125.0,
        "end": 4130.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.13000000000011,
        "end": 36.779999999999745,
        "average": 32.95499999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814817,
        "text_similarity": -0.03300078958272934,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the relative order (Maria asks after the speaker's comment) but omits the precise anchor/target timestamps and timing details provided in the reference, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that there is more parent participation because it is easier, when does she mention a teacher requesting an in-person interpreter for initial ARD meetings?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4232.2,
        "end": 4238.0
      },
      "pred_interval": {
        "start": 4165.0,
        "end": 4170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.19999999999982,
        "end": 68.0,
        "average": 67.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.06349206349206349,
        "text_similarity": 0.07560333609580994,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the core relation that the teacher's request occurs after the speaker's comment, but it omits the key timestamp details and judge notes provided in the reference, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host says, 'let's do one more question from Jesse,' when does Jesse begin asking about teachers interpreting?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4340.45,
        "end": 4347.8
      },
      "pred_interval": {
        "start": 4325.0,
        "end": 4330.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.449999999999818,
        "end": 17.800000000000182,
        "average": 16.625
      },
      "rationale_metrics": {
        "rouge_l": 0.16393442622950816,
        "text_similarity": 0.49514251947402954,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction only states the sequence (host then Jesse) but gives an incorrect host timestamp (4325.0s vs ~4330.3\u20134338.0s) and omits the precise time when Jesse begins (~4340.45s); key timing details are missing/incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Jesse finishes asking about legal liability for teachers interpreting, when does Maria state there isn't a government push for certification?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4367.0,
        "end": 4370.11
      },
      "pred_interval": {
        "start": 4365.0,
        "end": 4370.0
      },
      "iou": 0.587084148728022,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 0.10999999999967258,
        "average": 1.0549999999998363
      },
      "rationale_metrics": {
        "rouge_l": 0.15151515151515152,
        "text_similarity": 0.3908175230026245,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies that Maria states there isn't a government push for certification immediately after addressing liability and gives a near timestamp, but it is slightly off from the reference (4367s vs 4365s) and omits the explicit linkage to Jesse's question and the exact E1/E2 timestamping."
      }
    },
    {
      "question_id": "003",
      "question": "After Maria instructs to Google 'Executive Order 13166', when does she mention the CLASs standards for healthcare organizations?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4461.82,
        "end": 4474.23
      },
      "pred_interval": {
        "start": 4400.0,
        "end": 4405.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.81999999999971,
        "end": 69.22999999999956,
        "average": 65.52499999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.2388059701492537,
        "text_similarity": 0.7051283717155457,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer preserves the correct event order but the timestamps are substantially inaccurate (predicted 4400.0s/4405.0s vs correct ~4453\u20134474s), so it fails to match the reference timing within tolerance."
      }
    },
    {
      "question_id": "001",
      "question": "After Maria E. Mendoza explains Executive Order 13166, when does Jon Thompson ask about the regulation's enforcement mechanisms?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4470.0,
        "end": 4612.51
      },
      "gt_interval": {
        "start": 4479.38,
        "end": 4496.58
      },
      "pred_interval": {
        "start": 4527.5,
        "end": 4530.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.11999999999989,
        "end": 33.42000000000007,
        "average": 40.76999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.17777777777777776,
        "text_similarity": 0.3027222752571106,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the relative relation ('after') and that Jon Thompson asks about enforcement, but it omits the key temporal details (the specific start/end timestamps and anchor timing) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria E. Mendoza finishes stating her uncertainty about the executive order's trickle-down effect to individual schools, when does she mention the federal government's right to withdraw funds?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4470.0,
        "end": 4612.51
      },
      "gt_interval": {
        "start": 4508.48,
        "end": 4516.58
      },
      "pred_interval": {
        "start": 4530.0,
        "end": 4532.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.520000000000437,
        "end": 15.920000000000073,
        "average": 18.720000000000255
      },
      "rationale_metrics": {
        "rouge_l": 0.15625,
        "text_similarity": 0.23608070611953735,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that she mentions the federal government's right to withdraw funds, but it omits the key factual details provided in the correct answer (the E1/E2 timestamps and the 'once_finished' relation), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once Maria E. Mendoza finishes giving the healthcare example of funding withdrawal for lack of interpreters, when does she state that 'there are very strict laws'?",
      "video_id": "6CdKh4ayAzM",
      "video_number": "001",
      "segment": {
        "start": 4470.0,
        "end": 4612.51
      },
      "gt_interval": {
        "start": 4552.98,
        "end": 4555.18
      },
      "pred_interval": {
        "start": 4532.5,
        "end": 4535.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.479999999999563,
        "end": 20.18000000000029,
        "average": 20.329999999999927
      },
      "rationale_metrics": {
        "rouge_l": 0.09836065573770492,
        "text_similarity": 0.0016020219773054123,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction merely restates that she says 'there are very strict laws' but fails to provide the requested timing/timestamps or the 'once_finished' temporal relation given in the correct answer, omitting key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that what's most important is helping her kid understand their experience, when does she explain that we often center the other person instead of our kid?",
      "video_id": "Z6o8S8JDg00",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 44.150000000000006
      },
      "gt_interval": {
        "start": 10.281,
        "end": 17.954
      },
      "pred_interval": {
        "start": 24.5,
        "end": 26.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.219,
        "end": 8.346,
        "average": 11.282499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.08823529411764706,
        "text_similarity": 0.18799765408039093,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer preserves the order (the second event occurs after the first), the provided timestamps are wholly inconsistent with the ground-truth intervals, so the prediction is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker asks 'Could we do this course together?', when does she say 'That would just be great. You don't have to agree with anything. I think that would be great.'?",
      "video_id": "Z6o8S8JDg00",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 44.150000000000006
      },
      "gt_interval": {
        "start": 25.207,
        "end": 27.812
      },
      "pred_interval": {
        "start": 37.8,
        "end": 39.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.592999999999996,
        "end": 11.587999999999997,
        "average": 12.090499999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.10526315789473684,
        "text_similarity": 0.16447877883911133,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the relative order right (target follows anchor) but the timestamps are substantially incorrect and it omits part of the quoted phrase and end time, so it does not match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces herself as April Rehrig, when does the text 'IEPs' appear on screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 44.229,
        "end": 45.479
      },
      "pred_interval": {
        "start": 10.0,
        "end": 12.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.229,
        "end": 33.479,
        "average": 33.854
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.59782475233078,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the 'IEPs' text appears after the speaker's introduction but omits the precise timestamps and duration provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker explains that Section 504 is a civil rights statute, when does the text 'Civil Rights Statute' appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.493,
        "end": 71.953
      },
      "pred_interval": {
        "start": 35.0,
        "end": 37.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.492999999999995,
        "end": 34.953,
        "average": 33.723
      },
      "rationale_metrics": {
        "rouge_l": 0.2978723404255319,
        "text_similarity": 0.6811892986297607,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the relation that the text appears during the speaker's explanation, but it omits the specific timestamps and duration details provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions '504 meetings with five tips', when does she explain what to do before the meeting?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 26.541,
        "end": 33.582
      },
      "pred_interval": {
        "start": 110.0,
        "end": 112.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.459,
        "end": 78.418,
        "average": 80.9385
      },
      "rationale_metrics": {
        "rouge_l": 0.33962264150943394,
        "text_similarity": 0.6655956506729126,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the general relation that the explanation follows the mention, but it omits the precise timing and the nuance that the explanation starts after the speaker finishes saying '504 meetings with five tips' (and lacks the provided timestamps and end time)."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"This is a problem because pro tip\", when does the \"Pro-Tip\" visual with a thumbs-up icon appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 177.7,
        "end": 179.0
      },
      "pred_interval": {
        "start": 152.0,
        "end": 153.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.69999999999999,
        "end": 26.0,
        "average": 25.849999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.12,
        "text_similarity": 0.22194744646549225,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states the visual appears immediately after the speaker finishes, matching the reference timing, but it omits the exact appearance (177.7s) and disappearance (179s) timestamps provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"Now it's time to talk about tip two\", when does the text \"Parent Letter of Attachment\" appear on screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 234.0,
        "end": 236.0
      },
      "pred_interval": {
        "start": 198.0,
        "end": 199.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.0,
        "end": 37.0,
        "average": 36.5
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.279419481754303,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the text appears after the speaker, but it omits the precise timestamps and misleadingly implies it appears immediately ('right after') whereas the correct answer shows the text appears several seconds later (at 234s)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says it's time to jump into the second part of what they will talk about, when do the animated files appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 357.05,
        "end": 358.05
      },
      "pred_interval": {
        "start": 345.0,
        "end": 346.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.050000000000011,
        "end": 12.050000000000011,
        "average": 12.050000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.40928077697753906,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only gives an incorrect timestamp for the anchor speech (345.0s vs. 350.05\u2013353.05s) and omits any information about when the animated files appear (357.05\u2013358.05s), so it fails to match the key facts and temporal relation."
      }
    },
    {
      "question_id": "002",
      "question": "During the speaker's question 'What is inside a 504 plan?', when do the question mark graphics appear and disappear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.5,
        "end": 457.0
      },
      "pred_interval": {
        "start": 357.0,
        "end": 358.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.5,
        "end": 99.0,
        "average": 94.75
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.6584299802780151,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives a single, wrong timestamp (357.0s) instead of the correct 447.05\u2013451.76s question and 447.5s\u2013457.0s graphic appearance/disappearance window, omitting the appearance/disappearance timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'now it's time to dive into tip four', when does the large golden number '4' graphic appear?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 442.05,
        "end": 444.05
      },
      "pred_interval": {
        "start": 369.0,
        "end": 369.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.05000000000001,
        "end": 75.05000000000001,
        "average": 74.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666669,
        "text_similarity": 0.4266035556793213,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the graphic appears immediately after the speaker, but gives an incorrect timestamp (369.0s vs ~442.05s) and omits the animation timing details, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning the Parent Report, when does she start explaining what a Parent Report is?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 521.0,
        "end": 526.5
      },
      "pred_interval": {
        "start": 512.0,
        "end": 513.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.0,
        "end": 13.5,
        "average": 11.25
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814814,
        "text_similarity": 0.32527899742126465,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives wrong timestamps (saying the anchor ends at 512.0s) and claims the explanation starts immediately, which contradicts the correct timings (anchor 517.7\u2013518.6s, target 521.0\u2013526.5s); thus it is largely incorrect. "
      }
    },
    {
      "question_id": "002",
      "question": "During the speaker's explanation about getting her free guide, when does the visual graphic of the guide appear on the screen?",
      "video_id": "CS23nY2tX-4",
      "video_number": "003",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 579.8,
        "end": 584.0
      },
      "pred_interval": {
        "start": 647.0,
        "end": 648.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.20000000000005,
        "end": 64.0,
        "average": 65.60000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290325,
        "text_similarity": 0.4488036334514618,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a single time (647.0s) that contradicts the correct interval (graphic appears at 579.8s and disappears at 584.0s during the speaker's 578.8\u2013582.5s anchor), so it is factually incorrect and omits the correct timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the daughter mentions Berkeley, when does she explain why she probably won't get in?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 175.1,
        "end": 180.0
      },
      "pred_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.900000000000006,
        "end": 60.0,
        "average": 59.95
      },
      "rationale_metrics": {
        "rouge_l": 0.3508771929824561,
        "text_similarity": 0.6144170165061951,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation (the explanation comes after the mention) but the timestamps are completely wrong and it omits the correct start/end times; thus it fails on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the mother asks how scouting works, when does the daughter start explaining her basketball options?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 191.5,
        "end": 195.9
      },
      "pred_interval": {
        "start": 260.0,
        "end": 270.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 68.5,
        "end": 74.1,
        "average": 71.3
      },
      "rationale_metrics": {
        "rouge_l": 0.2985074626865672,
        "text_similarity": 0.47138142585754395,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the causal order (daughter speaks after the mother's question) but the timestamps are severely incorrect (predicted 260s\u2192270s vs. correct ~189.4s\u2192191.5s), so it fails to match the key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "While the daughter says she is weighing her options and is not sure yet, when does the mother appear in the frame, leaning on the bed?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 252.3,
        "end": 256.5
      },
      "pred_interval": {
        "start": 300.0,
        "end": 305.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.69999999999999,
        "end": 48.5,
        "average": 48.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2285714285714286,
        "text_similarity": 0.48820143938064575,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies both events but gives timestamps that are substantially wrong (predicted 300.0s/305.0s vs ground truth 243.4\u2013261.7s for the daughter's utterance and 252.3\u2013256.5s for the mother's appearance), so the temporal relation is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman on the right says she didn't go to Howard, when does she mention where she did go?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 365.0,
        "end": 368.0
      },
      "pred_interval": {
        "start": 395.0,
        "end": 400.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.0,
        "end": 32.0,
        "average": 31.0
      },
      "rationale_metrics": {
        "rouge_l": 0.0816326530612245,
        "text_similarity": 0.30112457275390625,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is incorrect and contradictory: it claims she mentions Howard University and uses a vague cue ('after the daughter laughs') instead of the precise timestamps; it omits the correct university name and the accurate timing given in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the daughter laughs, when does she state that she has many options for college?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 423.0,
        "end": 428.5
      },
      "pred_interval": {
        "start": 406.0,
        "end": 410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.0,
        "end": 18.5,
        "average": 17.75
      },
      "rationale_metrics": {
        "rouge_l": 0.08888888888888889,
        "text_similarity": 0.24455749988555908,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only gives a vague sequence ('after mentioning her high school experience') and omits the precise timing given in the correct answer, while also introducing an unsupported detail about high school; it therefore fails to match the reference. "
      }
    },
    {
      "question_id": "001",
      "question": "After the mother asks if every college has sororities and fraternities, when does the daughter state that not every school has Greek life?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 538.294,
        "end": 539.697
      },
      "pred_interval": {
        "start": 546.0,
        "end": 548.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.706000000000017,
        "end": 8.302999999999997,
        "average": 8.004500000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.728410542011261,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies both events and their order, but the timestamps are significantly inaccurate (off by roughly 17s for the mother's utterance and ~9s for the daughter's start) and it omits the daughter's end time, so it fails to match the reference closely."
      }
    },
    {
      "question_id": "002",
      "question": "After the mother says her one regret in life is not joining a sorority, when does she mention her AP at school is a 'die hard AKA'?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 587.969,
        "end": 592.336
      },
      "pred_interval": {
        "start": 639.0,
        "end": 641.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.03099999999995,
        "end": 48.66399999999999,
        "average": 49.84749999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.3125,
        "text_similarity": 0.653011679649353,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the event order (regret then AP mention) but the timestamps are substantially incorrect and do not match the reference time ranges, so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once the girl on the right asks if she did Columbia, when does the girl on the left respond?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 703.8,
        "end": 704.0
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.200000000000045,
        "end": 26.0,
        "average": 23.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.16326530612244897,
        "text_similarity": 0.31833362579345703,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the response occurs immediately after the question (matching the relative timing) but gives a wrong absolute timestamp (725.0s vs ~702.6\u2013704.0s) and omits the specific anchor/target intervals, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the girl on the left states the acceptance rate, when does she start explaining what scattergrams are?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.6,
        "end": 781.7
      },
      "pred_interval": {
        "start": 740.0,
        "end": 745.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.600000000000023,
        "end": 36.700000000000045,
        "average": 32.150000000000034
      },
      "rationale_metrics": {
        "rouge_l": 0.11267605633802817,
        "text_similarity": 0.45098572969436646,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted start time (740.0s) is substantially different from the ground truth (767.6s); it contradicts the correct timestamp and thus is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman on the right says \"That Sydney wasn't feeling well\", when does she say \"He's doing well\"?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 917.7,
        "end": 918.6
      },
      "pred_interval": {
        "start": 956.0,
        "end": 961.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.299999999999955,
        "end": 42.39999999999998,
        "average": 40.349999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.1379310344827586,
        "text_similarity": 0.296312153339386,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the correct ordering (first then second) but the timestamps are off by ~40\u201344 seconds and omit the precise start/end intervals and short gap indicated in the ground truth, so it is largely incorrect. "
      }
    },
    {
      "question_id": "003",
      "question": "Once the woman on the right says \"And then Sydney will be next\", when does the woman on the left start talking about the college application process?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 988.4,
        "end": 992.1
      },
      "pred_interval": {
        "start": 974.0,
        "end": 980.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.399999999999977,
        "end": 12.100000000000023,
        "average": 13.25
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.3914863169193268,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are incorrect and contradict the reference: it places the anchor at 974.0s and the target at 980.0s, whereas the ground truth has the anchor at 984.54\u2013986.4s and the target starting at 988.4s (after the anchor). This prediction hallucinates timings and fails to preserve the 'once_finished' relation."
      }
    },
    {
      "question_id": "001",
      "question": "Once the girl on the left finishes listing application platforms, when does she say \"Just word of advice, just start\"?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1086.0,
        "end": 1089.5
      },
      "pred_interval": {
        "start": 1056.0,
        "end": 1057.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.0,
        "end": 32.5,
        "average": 31.25
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.28998246788978577,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a single timestamp (1056.0s) that is about 30s earlier than the correct target interval (1086.0\u20131089.5s) and does not capture the described anchor/target relation, so it is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the girl on the right asks \"what type of law?\", when does the girl on the left reply saying she'd probably go into civil law?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1119.5,
        "end": 1120.9
      },
      "pred_interval": {
        "start": 1084.0,
        "end": 1085.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.5,
        "end": 35.90000000000009,
        "average": 35.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.08,
        "text_similarity": 0.14205679297447205,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only gives an incorrect time for the question (1084.0s) and omits the reply timing and the once_finished relation; it fails to match the provided anchor/target timestamps and key relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the mother says \"a small school too\", when does the daughter stretch her arms up?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.741,
        "end": 1242.0
      },
      "pred_interval": {
        "start": 1356.0,
        "end": 1357.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 115.25900000000001,
        "end": 115.0,
        "average": 115.12950000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.39441412687301636,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') but omits the key factual details provided in the reference (the precise start time 1240.741s and end time 1242.0s after the mother's speech ending at 1240.28s)."
      }
    },
    {
      "question_id": "002",
      "question": "While the mother is explaining how teachers can adjust grades, when does the daughter adjust her body position?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.0,
        "end": 1281.0
      },
      "pred_interval": {
        "start": 1409.0,
        "end": 1410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 131.0,
        "end": 129.0,
        "average": 130.0
      },
      "rationale_metrics": {
        "rouge_l": 0.13043478260869568,
        "text_similarity": 0.3952152132987976,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (daughter adjusts during the mother's explanation), which preserves the meaning of the annotated timestamps; omitting exact times is acceptable per the relative judgment."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks her daughter what she was doing, when does the daughter respond 'You was yelling her name'?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1410.0,
        "end": 1455.304
      },
      "gt_interval": {
        "start": 1423.817,
        "end": 1429.817
      },
      "pred_interval": {
        "start": 1425.0,
        "end": 1430.0
      },
      "iou": 0.7790716480672834,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.1829999999999927,
        "end": 0.18299999999999272,
        "average": 0.6829999999999927
      },
      "rationale_metrics": {
        "rouge_l": 0.05405405405405406,
        "text_similarity": 0.15415969491004944,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the basic fact that the daughter responded, but it omits the crucial timing details, span, and the 'after' relation given in the correct answer, so it fails to provide the required specific information."
      }
    },
    {
      "question_id": "002",
      "question": "Once the daughter finishes saying 'The front door', when does the woman on the right begin responding and laughing?",
      "video_id": "aIgDLOYEj50",
      "video_number": "004",
      "segment": {
        "start": 1410.0,
        "end": 1455.304
      },
      "gt_interval": {
        "start": 1428.184,
        "end": 1432.184
      },
      "pred_interval": {
        "start": 1435.0,
        "end": 1440.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.816000000000031,
        "end": 7.816000000000031,
        "average": 7.316000000000031
      },
      "rationale_metrics": {
        "rouge_l": 0.16,
        "text_similarity": 0.40243443846702576,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the woman responds after the daughter finishes) but omits the key precise timing details provided in the reference (start at 1428.184s, end at 1432.184s)."
      }
    },
    {
      "question_id": "001",
      "question": "After Susan asks the audience to click on the subscribe button, when does she mention that talks will happen every two weeks?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 23.621,
        "end": 26.608
      },
      "pred_interval": {
        "start": 185.0,
        "end": 190.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 161.379,
        "end": 163.392,
        "average": 162.38549999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.4566478133201599,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that Susan mentions the talks happen every two weeks, but it fails to provide the required timing details and event timestamps specified in the correct answer, omitting key factual elements."
      }
    },
    {
      "question_id": "002",
      "question": "Once Susan introduces Nick Prollins, when does Nick greet Susan?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 83.186,
        "end": 83.986
      },
      "pred_interval": {
        "start": 190.0,
        "end": 195.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 106.814,
        "end": 111.014,
        "average": 108.91399999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1395348837209302,
        "text_similarity": 0.38870084285736084,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that Nick greets Susan after she introduces him, matching the core meaning, but it omits the precise timing and timestamp details provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the man states he had a class of 40 grade six boys, when does the woman touch her face in surprise?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 195.0,
        "end": 197.51
      },
      "pred_interval": {
        "start": 195.0,
        "end": 196.0
      },
      "iou": 0.39840637450199345,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.0,
        "end": 1.509999999999991,
        "average": 0.7549999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.18867924528301888,
        "text_similarity": 0.5302530527114868,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') and the woman's surprised face touch, but it omits the specific timing details (start/end timestamps) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man mentions the Reggio Emilia approach, when does the woman interject 'Not at all'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 271.17,
        "end": 272.771
      },
      "pred_interval": {
        "start": 270.0,
        "end": 271.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.170000000000016,
        "end": 1.771000000000015,
        "average": 1.4705000000000155
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5973045825958252,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the general relation that she interjects when he mentions the Reggio Emilia approach, but it omits the precise timing details (woman starts at 271.170s after the man finishes at 270.59s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says he learned mostly about behavior management, when does the woman state that everyone needs classroom management tips?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.3,
        "end": 356.5
      },
      "pred_interval": {
        "start": 365.0,
        "end": 370.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.699999999999989,
        "end": 13.5,
        "average": 12.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.163265306122449,
        "text_similarity": 0.5579102039337158,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the ordering (the woman's line comes after the man's), but it omits the key factual details \u2014 the specific timestamps (354.3s\u2013356.5s and 342.5s) requested in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying they are digressing, when does the woman state that it is connected to what they will talk about?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 392.9,
        "end": 395.5
      },
      "pred_interval": {
        "start": 405.0,
        "end": 410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.100000000000023,
        "end": 14.5,
        "average": 13.300000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.2807017543859649,
        "text_similarity": 0.5749261379241943,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction merely restates that the woman speaks after the man and gives no timing information; it omits the specific timestamps (392.9\u2013395.5) required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman asks about the relationship between families and schools, when does the man describe his previous role at a bilingual school?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 460.0,
        "end": 468.923
      },
      "pred_interval": {
        "start": 420.0,
        "end": 425.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.0,
        "end": 43.923,
        "average": 41.9615
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.40034523606300354,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the man speaks after the woman's question and mentions a bilingual school, but it omits the key factual details in the reference (the specific role 'Head of Primary' and the precise start/end timestamps around 460s\u2013468.923s)."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes asking about the common denominators in the parent-teacher relationship, when does the man say it's a 'really great question'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.804,
        "end": 584.905
      },
      "pred_interval": {
        "start": 512.0,
        "end": 513.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.80399999999997,
        "end": 71.90499999999997,
        "average": 71.85449999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.4446742534637451,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timing (start at 512.0s) directly contradicts the ground-truth timing (man starts 'Really great question' at 583.804s), so it is incorrect and omits the correct interval."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes explaining that there was an initial impression among groups that their problems were unique, when does he start describing what they were actually saying?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 610.142,
        "end": 620.738
      },
      "pred_interval": {
        "start": 514.0,
        "end": 516.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 96.14200000000005,
        "end": 104.73800000000006,
        "average": 100.44000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.13114754098360656,
        "text_similarity": 0.44168275594711304,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly states he begins describing after acknowledging the initial impression but gives a wrong timestamp (514.0s vs the correct ~610.142s) and omits the quoted segment end time, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man talks about parents wanting their children to succeed academically, when does he mention that many parents are unsure how to support their child?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.2,
        "end": 724.5
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.799999999999955,
        "end": 5.5,
        "average": 8.149999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.29391396045684814,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly indicates the event occurs after the anchor (semantic relation) but omits the precise timestamps and judge notes provided in the correct answer, so it lacks required specificity."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes asking what 'the best' means in the context of raising a child, when does the man explain that it looks different in different contexts?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 762.4,
        "end": 767.8
      },
      "pred_interval": {
        "start": 840.0,
        "end": 845.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.60000000000002,
        "end": 77.20000000000005,
        "average": 77.40000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.07142857142857144,
        "text_similarity": 0.3339259624481201,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the man responds after the woman finishes, but it omits the key factual details (the exact timestamps and that his reply starts immediately at 762.4s), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman describes a picture of a parent and infant looking at each other, when does she demonstrate with her phone a shift in parental focus?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 822.7,
        "end": 825.8
      },
      "pred_interval": {
        "start": 900.0,
        "end": 900.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.29999999999995,
        "end": 74.20000000000005,
        "average": 75.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454545,
        "text_similarity": 0.34782665967941284,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the reference: the correct answer specifies a phone demonstration from 822.7s\u2013825.8s showing the shift, whereas the prediction denies any demonstration and gives an incorrect video end time, so it is essentially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man states he doesn't have children himself, when does he explain how he has spent his career working with children and families?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.7,
        "end": 880.4
      },
      "pred_interval": {
        "start": 925.0,
        "end": 936.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.299999999999955,
        "end": 55.60000000000002,
        "average": 50.94999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.1365581750869751,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') but omits the required timing and event-span details (the specific timestamps and event boundaries given in the correct answer), so it's incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the man asks 'Tell me what matters to you?', when does the woman ask if he asks this question to parents and teachers?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 902.9,
        "end": 909.0
      },
      "pred_interval": {
        "start": 978.0,
        "end": 984.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.10000000000002,
        "end": 75.0,
        "average": 75.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.17647058823529413,
        "text_similarity": 0.33873313665390015,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') and the woman's question content, but it omits the specific timestamps, exact quoted phrasing, and other details provided in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the woman says she has been on a 'triangle' of experiences, when does she list her roles as a parent, teacher, and tutor?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1003.2,
        "end": 1017.677
      },
      "pred_interval": {
        "start": 1005.0,
        "end": 1012.0
      },
      "iou": 0.4835255923188514,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.7999999999999545,
        "end": 5.677000000000021,
        "average": 3.7384999999999877
      },
      "rationale_metrics": {
        "rouge_l": 0.15151515151515152,
        "text_similarity": 0.3522786498069763,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the basic sequencing (she lists roles in relation to the 'triangle' remark) but omits all precise details given in the reference (timestamps, exact start/end, and the explicit 'once_finished' relation), making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the male speaker finishes saying 'Really great strategy, really great strategy', when does he begin talking about clarifying something?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1101.703,
        "end": 1108.353
      },
      "pred_interval": {
        "start": 1056.0,
        "end": 1062.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.702999999999975,
        "end": 46.353000000000065,
        "average": 46.02800000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.06896551724137932,
        "text_similarity": 0.15318557620048523,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the clarification begins immediately after the quoted phrase, matching the temporal relation, but it omits the precise timestamps and duration provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker describes most parents wanting their children and teachers to thrive, when does he start talking about the 1%?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1146.304,
        "end": 1154.554
      },
      "pred_interval": {
        "start": 1134.0,
        "end": 1140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.304000000000087,
        "end": 14.554000000000087,
        "average": 13.429000000000087
      },
      "rationale_metrics": {
        "rouge_l": 0.07142857142857144,
        "text_similarity": 0.12650541961193085,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted start time (1134.0s) is incorrect\u2014about 12.3 seconds earlier than the correct start (1146.304s)\u2014and it omits the target end time, thus contradicting the reference timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'who trains us to deal with these situations?', when does the woman respond 'No one'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1256.9,
        "end": 1257.3
      },
      "pred_interval": {
        "start": 1350.0,
        "end": 1352.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 93.09999999999991,
        "end": 94.70000000000005,
        "average": 93.89999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.45376425981521606,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the immediate temporal relation (she replies right after his question) but omits the precise timestamps and duration provided in the ground truth, so it is incomplete. "
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes describing demanding parents, when does the woman say she's 'starting to break out in hives'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1302.8,
        "end": 1306.5
      },
      "pred_interval": {
        "start": 1400.0,
        "end": 1402.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.20000000000005,
        "end": 95.5,
        "average": 96.35000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.24657534246575344,
        "text_similarity": 0.6703263521194458,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the causal/temporal relation (the woman speaks after the man finishes), but it omits the key timestamp details and precise timing/duration provided in the reference, which are important to the answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman says she would love to know more about that, when does the man state that the ABCD trust model is not specifically for schools or parents?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1423.0,
        "end": 1434.135
      },
      "pred_interval": {
        "start": 1425.0,
        "end": 1430.0
      },
      "iou": 0.44903457566232635,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 4.134999999999991,
        "average": 3.0674999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.1851851851851852,
        "text_similarity": 0.13518497347831726,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the man's statement occurs after the woman's expression of interest, but it omits the key factual details\u2014the exact timestamps (starts at 1423s, ends at 1434.135s) and the anchor/target timing noted in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "When is the next time the man introduces a letter of the ABCD trust model after he explains 'A is for ability'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1543.182,
        "end": 1544.983
      },
      "pred_interval": {
        "start": 1500.0,
        "end": 1510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.182000000000016,
        "end": 34.98299999999995,
        "average": 39.08249999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.3612414002418518,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that 'B' is the next letter introduced, but it omits the required timing information (the event occurs at ~1543.182\u20131544.983s), so the answer is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes inviting teachers to move beyond the 'us against them' mindset, when does he introduce the idea of 'family engagement'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1496.349,
        "end": 1501.218
      },
      "pred_interval": {
        "start": 1570.0,
        "end": 1580.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.65100000000007,
        "end": 78.78199999999993,
        "average": 76.2165
      },
      "rationale_metrics": {
        "rouge_l": 0.18867924528301888,
        "text_similarity": 0.343040406703949,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the 'family engagement' idea is introduced immediately after the man's invitation, matching the reference's relative timing; no factual contradictions or omissions are present."
      }
    },
    {
      "question_id": "001",
      "question": "After the man states 'believability', when does he ask if you will do what you say you're going to do?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1659.124,
        "end": 1661.589
      },
      "pred_interval": {
        "start": 1620.0,
        "end": 1630.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.124000000000024,
        "end": 31.588999999999942,
        "average": 35.35649999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.4745762711864407,
        "text_similarity": 0.5274717807769775,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamp (1620.0s) contradicts the reference times (E1 at 1653.278s, E2 at 1659.124\u20131661.589s) and thus misrepresents the event order and timing; it also omits the correct interval information."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman asks for an example, when does the man describe the advice 'under promise and over deliver'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1691.205,
        "end": 1694.03
      },
      "pred_interval": {
        "start": 1740.0,
        "end": 1750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.79500000000007,
        "end": 55.97000000000003,
        "average": 52.38250000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.41379310344827586,
        "text_similarity": 0.5426108837127686,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the event occurs after the woman's question, but the provided timestamp (1740.0s) is substantially later than the actual E2 interval (1691.205\u20131694.03s) and it omits the event time ranges, so it is factually inaccurate and incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining why schools might not always follow through on promises, when does the woman summarize the advice as 'under promise and over deliver'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1742.844,
        "end": 1747.709
      },
      "pred_interval": {
        "start": 1790.0,
        "end": 1800.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.15599999999995,
        "end": 52.29099999999994,
        "average": 49.723499999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.30000000000000004,
        "text_similarity": 0.5313528776168823,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the event occurs after the man speaks but gives a single timestamp (1790.0s) that contradicts the correct interval (starts 1742.844s, ends 1747.709s) and omits the start/end details, so it's largely temporally inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker asks about initiatives, when does he ask if they have parent representative councils?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1820.1,
        "end": 1826.2
      },
      "pred_interval": {
        "start": 185.0,
        "end": 186.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1635.1,
        "end": 1640.2,
        "average": 1637.65
      },
      "rationale_metrics": {
        "rouge_l": 0.10169491525423728,
        "text_similarity": 0.17518502473831177,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to provide the timing or the specific follow-up relationship given in the reference and instead gives an unrelated, vague sequencing claim about the female speaker; it omits the timestamps and key detail that the question is a specific follow-up to the initiatives query."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker says the reading breakfast was 'such a cool thing', when does the female speaker react with wide eyes?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1848.0,
        "end": 1849.0
      },
      "pred_interval": {
        "start": 193.0,
        "end": 194.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1655.0,
        "end": 1655.0,
        "average": 1655.0
      },
      "rationale_metrics": {
        "rouge_l": 0.0,
        "text_similarity": 0.08426286280155182,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that her wide-eyed reaction occurs after his mention, but it omits the precise timing and event boundaries (the provided timestamps and sequence details), so it is incomplete relative to the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the female speaker mentions the connection with character strengths, when does she give examples of these strengths?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1957.0,
        "end": 1963.8
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2000.0
      },
      "iou": 0.1359999999999991,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 36.200000000000045,
        "average": 21.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981132,
        "text_similarity": -0.01200772449374199,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly implies the examples come shortly after the mention (relative order), but it incorrectly states this occurs at the beginning of the video and omits the precise timestamps given in the reference, so it is factually imprecise."
      }
    },
    {
      "question_id": "002",
      "question": "Once the female speaker talks about opportunities for 'loose ties communications between school staff and families', when does the male speaker agree?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2008.0,
        "end": 2009.5
      },
      "pred_interval": {
        "start": 2000.0,
        "end": 2050.0
      },
      "iou": 0.03,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.0,
        "end": 40.5,
        "average": 24.25
      },
      "rationale_metrics": {
        "rouge_l": 0.11428571428571427,
        "text_similarity": 0.33906927704811096,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies that the male agrees but gives a timestamp (~2000.0s) that contradicts the correct timestamps (male agreement at 2008.0\u20132009.5s) and omits that the agreement immediately follows the female's turn."
      }
    },
    {
      "question_id": "003",
      "question": "After the female speaker introduces 'dependability', when does the male speaker explain it as 'being consistent'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2050.0,
        "end": 2054.5
      },
      "pred_interval": {
        "start": 2050.0,
        "end": 2100.0
      },
      "iou": 0.09,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.0,
        "end": 45.5,
        "average": 22.75
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.4243454039096832,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the male speaker's explanation time (\u22482050.0s), matching the target start; it omits the target end time and the anchor (female introduction) timestamps noted in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks 'what do I believe?', when does he state that having a school that has done the thinking makes a teacher feel more supported?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2142.885,
        "end": 2150.675
      },
      "pred_interval": {
        "start": 2135.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.885000000000218,
        "end": 10.675000000000182,
        "average": 9.2800000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.3757556676864624,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the qualitative relation ('after') but omits all required precise timing details (the start/end timestamps for both events) and thus fails to provide the specific information requested."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says she can do her part but asks about the parents' part, when does the man explicitly state they are not talking about a wall regarding boundaries?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2228.336,
        "end": 2229.739
      },
      "pred_interval": {
        "start": 2200.0,
        "end": 2205.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.335999999999785,
        "end": 24.739000000000033,
        "average": 26.53749999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.29850746268656714,
        "text_similarity": 0.474543958902359,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the relational fact ('after') but omits the precise timestamps and explicit time interval details requested in the correct answer, making it incomplete for the 'when' question."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes saying he got schooled on something he didn't realize, when does he explain his naive assumption about WhatsApp?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2246.965,
        "end": 2299.733
      },
      "pred_interval": {
        "start": 2260.0,
        "end": 2270.0
      },
      "iou": 0.18950879320800473,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.034999999999854,
        "end": 29.733000000000175,
        "average": 21.384000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.2807017543859649,
        "text_similarity": 0.6087501049041748,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the relation (he explains it after finishing), but it omits all required timestamps and precise timing details provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes describing the participant's WhatsApp call from a mother during her holiday, when does he state that this behavior must stop?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2339.8,
        "end": 2341.0
      },
      "pred_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.19999999999982,
        "end": 59.0,
        "average": 57.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.5200400352478027,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that he says the behavior must stop after describing the WhatsApp call, but it omits the precise timing information and the fact that the statement immediately follows the description."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks if anyone else would be treated like that in any other industry, when does the woman reply 'No'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2381.0,
        "end": 2381.3
      },
      "pred_interval": {
        "start": 2460.0,
        "end": 2465.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.0,
        "end": 83.69999999999982,
        "average": 81.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.14545454545454545,
        "text_similarity": 0.40982115268707275,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction implies an immediate reply, matching the reference's intent, but it fails to provide the required temporal detail (2381.0\u20132381.3s) and is essentially a restatement rather than a precise answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes talking about the school's duty to create boundaries, when does he suggest working towards positive change?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.2,
        "end": 2575.5
      },
      "pred_interval": {
        "start": 2536.0,
        "end": 2547.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.199999999999818,
        "end": 28.5,
        "average": 29.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.28289616107940674,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states he proposes positive change after discussing duty, preserving the main meaning, but it omits the explicit timing detail that this occurs immediately after (and the specific time interval) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman says 'That's right', when does she start talking about teachers having problems with school leadership regarding boundaries?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2600.5,
        "end": 2606.0
      },
      "pred_interval": {
        "start": 2558.0,
        "end": 2569.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.5,
        "end": 37.0,
        "average": 39.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2978723404255319,
        "text_similarity": 0.5866498947143555,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly indicates the discussion begins immediately after 'That's right', aligning with the reference's relative timing, but it omits the precise start time (2600.5s) and the end-time detail."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'What's in and what's out for me?', when is the next time he asks 'What are my red lines?'",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2697.043,
        "end": 2698.184
      },
      "pred_interval": {
        "start": 2570.0,
        "end": 2579.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 127.04300000000012,
        "end": 119.1840000000002,
        "average": 123.11350000000016
      },
      "rationale_metrics": {
        "rouge_l": 0.3606557377049181,
        "text_similarity": 0.6464073657989502,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates that 'What are my red lines?' comes after the other question, but it omits the specific timestamps and does not state that it is the very next question, thus failing to answer the asked 'when' with the required detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker talks about reflecting on professional boundaries, when does he ask about boundaries around communication with parents and colleagues?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2677.99,
        "end": 2692.02
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2685.0
      },
      "iou": 0.31834695731154516,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.989999999999782,
        "end": 7.019999999999982,
        "average": 7.504999999999882
      },
      "rationale_metrics": {
        "rouge_l": 0.13559322033898305,
        "text_similarity": 0.10020408034324646,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and does not provide the required timestamps or state the relative ordering; it fails to identify when the question about communication with parents and colleagues occurs and omits key factual details from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker asks if teachers are okay with answering WhatsApp messages from colleagues after school hours, when does he ask if they are comfortable sharing their personal mobile number with a parent?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.77,
        "end": 2736.23
      },
      "pred_interval": {
        "start": 2730.0,
        "end": 2745.0
      },
      "iou": 0.36157864190365707,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.230000000000018,
        "end": 8.769999999999982,
        "average": 5.5
      },
      "rationale_metrics": {
        "rouge_l": 0.0425531914893617,
        "text_similarity": 0.020244527608156204,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the general topic (communication boundaries) but fails to provide the requested timing details (the specific timestamps and next-question note) and thus does not answer 'when' he asks. It is overly vague and omits key factual elements from the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the female speaker talks about being clear about boundaries and communicating them with 'whole heart', when does the male speaker discuss the comfort derived from setting clear boundaries?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2840.24,
        "end": 2850.66
      },
      "pred_interval": {
        "start": 2790.0,
        "end": 2805.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.23999999999978,
        "end": 45.659999999999854,
        "average": 47.94999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.23684210526315788,
        "text_similarity": 0.2530282139778137,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the male speaker speaks after the female speaker about clear boundaries, but it omits the precise timing and segment details (E1/E2 timestamps and exact follow-up), so it is incomplete compared to the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says, 'I want this to be practical', when does he say, 'You have no idea'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2960.516,
        "end": 2964.8
      },
      "pred_interval": {
        "start": 2935.0,
        "end": 2940.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.516000000000076,
        "end": 24.800000000000182,
        "average": 25.15800000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.08163265306122448,
        "text_similarity": 0.05290302261710167,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the target occurs after the anchor but incorrectly claims it happens 'right after' the anchor; the ground truth timestamps show the target is ~34 seconds later, so the timing claim is misleading."
      }
    },
    {
      "question_id": "002",
      "question": "After the man asks, 'Tell me what matters to you right now', when does the woman make a thumbs-up gesture?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 3024.99,
        "end": 3026.99
      },
      "pred_interval": {
        "start": 3000.0,
        "end": 3005.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.98999999999978,
        "end": 21.98999999999978,
        "average": 23.48999999999978
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.07413282990455627,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates the thumbs-up happens after the question, but it is vague and omits the precise timestamps and anchor/target interval details provided in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes saying, 'Thank you for sharing that information with me', when does he immediately advise to 'take note of that teacher'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 3046.646,
        "end": 3049.969
      },
      "pred_interval": {
        "start": 3060.0,
        "end": 3065.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.353999999999814,
        "end": 15.030999999999949,
        "average": 14.192499999999882
      },
      "rationale_metrics": {
        "rouge_l": 0.07272727272727272,
        "text_similarity": 0.13417531549930573,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that the instruction occurs immediately after the man finishes that line, matching the reference's key relation (target immediately follows anchor); omission of raw timestamps does not change the semantic answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes suggesting to invite families to propose solutions, when does the woman react with a wide-eyed expression?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3069.0,
        "end": 3070.0
      },
      "pred_interval": {
        "start": 3125.0,
        "end": 3126.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.0,
        "end": 56.0,
        "average": 56.0
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.24549832940101624,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys that the woman's wide-eyed reaction occurs immediately after the man's suggestion, but it omits the precise timestamps and exact start/end interval provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes warning against creating a 'cycle of learned helplessness', when does he ask how they would approach the problem?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3136.766,
        "end": 3138.327
      },
      "pred_interval": {
        "start": 3195.0,
        "end": 3197.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.233999999999924,
        "end": 58.672999999999774,
        "average": 58.45349999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.12244897959183673,
        "text_similarity": 0.4015464186668396,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately captures the key point that his question comes immediately after the warning (the target immediately follows the anchor), which preserves the correct answer's meaning despite omitting exact timestamps."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman first states that the advice is about 'a way of being', when does she re-emphasize that 'This is about a way of being'?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3178.623,
        "end": 3181.496
      },
      "pred_interval": {
        "start": 3145.0,
        "end": 3146.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.62300000000005,
        "end": 35.496000000000095,
        "average": 34.55950000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.08823529411764706,
        "text_similarity": 0.0782390832901001,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the re-emphasis occurs after the first statement, but it omits the precise timestamps and alignment details given in the correct answer, so it is incomplete though not contradictory."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman suggests to 'crack a window open', when does she ask 'what would happen if?'",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3213.0,
        "end": 3217.0
      },
      "pred_interval": {
        "start": 3295.0,
        "end": 3304.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 82.0,
        "end": 87.0,
        "average": 84.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3768115942028986,
        "text_similarity": 0.7672818899154663,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events and their order (the question follows the suggestion), but the provided timestamps are significantly offset from the reference (off by ~80\u201390 seconds) and it omits the event durations, so it does not match the correct timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the man confirms 'building bridges', when does the woman ask him about traveling?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3390.0,
        "end": 3482.7169999999996
      },
      "gt_interval": {
        "start": 3401.076,
        "end": 3404.512
      },
      "pred_interval": {
        "start": 3475.6,
        "end": 3478.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.52399999999989,
        "end": 73.68799999999965,
        "average": 74.10599999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.578382670879364,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (\u2018after\u2019) between the two utterances, but it omits the specific timestamps (E1 and E2) given in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says his website is on the screen, when does he mention having other tips and resources?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3390.0,
        "end": 3482.7169999999996
      },
      "gt_interval": {
        "start": 3425.376,
        "end": 3431.514
      },
      "pred_interval": {
        "start": 3479.0,
        "end": 3480.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.623999999999796,
        "end": 48.485999999999876,
        "average": 51.054999999999836
      },
      "rationale_metrics": {
        "rouge_l": 0.24390243902439027,
        "text_similarity": 0.40163981914520264,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that he mentions tips and resources after saying his website is on screen) but omits the precise start/end timestamps and duration given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman asks viewers to click the subscribe button, when does she mention inviting Nick back?",
      "video_id": "PQF4Fe1EQdk",
      "video_number": "005",
      "segment": {
        "start": 3390.0,
        "end": 3482.7169999999996
      },
      "gt_interval": {
        "start": 3471.07,
        "end": 3474.532
      },
      "pred_interval": {
        "start": 3481.0,
        "end": 3482.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.929999999999836,
        "end": 8.167999999999665,
        "average": 9.04899999999975
      },
      "rationale_metrics": {
        "rouge_l": 0.24390243902439024,
        "text_similarity": 0.6107374429702759,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the temporal relation (she invites Nick back after asking viewers to subscribe) but omits the specific timestamps and duration window provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker explains that she will show what to do before, during, and after parent-teacher conferences with five tips, when does the '5' graphic appear on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.258,
        "end": 37.358
      },
      "pred_interval": {
        "start": 195.0,
        "end": 196.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 163.742,
        "end": 158.642,
        "average": 161.192
      },
      "rationale_metrics": {
        "rouge_l": 0.2580645161290323,
        "text_similarity": 0.6058183908462524,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives a completely incorrect timestamp (195.0s) for the '5' graphic, contradicting the ground-truth timing of about 31.258s\u201337.358s."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker introduces herself as a special education advocate, when do the visual overlays 'IEPs' and '504 Plans' appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 47.954,
        "end": 51.274
      },
      "pred_interval": {
        "start": 187.0,
        "end": 188.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 139.046,
        "end": 136.726,
        "average": 137.886
      },
      "rationale_metrics": {
        "rouge_l": 0.3137254901960784,
        "text_similarity": 0.6661974191665649,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a completely incorrect timestamp (187.0s) instead of ~47.95\u201351.27s and omits the disappearance time; it only correctly notes the overlays coincide with her introduction."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what one needs to do to prepare to help their child, when does the 'How Do You Prepare?' graphic appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 192.8,
        "end": 195.0
      },
      "pred_interval": {
        "start": 245.0,
        "end": 246.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.19999999999999,
        "end": 51.0,
        "average": 51.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322037,
        "text_similarity": 0.3319936692714691,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the relative timing (the graphic appears immediately after the speaker's question) but omits the precise timestamps and duration (192.8s\u2013195.0s) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker mentions her guide 'The Ten Keys to Communication', when is the guide's cover displayed on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 238.0,
        "end": 242.0
      },
      "pred_interval": {
        "start": 270.0,
        "end": 271.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.0,
        "end": 29.0,
        "average": 30.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2807017543859649,
        "text_similarity": 0.5524176955223083,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly notes the cover appears while the speaker mentions the guide, but it omits the key temporal details given in the reference (the cover is shown from 238.0s to 242.0s within the speaker's 234.97\u2013247.03s remark), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "During the speaker's introduction of 'tip two', when does the 'Tip 2' graphic appear on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 294.0,
        "end": 298.0
      },
      "pred_interval": {
        "start": 295.0,
        "end": 296.0
      },
      "iou": 0.25,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 2.0,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.27450980392156865,
        "text_similarity": 0.7145877480506897,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the 'Tip 2' graphic appears during the speaker's introduction, but it omits the precise timing details (appears at 294.0s, disappears at 298.0s, and the speaker's exact introduction interval), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what the difference is between IEP and 504 plans, when does the graphic with the number '10' appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 380.8,
        "end": 383.86
      },
      "pred_interval": {
        "start": 345.0,
        "end": 346.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.80000000000001,
        "end": 37.860000000000014,
        "average": 36.83000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962265,
        "text_similarity": 0.333191454410553,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the graphic appears after the speaker's question, but it omits the key timing details provided in the correct answer (appears at 380.8s and disappears at 383.86s)."
      }
    },
    {
      "question_id": "002",
      "question": "After the text overlay 'Academic Adjustments' appears, when does the text overlay 'Accommodations' appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 450.722,
        "end": 451.722
      },
      "pred_interval": {
        "start": 370.0,
        "end": 371.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.72199999999998,
        "end": 80.72199999999998,
        "average": 80.72199999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.6887931823730469,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates that 'Accommodations' appears after 'Academic Adjustments', but it omits the precise timestamps and incorrectly asserts it appears 'immediately' after, which contradicts the 2-second gap in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker describes where children might be struggling by listing areas, when do icons representing different areas of need appear?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 455.722,
        "end": 460.135
      },
      "pred_interval": {
        "start": 380.0,
        "end": 381.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.72199999999998,
        "end": 79.13499999999999,
        "average": 77.42849999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1509433962264151,
        "text_similarity": 0.39798927307128906,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states that the icons appear during the speaker's listing of areas (captures the 'during' relation), but it omits the specific timing details provided in the reference (the exact onset and end timestamps)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces question two, when does she first ask what the teacher is doing to support the child?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 516.831,
        "end": 519.018
      },
      "pred_interval": {
        "start": 512.0,
        "end": 513.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.831000000000017,
        "end": 6.018000000000029,
        "average": 5.424500000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.13114754098360654,
        "text_similarity": 0.21370747685432434,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the question is asked immediately after introducing question two, matching the core sequence; however it omits the precise timestamps and the note about the brief overlap between anchor and target, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the discussion about the Meeting Toolkit, when does the speaker highlight how it provides clarity on accommodations versus modifications?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 609.57,
        "end": 615.0
      },
      "pred_interval": {
        "start": 567.0,
        "end": 568.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.57000000000005,
        "end": 47.0,
        "average": 44.785000000000025
      },
      "rationale_metrics": {
        "rouge_l": 0.16393442622950818,
        "text_similarity": 0.39125752449035645,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly locates the content during the Meeting Toolkit discussion but is overly vague and omits the required event labels and precise timestamps (E1/E2 and 609.5\u2013640.0s / 609.0\u2013615.0s), so it lacks essential details."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker talking about implementing new supports and services and wanting to follow up, when does the 'Follow Up' graphic appear on screen?",
      "video_id": "ANz32spFUqQ",
      "video_number": "006",
      "segment": {
        "start": 690.0,
        "end": 887.283
      },
      "gt_interval": {
        "start": 707.435,
        "end": 710.155
      },
      "pred_interval": {
        "start": 825.3,
        "end": 826.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 117.86500000000001,
        "end": 116.14499999999998,
        "average": 117.005
      },
      "rationale_metrics": {
        "rouge_l": 0.14545454545454545,
        "text_similarity": 0.35237938165664673,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly asserts the graphic appears when the speaker discusses follow-up, but it is vague and claims it appears at the 'exact moment' without the precise timestamps or duration given in the reference, thus omitting key timing details and risking inaccuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once Margaret finishes introducing herself, when does she introduce her husband Marco and sister Mary?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 9.58,
        "end": 12.102
      },
      "pred_interval": {
        "start": 0.0,
        "end": 3.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.58,
        "end": 9.102,
        "average": 9.341000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.0930232558139535,
        "text_similarity": 0.39052414894104004,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the sequence (she introduces Marco and Mary after herself) but fails to provide the requested timing information (the specific timestamps and that the family introduction directly follows her self-introduction), omitting key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After Margaret states they are speaking to primary and secondary teachers specifically, when does she say that the information can more broadly benefit students?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 50.9,
        "end": 55.67
      },
      "pred_interval": {
        "start": 15.0,
        "end": 18.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.9,
        "end": 37.67,
        "average": 36.785
      },
      "rationale_metrics": {
        "rouge_l": 0.06666666666666667,
        "text_similarity": 0.24460288882255554,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives a timestamp of 15.0s, which contradicts the correct timestamps (\u224844.2\u201355.7s) and therefore is completely incorrect about when the broader benefit statement occurs."
      }
    },
    {
      "question_id": "003",
      "question": "After Margaret tells interpreters and translators to email them for a certificate of attendance, when does she state that they are not producing certificates?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.787,
        "end": 114.451
      },
      "pred_interval": {
        "start": 20.0,
        "end": 22.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 85.787,
        "end": 92.451,
        "average": 89.119
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.47725653648376465,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timings (20s/21s) do not match the reference timestamps (~91\u2013114s) and thus are incorrect; the prediction fails to identify the correct moment when she says they are not producing certificates."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker touches on budgets and administrators, when does she mention pursuing things career-wise?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 172.462
      },
      "pred_interval": {
        "start": 240.0,
        "end": 245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.0,
        "end": 72.53800000000001,
        "average": 72.769
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5392024517059326,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation that the career-wise comment comes after budgets and administrators, but it omits the specific timing details (the provided timestamps ~167\u2013172s) that the correct answer includes."
      }
    },
    {
      "question_id": "002",
      "question": "After Marco says they are all 'language geeks', when does he describe his experience teaching in a bilingual program on the Mexican border?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 278.303,
        "end": 309.735
      },
      "pred_interval": {
        "start": 260.0,
        "end": 270.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.302999999999997,
        "end": 39.735000000000014,
        "average": 29.019000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.6605955362319946,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the bilingual-teaching remark comes after the 'language geeks' comment) but omits the specific timestamps given in the correct answer and adds a location detail not specified in the reference, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After Marco describes his experience of having to translate English handouts into Spanish, when does Margaret share a similar experience with campus newsletters?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 331.826,
        "end": 355.983
      },
      "pred_interval": {
        "start": 280.0,
        "end": 290.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.82600000000002,
        "end": 65.983,
        "average": 58.90450000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.4045371115207672,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (that Margaret speaks after Marco) but fails to provide the required timing details (Margaret: 331.826s\u2013355.983s), so the answer is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions working on the campus newsletter all week for a Friday release, when does she describe being asked to translate it on Thursday afternoon?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.383,
        "end": 355.983
      },
      "pred_interval": {
        "start": 345.0,
        "end": 350.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.382999999999981,
        "end": 5.983000000000004,
        "average": 7.682999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.14492753623188406,
        "text_similarity": 0.41482144594192505,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states that she was asked to translate on Thursday afternoon after mentioning the newsletter, preserving the relative ordering, but it omits the precise timestamp details and the note that the target segment immediately follows the anchor."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker finishes her point about being asked to translate due to bilingualism, when does the second speaker (Mary Lamb) introduce herself?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 413.696,
        "end": 416.456
      },
      "pred_interval": {
        "start": 360.0,
        "end": 365.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.696000000000026,
        "end": 51.45600000000002,
        "average": 52.57600000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.17391304347826086,
        "text_similarity": 0.46720272302627563,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction is factually correct in sequence (Mary speaks after the first speaker) but omits the key factual details provided in the reference\u2014precise timestamps and the noted brief pause\u2014so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker defines 'language access', when does she start talking about 'LEP'?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 705.6,
        "end": 710.0
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.399999999999977,
        "end": 20.0,
        "average": 19.69999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.17777777777777778,
        "text_similarity": 0.555978536605835,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the order right (LEP is discussed after language access) but incorrectly states it occurs 'immediately after' and omits the provided timestamps and the specified 6.6s gap, contradicting key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker clarifies that they are 'not talking about politics today', when does she explain that language comes with 'cultural and emotional baggage'?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 757.048,
        "end": 780.333
      },
      "pred_interval": {
        "start": 740.0,
        "end": 745.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.048000000000002,
        "end": 35.33299999999997,
        "average": 26.190499999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.1,
        "text_similarity": 0.20594695210456848,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer fails to address when the speaker discusses 'cultural and emotional baggage' and instead restates a different event (the politics clarification after defining 'LEP'), omitting the required timestamps and the baggage event entirely."
      }
    },
    {
      "question_id": "003",
      "question": "Once the male voice finishes inviting participants to the chat, when does the female voice add to the chat invitation?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 822.133,
        "end": 827.458
      },
      "pred_interval": {
        "start": 760.0,
        "end": 765.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.13300000000004,
        "end": 62.45799999999997,
        "average": 62.295500000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.2105263157894737,
        "text_similarity": 0.5253849029541016,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the female voice speaks shortly after the male voice, but it omits the crucial precise timing (start at 822.133s, end at 827.458s) and the exact relation to the anchor finishing, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker explains 'back translating' through DeepL, when does she say they will show an example?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 938.629,
        "end": 940.511
      },
      "pred_interval": {
        "start": 960.0,
        "end": 961.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.37099999999998,
        "end": 20.489000000000033,
        "average": 20.930000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.04545454545454545,
        "text_similarity": 0.14375966787338257,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted time (960.0s) is incorrect compared to the correct target interval (938.629\u2013940.511s) and it omits the anchor interval and the 'once_finished' relation, so it fails to match the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker points out that 'UIL Academics' was not translated by Google Translate, when does she explain the cultural meaning of 'a letter' in the US context?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 979.009,
        "end": 1035.774
      },
      "pred_interval": {
        "start": 975.0,
        "end": 976.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0090000000000146,
        "end": 59.77399999999989,
        "average": 31.89149999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.07407407407407407,
        "text_similarity": 0.24251770973205566,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted timestamp (975.0s) is close but incorrect: the correct explanation begins at 979.009s and continues to 1035.774s, with a different visual context and preceding discussion, so the prediction misplaces the event."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker discusses 'a letter referring to a letter jacket', when does she suggest changing the vocabulary for accurate translation?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1107.0,
        "end": 1150.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1052.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.0,
        "end": 98.0,
        "average": 77.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1935483870967742,
        "text_similarity": 0.36632099747657776,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the suggestion to 'change your vocabulary' occurs after the discussion, but it is vague and omits the key precise timing (the target start at 1107.0s and end at 1150.0s) and the explicit relation mapping; thus it lacks necessary detail."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that Google Translate and DeepL are almost identical and accurate for the student handbook, when does she highlight a minor difference in DeepL's translation?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1151.0,
        "end": 1161.0
      },
      "pred_interval": {
        "start": 1060.0,
        "end": 1062.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 91.0,
        "end": 99.0,
        "average": 95.0
      },
      "rationale_metrics": {
        "rouge_l": 0.15625,
        "text_similarity": 0.13717928528785706,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer is incorrect: it gives a single timestamp (1060.0s) that does not match the referenced interval (anchor 1144.0s\u20131150s; target 1151.0s\u20131161.0s). This misplaces the described event and fails to capture the correct timing relation."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining why AI machine translations struggle with literary texts, when does she provide the first example of a mistranslated Russian literary text?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1200.0,
        "end": 1204.0
      },
      "pred_interval": {
        "start": 1070.0,
        "end": 1072.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 130.0,
        "end": 132.0,
        "average": 131.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.4341024160385132,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (1070.0s) directly contradicts the reference, which places the anchor ending at 1199.0s and the example starting at 1200.0s, so the prediction is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the Spanish-speaking father begins his first statement, when does the interpreter finish translating it to English?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1467.348,
        "end": 1510.677
      },
      "pred_interval": {
        "start": 1425.0,
        "end": 1430.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.347999999999956,
        "end": 80.67699999999991,
        "average": 61.51249999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352942,
        "text_similarity": 0.5992062091827393,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only states a vague 'after' relation and gives an incorrect start time (1425.0s) while failing to provide the interpreter's actual finish time (~1510.677s) or the correct event timestamps, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the lecturer asks what's hard about consecutive interpretation, when does the interpreter finish explaining her challenges?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1509.179,
        "end": 1519.19
      },
      "pred_interval": {
        "start": 1500.0,
        "end": 1510.0
      },
      "iou": 0.04278269932255916,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.179000000000087,
        "end": 9.190000000000055,
        "average": 9.184500000000071
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814814,
        "text_similarity": 0.5446744561195374,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and contradicts the reference: it claims the interpreter finishes when the lecturer asks (and gives the wrong time 1500.0s), whereas the correct timeline shows the interpreter completes at 1519.19s after the question at ~1506.03\u20131509.159s."
      }
    },
    {
      "question_id": "003",
      "question": "After the lecturer introduces sight translation, when does the interpreter begin reading the handwritten note aloud?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1556.54,
        "end": 1558.452
      },
      "pred_interval": {
        "start": 1560.0,
        "end": 1570.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.4600000000000364,
        "end": 11.548000000000002,
        "average": 7.504000000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962262,
        "text_similarity": 0.6123759746551514,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the interpreter starts after the lecturer, but the timestamp is inaccurate: the interpreter actually begins at 1556.54s (lecturer ends at 1550.871s), not at 1560.0s, and it omits the precise start/end timestamps given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the main presenter mentions a side exercise on the next slide, when does he begin discussing the importance of preparation for interpreting?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1615.359,
        "end": 1621.799
      },
      "pred_interval": {
        "start": 1620.0,
        "end": 1630.0
      },
      "iou": 0.12287412062017408,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.641000000000076,
        "end": 8.201000000000022,
        "average": 6.421000000000049
      },
      "rationale_metrics": {
        "rouge_l": 0.208955223880597,
        "text_similarity": 0.38826191425323486,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly places the discussion after the anchor and gives a target time within the true target interval, but the anchor time is substantially incorrect (1590.0s vs 1614.659s) and the predicted start (1620.0s) is several seconds later than the actual start (1615.359s); it also omits the target's full duration and explicit explanation of importance."
      }
    },
    {
      "question_id": "002",
      "question": "After the main presenter describes an interpreter as a 'traffic cop', when does he describe the typical reactions people have to being instructed by an interpreter?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1703.019,
        "end": 1712.776
      },
      "pred_interval": {
        "start": 1630.0,
        "end": 1640.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.019,
        "end": 72.77600000000007,
        "average": 72.89750000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.1142857142857143,
        "text_similarity": 0.22427643835544586,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the relative order (target after anchor) but the timestamps are substantially inaccurate compared to the reference (predicted 1630/1640s vs. correct 1680.989/1703.019\u20131712.776s), so it fails to match the correct timings."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says he will see if the AI can understand him, when does he start speaking in Russian?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1813.0,
        "end": 1829.8
      },
      "pred_interval": {
        "start": 185.0,
        "end": 186.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1628.0,
        "end": 1643.8,
        "average": 1635.9
      },
      "rationale_metrics": {
        "rouge_l": 0.21818181818181817,
        "text_similarity": 0.3307512402534485,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives completely different timestamps (185s\u2013186s) and a hallucinated quote, failing to match the correct timings (1810.2\u20131829.8s) or the once_finished relation, so it is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker describes training attorneys and judges about simultaneous interpretation, when does he explain the purpose of this for non-bilingual people?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.703,
        "end": 1964.21
      },
      "pred_interval": {
        "start": 205.0,
        "end": 206.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1754.703,
        "end": 1758.21,
        "average": 1756.4565
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.4176638126373291,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the temporal relation (explanation comes after training) but the timestamps are completely incorrect (205s/206s vs. ~1950\u20131964s) and it fails to match the correct intervals, so it is largely wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the female speaker says it's hard to hear over the sound of her own voice, when does the male speaker comment about being distracted by reading?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2146.342,
        "end": 2148.204
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.3420000000001,
        "end": 8.204000000000178,
        "average": 12.273000000000138
      },
      "rationale_metrics": {
        "rouge_l": 0.2571428571428571,
        "text_similarity": 0.6075935363769531,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the male comment occurs after the female's remark, preserving the core relationship, but it omits the specific timestamps and precise timing details provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Interpreting' slide, when does the female speaker state that teaching and interpreting are two different jobs?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2219.994,
        "end": 2241.697
      },
      "pred_interval": {
        "start": 2190.0,
        "end": 2200.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.994000000000142,
        "end": 41.697000000000116,
        "average": 35.84550000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.5265408158302307,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly asserts that the speaker's statement occurs while the 'Interpreting' slide is displayed, but it omits the precise timestamps and relative/absolute timing details given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the male speaker explains that doing the interpretation exercise makes people more willing to speak slowly and make pauses, what is the next action he suggests?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2169.782,
        "end": 2173.68
      },
      "pred_interval": {
        "start": 2250.0,
        "end": 2260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.21799999999985,
        "end": 86.32000000000016,
        "average": 83.269
      },
      "rationale_metrics": {
        "rouge_l": 0.1728395061728395,
        "text_similarity": 0.48799657821655273,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer is vague and misses the specific next actions the speaker lists (giving written information or hiring an interpreter); it does not match the factual content of the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the other speaker states that translating 100 pages would take longer than a weekend, when does the main speaker agree and say it would probably take a month?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2348.812,
        "end": 2349.894
      },
      "pred_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.1880000000001,
        "end": 50.10600000000022,
        "average": 48.14700000000016
      },
      "rationale_metrics": {
        "rouge_l": 0.1016949152542373,
        "text_similarity": 0.3024798333644867,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the causal/order relation (the main speaker agrees after the other speaker), but it omits the key factual details in the reference\u2014specific start/end timestamps and the immediate follow-up relation\u2014so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the hourly rates for interpreters, when does he mention there is often a two-hour minimum?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2378.997,
        "end": 2380.078
      },
      "pred_interval": {
        "start": 2460.0,
        "end": 2465.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.00300000000016,
        "end": 84.92200000000003,
        "average": 82.96250000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.15094339622641512,
        "text_similarity": 0.652658998966217,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the two-hour minimum is mentioned after discussing hourly rates, but it omits the specific timing details (the timestamps 2378.997s\u20132380.078s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions being aware of the difference between freelancers and agencies, when does he explain that most translators and interpreters are freelancers who work for agencies?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2403.56,
        "end": 2407.963
      },
      "pred_interval": {
        "start": 2500.0,
        "end": 2510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 96.44000000000005,
        "end": 102.03699999999981,
        "average": 99.23849999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.07017543859649122,
        "text_similarity": 0.012138117104768753,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the explanation occurs after the mention but omits key factual details\u2014specific timestamps and that the target event immediately follows the anchor\u2014making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions working for an agency, when does she mention working as a freelancer?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2686.2,
        "end": 2687.5
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2685.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.199999999999818,
        "end": 2.5,
        "average": 9.349999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.15094339622641512,
        "text_similarity": 0.26219442486763,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly locates the freelancer mention near the correct time but gives an incorrect anchor time (2670.0s vs 2684.8\u20132686.0s) and misstates the relative timing; overall the timings are inaccurate and the relationship between anchor and target is not preserved."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'we can dare to dream', when does Marco start talking about his Spanish interpreting skills?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2733.4,
        "end": 2738.4
      },
      "pred_interval": {
        "start": 2695.0,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.40000000000009,
        "end": 38.40000000000009,
        "average": 38.40000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.23940697312355042,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps contradict the reference (2695.0s/2700.0s vs correct 2732.7s\u21922733.4s) and falsely implies a 5s gap rather than the immediate transition described, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After Marco describes how teaching Spanish improved his interpreting skills, when does the speaker (Margaret) share her similar experience about teaching young children?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2749.5,
        "end": 2752.9
      },
      "pred_interval": {
        "start": 2710.0,
        "end": 2720.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.5,
        "end": 32.90000000000009,
        "average": 36.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.11940298507462685,
        "text_similarity": 0.26447874307632446,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (Margaret speaks after Marco) but the timestamps are substantially incorrect compared to the reference (off by ~28\u201339 seconds) and thus do not align with the events described."
      }
    },
    {
      "question_id": "001",
      "question": "Once the female speaker finishes listing language populations like Vietnamese, German, and French, when does she mention Arabic?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2857.835,
        "end": 2858.836
      },
      "pred_interval": {
        "start": 2856.0,
        "end": 2860.0
      },
      "iou": 0.25024999999993724,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.8350000000000364,
        "end": 1.1640000000002146,
        "average": 1.4995000000001255
      },
      "rationale_metrics": {
        "rouge_l": 0.046511627906976744,
        "text_similarity": 0.0805930644273758,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly indicates Arabic is mentioned after listing Vietnamese, German, and French, but it omits the specified timestamps and the important detail that the mention immediately follows the anchor speech, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male speaker asks if an agency can provide a price for an interpreter scenario, when does he state that it's not a trade secret?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2915.411,
        "end": 2918.755
      },
      "pred_interval": {
        "start": 2934.0,
        "end": 2937.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.588999999999942,
        "end": 18.24499999999989,
        "average": 18.416999999999916
      },
      "rationale_metrics": {
        "rouge_l": 0.08163265306122448,
        "text_similarity": 0.16386491060256958,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the statement occurs after the price question but omits the crucial timing details (exact timestamps and that the target immediately follows the anchor), so it's incomplete relative to the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the male speaker invites participants to unmute and ask questions, when does he mention that an email with a video link will be sent next week?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2969.806,
        "end": 2975.771
      },
      "pred_interval": {
        "start": 2970.0,
        "end": 2973.0
      },
      "iou": 0.5029337803855704,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.19399999999995998,
        "end": 2.7710000000001855,
        "average": 1.4825000000000728
      },
      "rationale_metrics": {
        "rouge_l": 0.06666666666666667,
        "text_similarity": 0.22734889388084412,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the target occurs after the invitation (preserving the relative ordering), but it omits the specific timestamps and the note about a brief transition, so it is incomplete relative to the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman on the top left panel says \"I would go to that school as a starting point\", how long does she continue explaining the process of approaching a school?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3031.4,
        "end": 3049.5
      },
      "pred_interval": {
        "start": 3030.0,
        "end": 3045.0
      },
      "iou": 0.6974358974358927,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.400000000000091,
        "end": 4.5,
        "average": 2.9500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.13559322033898305,
        "text_similarity": 0.3038041889667511,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer fails to provide the requested duration and only restates that she begins explaining immediately; it omits the key factual element (the 18.1s span) and thus does not answer the question."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man on the top left panel finishes mentioning PTA meetings or board meetings, when does the woman on the top left panel start talking about who they want to know?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3059.8,
        "end": 3062.05
      },
      "pred_interval": {
        "start": 3060.0,
        "end": 3075.0
      },
      "iou": 0.13486842105264515,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.1999999999998181,
        "end": 12.949999999999818,
        "average": 6.574999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.04081632653061224,
        "text_similarity": 0.1584462970495224,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the woman speaks after the man and addresses who they want to know, but it omits the explicit timing details and the note that her remark is an immediate follow-up with precise timestamps."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man on the top left panel finishes explaining how to use YouTube videos for practice, when does the woman on the top left panel begin mentioning volunteering through church connections?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3110.298,
        "end": 3113.563
      },
      "pred_interval": {
        "start": 3120.0,
        "end": 3135.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.702000000000226,
        "end": 21.436999999999898,
        "average": 15.569500000000062
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.07713104039430618,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the woman begins mentioning volunteering immediately after the man finishes, but it omits the precise timestamps and the exact duration of the target event provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes asking her main question about recommendations for remote interpreting in educational settings, when does the man (Jesse Thompson) ask if she'll be working directly for the school or an agency?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3259.94,
        "end": 3264.367
      },
      "pred_interval": {
        "start": 3415.0,
        "end": 3418.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 155.05999999999995,
        "end": 153.6329999999998,
        "average": 154.34649999999988
      },
      "rationale_metrics": {
        "rouge_l": 0.20338983050847456,
        "text_similarity": 0.45301246643066406,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the relative ordering (the man asks after the woman finishes), but it omits the required event timestamps, event indices, and precise timing details present in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman says 'That's a great point' for the second time, when does she state that she will be persistent?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3384.717,
        "end": 3386.626
      },
      "pred_interval": {
        "start": 3420.0,
        "end": 3420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.2829999999999,
        "end": 33.373999999999796,
        "average": 34.32849999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413793,
        "text_similarity": 0.5413782596588135,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the temporal relation (that the persistence remark occurs after the second 'That's a great point'), but it omits the precise event timestamps and boundaries given in the correct answer, which are key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions she has been doing IEP meetings since January, when does she state that 80% of them were virtual?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3419.487,
        "end": 3423.472
      },
      "pred_interval": {
        "start": 3495.0,
        "end": 3500.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.51299999999992,
        "end": 76.52799999999979,
        "average": 76.02049999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307693,
        "text_similarity": 0.17838911712169647,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer correctly conveys the key temporal relation that the 80% virtual remark occurs after the speaker says she has been doing IEP meetings since January, matching the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker describes IEPs as not straightforward, when does another person define an IEP as an individualized education plan under special education?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3472.184,
        "end": 3478.875
      },
      "pred_interval": {
        "start": 3505.0,
        "end": 3510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.8159999999998,
        "end": 31.125,
        "average": 31.9704999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.03571428571428571,
        "text_similarity": 0.04638253152370453,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly restates that another person defines IEP as an individualized education plan, but it omits the required timestamps and the fact that the target utterance immediately follows the anchor, thus missing key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions that agencies don't get the information, when does she give examples like a brief summary or an IP packet?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3616.2,
        "end": 3624.0
      },
      "pred_interval": {
        "start": 3625.0,
        "end": 3640.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.800000000000182,
        "end": 16.0,
        "average": 12.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.3880597014925373,
        "text_similarity": 0.5410134196281433,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly collapses distinct events into a single time (3625.0s) and misplaces the example interval (actual examples 3616.2\u20133624.0s after the 3613.0s mention), so it is largely temporally inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says that doing the budget is the hardest part, when does she mention 'numbers, the dates, and all this'?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3631.3,
        "end": 3633.3
      },
      "pred_interval": {
        "start": 3670.0,
        "end": 3685.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.69999999999982,
        "end": 51.69999999999982,
        "average": 45.19999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.47457627118644075,
        "text_similarity": 0.5921757221221924,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the 'after' relation but gives an incorrect single timestamp (3670.0s) far later than the correct interval (starts 3631.3s\u20133633.3s) and omits the required start/end timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker suggests asking people to share their screen, when does she suggest asking them to scroll as they read?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3669.7,
        "end": 3672.2
      },
      "pred_interval": {
        "start": 3700.0,
        "end": 3715.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.300000000000182,
        "end": 42.80000000000018,
        "average": 36.55000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.4444444444444445,
        "text_similarity": 0.533881425857544,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the scroll request occurs after the share-screen suggestion but gives a timestamp (3700.0s) ~30s later than the correct interval (3669.7\u20133672.2s) and omits the share-screen timestamp and relation details, so it is substantially inaccurate/incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the first female speaker asks about inquiring with the school for contacts with various specialists for special education IEPs, when does the second female speaker state that it's a great idea for background information?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3750.0,
        "end": 3853.87
      },
      "gt_interval": {
        "start": 3772.54,
        "end": 3777.487
      },
      "pred_interval": {
        "start": 3756.9,
        "end": 3762.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.639999999999873,
        "end": 14.586999999999989,
        "average": 15.11349999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.27848101265822783,
        "text_similarity": 0.32904499769210815,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a similar start time for the first speaker but places the second speaker about 9.6 seconds earlier than the reference, reversing the temporal relation (not 'after') and thus contradicting the correct ordering and timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second female speaker finishes asking what professionals usually talk about, when does she ask about the terminologies they use?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3750.0,
        "end": 3853.87
      },
      "gt_interval": {
        "start": 3782.973,
        "end": 3786.917
      },
      "pred_interval": {
        "start": 3764.9,
        "end": 3768.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.072999999999865,
        "end": 18.016999999999825,
        "average": 18.044999999999845
      },
      "rationale_metrics": {
        "rouge_l": 0.15151515151515152,
        "text_similarity": 0.1996299922466278,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives timestamps that are substantially different from the reference (off by ~14\u201318s) and omits the precise end/start times and the 'next' relation; it therefore fails to accurately match the ground truth despite identifying two event times."
      }
    },
    {
      "question_id": "003",
      "question": "Once the male speaker finishes saying that interpreters are friendly and help each other, when does the second female speaker explain that it's because it's a small community?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 3750.0,
        "end": 3853.87
      },
      "gt_interval": {
        "start": 3843.755,
        "end": 3850.083
      },
      "pred_interval": {
        "start": 3770.9,
        "end": 3775.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.85500000000002,
        "end": 74.18299999999999,
        "average": 73.519
      },
      "rationale_metrics": {
        "rouge_l": 0.12987012987012986,
        "text_similarity": 0.23596134781837463,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the causal relation (explanation follows the male speaker) but the timestamps are substantially incorrect (off by ~68\u201373 seconds), so it fails on factual alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker introduces the topic of a parent letter, when does she mention that emotional language is fraught with danger for AI?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1264.183,
        "end": 1268.577
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1235.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.18299999999999,
        "end": 33.577,
        "average": 33.879999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.3793103448275862,
        "text_similarity": 0.6997089385986328,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the relative relation ('shortly after') but gives an incorrect E1 timestamp (1230.0s vs 1245.195s) and omits the precise E2 interval (1264.183\u20131268.577s), so it is imprecise and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker reads the ambiguous phrase 'I would have raised my hand on her child', when does she begin questioning its meaning?",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1297.182,
        "end": 1306.16
      },
      "pred_interval": {
        "start": 1240.0,
        "end": 1245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.182000000000016,
        "end": 61.16000000000008,
        "average": 59.17100000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.32142857142857145,
        "text_similarity": 0.3551674485206604,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the correct temporal relation (questioning occurs after the phrase) but gives substantially incorrect absolute timestamps and omits the questioning end time, so it fails to match the key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes saying that something 'doesn't make a lot of sense', when does the second speaker say 'Over to me?'",
      "video_id": "6Phe1ALDZSk",
      "video_number": "007",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1340.99,
        "end": 1341.351
      },
      "pred_interval": {
        "start": 1250.0,
        "end": 1255.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.99000000000001,
        "end": 86.35100000000011,
        "average": 88.67050000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.4306720495223999,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the temporal order (second speaker follows the first) but gives completely incorrect timestamps (1250/1255s vs ~1335\u20131341s) and omits the precise intervals and relation; therefore it is largely factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what she is talking about, when does she begin to explain it?",
      "video_id": "y9bwM3YYMd0",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 23.383
      },
      "gt_interval": {
        "start": 1.974,
        "end": 5.3
      },
      "pred_interval": {
        "start": 2.0,
        "end": 3.0
      },
      "iou": 0.3006614552014432,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.026000000000000023,
        "end": 2.3,
        "average": 1.1629999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814817,
        "text_similarity": 0.24888238310813904,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to answer when the explanation begins and omits the key timing information (E2 start at ~1.974s and completion), merely saying the question occurs at the start, so it is largely incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to document evidence and justify a request, when does she mention that 'all of this can be documented in writing'?",
      "video_id": "y9bwM3YYMd0",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 23.383
      },
      "gt_interval": {
        "start": 11.189,
        "end": 14.2
      },
      "pred_interval": {
        "start": 16.0,
        "end": 17.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.811,
        "end": 2.8000000000000007,
        "average": 3.8055000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.0634920634920635,
        "text_similarity": 0.06025958061218262,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly restates that the phrase follows the advice to document evidence and justify a request, but it fails to provide the required timing details (the specific timestamps 11.189s\u201314.2s) and thus omits key factual information."
      }
    },
    {
      "question_id": "001",
      "question": "After the male student in the plaid shirt says that they were 'invalidated', when does he mention 'mental health'?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 10.6,
        "end": 11.8
      },
      "pred_interval": {
        "start": 12.0,
        "end": 13.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.4000000000000004,
        "end": 1.1999999999999993,
        "average": 1.2999999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.0784313725490196,
        "text_similarity": -0.04572690278291702,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the reference: the correct answer states 'mental health' occurs later (10.6\u201311.8s) after the anchor, not immediately 'right after' 'invalidated', and it also omits the timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "After the female student in the black coat talks about 'basic respect', when does the female student in the purple hoodie question why a first-grader incident is being brought up?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 59.8,
        "end": 64.7
      },
      "pred_interval": {
        "start": 145.0,
        "end": 150.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 85.2,
        "end": 85.3,
        "average": 85.25
      },
      "rationale_metrics": {
        "rouge_l": 0.08955223880597013,
        "text_similarity": -0.0026016831398010254,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the temporal relation (the purple-hoodie question happens after the black-coat remark) but omits the crucial timestamps and event intervals provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the female student in the black hijab asserts that she 'did put a conclusion', when does the female student in the white hoodie explain the 'trauma-informed approach'?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.0,
        "end": 123.6
      },
      "pred_interval": {
        "start": 160.0,
        "end": 170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.0,
        "end": 46.400000000000006,
        "average": 44.2
      },
      "rationale_metrics": {
        "rouge_l": 0.1694915254237288,
        "text_similarity": 0.10704553127288818,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the key temporal relation (the white-hoodie student's explanation occurs after the black-hijab student's remark) but omits the specific timestamps and duration details given in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the first student finishes speaking about seeing their point of view, when does the man in the black vest and backpack start speaking?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 180.8,
        "end": 184.6
      },
      "pred_interval": {
        "start": 245.0,
        "end": 246.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.19999999999999,
        "end": 61.400000000000006,
        "average": 62.8
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322037,
        "text_similarity": 0.44203659892082214,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the man speaks after the student, but it omits the precise timestamps given in the reference (man starts at 180.8s, student ends at 179.0s) and misleadingly characterizes the start as \"immediately\" despite an ~1.8s gap."
      }
    },
    {
      "question_id": "001",
      "question": "After the girl in the purple hoodie finishes her statement, when does the man with the microphone ask if anyone else wants to speak?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 330.0,
        "end": 384.801
      },
      "gt_interval": {
        "start": 335.3,
        "end": 337.5
      },
      "pred_interval": {
        "start": 362.5,
        "end": 364.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.19999999999999,
        "end": 27.30000000000001,
        "average": 27.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3928571428571428,
        "text_similarity": 0.540546178817749,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the event occurs after the girl speaks but gives a significantly incorrect timestamp (362.5s vs the correct 335.3\u2013337.5s) and omits the event end time, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the girl in the grey hoodie finishes her explanation about introverts, when does the male student in the blue jacket start speaking?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 330.0,
        "end": 384.801
      },
      "gt_interval": {
        "start": 363.5,
        "end": 372.7
      },
      "pred_interval": {
        "start": 370.0,
        "end": 371.6
      },
      "iou": 0.17391304347826356,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 1.099999999999966,
        "average": 3.799999999999983
      },
      "rationale_metrics": {
        "rouge_l": 0.34374999999999994,
        "text_similarity": 0.5485409498214722,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the male speaks after the girl, but gives an incorrect start time (370.0s vs the reference 363.5s) and omits the girl's end time and the male's finish time, making it factually incomplete and inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man with the microphone asks the 'brother' if he wants to say anything, when does the man in the black vest respond?",
      "video_id": "f6q4KLKM5l4",
      "video_number": "010",
      "segment": {
        "start": 330.0,
        "end": 384.801
      },
      "gt_interval": {
        "start": 378.0,
        "end": 383.6
      },
      "pred_interval": {
        "start": 373.0,
        "end": 374.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 9.600000000000023,
        "average": 7.300000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.36065573770491804,
        "text_similarity": 0.5232016444206238,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives an incorrect timestamp (373.0s) that contradicts the reference start time (378.0s) and omits the response end time and the immediate 'once_finished' relation, so it is largely wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states that the cat comes in whenever it's showtime, when does she ask 'How do you know?'",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 58.579,
        "end": 60.615
      },
      "pred_interval": {
        "start": 26.0,
        "end": 27.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.579,
        "end": 33.615,
        "average": 33.097
      },
      "rationale_metrics": {
        "rouge_l": 0.30434782608695654,
        "text_similarity": 0.2453458160161972,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that the question follows immediately after the statement, but it omits the precise timing information (the given timestamps 58.579s\u201360.615s) included in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'We are going live', when does she welcome the friends?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.063,
        "end": 104.724
      },
      "pred_interval": {
        "start": 39.0,
        "end": 40.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.063,
        "end": 64.724,
        "average": 64.8935
      },
      "rationale_metrics": {
        "rouge_l": 0.10256410256410255,
        "text_similarity": 0.27925756573677063,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction directly contradicts the reference: the correct answer states 'Welcome friends' occurs later (~104.06s), not immediately after 'We are going live', so the timing is incorrect and key temporal details are omitted."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the Summer Stride Tuesday Night Author Series, when does she mention that it's summertime for adults?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 198.433,
        "end": 202.298
      },
      "pred_interval": {
        "start": 58.0,
        "end": 59.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 140.433,
        "end": 143.298,
        "average": 141.8655
      },
      "rationale_metrics": {
        "rouge_l": 0.21276595744680848,
        "text_similarity": 0.4007507264614105,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the 'summertime for adults' remark comes after the series introduction, preserving the main relation, but it omits the specific timing details and exact timestamps provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the 'Summer Stride Tuesday Night Author Series', when does she describe the Summer Stride reading challenge for adults?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.9,
        "end": 254.0
      },
      "pred_interval": {
        "start": 245.0,
        "end": 246.0
      },
      "iou": 0.019960079840319365,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.099999999999994,
        "end": 8.0,
        "average": 24.549999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.12698412698412698,
        "text_similarity": 0.24306905269622803,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the temporal relation that the adult reading challenge is mentioned after the Tuesday Night Author Series, but it omits the specific timestamps and descriptive details included in the reference answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"And it's really fun.\", when does she mention Malaka Garib doing a zine?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 342.37,
        "end": 345.33
      },
      "pred_interval": {
        "start": 395.0,
        "end": 400.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.629999999999995,
        "end": 54.670000000000016,
        "average": 53.650000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.0851063829787234,
        "text_similarity": -0.01591215282678604,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the event occurs after the anchor utterance, matching the key temporal relation, but it omits the specific timestamps and detailed timing information provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces Rhodessa Jones, when is the next time she says \"So please come check that out.\"?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 388.074,
        "end": 389.334
      },
      "pred_interval": {
        "start": 460.0,
        "end": 465.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.92599999999999,
        "end": 75.666,
        "average": 73.79599999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.04761904761904762,
        "text_similarity": 0.043385908007621765,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the phrase occurs after the introduction but omits the essential timing details provided in the correct answer (388.074\u2013389.334s), so it fails to answer the question as requested."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela mentions that any question is open for the chat, when does she hold up the physical copy of 'The Overly Honest Teacher'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 563.7,
        "end": 567.0
      },
      "pred_interval": {
        "start": 512.0,
        "end": 513.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.700000000000045,
        "end": 54.0,
        "average": 52.85000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307693,
        "text_similarity": 0.49119481444358826,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the temporal relation that Angela holds up the book after her remark, but it omits the specific timestamps (anchor 550.0\u2013555.0s and target 563.7\u2013567.0s) present in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once Angela finishes saying she will turn it over to Meredith, when does Meredith begin speaking?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 590.0,
        "end": 594.0
      },
      "pred_interval": {
        "start": 514.0,
        "end": 515.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.0,
        "end": 79.0,
        "average": 77.5
      },
      "rationale_metrics": {
        "rouge_l": 0.0851063829787234,
        "text_similarity": 0.48695698380470276,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly indicates Meredith begins speaking after Angela finishes, preserving the core temporal relation, but it omits the precise timestamps and the explicit note that Meredith's turn immediately follows at 590.0s\u2013594.0s."
      }
    },
    {
      "question_id": "003",
      "question": "After Meredith introduces herself as the author, when does she start talking about what everyone has gone through in the last 18 months regarding education?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 625.0,
        "end": 679.0
      },
      "pred_interval": {
        "start": 516.0,
        "end": 517.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 109.0,
        "end": 162.0,
        "average": 135.5
      },
      "rationale_metrics": {
        "rouge_l": 0.339622641509434,
        "text_similarity": 0.3744235336780548,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the key relation: Meredith discusses the last 18 months after introducing herself, which matches the correct answer's relative timing (target occurs after anchor)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the main topic slide, when does the first specific point, 'Consistency', appear on screen?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 727.0,
        "end": 727.9
      },
      "pred_interval": {
        "start": 690.0,
        "end": 700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.0,
        "end": 27.899999999999977,
        "average": 32.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.24000000000000002,
        "text_similarity": 0.4653143882751465,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the qualitative relation that 'Consistency' appears after the main topic slide, but it omits the key factual timing details (727.0s appearance and 727.9s settling, plus the title slide times) required by the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the last point, 'Autonomy', appears on screen, when does the speaker begin to talk about her past teaching experience and starting the year with the definition of autonomy?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 749.5,
        "end": 751.9
      },
      "pred_interval": {
        "start": 840.0,
        "end": 850.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.5,
        "end": 98.10000000000002,
        "average": 94.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.26865671641791045,
        "text_similarity": 0.5444159507751465,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the relation ('after') but omits the key factual details (the specific timestamps and relative timing) provided in the correct answer, making it overly vague."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker uses the example of traffic lights to explain consistency, when does she give the example of microwave popcorn instructions?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 822.0,
        "end": 831.0
      },
      "pred_interval": {
        "start": 890.0,
        "end": 900.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 68.0,
        "end": 69.0,
        "average": 68.5
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.5209380984306335,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the microwave popcorn example occurs after the traffic lights example (relation = next), but it omits the key temporal details/timestamps (822.0s\u2013831.0s) requested by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions setting meal times as important, when does she elaborate on discussing meals further during the evening?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 891.0
      },
      "pred_interval": {
        "start": 954.0,
        "end": 962.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.0,
        "end": 71.0,
        "average": 71.0
      },
      "rationale_metrics": {
        "rouge_l": 0.09836065573770492,
        "text_similarity": 0.15088137984275818,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') that the elaboration occurs after mentioning meal times, but it omits key factual details from the reference (exact timestamps and quoted phrasing), making it incomplete for the requested answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide lists 'Daily schedule of classes', 'Set meal times', etc., when does the speaker elaborate on students crashing and burning due to lack of food?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 900.2,
        "end": 911.0
      },
      "pred_interval": {
        "start": 870.0,
        "end": 873.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.200000000000045,
        "end": 38.0,
        "average": 34.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.03278688524590164,
        "text_similarity": 0.13427060842514038,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the relation that the elaboration occurs during the discussion of 'Daily schedule of classes', matching the reference's 'during' relation; it omits the exact timestamps and quoted phrasing provided in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that all listed things can be implemented at home, when does the slide update to reveal the 'Having a schedule and routine at home mimics...' text?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 964.9,
        "end": 965.0
      },
      "pred_interval": {
        "start": 1074.0,
        "end": 1076.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 109.10000000000002,
        "end": 111.0,
        "average": 110.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.14492753623188406,
        "text_similarity": 0.17102475464344025,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the causal relation ('once the speaker finishes') but omits the key factual timing details (the anchor and target timestamps and the exact moment the text appears), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes talking about morning hygiene routines, when does she start talking about knowing the time to leave the house?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1059.9,
        "end": 1067.9
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1060.0
      },
      "iou": 0.00558659217876584,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.900000000000091,
        "end": 7.900000000000091,
        "average": 8.900000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.14545454545454548,
        "text_similarity": 0.2820405960083008,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer gives a roughly correct start time (1060.0s vs 1059.9s) but incorrectly states the speaker finished hygiene at 1050.0s (should be 1059.9s) and omits the completion time of 1067.9s, so the timeline is notably incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the 'After school' list of activities is displayed, when does the speaker mention 'making time for dinner'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1104.2,
        "end": 1107.0
      },
      "pred_interval": {
        "start": 1090.0,
        "end": 1100.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.200000000000045,
        "end": 7.0,
        "average": 10.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.25396825396825395,
        "text_similarity": 0.3513466417789459,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a time window that does not match the ground-truth target (1104.2\u20131107.0); the predicted 1090.0\u20131100.0 is earlier and does not overlap the correct target, though it falls within the broader slide period. This is factually incorrect and thus receives low credit."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes being consistent, when does she mention that parents might sometimes feel like 'the heavy'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1140.4,
        "end": 1145.7
      },
      "pred_interval": {
        "start": 1140.0,
        "end": 1150.0
      },
      "iou": 0.5299999999999955,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.40000000000009095,
        "end": 4.2999999999999545,
        "average": 2.3500000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.12903225806451615,
        "text_similarity": 0.29323410987854004,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction roughly matches the start time (1140.0s vs 1140.4s) but overextends the end by ~4.3s (1150.0s vs 1145.7s), so it is imprecise though not completely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes discussing how consistency helps with sibling rivalry, when is the 'ACCOUNTABILITY' slide fully displayed?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1246.0,
        "end": 1247.5
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.0,
        "end": 7.5,
        "average": 11.75
      },
      "rationale_metrics": {
        "rouge_l": 0.20833333333333334,
        "text_similarity": 0.4296775460243225,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect: it gives an interval (1230.0\u20131240.0s) that is earlier than the correct display time (1246.0\u20131247.5s) and contradicts the relation that the slide appears after the speaker finishes at 1241.0s."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker emphasizes the importance of repeatedly stressing accountability, when does the second panel describing accountability appear on the slide?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1285.7,
        "end": 1286.2
      },
      "pred_interval": {
        "start": 1350.0,
        "end": 1360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.29999999999995,
        "end": 73.79999999999995,
        "average": 69.04999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.17777777777777776,
        "text_similarity": 0.44284796714782715,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timing (1350.0\u20131360.0s) is completely inconsistent with the correct timestamps (starts at 1285.7s, fully animated by 1286.2s) and thus contradicts the reference and omits the correct relation to the speaker's timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that accountability is the baseline foundation for a school community, when does she mention 'due dates for homework assignments'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1329.7,
        "end": 1331.9
      },
      "pred_interval": {
        "start": 1400.0,
        "end": 1410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.29999999999995,
        "end": 78.09999999999991,
        "average": 74.19999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.4186046511627907,
        "text_similarity": 0.5094466805458069,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted interval (1400.0\u20131410.0s) is far from the correct timing (1329.7\u20131331.9s), so the answer is incorrect; although both place the mention after the baseline statement, the predicted times are materially wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"If there's one thing you take away to put in your toolbox tonight, I hope it is this\", when does she explain what students had to write if they said something negative?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1442.41,
        "end": 1454.99
      },
      "pred_interval": {
        "start": 1425.0,
        "end": 1430.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.410000000000082,
        "end": 24.99000000000001,
        "average": 21.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.07792207792207792,
        "text_similarity": 0.20635411143302917,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that she explains it afterward but provides no timing or timestamp details and thus fails to answer the asked 'when' with the specific interval given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes talking about reminding themselves of positive thoughts, when does she introduce the topic of 'Restorative practice when community has been broken'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1486.37,
        "end": 1488.95
      },
      "pred_interval": {
        "start": 1560.0,
        "end": 1565.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.63000000000011,
        "end": 76.04999999999995,
        "average": 74.84000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.44117647058823534,
        "text_similarity": 0.6230695247650146,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the new topic follows the prior remark) but omits the key factual details\u2014specific start/end timestamps (1486.37s\u20131488.95s) and the reference time (1480.02s)\u2014so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "While the green slide titled \"Holding everyone accountable for their own choices and responsibilities\" is displayed, when does the speaker give the example of parents getting a dog for their kids?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1524.93,
        "end": 1577.73
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.06999999999994,
        "end": 22.269999999999982,
        "average": 43.66999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.3293008804321289,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the dog example occurs while the green slide is displayed (relation 'during') but omits the key factual elements of the precise start/end timestamps for the slide and for the example, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states that 'we have to equip them with their ability to be able to overcome obstacles', when does she explain what saying 'no' does?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1785.657,
        "end": 1788.202
      },
      "pred_interval": {
        "start": 178.0,
        "end": 182.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1607.657,
        "end": 1606.202,
        "average": 1606.9295
      },
      "rationale_metrics": {
        "rouge_l": 0.08823529411764706,
        "text_similarity": 0.04214440658688545,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives a wrong anchor timestamp (178.0s vs 1781.0s) and fails to provide the precise target timestamps or the immediate 'once_finished' relation, only vaguely saying 'shortly after.'"
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to 'help and not hinder their development', when does she suggest brainstorming for an essay instead of writing it for them?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1881.94,
        "end": 1883.282
      },
      "pred_interval": {
        "start": 195.0,
        "end": 198.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1686.94,
        "end": 1685.282,
        "average": 1686.1109999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.07407407407407408,
        "text_similarity": -0.055361419916152954,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly indicates the action occurs after the advice but gives a single timestamp (195.0s) that is wildly inconsistent with the correct target interval (~1881.94\u20131883.282s), so the timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide transitions to 'Collaboration Form Two', when does the speaker say that teachers want to work with parents and guardians?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1934.726,
        "end": 1943.0
      },
      "pred_interval": {
        "start": 204.0,
        "end": 206.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1730.726,
        "end": 1737.0,
        "average": 1733.863
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320756,
        "text_similarity": 0.2151397168636322,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives a single timestamp (204.0s) that is far from the correct intervals (~1930.7\u20131931.2s anchor and 1934.726\u20131943s target); although it implies 'after', the timing is incorrect and key interval details are missing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"It is so important so that we can get a hold of you when we need to be able to talk,\" when do the bullet points on the slide disappear?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2163.0,
        "end": 2163.5
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.0,
        "end": 23.5,
        "average": 28.25
      },
      "rationale_metrics": {
        "rouge_l": 0.10000000000000002,
        "text_similarity": 0.28006210923194885,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the bullets disappear immediately after the quoted line, matching the core timing, but it omits the specific timestamps and duration details (start at 2163.0s, complete at 2163.5s) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker describes a harmonious journey with unicorns and rainbows, when does she say, \"It's not always going to be perfect. And there's going to be times where we are going to continue to butt heads\"?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2176.5,
        "end": 2181.0
      },
      "pred_interval": {
        "start": 2190.0,
        "end": 2200.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.5,
        "end": 19.0,
        "average": 16.25
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814814,
        "text_similarity": 0.23739281296730042,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the event order but gives incorrect timestamps that do not match the reference intervals (2190.0s/2200.0s vs correct 2176.5\u20132181.0s) and omits the specified once_finished relation and judge conversion, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker suggests saying, \"I don't think this is going the way that either of us intended,\" when does she suggest scheduling time later in the week for a phone call?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2219.5,
        "end": 2226.5
      },
      "pred_interval": {
        "start": 2250.0,
        "end": 2260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.5,
        "end": 33.5,
        "average": 32.0
      },
      "rationale_metrics": {
        "rouge_l": 0.046511627906976744,
        "text_similarity": 0.19017094373703003,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamp (2250.0s) is incorrect: the correct event occurs from 2219.5s to 2226.5s (beginning at 2219.5s), so the prediction is 23.5s later and outside the correct interval."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that most classrooms will have a homework board, when does she suggest that students should come to school equipped with a planner?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2495.0,
        "end": 2500.0
      },
      "pred_interval": {
        "start": 2536.0,
        "end": 2547.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.0,
        "end": 47.0,
        "average": 44.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24390243902439024,
        "text_similarity": 0.26086029410362244,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the planner suggestion follows the homework-board remark) but omits the key factual detail that students should come equipped 'by third grade and beyond,' making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker suggests having accessible snacks that can be accessed independently at home, when does she mention tasking students with making their own lunch or breakfast?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2538.8,
        "end": 2542.8
      },
      "pred_interval": {
        "start": 2598.0,
        "end": 2609.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.19999999999982,
        "end": 66.19999999999982,
        "average": 62.69999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.15477775037288666,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the lunch/breakfast task is mentioned after the snacks comment) but fails to provide the requested timing details (the specific timestamps) from the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker suggests having students set out their clothes the night before, when does she mention that these actions will help ease up on hectic morning routines?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2604.5,
        "end": 2608.0
      },
      "pred_interval": {
        "start": 2620.0,
        "end": 2631.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.5,
        "end": 23.0,
        "average": 19.25
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324328,
        "text_similarity": 0.3345527648925781,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly captures the temporal relation\u2014she mentions easing hectic mornings after suggesting students set out their clothes\u2014matching the reference's 'after' relation without contradiction."
      }
    },
    {
      "question_id": "001",
      "question": "After Meredith asks Angela if there are any questions, when does Angela respond about pushing her buttons?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2698.0,
        "end": 2701.0
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2680.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.0,
        "end": 21.0,
        "average": 24.5
      },
      "rationale_metrics": {
        "rouge_l": 0.13636363636363638,
        "text_similarity": 0.46740955114364624,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (Angela responds after Meredith's question) but omits the key temporal details given in the reference (the specific start/end timestamps for both utterances)."
      }
    },
    {
      "question_id": "002",
      "question": "Once Angela finishes her question about kindergartener and eighth grader interactions on cell phones, when does Meredith begin to answer?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2771.5,
        "end": 2773.5
      },
      "pred_interval": {
        "start": 2730.0,
        "end": 2740.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.5,
        "end": 33.5,
        "average": 37.5
      },
      "rationale_metrics": {
        "rouge_l": 0.11538461538461539,
        "text_similarity": 0.2853081524372101,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that Meredith begins to answer Angela's question but omits the crucial timing details (2771.5s start, 2773.5s end) and the 'once_finished' relation, so it fails to answer the question as asked."
      }
    },
    {
      "question_id": "003",
      "question": "After Meredith encourages parents to follow their students on social media, when does she explain how to approach conversations offline?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2717.3,
        "end": 2729.9
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 2860.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 132.69999999999982,
        "end": 130.0999999999999,
        "average": 131.39999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.16949152542372883,
        "text_similarity": 0.4559140205383301,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that Meredith explains offline after encouraging follows) but omits the precise timing/timestamps and duration details provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker talks about establishing very baseline questions to begin with around social media with kids, when does she mention having family meetings around responsibility?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2893.0,
        "end": 2896.0
      },
      "pred_interval": {
        "start": 2935.0,
        "end": 2946.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.0,
        "end": 50.0,
        "average": 46.0
      },
      "rationale_metrics": {
        "rouge_l": 0.08,
        "text_similarity": -0.033217351883649826,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly captures the temporal relation that the mention of family meetings occurs after the discussion of baseline questions about social media, matching the reference's relative timing. It introduces no contradictions or hallucinations."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having to change how you talk in terms of voice projection for different age groups in the classroom, when does she advise being careful about the words you're choosing to use?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2921.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 3007.0,
        "end": 3018.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 86.0,
        "end": 95.0,
        "average": 90.5
      },
      "rationale_metrics": {
        "rouge_l": 0.07894736842105264,
        "text_similarity": -0.05083794891834259,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction restates that the advice comes after the voice-projection discussion, capturing the sequence, but it fails to provide the required precise timestamps and anchor/target identification given in the correct answer, omitting key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After Meredith discusses students possibly feeling social anxiety and insecurity when re-entering school, when does she suggest getting them together with friends and classmates ahead of time?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3092.1,
        "end": 3098.5
      },
      "pred_interval": {
        "start": 3125.0,
        "end": 3146.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.90000000000009,
        "end": 47.5,
        "average": 40.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.3013698630136986,
        "text_similarity": 0.6139394640922546,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the order (discussion then suggestion) but gives significantly different single timestamps (\u224854s later) and omits the precise intervals and the 'once_finished' relation, so it does not match the ground-truth timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After Meredith Esau states that social and emotional learning doesn't have to exist in its own silo, when does she talk about teachers weaving social-emotional learning into debate?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3227.397,
        "end": 3232.508
      },
      "pred_interval": {
        "start": 3256.0,
        "end": 3274.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.603000000000065,
        "end": 41.49200000000019,
        "average": 35.04750000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.45791277289390564,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the temporal relation (that the weaving discussion occurs after the silo comment) but omits the key factual details (the specific start/end timestamps) requested by the question, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During Meredith Esau's explanation about enabling students to see their unique talents, when does she mention students wanting to code instead of playing football?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3269.041,
        "end": 3312.931
      },
      "pred_interval": {
        "start": 3309.0,
        "end": 3320.0
      },
      "iou": 0.07714044624109682,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.95899999999983,
        "end": 7.06899999999996,
        "average": 23.513999999999896
      },
      "rationale_metrics": {
        "rouge_l": 0.09836065573770493,
        "text_similarity": 0.38166743516921997,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly links the football vs. coding example to Meredith's discussion of enabling students, but it incorrectly states the timing as 'after' rather than 'during' and omits the provided timestamps, so it contradicts the key temporal relation."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela finishes asking about parents in conflict regarding screen time, when does Meredith start her response by saying \"Absolutely\"?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3400.93,
        "end": 3402.12
      },
      "pred_interval": {
        "start": 3495.0,
        "end": 3500.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 94.07000000000016,
        "end": 97.88000000000011,
        "average": 95.97500000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.5765793919563293,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation \u2014 Meredith says 'Absolutely' immediately after Angela's question \u2014 which matches the reference (absolute times mapped to a relative 'after')."
      }
    },
    {
      "question_id": "002",
      "question": "After Meredith states that you should \"never put your student in the middle\", when does she suggest helping them develop their own sense of compromise?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3462.72,
        "end": 3469.49
      },
      "pred_interval": {
        "start": 3505.0,
        "end": 3510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.2800000000002,
        "end": 40.51000000000022,
        "average": 41.39500000000021
      },
      "rationale_metrics": {
        "rouge_l": 0.26229508196721313,
        "text_similarity": 0.6673646569252014,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction captures the causal/temporal link between the quote and the suggestion, but is imprecise about timing\u2014it implies simultaneity ('once') rather than the correct answer's explicit 'after' relationship and omits the provided timestamps."
      }
    },
    {
      "question_id": "003",
      "question": "After Angela lists several places where Meredith's book is available, when does she specifically mention Green Apple Books?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3556.06,
        "end": 3559.12
      },
      "pred_interval": {
        "start": 3605.0,
        "end": 3610.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.940000000000055,
        "end": 50.88000000000011,
        "average": 49.91000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5433905124664307,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (Green Apple Books is mentioned after the list) but omits the precise timestamps and incorrectly attributes the mention to Meredith instead of Angela, making it incomplete and partially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela asks if librarians buy digital books, when does Anissa confirm they do?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3595.925,
        "end": 3600.567
      },
      "pred_interval": {
        "start": 3625.0,
        "end": 3630.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.074999999999818,
        "end": 29.432999999999993,
        "average": 29.253999999999905
      },
      "rationale_metrics": {
        "rouge_l": 0.20833333333333331,
        "text_similarity": 0.47127413749694824,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states Anissa confirms they do, but the timestamp is incorrect\u20143625.0s is about 25\u201330 seconds later than the referenced response window (3595.925\u20133600.567s) and omits the precise start/end times."
      }
    },
    {
      "question_id": "002",
      "question": "Once Anissa finishes asking Angela if she wants to take the YouTube viewer's question, when does Angela say 'Sure, yeah'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3617.561,
        "end": 3621.102
      },
      "pred_interval": {
        "start": 3745.0,
        "end": 3750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 127.43899999999985,
        "end": 128.89800000000014,
        "average": 128.1685
      },
      "rationale_metrics": {
        "rouge_l": 0.2909090909090909,
        "text_similarity": 0.6384466886520386,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamp (3745.0s) is far from the correct start time (3617.561s) and contradicts the immediate follow-up; it does not match the referenced interval (3617.561\u20133621.102s)."
      }
    },
    {
      "question_id": "003",
      "question": "After Meredith begins answering the question about schools helping children cope with COVID deaths, when does Angela next speak?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3720.052,
        "end": 3723.137
      },
      "pred_interval": {
        "start": 3785.0,
        "end": 3790.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.94799999999987,
        "end": 66.86299999999983,
        "average": 65.90549999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962265,
        "text_similarity": 0.6141279935836792,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (3785.0s) is substantially different from the correct next-speech time (3720.052s) and omits the quoted utterance and end time, so it is essentially incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After Angela finishes stating that they need to pick one more winner who will get a digital code, when does she clarify that it's an actual digital ebook?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3778.3,
        "end": 3780.3
      },
      "pred_interval": {
        "start": 3756.0,
        "end": 3762.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.300000000000182,
        "end": 18.300000000000182,
        "average": 20.300000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.358974358974359,
        "text_similarity": 0.6950763463973999,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction reverses the temporal order: it says the winner announcement comes after the ebook clarification, whereas the correct answer states the ebook clarification occurs after the announcement; it also omits the timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "Once Angela finishes stating her intention to put her email in the chat, when do her fingers come into view as she appears to type?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3833.5,
        "end": 3840.4
      },
      "pred_interval": {
        "start": 3849.0,
        "end": 3850.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.5,
        "end": 9.599999999999909,
        "average": 12.549999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.5994520783424377,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (fingers appear after she finishes stating her intention) but omits the specific timestamps and duration details provided in the reference, so it's incomplete. "
      }
    },
    {
      "question_id": "001",
      "question": "After the woman at the bottom finishes describing the usefulness of the book for specific tips, when does she start reading the quote about teaching children?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 3930.0,
        "end": 3989.9829999999997
      },
      "gt_interval": {
        "start": 3945.123,
        "end": 3950.606
      },
      "pred_interval": {
        "start": 3954.0,
        "end": 3962.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.876999999999953,
        "end": 11.393999999999778,
        "average": 10.135499999999865
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454545,
        "text_similarity": 0.23437267541885376,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') but fails to provide the requested timing details (start/finish timestamps or relative timing), omitting key factual elements and precision from the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'we want to be your allies', when does she talk about parents and teachers wanting the best for the kids?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1953.971,
        "end": 1964.847
      },
      "pred_interval": {
        "start": 205.0,
        "end": 206.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1748.971,
        "end": 1758.847,
        "average": 1753.909
      },
      "rationale_metrics": {
        "rouge_l": 0.6060606060606061,
        "text_similarity": 0.634456992149353,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted preserves the event order but the timestamps are wildly incorrect (205/206s vs ~1950/1954s), so it fails to match the correct temporal locations."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes discussing the scaffolding teachers have in place, when does she mention bringing students to meetings?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.427,
        "end": 2061.512
      },
      "pred_interval": {
        "start": 214.0,
        "end": 215.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1844.4270000000001,
        "end": 1846.5120000000002,
        "average": 1845.4695000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.20512820512820512,
        "text_similarity": 0.5636587142944336,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the correct relation (she mentions bringing students right after discussing scaffolding) but the provided timestamps do not align with the reference ranges and lack the required accuracy/completeness."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes her parents attending a parent-teacher conference without her, when does she explain how her presence could have helped?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2110.911,
        "end": 2135.889
      },
      "pred_interval": {
        "start": 217.0,
        "end": 218.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1893.911,
        "end": 1917.8890000000001,
        "average": 1905.9
      },
      "rationale_metrics": {
        "rouge_l": 0.40476190476190477,
        "text_similarity": 0.6175833940505981,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the second event occurs after the first, but the provided timestamps (217s\u2192218s) are vastly different from the reference ranges (~2096\u20132109s and ~2111\u20132136s) and it omits the required time ranges, so the timing information is incorrect and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining how collaborating with parents increases involvement on a holistic level in the academic environment, when does she start talking about identifying unique talents and abilities?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2340.0,
        "end": 2348.835
      },
      "pred_interval": {
        "start": 2345.0,
        "end": 2365.0
      },
      "iou": 0.15340000000000145,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 16.164999999999964,
        "average": 10.582499999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.125,
        "text_similarity": 0.05525028333067894,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the topic comes after the prior explanation, but it omits the precise timing (2340.9s start, 2348.835s end) and the fact that the target immediately follows the anchor, so it is incomplete for the asked 'when'."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says it's our duty to instill independence, resilience, and self-reliance in students, when does she state that 'autonomy is action when we...'?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2407.49,
        "end": 2412.5
      },
      "pred_interval": {
        "start": 2475.0,
        "end": 2485.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.51000000000022,
        "end": 72.5,
        "average": 70.00500000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.09999999999999999,
        "text_similarity": 0.016002435237169266,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the content of the phrase ('when we give them choices') but fails to answer the asked 'when'\u2014it omits the required timestamps and temporal relation (target follows anchor after a brief pause), so it is largely incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions students experiencing a gamut of emotions within a calendar day, when does she begin discussing their ability to be allies and advocates for others?",
      "video_id": "g33LDzFuj7k",
      "video_number": "011",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2429.86,
        "end": 2438.809
      },
      "pred_interval": {
        "start": 2505.0,
        "end": 2515.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.13999999999987,
        "end": 76.1909999999998,
        "average": 75.66549999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.07547169811320754,
        "text_similarity": 0.09370635449886322,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the sequence (that the discussion follows the mention of students' emotions) but omits key factual details from the reference\u2014specific start/end timestamps and the brief pause/visual transition\u2014making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating that this is 'practice dialogue number one', when does the English speaker (teacher) begin her first segment?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 81.412,
        "end": 86.516
      },
      "pred_interval": {
        "start": 4.0,
        "end": 5.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.412,
        "end": 81.516,
        "average": 79.464
      },
      "rationale_metrics": {
        "rouge_l": 0.1904761904761905,
        "text_similarity": 0.3412700891494751,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the 'after' relation (that the English speaker begins after 'practice dialogue number one') but omits key factual details\u2014the specific timestamps (anchor ends at 28.373s; target starts at 81.412s and ends at 86.516s)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes reading the English segment for Segment 5, when does she start reading the Telugu segment for Segment 6?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 150.0,
        "end": 233.917
      },
      "gt_interval": {
        "start": 158.981,
        "end": 170.016
      },
      "pred_interval": {
        "start": 156.0,
        "end": 162.0
      },
      "iou": 0.21539668949771743,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.9809999999999945,
        "end": 8.015999999999991,
        "average": 5.498499999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.2641509433962264,
        "text_similarity": 0.5540945529937744,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamps are inaccurate (correct finish 154.706s vs 150.0s, correct start 158.981s vs 156.0s), and it omits the end time, the beep cue, and the stated 'after' relation, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes reading the English segment for Segment 7, when does she start reading the Telugu segment for Segment 8?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 150.0,
        "end": 233.917
      },
      "gt_interval": {
        "start": 187.957,
        "end": 202.515
      },
      "pred_interval": {
        "start": 198.0,
        "end": 204.0
      },
      "iou": 0.2814311537742308,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.043000000000006,
        "end": 1.4850000000000136,
        "average": 5.76400000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2641509433962264,
        "text_similarity": 0.5354629158973694,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the correct ordering (finish before start) but the timestamps are substantially off from the reference (predicted 192.0s vs correct 184.502s, and 198.0s vs 187.957s), and it omits the end time and the noted beep\u2014thus largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "While the 'Thank You!' screen is displayed, when does the speaker begin her concluding remarks about the dialogue?",
      "video_id": "pzuzJ9H-4jw",
      "video_number": "012",
      "segment": {
        "start": 150.0,
        "end": 233.917
      },
      "gt_interval": {
        "start": 209.544,
        "end": 233.917
      },
      "pred_interval": {
        "start": 225.0,
        "end": 225.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.455999999999989,
        "end": 8.917000000000002,
        "average": 12.186499999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.44800806045532227,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves that the remarks occur during the 'Thank You!' screen, but it gives substantially incorrect timing: the speaker actually starts at 209.544s (not 225.0s) and the Thank You! screen begins at 207.801s (not 210.0s), so it omits a key factual element and misstates the main timestamps."
      }
    },
    {
      "question_id": "001",
      "question": "After the introductory speaker says, 'And I will turn it over to you,' when does Megan start speaking her introductory remarks?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 88.123,
        "end": 97.103
      },
      "pred_interval": {
        "start": 205.0,
        "end": 205.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 116.877,
        "end": 107.897,
        "average": 112.387
      },
      "rationale_metrics": {
        "rouge_l": 0.13043478260869562,
        "text_similarity": 0.5402395725250244,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates Megan speaks 'after' the anchor event but gives a completely incorrect timestamp (205.0s vs. the correct start at 88.123s), so it is largely wrong despite the relational match."
      }
    },
    {
      "question_id": "002",
      "question": "After Megan displays the 'Pandemic Parenting Principles' slide, when does she first mention graduating from Fairfield in 2010?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 101.112,
        "end": 102.697
      },
      "pred_interval": {
        "start": 205.0,
        "end": 205.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 103.888,
        "end": 102.303,
        "average": 103.0955
      },
      "rationale_metrics": {
        "rouge_l": 0.09523809523809523,
        "text_similarity": 0.47844576835632324,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction places the mention at 205.0s, which contradicts the reference timing of 101.112\u2013102.697 (after the slide at 91.230\u201393.470); although it identifies the graduation mention, the timestamp is far off."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions she got her master's in early childhood from BC, when does she start talking about teaching in Newton and Wellesley?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.6,
        "end": 174.5
      },
      "pred_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.4,
        "end": 65.5,
        "average": 65.95
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981132,
        "text_similarity": 0.07362000644207001,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted start time (235.0s) contradicts the ground truth (starts at 168.6s immediately after 168.2s); this large timing discrepancy makes the answer incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is talking about the Jesuit ideals instilled during her time at Fairfield, when does she mention the ability to reflect on where she was and wanted to go?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 352.0,
        "end": 355.5
      },
      "pred_interval": {
        "start": 260.0,
        "end": 265.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 92.0,
        "end": 90.5,
        "average": 91.25
      },
      "rationale_metrics": {
        "rouge_l": 0.16901408450704225,
        "text_similarity": 0.5011229515075684,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the Jesuit-ideals context but gives a significantly incorrect timestamp (260.0s vs the correct ~270.0\u2013275.637s), so it fails on the key temporal detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions offering strategies to help motivate your child, when does she introduce the topic of handwriting?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 351.8,
        "end": 361.0
      },
      "pred_interval": {
        "start": 360.0,
        "end": 375.0
      },
      "iou": 0.04310344827586209,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.199999999999989,
        "end": 14.0,
        "average": 11.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.29002970457077026,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction states the opposite temporal order\u2014claiming the offer of strategies comes after the handwriting discussion\u2014contradicting the ground truth timestamps which show handwriting is introduced after the strategies remark."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide displays '2-5 minutes of handwriting practice adds up!', when does the speaker explain the importance of modeling numbers for children?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 396.0,
        "end": 413.0
      },
      "pred_interval": {
        "start": 420.0,
        "end": 435.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.0,
        "end": 22.0,
        "average": 23.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.41392824053764343,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the relation ('during') that the explanation occurs while the slide is displayed, but it omits the specific timing details (348.0\u2013414.0s and 396.0\u2013413.0s) given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes talking about using magnetic letters for word building, when does she start discussing ordering numbers?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 455.216,
        "end": 464.045
      },
      "pred_interval": {
        "start": 480.0,
        "end": 495.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.783999999999992,
        "end": 30.954999999999984,
        "average": 27.869499999999988
      },
      "rationale_metrics": {
        "rouge_l": 0.25531914893617025,
        "text_similarity": 0.5872951745986938,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that discussion of ordering numbers follows the magnetic letters segment) but omits the critical timestamp details (E1 at 454.055s, E2 at 455.216s\u2013464.045s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker describes the specific elements a child included on their glowfish poster, when does she start to explain the general benefits of using big poster boards?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 532.8,
        "end": 542.0
      },
      "pred_interval": {
        "start": 510.0,
        "end": 512.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.799999999999955,
        "end": 30.0,
        "average": 26.399999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.6502161622047424,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately reflects the correct relation (once_finished): it states the speaker begins explaining general benefits immediately after describing the poster details, preserving the original meaning."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes showing the second poster example about the solar system, when does she explicitly list the general benefits of posters?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 576.835,
        "end": 593.004
      },
      "pred_interval": {
        "start": 540.0,
        "end": 542.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.835000000000036,
        "end": 51.00400000000002,
        "average": 43.91950000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6747376918792725,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the speaker lists benefits after the solar-system poster, matching the relation, but it omits the specific timing (576.835s-593.004) and the note about the pause/visual transition, which are key details in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker makes a general statement about children hesitating to write about things they can't draw, when does she provide a personal example of her nephew?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 672.0,
        "end": 690.0
      },
      "pred_interval": {
        "start": 570.0,
        "end": 572.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 102.0,
        "end": 118.0,
        "average": 110.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24657534246575344,
        "text_similarity": 0.5032650232315063,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the nephew example occurs after the general statement, but it omits the key detail that it is an immediate/direct follow-up (and the specific timestamps) provided in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions a 'how-to drawing type book', when does she explain that drawing is a big piece of practice in addition to writing?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.375,
        "end": 704.155
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.625,
        "end": 25.845000000000027,
        "average": 25.735000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.4507042253521127,
        "text_similarity": 0.606590747833252,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the relation and paraphrases the content, but both timestamps are significantly incorrect (about 30s off) and it omits the correct time span for the second utterance."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker transitions to the 'MAKE YOUR OWN MATH GAMES' slide, when does she specifically describe making green and pink number cards?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 744.49,
        "end": 748.575
      },
      "pred_interval": {
        "start": 740.0,
        "end": 745.0
      },
      "iou": 0.05947521865889075,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.490000000000009,
        "end": 3.5750000000000455,
        "average": 4.032500000000027
      },
      "rationale_metrics": {
        "rouge_l": 0.3636363636363636,
        "text_similarity": 0.6462584137916565,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the correct temporal relation (description occurs after the slide), but both timestamps are inaccurate\u2014the slide time is off by ~17s and the quoted utterance time is ~2.5s earlier than the actual start (and omits the full 744.49\u2013748.575s interval)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that a collection of 'just right' books is key to helping children learn to read, when does she show an example of a Scholastic reader?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 911.4,
        "end": 915.0
      },
      "pred_interval": {
        "start": 925.0,
        "end": 930.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.600000000000023,
        "end": 15.0,
        "average": 14.300000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.1754385964912281,
        "text_similarity": 0.4447387158870697,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relative relation ('after') but omits the key factual details (the specific start/end timestamps for the mention and the Scholastic reader) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "During the explanation of the '5 Finger Test', when does the speaker describe what constitutes a 'just right' book?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 986.5,
        "end": 970.0
      },
      "pred_interval": {
        "start": 945.0,
        "end": 950.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.5,
        "end": 20.0,
        "average": 30.75
      },
      "rationale_metrics": {
        "rouge_l": 0.27118644067796605,
        "text_similarity": 0.7470777034759521,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that the 'just right' description occurs during the '5 Finger Test' explanation, but it omits the specific timestamps and the key detail that the speaker pinpoints 2\u20133 words as making a book 'just right.'"
      }
    },
    {
      "question_id": "001",
      "question": "While the images of the cardboard clocks are displayed, when does the speaker mention a child drawing a puppy on one of them?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1058.2,
        "end": 1060.95
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1052.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.200000000000045,
        "end": 8.950000000000045,
        "average": 8.575000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306123,
        "text_similarity": 0.4785081744194031,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that the speaker mentions a child drawing a puppy while the cardboard clocks are displayed, which preserves the essential relation conveyed by the reference answer despite omitting explicit timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "While the 'Weekend News' template is shown on the screen, when does the speaker say that kids would be excited to share their news?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1131.3,
        "end": 1138.0
      },
      "pred_interval": {
        "start": 1060.0,
        "end": 1062.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.29999999999995,
        "end": 76.0,
        "average": 73.64999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.19230769230769232,
        "text_similarity": 0.43459340929985046,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that the speaker's remark occurs during the 'Weekend News' visual display, matching the reference that the utterance falls within the template's on-screen interval."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the 'Hide & Go Seek' sight word game, when does she start explaining the 'Memory' sight word game?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1204.2,
        "end": 1205.5
      },
      "pred_interval": {
        "start": 1070.0,
        "end": 1072.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 134.20000000000005,
        "end": 133.5,
        "average": 133.85000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333334,
        "text_similarity": 0.6472699642181396,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction is directionally correct (Memory begins after Hide & Go Seek) but omits the key factual timing details provided in the correct answer (the exact start at 1204.2s and end at 1205.5s), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes recommending non-fiction books if the home collection is mostly storybooks, when does she start talking about having visuals to practice multiplication?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1250.14,
        "end": 1251.01
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.1400000000001,
        "end": 6.009999999999991,
        "average": 13.075000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.2641509433962264,
        "text_similarity": 0.645048201084137,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the sequence (she discusses visuals after recommending non-fiction), but it fails to provide the requested timing details (the specific start/end timestamps) and is therefore incomplete relative to the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes explaining that dry erase boards help with handwriting consistency, when does she start talking about having math tools for exploration?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1322.321,
        "end": 1324.997
      },
      "pred_interval": {
        "start": 1260.0,
        "end": 1275.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.32099999999991,
        "end": 49.99700000000007,
        "average": 56.15899999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.4528301886792453,
        "text_similarity": 0.5707978010177612,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct topic shift but gives a substantially incorrect start time (1260.0s vs the correct 1322.321s) and omits the end time; timing is the primary task so this is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes mentioning having sharpened pencils around for home setup, when does she display and introduce the word wall for visual reinforcement?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1425.637,
        "end": 1450.0
      },
      "pred_interval": {
        "start": 1290.0,
        "end": 1305.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 135.63699999999994,
        "end": 145.0,
        "average": 140.31849999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.19607843137254902,
        "text_similarity": 0.5273145437240601,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a much earlier timestamp (1290.0s) that contradicts the correct timestamps (\u22481425.6s to 1450s) and omits the show-slide onset and end details, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions having an alphabet chart or number line for easy accessibility, when does she introduce the word wall?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1425.2,
        "end": 1427.5
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.200000000000045,
        "end": 7.5,
        "average": 8.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.3137254901960784,
        "text_similarity": 0.3800065517425537,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the 'after' relation (that the word wall is introduced after the chart/number line), but it omits the key factual details\u2014specific start/end timestamps and segment identifiers\u2014given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker suggests parents type the words for a book while the child illustrates, when does she suggest having the child practice typing?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1506.0,
        "end": 1508.0
      },
      "pred_interval": {
        "start": 1530.0,
        "end": 1535.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.0,
        "end": 27.0,
        "average": 25.5
      },
      "rationale_metrics": {
        "rouge_l": 0.21875,
        "text_similarity": 0.4019029140472412,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the event (child practice typing) but gives an inaccurate timestamp (1530.0s) versus the correct 1506.0\u20131508.0s, so it's semantically right but factually incorrect on timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that games help build skills, when does she mention 'problem solving'?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1617.701,
        "end": 1618.281
      },
      "pred_interval": {
        "start": 165.0,
        "end": 167.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1452.701,
        "end": 1451.281,
        "average": 1451.991
      },
      "rationale_metrics": {
        "rouge_l": 0.2553191489361702,
        "text_similarity": 0.4731225073337555,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that 'problem solving' is mentioned after the skills discussion, but it omits the required specific timing and event details (e.g., E2 at 1617.701\u20131618.281), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker compares reading less than a minute a day to 20 minutes a day, when does she state that 1.8 million words are exposed per year?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1683.016,
        "end": 1684.426
      },
      "pred_interval": {
        "start": 183.0,
        "end": 185.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1500.016,
        "end": 1499.426,
        "average": 1499.721
      },
      "rationale_metrics": {
        "rouge_l": 0.3188405797101449,
        "text_similarity": 0.4151245355606079,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the 1.8 million words remark follows the comparison, but it omits the key timing details given in the correct answer (the specific timestamps 1683.016s\u20131684.426s and the anchor at 1655.553s), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the 'Q&A' slide is displayed, when does the slide asking 'COVID and religious education?' appear?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.8,
        "end": 1803.9
      },
      "pred_interval": {
        "start": 125.0,
        "end": 130.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1672.8,
        "end": 1673.9,
        "average": 1673.35
      },
      "rationale_metrics": {
        "rouge_l": 0.2622950819672131,
        "text_similarity": 0.3769761919975281,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only states a loose sequential relation tied to the speaker's remark about music, not the 'Q&A' slide finishing; it omits the precise timestamps and the explicit 'once_finished' relation, and thus fails to match the correct answer's factual anchor and details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker concludes her statement about music being important for religious education, when does she start talking about children learning about saints?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1840.4,
        "end": 1844.9
      },
      "pred_interval": {
        "start": 140.0,
        "end": 145.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1700.4,
        "end": 1699.9,
        "average": 1700.15
      },
      "rationale_metrics": {
        "rouge_l": 0.25396825396825395,
        "text_similarity": 0.3910013437271118,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives a completely incorrect timestamp (140.0s) and omits the correct end/start times and relation; it contradicts the reference (1840.4s start) and therefore is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes asking how schools can assist with the transition to in-person learning, when does the slide listing 'clear expectations' appear?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1879.3,
        "end": 1940.0
      },
      "pred_interval": {
        "start": 160.0,
        "end": 165.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1719.3,
        "end": 1775.0,
        "average": 1747.15
      },
      "rationale_metrics": {
        "rouge_l": 0.22950819672131148,
        "text_similarity": 0.3363672196865082,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (160.0s) is completely inconsistent with the correct timestamps (~1879\u20131976s) and omits the correct temporal relation and display duration, so it is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks, 'How to ensure children are not being distracted by non-school work when online?', when does she start listing tips?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.342,
        "end": 1963.495
      },
      "pred_interval": {
        "start": 25.0,
        "end": 30.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1934.342,
        "end": 1933.495,
        "average": 1933.9185
      },
      "rationale_metrics": {
        "rouge_l": 0.2745098039215686,
        "text_similarity": 0.3456468880176544,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect \u2014 it gives a wrong timestamp (25.0s) and says tips start immediately after the question, whereas the reference shows the tips begin at 1959.342s (about 2.45s after the question) with a specific quoted start phrase."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes giving tips on staying on task, when does she offer to answer questions?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1997.897,
        "end": 2003.182
      },
      "pred_interval": {
        "start": 105.0,
        "end": 110.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1892.897,
        "end": 1893.182,
        "average": 1893.0394999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.14492753623188404,
        "text_similarity": 0.21256396174430847,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states she offers to answer questions after finishing, but the timestamp (105.0s) is wildly inaccurate compared to the reference (~1996s\u21921998s) and it omits the precise timing/utterance details, making it factually incorrect and imprecise."
      }
    },
    {
      "question_id": "003",
      "question": "After the host says 'Great. I have two more. Thank you for that.', when does she ask the question about kindergarten?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2083.534,
        "end": 2093.534
      },
      "pred_interval": {
        "start": 115.0,
        "end": 120.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1968.534,
        "end": 1973.534,
        "average": 1971.034
      },
      "rationale_metrics": {
        "rouge_l": 0.13043478260869568,
        "text_similarity": 0.3344193994998932,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives a wrong timestamp (115.0s vs the correct ~2082.6s/2083.5s), omits the exact start/end times and relation, and only vaguely says 'shortly after' rather than matching the precise grounding."
      }
    },
    {
      "question_id": "001",
      "question": "Once the female speaker on the right finishes asking the question about the emotional side of entering a new grade, when does the female speaker on the left begin to respond?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2297.683
      },
      "gt_interval": {
        "start": 2181.936,
        "end": 2182.54
      },
      "pred_interval": {
        "start": 2135.6,
        "end": 2140.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.33600000000024,
        "end": 41.840000000000146,
        "average": 44.08800000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.16129032258064516,
        "text_similarity": 0.30434879660606384,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the left speaker responds right after the right speaker finishes) but omits the precise timestamps and the specific completion detail provided in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "When is the next time the female speaker on the left mentions a way students are socializing online after she describes a student's weekly Zoom calls?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2297.683
      },
      "gt_interval": {
        "start": 2204.249,
        "end": 2210.952
      },
      "pred_interval": {
        "start": 2198.0,
        "end": 2200.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.248999999999796,
        "end": 10.952000000000226,
        "average": 8.600500000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.1379310344827586,
        "text_similarity": 0.1929502934217453,
        "llm_judge_score": 1,
        "llm_judge_justification": "Incorrect: the predicted timestamp (2198.0s) falls within the anchor segment, not the next mention; the correct next mention begins at 2204.249s and continues to 2210.952s, so the prediction omits and misplaces the required temporal information."
      }
    },
    {
      "question_id": "003",
      "question": "After the female speaker on the left finishes talking about an online newspaper, when does she begin to introduce the 'Outschool' platform?",
      "video_id": "kQpSkCpDE4g",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2297.683
      },
      "gt_interval": {
        "start": 2227.882,
        "end": 2232.043
      },
      "pred_interval": {
        "start": 2200.0,
        "end": 2202.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.882000000000062,
        "end": 30.04300000000012,
        "average": 28.96250000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814814,
        "text_similarity": 0.320669949054718,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted start time (2200.0s) contradicts the reference: the anchor finishes at 2210.952s and the 'Outschool' mention begins at 2227.882s, so the prediction is factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'Number four', when does the text 'Parents don't get trained' appear on screen?",
      "video_id": "J-upF-lwWvg",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 46.400000000000006
      },
      "gt_interval": {
        "start": 2.02,
        "end": 3.73
      },
      "pred_interval": {
        "start": 3.6,
        "end": 4.2
      },
      "iou": 0.05963302752293573,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.58,
        "end": 0.4700000000000002,
        "average": 1.0250000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.42553191489361697,
        "text_similarity": 0.6572409868240356,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the relation (the text appears after the speaker says 'Number four') but omits the precise start/end timestamps (2.02s\u20133.73s) and misleadingly implies it appears immediately, so it lacks key timing details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'communicating at the IEP table', when does she continue her explanation about parents at the IEP table?",
      "video_id": "J-upF-lwWvg",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 46.400000000000006
      },
      "gt_interval": {
        "start": 9.85,
        "end": 12.35
      },
      "pred_interval": {
        "start": 15.8,
        "end": 16.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.950000000000001,
        "end": 4.049999999999999,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.30508474576271183,
        "text_similarity": 0.7291017174720764,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures that the speaker continues talking about parents after finishing 'communicating at the IEP table' (the once_finished relation), but it omits the precise timestamps and slightly overstates by saying 'immediately' rather than specifying the ~0.55s gap and the exact start/end times provided in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'And number five', when does the text 'you don't have the playbook' appear?",
      "video_id": "J-upF-lwWvg",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 46.400000000000006
      },
      "gt_interval": {
        "start": 24.8,
        "end": 26.0
      },
      "pred_interval": {
        "start": 27.9,
        "end": 28.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.099999999999998,
        "end": 2.5,
        "average": 2.799999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3673469387755102,
        "text_similarity": 0.6566959619522095,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys that the text appears after the speaker's line, but it omits the specific timestamps (24.8\u201326.0s) and implying it appears 'right after' is misleading given the ~3.5s gap from 21.34s."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions they have three presentations, when does she introduce the first presenter, Khadija Mohamed?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 40.767,
        "end": 45.473
      },
      "pred_interval": {
        "start": 195.0,
        "end": 196.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 154.233,
        "end": 150.527,
        "average": 152.38
      },
      "rationale_metrics": {
        "rouge_l": 0.25641025641025644,
        "text_similarity": 0.5935574173927307,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (195.0s) is completely incorrect and contradicts the correct introduction interval (40.767\u201345.473s); it also omits the relation to the earlier mention, so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions revealing the hidden curriculum, when does the slide change to display 'Teaching Scotland's Future'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.8,
        "end": 202.8
      },
      "pred_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.19999999999999,
        "end": 37.19999999999999,
        "average": 35.19999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.15686274509803924,
        "text_similarity": 0.3212658762931824,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the relative ordering (the slide appears after the speaker's remark) but omits the key factual details and timestamps provided in the correct answer about when the slide begins and fully appears."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing teacher educators, when does a blue speech bubble with the question 'Is the team all right?' appear on the screen?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 245.5,
        "end": 258.7
      },
      "pred_interval": {
        "start": 265.0,
        "end": 270.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.5,
        "end": 11.300000000000011,
        "average": 15.400000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.26229508196721313,
        "text_similarity": 0.3907741904258728,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the bubble appears during the discussion of teacher educators, but it omits the precise timing and duration details provided in the reference (start/end timestamps and overlap specifics)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing the challenges faced by collectivist teachers, when does she state the research question about how minority ethnic teachers use their cultural, religious, and linguistic skills?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 390.6,
        "end": 394.78
      },
      "pred_interval": {
        "start": 365.0,
        "end": 372.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.600000000000023,
        "end": 22.779999999999973,
        "average": 24.189999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.1016949152542373,
        "text_similarity": 0.1212393194437027,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the relative relation ('after') that the research question follows the discussion, but it omits the precise timing details (the specific end/start timestamps and duration) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker quotes Ladson-Billings about Critical Race Theory, when does she explain what Critical Race Theory helps to do?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 420.0,
        "end": 427.3
      },
      "pred_interval": {
        "start": 408.0,
        "end": 419.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.0,
        "end": 8.300000000000011,
        "average": 10.150000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.08695652173913043,
        "text_similarity": 0.30304616689682007,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a time (408.0s) that contradicts the reference (starts at 420.0s and finishes at 427.3s); this is a major factual temporal error, so it receives minimal credit."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the 'racial microaggression framework', when does she mention the time period 'the early 1970s to the 1990s'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 517.1,
        "end": 519.1
      },
      "pred_interval": {
        "start": 510.0,
        "end": 512.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.100000000000023,
        "end": 7.100000000000023,
        "average": 7.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.3548387096774193,
        "text_similarity": 0.5989960432052612,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys that the time period is mentioned shortly after the 'racial microaggression framework,' matching the reference's key point that E2 occurs after E1; lacking exact timestamps does not change the relative ordering."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker shares discussions from her study, when does the first speech bubble graphic appear on the 'Cultural and Linguistic experiences' slide?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 574.2,
        "end": 574.9
      },
      "pred_interval": {
        "start": 540.0,
        "end": 542.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.200000000000045,
        "end": 32.89999999999998,
        "average": 33.55000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3703703703703703,
        "text_similarity": 0.6047426462173462,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the graphic appears while the speaker is sharing discussions on that slide, but it omits the specific timing details (the provided timestamps and relative mapping) given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions a teacher in Edinburgh trying to talk about the slave trade issue with her class, when does the speaker state that the discussion 'went terribly wrong'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 721.0,
        "end": 722.451
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 7.548999999999978,
        "average": 5.774499999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.3125,
        "text_similarity": 0.6174486875534058,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the event and its ordering but gives a single timestamp (725.0s) that is about 2.5\u20134 seconds later than the reference interval (721.0\u2013722.45s) and omits the precise interval notation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the teacher asks Muslim children to draw an image of what they think God looks like, when does the speaker describe the Muslim kids just sitting there and staring?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 746.761,
        "end": 793.029
      },
      "pred_interval": {
        "start": 745.0,
        "end": 750.0
      },
      "iou": 0.06743842261966797,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.7609999999999673,
        "end": 43.028999999999996,
        "average": 22.394999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.40625,
        "text_similarity": 0.6362952589988708,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mentions the correct event but gives the wrong timestamp (745.0s), which falls inside the teacher-asking interval rather than the actual description interval beginning at 746.761s, so it is factually incorrect and misses the temporal relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the teacher asks what's happening in Burma, when do the children ask why it's not in the news?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 897.0,
        "end": 899.8
      },
      "pred_interval": {
        "start": 925.0,
        "end": 930.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.0,
        "end": 30.200000000000045,
        "average": 29.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.2040816326530612,
        "text_similarity": 0.4669252038002014,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly captures the key relation: the children ask about the news after the teacher's question, which matches the reference (relative timing) without adding or contradicting details."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stella finishes inviting Jacqueline to introduce herself, when does Jacqueline begin speaking?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1145.3,
        "end": 1146.2
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1052.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 95.29999999999995,
        "end": 94.20000000000005,
        "average": 94.75
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.6793020963668823,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that Jacqueline speaks immediately after Stella, but it gives a wrong timestamp for Stella finishing (1050.0s vs 1145.0s) and omits Jacqueline's actual start/end times, so it is factually incorrect and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After Khadija finishes her presentation and apology, when does Stella begin thanking her?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1119.9,
        "end": 1121.2
      },
      "pred_interval": {
        "start": 1248.0,
        "end": 1250.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 128.0999999999999,
        "end": 128.79999999999995,
        "average": 128.44999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.5800557136535645,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the event order (Khadija then Stella) but the timestamps are substantially incorrect (predicted ~1250s vs reference ~1114\u20131119.9s), omits the end time, and misrepresents the gap between events."
      }
    },
    {
      "question_id": "003",
      "question": "After Jacqueline says, 'Let me just see if I can share these slides with you', when does her presentation's title slide appear in full screen?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1177.8,
        "end": 1182.0
      },
      "pred_interval": {
        "start": 1260.0,
        "end": 1260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 82.20000000000005,
        "end": 78.0,
        "average": 80.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1927710843373494,
        "text_similarity": 0.4382363557815552,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a substantially incorrect time for Jacqueline's utterance (1260.0s vs 1154.7s) and omits the correct full-screen slide timestamps (\u22481177.8s\u20131182.0s), so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes talking about how students of color were feeling left out at the secondary school, when does she transition to the slide about 'Race in Scotland'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1260.0,
        "end": 1269.32
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.0,
        "end": 29.319999999999936,
        "average": 29.659999999999968
      },
      "rationale_metrics": {
        "rouge_l": 0.3278688524590164,
        "text_similarity": 0.5588468909263611,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the speaker transitions to the 'Race in Scotland' slide but omits the crucial timing details and the quoted remark ('So a couple of statistics...'), so it is incomplete compared to the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that only 40% of Scottish people surveyed agreed that immigrants make Scotland a better place, when does she mention the number of hate crimes reported in Scotland?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1312.001,
        "end": 1323.455
      },
      "pred_interval": {
        "start": 1250.0,
        "end": 1260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.000999999999976,
        "end": 63.45499999999993,
        "average": 62.72799999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.4942871332168579,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to provide the requested timing\u2014it only restates that she mentions hate crimes and omits the key timestamps (mentioning begins at ~1312.001s and the number is finished at ~1323.455s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker explains that colourblind racism leads to the omission and avoidance of race issues in the classroom, when does she mention that teachers fear talking about race?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1376.326,
        "end": 1379.45
      },
      "pred_interval": {
        "start": 1270.0,
        "end": 1280.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 106.32600000000002,
        "end": 99.45000000000005,
        "average": 102.88800000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.380952380952381,
        "text_similarity": 0.6746355891227722,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that she mentions teachers fearing talking about race after the explanation, but it omits the precise timestamps and explicit 'once_finished' relation given in the correct answer, making it incomplete for the asked 'when'."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says that Critical Race Theory \"really underpins everything that I do when it comes to research\", when does she start discussing the \"Methods\" of their research?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1453.971,
        "end": 1486.746
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.971000000000004,
        "end": 66.7460000000001,
        "average": 55.35850000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.125,
        "text_similarity": 0.18889866769313812,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly asserts the 'Methods' discussion occurs immediately after the CRT remark; the ground truth shows the target begins ~34s after the anchor (anchor ends 1419.557s, target begins 1453.971s), and the prediction omits the provided timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker describes the first tenet of Critical Race Theory as the assertion that \"racism is normal, it's ordinary, it's systemic\", when does she describe the next tenet?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1440.328,
        "end": 1450.256
      },
      "pred_interval": {
        "start": 1420.0,
        "end": 1430.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.327999999999975,
        "end": 20.256000000000085,
        "average": 20.29200000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.14492753623188406,
        "text_similarity": 0.14966244995594025,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that the second tenet is described after the first and repeats the first tenet's content, but it omits the specific timestamps and precise timing details given in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that students wholeheartedly disagreed with the idea of equal chance regardless of race/ethnicity, when does she introduce Omar's quote about teachers trying to motivate them?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.0,
        "end": 1618.0
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.0,
        "end": 18.0,
        "average": 20.5
      },
      "rationale_metrics": {
        "rouge_l": 0.37288135593220334,
        "text_similarity": 0.465827077627182,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the relative ordering right (Omar's quote occurs after), but the timestamp for the first event is incorrect (1590.0s vs 1611.0s) and it fails to provide the specific 1613.0\u20131618.0 span, so it is incomplete and imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says she emailed 31 schools, when does she state how many responses she received?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1782.3,
        "end": 1783.5
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1770.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.299999999999955,
        "end": 13.5,
        "average": 12.899999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.1923076923076923,
        "text_similarity": 0.19091103971004486,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately conveys the key temporal relationship\u2014she states the number of responses immediately after saying she emailed 31 schools\u2014matching the correct answer's meaning despite omitting timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that one of the secured schools dropped out before recruiting, when does she mention that the second school dropped out a day before the focus groups began?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1818.0,
        "end": 1825.4
      },
      "pred_interval": {
        "start": 1830.0,
        "end": 1830.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.0,
        "end": 4.599999999999909,
        "average": 8.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.16393442622950818,
        "text_similarity": 0.36400696635246277,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states that the second school dropped out a day before the focus groups and that this is mentioned immediately after the first school's withdrawal, but it omits the precise timestamps and transcript alignment provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker describes the gatekeeper's reason for not including Black students, when does she state that the gatekeeper didn't ask them to participate?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1907.394,
        "end": 1909.8
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 1950.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.605999999999995,
        "end": 40.200000000000045,
        "average": 41.40300000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.3120926320552826,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that the statement occurs immediately at the end of the gatekeeper's explanation, preserving the original meaning; it omits the exact timestamps provided in the reference but introduces no contradictions or hallucinations."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says teachers avoided the topic because they didn't want to be seen as racist, when does she explain that a lack of interest convergence led to inaction?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.768,
        "end": 1967.955
      },
      "pred_interval": {
        "start": 195.0,
        "end": 203.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1764.768,
        "end": 1764.955,
        "average": 1764.8615
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.6743341684341431,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the required relative ordering (that the explanation about lack of interest convergence follows the teachers-being-seen-as-racist remark), preserving the original meaning; although it omits timestamps, the judge requested a relative answer."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide titled 'The Normalcy of Racism', when does the speaker explain why whiteness is considered neutral?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1991.32,
        "end": 2002.951
      },
      "pred_interval": {
        "start": 204.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1787.32,
        "end": 1792.951,
        "average": 1790.1354999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.32653061224489793,
        "text_similarity": 0.6472861766815186,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that the explanation occurs during the slide display, but it omits the crucial timestamp details (1984.0\u20132010.0 for the slide and 1991.320\u20132002.951 for the explanation), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining Rashida's reasoning for not wearing a hijab, when does she mention Omar's comment about jokes hurting?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2082.096,
        "end": 2085.039
      },
      "pred_interval": {
        "start": 211.0,
        "end": 216.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1871.096,
        "end": 1869.0390000000002,
        "average": 1870.0675
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307692,
        "text_similarity": 0.3743070662021637,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the relative timing (Omar's comment occurs after the speaker finishes Rashida's point) but omits the precise timestamps and explicit E1/E2 timing details given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker discusses students internalizing their experience of 'othering' and exclusion, when does she mention that teachers would mostly ignore comments or engage in biased language?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2148.8,
        "end": 2166.4
      },
      "pred_interval": {
        "start": 2135.0,
        "end": 2145.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.800000000000182,
        "end": 21.40000000000009,
        "average": 17.600000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.5990220308303833,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the teachers' behavior is mentioned after the students' experience), but it omits the specific timestamps/time interval given in the correct answer. It also adds no contradictory or hallucinated details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker states she is glad to have been part of the study, when does she say that the students did not feel heard or supported?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2205.5,
        "end": 2210.0
      },
      "pred_interval": {
        "start": 2165.0,
        "end": 2175.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.5,
        "end": 35.0,
        "average": 37.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.4853530526161194,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly conveys the relative timing (she says students didn\u2019t feel heard/support shortly after finishing the remark), but it omits the precise timestamps and adds the minor wording 'once again,' which is unnecessary."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes her statement about acknowledging bias being scary but important, when does the slide transition to show the 'Schools can:' recommendations?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2333.0,
        "end": 2333.5
      },
      "pred_interval": {
        "start": 2195.0,
        "end": 2205.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 138.0,
        "end": 128.5,
        "average": 133.25
      },
      "rationale_metrics": {
        "rouge_l": 0.35714285714285715,
        "text_similarity": 0.6084268689155579,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the slide appears after the speaker finishes (matching the relation), but it omits the crucial timing detail\u2014the slide actually transitions about 5\u20135.5 seconds later (2333.0\u20132333.5s after the finish at 2328.0s), so it's incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces implementing curriculum that explicitly includes race talk and counter narratives, when does she explain how teachers can learn to put this into practice?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2345.1,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2395.0,
        "end": 2405.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.90000000000009,
        "end": 35.5,
        "average": 42.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.15625,
        "text_similarity": 0.32729166746139526,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are substantially wrong\u2014both times (2395.0 and 2405.0) fall well after the correct target interval (2345.1\u20132369.5) and it also fails to provide the anchor/target span detail given in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker mentions that the racial equality framework from a couple of years ago is 'very general,' when does she suggest specific, practical training would be more helpful?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2453.2,
        "end": 2458.5
      },
      "pred_interval": {
        "start": 2465.0,
        "end": 2475.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.800000000000182,
        "end": 16.5,
        "average": 14.150000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.15584415584415584,
        "text_similarity": 0.184846892952919,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamps are substantially off (about 17\u201320+ seconds later) and omit the quoted target segment; it does not match the correct anchor/target timing or content, so it is largely incorrect though on the general topic."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker says 'Thank you', when does the title slide for the presentation appear on screen and is acknowledged?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2535.7,
        "end": 2536.7
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2500.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.69999999999982,
        "end": 36.69999999999982,
        "average": 41.19999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307692,
        "text_similarity": 0.3993649482727051,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the main relation that the title slide appears after the first speaker says 'Thank you' and is acknowledged, but it omits all precise timestamps, event labels (E1/E2), and the specific timing of the acknowledgement, thus missing key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Outline' slide, when does Dr. Nighet Riaz state that racism is normalized in everyday interactions?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2593.7,
        "end": 2602.4
      },
      "pred_interval": {
        "start": 2530.0,
        "end": 2540.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.69999999999982,
        "end": 62.40000000000009,
        "average": 63.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.08,
        "text_similarity": 0.11426597833633423,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the event occurs during the 'Outline' slide, but it omits the precise time intervals and containment relation given in the reference (2581.9\u20132627.0 and 2593.7\u20132602.4) and slightly misspells the speaker's name."
      }
    },
    {
      "question_id": "003",
      "question": "After Dr. Nighet Riaz states her name, when does she explain her roles at the University of the West of Scotland and Advance HE?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2550.6,
        "end": 2567.6
      },
      "pred_interval": {
        "start": 2560.0,
        "end": 2570.0
      },
      "iou": 0.39175257731958113,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.400000000000091,
        "end": 2.400000000000091,
        "average": 5.900000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.11940298507462685,
        "text_similarity": 0.2205609679222107,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that she explains her roles after saying her name, but it omits the precise timing information and timestamps given in the reference (and slightly misnames her), so it is incomplete for the asked 'when' detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions disrupting the narrative, when does she start discussing global citizenship through the lens of the beneficent other?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2700.74,
        "end": 2707.407
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2680.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.73999999999978,
        "end": 27.407000000000153,
        "average": 29.073499999999967
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333334,
        "text_similarity": 0.4900050461292267,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamps (2670s/2680s) are significantly earlier than the ground-truth anchor/target times (~2700.08s finishing and 2700.74s start) and thus do not match the required timing or precision."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing global citizenship and Scotland's curricular intention to imbricate it through the curriculum, when does she specifically mention it presenting a cross-curricular and whole school approach?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2790.853,
        "end": 2797.969
      },
      "pred_interval": {
        "start": 2690.0,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 100.85300000000007,
        "end": 97.96900000000005,
        "average": 99.41100000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.2535211267605634,
        "text_similarity": 0.39457637071609497,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer references the correct topic but gives timestamps that are far off (2700s vs correct ~2790.9s) and omits the exact quoted target span and end time, so it is factually incorrect. "
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Decolonising the Curriculum', when does the speaker begin talking about that specific term?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2851.15,
        "end": 2854.233
      },
      "pred_interval": {
        "start": 2710.0,
        "end": 2720.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 141.1500000000001,
        "end": 134.23300000000017,
        "average": 137.69150000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322035,
        "text_similarity": 0.6187852621078491,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (2710.0s \u2192 2720.0s) are far earlier than the reference (slide fully visible at 2850.5s, speaker at 2851.150s) and thus contradict the correct timing, omitting the precise transition details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that decolonisation moves out of a western framework, when does she start mentioning Sophia Kell?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2904.8,
        "end": 2905.4
      },
      "pred_interval": {
        "start": 2958.0,
        "end": 2960.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.19999999999982,
        "end": 54.59999999999991,
        "average": 53.899999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571425,
        "text_similarity": 0.3507099747657776,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that Sophia Kell is mentioned after the explanation, but it omits key factual details: the precise timestamps (anchor ends at 2904.0s; target 2904.8\u20132905.4s) and that the mention occurs immediately after the anchor."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker describes her journey from compulsory to higher education, when does she identify internalized racism as a large part of her imposter syndrome?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3077.4,
        "end": 3085.5
      },
      "pred_interval": {
        "start": 3125.0,
        "end": 3140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.59999999999991,
        "end": 54.5,
        "average": 51.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.16129032258064516,
        "text_similarity": 0.3683556914329529,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately and succinctly captures the correct relation and content: she identifies internalized racism as a major part of her imposter syndrome after describing her journey from compulsory to higher education."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker recounts a SAMI colleague advising her to channel frustration into something positive, when does she mention the planning of the project called Humari Pehchan?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3060.6,
        "end": 3064.5
      },
      "pred_interval": {
        "start": 3165.0,
        "end": 3180.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 104.40000000000009,
        "end": 115.5,
        "average": 109.95000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.1639344262295082,
        "text_similarity": 0.35680094361305237,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly states the relation (that the project planning is mentioned after the SAMI colleague's advice) and includes the full project name, but it omits the specific timestamp details present in the reference answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker outlines the project's aim to bring families, schools, and community organizations together for storytelling, when does she state that the project is a call for action and a provocation?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3121.9,
        "end": 3125.0
      },
      "pred_interval": {
        "start": 3205.0,
        "end": 3220.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.09999999999991,
        "end": 95.0,
        "average": 89.04999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.25316455696202533,
        "text_similarity": 0.44742265343666077,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but omits the precise timestamps and full statement details required by the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining the research methodology's approach to power imbalances, when does she introduce the project's aim for children and parents?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.427,
        "end": 3304.244
      },
      "pred_interval": {
        "start": 3295.0,
        "end": 3306.0
      },
      "iou": 0.5260342570989708,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.572999999999865,
        "end": 1.7559999999998581,
        "average": 4.164499999999862
      },
      "rationale_metrics": {
        "rouge_l": 0.3174603174603175,
        "text_similarity": 0.33153682947158813,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the ordering (introduction after finish) but the timestamps are substantially off: the finish is ~7.4s later than the ground truth and the introduction time is ~17.6s later, missing the actual start (3288.427s) and end (3304.244s) times, so the answer is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker concludes the description of story development using heritage language, when does she start listing the project participants?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3305.525,
        "end": 3316.596
      },
      "pred_interval": {
        "start": 3347.0,
        "end": 3358.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.47499999999991,
        "end": 41.403999999999996,
        "average": 41.43949999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2807017543859649,
        "text_similarity": 0.5071883797645569,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the temporal relation but gives substantially incorrect timestamps (finish at 3347.0s vs 3304.2s and start at 3358.0s vs 3305.525s) and omits the correct list completion time, so it is mostly factually wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the project was postponed to September, when does she state the duration of the project and its output?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3369.8,
        "end": 3378.21
      },
      "pred_interval": {
        "start": 3395.0,
        "end": 3406.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.199999999999818,
        "end": 27.789999999999964,
        "average": 26.49499999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.29629629629629634,
        "text_similarity": 0.6617656946182251,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly preserves the 'after' relation but gives entirely incorrect timestamps (E1 should be 3344.280s, not 3395.0s) and fails to report the correct E2 span (3369.800\u20133378.210s), so key factual timing details are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker (Niget) finishes saying 'thank you', when does the other speaker (Katerina) start thanking her?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3413.516,
        "end": 3415.117
      },
      "pred_interval": {
        "start": 3495.0,
        "end": 3500.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.48399999999992,
        "end": 84.88299999999981,
        "average": 83.18349999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.20833333333333331,
        "text_similarity": 0.5131296515464783,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relation (Katerina starts immediately after Niget), but it gives a significantly incorrect time for Niget's end (3495.0s vs 3413s) and omits the actual Katerina start timestamp, so key factual details are wrong or missing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker in the bottom left talks about extreme prevent agendas, when does she talk about overt acts of racism in schools?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3579.7,
        "end": 3585.6
      },
      "pred_interval": {
        "start": 3625.0,
        "end": 3645.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.30000000000018,
        "end": 59.40000000000009,
        "average": 52.350000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.24657534246575347,
        "text_similarity": 0.40985411405563354,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that the speaker discusses overt racism after mentioning prevention, but the timestamp is incorrect (predicts 3625.0s vs. the correct 3579.7\u20133585.6s) and it omits the anchor's actual time window."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker in the bottom right discusses the concept of 'racism without racists', when does she explain that the system itself is inherently racist?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3628.4,
        "end": 3675.8
      },
      "pred_interval": {
        "start": 3675.0,
        "end": 3695.0
      },
      "iou": 0.01201201201201476,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.59999999999991,
        "end": 19.199999999999818,
        "average": 32.899999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.2894736842105263,
        "text_similarity": 0.5290990471839905,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct event but gives an incorrect start time (3675.0s) while the reference indicates the explanation spans 3628.4s\u20133675.8s; this large timing error (missing the bulk of the segment) makes the answer largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the host thanks the speakers, when does she introduce a question for Jackie?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3771.2,
        "end": 3772.9
      },
      "pred_interval": {
        "start": 3750.0,
        "end": 3760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.199999999999818,
        "end": 12.900000000000091,
        "average": 17.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.36,
        "text_similarity": 0.5111323595046997,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a timestamp (3750.0s) that contradicts the ground-truth introduction at 3771.2\u20133772.9s and therefore fails to match the correct timing; it omits the correct timestamps and is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After Jackie states that the US has been using CRT in anti-discrimination training, when does she mention that it hasn't been implemented in Scotland?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3861.8,
        "end": 3866.4
      },
      "pred_interval": {
        "start": 3840.0,
        "end": 3850.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.800000000000182,
        "end": 16.40000000000009,
        "average": 19.100000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.1846153846153846,
        "text_similarity": 0.4788418114185333,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives a single timestamp (3840.0s) that is far off from the correct segments (US: 3851.6\u20133861.1s; Scotland: 3861.8\u20133866.4s) and incorrectly collapses two related remarks into one moment, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After Jackie concludes her answer about diversity being everyone's issue, when does the host pick up on Greg's statement and question?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3918.884,
        "end": 3925.172
      },
      "pred_interval": {
        "start": 3930.0,
        "end": 3940.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.115999999999985,
        "end": 14.827999999999975,
        "average": 12.97199999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.25396825396825395,
        "text_similarity": 0.6223525404930115,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the host picks up after Jackie (relative order) but gives a single, incorrect absolute time (3930.0s) and omits the correct precise intervals (Jackie ~3897.083\u20133898.565s; host ~3918.884\u20133925.172s), so it is factually inaccurate and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman in the top-right finishes her sentence about normalising provocation, when does the woman in the top-left start speaking about a national campaign?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3954.0,
        "end": 4036.3
      },
      "pred_interval": {
        "start": 3985.0,
        "end": 4000.0
      },
      "iou": 0.18226002430133617,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.0,
        "end": 36.30000000000018,
        "average": 33.65000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.08955223880597014,
        "text_similarity": 0.17837098240852356,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') between the two speakers, but it omits key factual details from the reference such as the exact start time (3954.0s), the quoted lead-in, and the target's end time. "
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman in the top-right finishes saying they have 10 minutes before wrapping up, when does the woman in the bottom-left start speaking?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4129.3,
        "end": 4130.2
      },
      "pred_interval": {
        "start": 4125.0,
        "end": 4130.0
      },
      "iou": 0.13461538461535436,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.300000000000182,
        "end": 0.1999999999998181,
        "average": 2.25
      },
      "rationale_metrics": {
        "rouge_l": 0.39999999999999997,
        "text_similarity": 0.5298316478729248,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives an incorrect finish time (4125.0s vs 4126.3s) and wrongly claims the bottom-left starts immediately, contradicting the correct start at 4129.3s (a ~3s gap); thus it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After Lisa (woman in bottom-left) asks if anyone would like to put their hand up, when is the next time an unidentified woman speaks to assist her?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4214.2,
        "end": 4215.3
      },
      "pred_interval": {
        "start": 4165.0,
        "end": 4170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.19999999999982,
        "end": 45.30000000000018,
        "average": 47.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2985074626865672,
        "text_similarity": 0.6416171789169312,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives incorrect timestamps that do not match the ground truth (Lisa at 4187.4s and the woman at 4214.2\u20134215.3s); the prediction is off by ~22s and ~44s respectively and omits the correct end time, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After Lisa (woman in bottom-left) says 'You have the floor' to Ken, when does Ken (man in bottom-right) start asking his question?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4227.7,
        "end": 4304.7
      },
      "pred_interval": {
        "start": 4200.0,
        "end": 4205.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.699999999999818,
        "end": 99.69999999999982,
        "average": 63.69999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.41379310344827586,
        "text_similarity": 0.5876369476318359,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates Ken speaks after Lisa, but the timestamps are substantially incorrect (off by ~20s) and it omits Ken's question completion time, so it is factually incomplete and imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker (top right) says she was hoping to be told who the next Education Minister was, when does the speaker (top left) say she was excited for an announcement about a new education minister?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4405.248,
        "end": 4411.436
      },
      "pred_interval": {
        "start": 4325.0,
        "end": 4330.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.24799999999959,
        "end": 81.4359999999997,
        "average": 80.84199999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.06451612903225808,
        "text_similarity": 0.17833885550498962,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the top-left speaker speaks after the top-right speaker), but it omits the specific timing details provided in the correct answer (the exact start/end timestamps)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker (top right) says there are many voices missing within policy construction, when does the speaker (top left) start talking about Kokab Stewart?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4411.577,
        "end": 4421.13
      },
      "pred_interval": {
        "start": 4365.0,
        "end": 4370.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.577000000000226,
        "end": 51.13000000000011,
        "average": 48.85350000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.24982351064682007,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the temporal relation (the top-left speaker speaks about Kokab Stewart after the top-right speaker), but it omits the precise timestamps and event boundaries given in the reference, making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker (bottom left) says 'I am a lowly teacher more so than a policy expert', when does she start talking about mandated teacher training in anti-racism?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4463.676,
        "end": 4476.028
      },
      "pred_interval": {
        "start": 4405.0,
        "end": 4410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.676000000000386,
        "end": 66.02800000000025,
        "average": 62.35200000000032
      },
      "rationale_metrics": {
        "rouge_l": 0.0634920634920635,
        "text_similarity": 0.19581231474876404,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that the topic follows the quoted line but provides no timing or the documented start/end timestamps; it therefore omits key factual details required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that a policy won't translate into practice without teacher buy-in, when does she start talking about specific and mandated training for teachers?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4487.6,
        "end": 4494.5
      },
      "pred_interval": {
        "start": 4520.0,
        "end": 4530.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.399999999999636,
        "end": 35.5,
        "average": 33.94999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.16266298294067383,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives substantially different timestamps (4520.0s and 4530.0s) than the correct times (anchor ends 4487.5s, target starts 4487.6s), so it fails to provide the correct start time and relation."
      }
    },
    {
      "question_id": "002",
      "question": "After David finishes asking if it's appropriate to apply critical race theory to Irish racism in Scotland, when does Jackie respond?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4674.198,
        "end": 4676.359
      },
      "pred_interval": {
        "start": 4560.0,
        "end": 4570.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 114.19800000000032,
        "end": 106.35900000000038,
        "average": 110.27850000000035
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.19546666741371155,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction preserves the 'after' relation but gives completely incorrect absolute timestamps (4560/4570s vs correct ~4666.39\u20134673.14s and 4674.20\u20134676.36s) and omits the target's exact timing and final word, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once Jackie finishes saying she will stop before making a political boo-boo, when does the speaker (top right) begin to discuss critical race theory's applicability beyond color racial issues?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4576.21,
        "end": 4586.726
      },
      "pred_interval": {
        "start": 4600.0,
        "end": 4610.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.789999999999964,
        "end": 23.274000000000342,
        "average": 23.532000000000153
      },
      "rationale_metrics": {
        "rouge_l": 0.06153846153846154,
        "text_similarity": 0.18425427377223969,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (discussion begins after Jackie finishes) but the provided timestamps are inaccurate and do not match the correct start (4576.210s) or include the correct end time, so it is factually incorrect and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the top-left female speaker finishes stating she is looking forward to inviting Nicola to present her work, when does she explain the reason for the invitation?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4663.9,
        "end": 4672.2
      },
      "pred_interval": {
        "start": 4650.0,
        "end": 4652.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.899999999999636,
        "end": 20.199999999999818,
        "average": 17.049999999999727
      },
      "rationale_metrics": {
        "rouge_l": 0.3116883116883117,
        "text_similarity": 0.5477692484855652,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the explanation immediately follows the statement, but it gives a significantly wrong timestamp (4650.0s vs the correct anchor end at 4663.9s) and omits the precise target interval, so the timing is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the top-left female speaker asks if there are any more questions, when does the top-right female speaker begin to answer a question from 'Sarah Khan'?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4697.9,
        "end": 4703.6
      },
      "pred_interval": {
        "start": 4790.0,
        "end": 4800.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 92.10000000000036,
        "end": 96.39999999999964,
        "average": 94.25
      },
      "rationale_metrics": {
        "rouge_l": 0.31168831168831174,
        "text_similarity": 0.5598171949386597,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the relative order (target after anchor) but the absolute timestamps are off by about 100 seconds and it omits the event durations, so it does not match the reference. "
      }
    },
    {
      "question_id": "003",
      "question": "After the top-right female speaker mentions that UWS has included a clear statement in placement handbooks, when does she describe the challenge of students having the confidence to speak up about discrimination?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4738.4,
        "end": 4750.8
      },
      "pred_interval": {
        "start": 4810.0,
        "end": 4820.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.60000000000036,
        "end": 69.19999999999982,
        "average": 70.40000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.29545454545454547,
        "text_similarity": 0.3733362555503845,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (anchor then target) but gives timestamps that are significantly offset (~80\u201390s later) and omits the precise interval and immediate-follow relation specified in the correct answer, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the top-left woman finishes speaking about BAME students experiencing racism and leaving, when does the bottom-right woman begin speaking about the important message?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4841.8,
        "end": 4845.0
      },
      "pred_interval": {
        "start": 4835.0,
        "end": 4840.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.800000000000182,
        "end": 5.0,
        "average": 5.900000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.4137931034482759,
        "text_similarity": 0.5105847120285034,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the relative ordering (bottom-right speaks shortly after), but it gives an incorrect absolute time for the top-left finish (4835.0s vs 4837.0s) and omits the precise start (4841.8s) and end (4845.0s) timestamps for the bottom-right speaker."
      }
    },
    {
      "question_id": "002",
      "question": "After the bottom-right woman states that including an explicit statement in handbooks can make a difference in a student's life, when does she mention that they only have four minutes left?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4880.8,
        "end": 4897.0
      },
      "pred_interval": {
        "start": 4900.0,
        "end": 4905.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.199999999999818,
        "end": 8.0,
        "average": 13.599999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.19444444444444445,
        "text_similarity": 0.42974400520324707,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction locates the mention but gives an incorrect single timestamp (4900.0s) and omits the correct interval (4880.8s\u20134897.0s) and the E1 timing (4866.6s); thus it is factually inaccurate and misses key timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the bottom-right woman finishes describing the story from the book 'Whistling Vivaldi', when does she mention that there are many other examples in that book?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4986.36,
        "end": 4989.384
      },
      "pred_interval": {
        "start": 4960.0,
        "end": 4965.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.359999999999673,
        "end": 24.384000000000015,
        "average": 25.371999999999844
      },
      "rationale_metrics": {
        "rouge_l": 0.27692307692307694,
        "text_similarity": 0.35563182830810547,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a time of 4960.0s which contradicts the reference (finish at 4985.9s and mention at 4986.360\u20134989.384); the event is mislocated and not aligned with the correct timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker expresses her upset about the schools' reluctance to participate, when does she mention Negat having difficulties with recruitment?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 5023.8,
        "end": 5035.8
      },
      "pred_interval": {
        "start": 5062.0,
        "end": 5073.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.19999999999982,
        "end": 37.19999999999982,
        "average": 37.69999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.3288206458091736,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the Negat remark occurs after the upset), but it omits the key factual elements requested \u2014 the precise timestamps (5023.8s\u20135035.8s) and the end time of the upset segment (5023.6s)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'there is no neutral position' for the first time following Jackie's quote, when does she say it again?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 5084.475,
        "end": 5085.8
      },
      "pred_interval": {
        "start": 5149.0,
        "end": 5158.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.52499999999964,
        "end": 72.19999999999982,
        "average": 68.36249999999973
      },
      "rationale_metrics": {
        "rouge_l": 0.2033898305084746,
        "text_similarity": 0.4172831177711487,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives two timestamps but they are far from the reference times (5149.0/5158.0s vs. 5080.0\u20135083.8s and 5084.475\u20135085.8s) and omits end times and the 'next' relation, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes quoting the first Martin Luther King line, when does she start quoting the second one about accepting evil?",
      "video_id": "0S2MoSiyLiw",
      "video_number": "015",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 5105.5,
        "end": 5114.1
      },
      "pred_interval": {
        "start": 5165.0,
        "end": 5172.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.5,
        "end": 57.899999999999636,
        "average": 58.69999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.16129032258064516,
        "text_similarity": 0.4034647047519684,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives a start time of 5165.0s which is \u224859.5s later than the correct 5105.5s and omits the first quote's end time and the second quote's end time; thus it is factually incorrect and missing key timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says that the team is going to do a quick introduction, when does Ashley Satri introduce herself?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 84.156,
        "end": 102.754
      },
      "pred_interval": {
        "start": 185.0,
        "end": 192.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 100.844,
        "end": 89.246,
        "average": 95.04499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2553191489361702,
        "text_similarity": 0.5975664854049683,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction is factually correct that Ashley speaks after the anchor's remark, but it fails to provide the requested timing details (the specific time interval 84.156s\u2013102.754s) and is thus incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Next, after Ashley Satri finishes introducing herself, when does Carly Thibodeau introduce herself?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 106.54,
        "end": 116.471
      },
      "pred_interval": {
        "start": 192.0,
        "end": 197.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 85.46,
        "end": 80.529,
        "average": 82.99449999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.26086956521739124,
        "text_similarity": 0.5690699815750122,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that Carly introduces herself after Ashley, but it omits the key timing details (Carly speaks from 106.54s to 116.471s) requested in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning the \"IDEA Supervision, Monitoring, and Support team\", when does she begin listing other teams within that department?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.641,
        "end": 188.788
      },
      "pred_interval": {
        "start": 152.0,
        "end": 160.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.64099999999999,
        "end": 28.78800000000001,
        "average": 30.7145
      },
      "rationale_metrics": {
        "rouge_l": 0.1,
        "text_similarity": 0.23744450509548187,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps and spacing (152.0s \u2192 160.0s) contradict the reference (anchor ends 184.622s, target starts 184.641s immediately after); the prediction is factually incorrect about timing and sequence."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining the purpose of an IEP, when does she highlight the phrase \"prepare them\" on the slide?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.569,
        "end": 304.375
      },
      "pred_interval": {
        "start": 204.0,
        "end": 208.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.56900000000002,
        "end": 96.375,
        "average": 88.97200000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.29629629629629634,
        "text_similarity": 0.5346798896789551,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted time (204.0s) contradicts the ground-truth interval (285.569\u2013304.375s); it misplaces the highlight by ~81.6 seconds and does not match the annotated event."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes saying \"So please feel free to reach out\", when does the slide transition to \"The IEP Decision Making Process\"?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 324.55,
        "end": 326.4
      },
      "pred_interval": {
        "start": 270.0,
        "end": 272.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.55000000000001,
        "end": 54.39999999999998,
        "average": 54.474999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.1754385964912281,
        "text_similarity": 0.509445071220398,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly gives 270.0s for the transition, which conflicts with the ground truth start time of 324.55s (fully displayed by 326.4s); it also omits the precise start and full-display timings and thus is factually incorrect. "
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks what the IEP meeting is, when does she define it as a communication vehicle?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 348.721,
        "end": 354.0
      },
      "pred_interval": {
        "start": 365.0,
        "end": 372.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.278999999999996,
        "end": 18.0,
        "average": 17.139499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5685991048812866,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a single incorrect timestamp (365.0s) and omits the correct event intervals and the 'once_finished' relation; it contradicts the detailed timings in the reference and is therefore largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker explains that the SAU has the ultimate responsibility for FAPE, when does she mention that they will discuss disagreement on the next slide?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 404.242,
        "end": 409.428
      },
      "pred_interval": {
        "start": 409.0,
        "end": 410.0
      },
      "iou": 0.07433136505731133,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.757999999999981,
        "end": 0.5720000000000027,
        "average": 2.664999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.3404255319148936,
        "text_similarity": 0.4970489740371704,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted timestamp (409.0s) falls within the correct interval (404.242\u2013409.428s) and correctly places the remark after the SAU explanation, so it accurately matches the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Recap' slide appears, when does the speaker state that the IEP meeting serves as a communication vehicle?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 529.94,
        "end": 533.504
      },
      "pred_interval": {
        "start": 418.0,
        "end": 420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 111.94000000000005,
        "end": 113.50400000000002,
        "average": 112.72200000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.326530612244898,
        "text_similarity": 0.6320111751556396,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (418.0s) contradicts the reference interval (529.94\u2013533.504s) and occurs well before the recap slide (\u2248522s), so it is incorrect and does not match the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that the SAU has ultimate responsibility for FAPE, when does she mention that dispute resolution options are available?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 544.0,
        "end": 547.0
      },
      "pred_interval": {
        "start": 510.0,
        "end": 512.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 35.0,
        "average": 34.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2553191489361702,
        "text_similarity": 0.6306077241897583,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys the key relation that mention of dispute resolution occurs after the SAU responsibility statement; although it omits timestamps, it preserves the required relative ordering."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Required Participants for IEP Meetings' slide, when does the speaker describe the qualifications of a representative from the SAU?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 584.0,
        "end": 600.0
      },
      "pred_interval": {
        "start": 630.0,
        "end": 640.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.0,
        "end": 40.0,
        "average": 43.0
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306123,
        "text_similarity": 0.6264122128486633,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the relation (the description occurs during the slide), but it omits the key factual timestamps provided in the correct answer (slide 521\u2013700s and description 584\u2013600s), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the special education director, IP coordinator, and assistant principal as part of the team, when does she state that the child must be invited?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 700.0,
        "end": 713.5
      },
      "pred_interval": {
        "start": 725.0,
        "end": 730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.0,
        "end": 16.5,
        "average": 20.75
      },
      "rationale_metrics": {
        "rouge_l": 0.13559322033898305,
        "text_similarity": 0.3000589609146118,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the child is mentioned after the listed team members, matching the relative ordering, but it omits the explicit timing details and the conditional phrasing ('whenever applicable, the child') present in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the conditions for when a team member's attendance is not necessary, when does she begin discussing the conditions for an excusal?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.0,
        "end": 776.0
      },
      "pred_interval": {
        "start": 740.0,
        "end": 745.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.0,
        "end": 31.0,
        "average": 30.0
      },
      "rationale_metrics": {
        "rouge_l": 0.23684210526315794,
        "text_similarity": 0.4749266505241394,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted start time (740.0s) contradicts the correct start (769.0s) and even precedes the anchor end at 755.0s, so it is factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'What if the parent can't attend the IEP meeting?', when does she begin explaining the requirements for public agencies?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 909.0,
        "end": 924.0
      },
      "pred_interval": {
        "start": 870.0,
        "end": 872.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 52.0,
        "average": 45.5
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.36089009046554565,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only restates that the question occurs 'at the start of this segment' and gives no timing or when the speaker begins explaining the requirements, omitting the key timestamped details from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses offering other methods for parents to attend IEP meetings, when does she explain that a meeting might be conducted without a parent?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 950.0,
        "end": 965.0
      },
      "pred_interval": {
        "start": 935.0,
        "end": 940.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.0,
        "end": 25.0,
        "average": 20.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3043478260869565,
        "text_similarity": 0.6039890050888062,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is incorrect: the correct segment introducing meetings without a parent is 950.0\u2013965.0s, whereas the prediction gives 935.0s (about 15s earlier) and omits the provided time ranges and relation, thus contradicting key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After Ashley suggests recording attempts to contact parents in the written notice, when does Carly agree with this recommendation?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1076.3,
        "end": 1077.4
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1052.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.299999999999955,
        "end": 25.40000000000009,
        "average": 25.850000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.21276595744680854,
        "text_similarity": 0.4147176742553711,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the relative order (Carly after Ashley) but gives incorrect absolute timestamps and omits the start/finish intervals; both event times are significantly off from the reference (Ashley at 1062.7s vs 1050.0s; Carly begins at 1076.3s vs 1052.0s)."
      }
    },
    {
      "question_id": "002",
      "question": "Once Ashley finishes posing the question about holding an IEP meeting with only an 18-year-old student, when does Carly offer her initial thought on the matter?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1117.7,
        "end": 1122.7
      },
      "pred_interval": {
        "start": 1052.0,
        "end": 1053.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.70000000000005,
        "end": 69.70000000000005,
        "average": 67.70000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.36666666666666664,
        "text_similarity": 0.6805726885795593,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamp (1052.0s) contradicts the ground truth (Carly begins at 1117.7s after Ashley finishes at 1068.7s); the response is factually incorrect about when Carly offers her thought."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'determining those present levels', when does she mention the 'Office Hours Archives \u2013 Data Collection Modules' link?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1233.32,
        "end": 1234.36
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1240.0
      },
      "iou": 0.10399999999999636,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.3199999999999363,
        "end": 5.6400000000001,
        "average": 4.480000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.6312539577484131,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that the link is mentioned after the phrase 'determining those present levels,' matching the reference's temporal relation without contradicting any details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'determining modifications and/or accommodations', when does she mention the 'MTSS office'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1291.054,
        "end": 1294.278
      },
      "pred_interval": {
        "start": 1250.0,
        "end": 1260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.05400000000009,
        "end": 34.27800000000002,
        "average": 37.666000000000054
      },
      "rationale_metrics": {
        "rouge_l": 0.28,
        "text_similarity": 0.6137755513191223,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states that the 'MTSS office' mention occurs after the quoted phrase, but it omits the precise timestamps and detailed event boundaries provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'This is an IEP checklist that I think Carly developed', when does she describe what the checklist tells you to do?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1366.516,
        "end": 1375.503
      },
      "pred_interval": {
        "start": 1270.0,
        "end": 1280.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 96.51600000000008,
        "end": 95.50299999999993,
        "average": 96.0095
      },
      "rationale_metrics": {
        "rouge_l": 0.3870967741935484,
        "text_similarity": 0.7404019832611084,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the description occurs after the quoted remark, matching the key temporal relation, but it omits the specific timestamps and timing details provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"number five\", when does the \"Amendments\" slide fully appear on screen?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1443.918,
        "end": 1444.018
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1412.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.91799999999989,
        "end": 32.01800000000003,
        "average": 32.96799999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.5384615384615384,
        "text_similarity": 0.7202454805374146,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps are substantially different from the ground truth (1439.347 vs 1410.0 and 1443.918 vs 1412.0) and it omits the stability time and relation, so it is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the \"IEP Meeting Timelines\" slide appears on screen, when does the speaker state that timelines can be a little bit confusing?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1517.804,
        "end": 1519.454
      },
      "pred_interval": {
        "start": 1560.0,
        "end": 1562.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.19599999999991,
        "end": 42.54600000000005,
        "average": 42.37099999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.44776119402985076,
        "text_similarity": 0.7668039202690125,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the speaker says the line after the slide appears, but the provided timestamps are significantly different from the reference (off by ~45s) and it omits the precise stable/range timings given in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker explains that an advanced written notice needs to go out seven days prior to the IEP meeting, when do they state that parents must sign to waive this 7-day advanced written notice?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1560.813,
        "end": 1570.038
      },
      "pred_interval": {
        "start": 1580.0,
        "end": 1582.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.186999999999898,
        "end": 11.961999999999989,
        "average": 15.574499999999944
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.6870050430297852,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer preserves the relative order (parents sign after the explanation) but gives incorrect absolute timestamps that do not match the reference time ranges, so the timing is substantially wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker explains the 60-calendar-day and 45-school-day evaluation timelines, when does she explain that evaluation reports must be provided to the parent at least three days prior to the IEP meeting?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1633.362,
        "end": 1641.913
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1620.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.36200000000008,
        "end": 21.91300000000001,
        "average": 32.637500000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.13953488372093023,
        "text_similarity": 0.3031717538833618,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and fails to provide the required timestamps or the precise 'after' relation; it does not state when the reports must be provided (the E1/E2 times and completion at 1641.913s), so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide changes to 'Requirement that Program be in Effect', when does the speaker clarify that the 30-day timeline applies to both IEP development and implementation?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1719.674,
        "end": 1731.971
      },
      "pred_interval": {
        "start": 1620.0,
        "end": 1650.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 99.67399999999998,
        "end": 81.971,
        "average": 90.82249999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714288,
        "text_similarity": 0.3003307580947876,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the relative relation ('after') but omits the key factual specifics (the anchor and target timestamps and event boundaries), making it incomplete compared to the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the annual meeting date for the student as January 6th, 2022, when does she state when the next annual meeting must be held?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1785.48,
        "end": 1793.83
      },
      "pred_interval": {
        "start": 1650.0,
        "end": 1680.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 135.48000000000002,
        "end": 113.82999999999993,
        "average": 124.65499999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.12698412698412698,
        "text_similarity": 0.34210094809532166,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only restates that the speaker mentions the next meeting occurs after the January 6, 2022 statement and gives no timing details or the required timestamps/relation provided in the correct answer, so it is largely incomplete despite capturing the relative ordering."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the annual meeting date of January 6, 2022, when does she mention that the duration of the IEP begins on January 16?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.116,
        "end": 1878.561
      },
      "pred_interval": {
        "start": 178.0,
        "end": 182.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1695.116,
        "end": 1696.561,
        "average": 1695.8384999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454546,
        "text_similarity": 0.7398525476455688,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the key relation and dates (IEP starts Jan 16 after the Jan 6 annual meeting), but it omits the specific timestamps given in the reference answer."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the 'Annual IEP & Duration of IEP' diagram, when does the speaker explain the 7-day notice period?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1901.094,
        "end": 1909.493
      },
      "pred_interval": {
        "start": 195.0,
        "end": 198.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1706.094,
        "end": 1711.493,
        "average": 1708.7935
      },
      "rationale_metrics": {
        "rouge_l": 0.3111111111111111,
        "text_similarity": 0.570685863494873,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relation ('during') that the speaker explains the 7-day notice while the diagram is displayed, but it omits key factual timestamps (diagram display and the explanation start/end times) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says that there are two sets of 364-day timelines, when does she next discuss parents waiving the 7-day notice?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1896.915,
        "end": 1901.942
      },
      "pred_interval": {
        "start": 204.0,
        "end": 207.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1692.915,
        "end": 1694.942,
        "average": 1693.9285
      },
      "rationale_metrics": {
        "rouge_l": 0.459016393442623,
        "text_similarity": 0.6238307952880859,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the topic of parents waiving the 7-day notice is discussed next, but it omits the required timing details (start/end timestamps) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if there are any other questions about timelines, when does she say they are 'good for now'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2192.362,
        "end": 2131.025
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2135.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.36200000000008,
        "end": 3.974999999999909,
        "average": 33.168499999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.5587936639785767,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the ordering (asks then says 'good for now') but the timestamps are significantly incorrect compared to the reference (off by ~50\u201362 seconds), so key factual timing information is wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the procedural manual, when does she introduce the Maine Unified Special Education Regulations (MUSER)?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2219.043,
        "end": 2229.826
      },
      "pred_interval": {
        "start": 2140.0,
        "end": 2145.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.04300000000012,
        "end": 84.82600000000002,
        "average": 81.93450000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306123,
        "text_similarity": 0.4214060306549072,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and contradicts the reference: it places MUSER at 2140.0s, which is before the procedural manual finishes (~2203.659s), whereas the correct introduction occurs at 2219.043s-2229.826s."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the 'Special Education Laws and Regulations', when does the '2024-25 Professional Development Schedule' slide appear?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2361.5,
        "end": 2421.5
      },
      "pred_interval": {
        "start": 2340.0,
        "end": 2350.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.5,
        "end": 71.5,
        "average": 46.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.7611820101737976,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the slide appears after the mention), but it omits the key factual details (the precise start and end timestamps) provided in the reference answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes encouraging viewers to reach out to them, when does the speaker say, 'I think that is it'?",
      "video_id": "eIt2t9mkSZA",
      "video_number": "016",
      "segment": {
        "start": 2490.0,
        "end": 2538.75
      },
      "gt_interval": {
        "start": 2514.0,
        "end": 2516.5
      },
      "pred_interval": {
        "start": 2534.8,
        "end": 2535.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.800000000000182,
        "end": 18.5,
        "average": 19.65000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.2807017543859649,
        "text_similarity": 0.37283873558044434,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction places the phrase at 2534.8s, which is about 20s later than the ground-truth interval (2514.0\u20132516.5s) and fails to match the correct timing and event relation, omitting the precise interval information."
      }
    },
    {
      "question_id": "002",
      "question": "After the host introduces Stephen McKinney, when does Stephen McKinney start talking about the dramatic impact of the pandemic?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 101.9,
        "end": 107.8
      },
      "pred_interval": {
        "start": 18.0,
        "end": 21.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.9,
        "end": 86.8,
        "average": 85.35
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.5124228596687317,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted start time (18.0s) directly contradicts the ground truth (Stephen begins at 101.9s after an interrupted attempt); it is factually incorrect and omits the interruption detail."
      }
    },
    {
      "question_id": "003",
      "question": "After Stephen McKinney mentions that social problems like child mental health pre-existed COVID-19 and were exacerbated, when does he bring up the Carers Scotland Act 2016?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 160.326,
        "end": 171.144
      },
      "pred_interval": {
        "start": 195.0,
        "end": 196.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.67400000000001,
        "end": 24.855999999999995,
        "average": 29.765
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.47745782136917114,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct topic but gives a timestamp (195.0s) that is significantly later (~24s) than the correct start (160.326s) and end (171.144s), so the timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker states the Carers Scotland Act 2016 was published in 2018 by the Scottish Government, when does he state that the Act applies to adult and young carers?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.5,
        "end": 171.0
      },
      "pred_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.5,
        "end": 69.0,
        "average": 67.75
      },
      "rationale_metrics": {
        "rouge_l": 0.1694915254237288,
        "text_similarity": 0.12088481336832047,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer is vague and circular, failing to provide the required timestamps or the temporal relation; it omits the key factual details (anchor at 167.5s and target 168.5\u2013171.0s) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker defines a young carer as a person under 18 with caring responsibilities, when does he provide an additional condition for defining a young carer?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 217.0,
        "end": 222.5
      },
      "pred_interval": {
        "start": 240.0,
        "end": 245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.0,
        "end": 22.5,
        "average": 22.75
      },
      "rationale_metrics": {
        "rouge_l": 0.24615384615384614,
        "text_similarity": 0.33154797554016113,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that an additional condition is given after the initial definition but fails to provide the required timing details (the specific timestamps 216.5s\u2013222.5s), omitting key factual elements from the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker cites the 2011 census data about the age distribution of young carers in the UK, when does he mention that Scottish Government guidance acknowledges very young carers?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 236.0,
        "end": 244.5
      },
      "pred_interval": {
        "start": 245.0,
        "end": 250.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.0,
        "end": 5.5,
        "average": 7.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.24514132738113403,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the semantic sequence (census data followed by mention of Scottish guidance on very young carers) but omits the key timing details and the fact that the target event starts immediately after the anchor (specific timestamps 235.0s\u2192236.0s\u2013244.5s)."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker says he just wanted to introduce the topic, when does he refer to 'invisible children'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 424.5,
        "end": 426.1
      },
      "pred_interval": {
        "start": 345.0,
        "end": 346.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.5,
        "end": 80.10000000000002,
        "average": 79.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.12765957446808512,
        "text_similarity": 0.07159116119146347,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the relative relation that the 'invisible children' reference comes after the introduction, but it omits the precise timestamps and inaccurately implies it occurs immediately ('right after') rather than several seconds later."
      }
    },
    {
      "question_id": "002",
      "question": "After John says 'Many thanks, Stephen', when is the next time he speaks to introduce the next presentation?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 461.0,
        "end": 465.0
      },
      "pred_interval": {
        "start": 405.0,
        "end": 406.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.0,
        "end": 59.0,
        "average": 57.5
      },
      "rationale_metrics": {
        "rouge_l": 0.21276595744680854,
        "text_similarity": 0.4614698886871338,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states John introduces the next presentation, but incorrectly claims it happens immediately and omits key details (timestamps and that he introduces Katie), so it contradicts and is incomplete versus the reference."
      }
    },
    {
      "question_id": "003",
      "question": "While Katie's first slide 'Widening the gap? The challenges for equitable music education in Scotland' is displayed, when does she mention Leo Moscardini?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 490.7,
        "end": 504.0
      },
      "pred_interval": {
        "start": 415.0,
        "end": 416.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.69999999999999,
        "end": 88.0,
        "average": 81.85
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.4169631600379944,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states she mentions Leo Moscardini while the first slide is displayed, but it omits the key timing details and the specific interval (E2: 490.7\u2013504s) provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes listing what the presentation will cover, when does she say 'Okay'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 526.04,
        "end": 527.9
      },
      "pred_interval": {
        "start": 510.0,
        "end": 510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.039999999999964,
        "end": 17.899999999999977,
        "average": 16.96999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.24390243902439024,
        "text_similarity": 0.38837194442749023,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that she says 'Okay' immediately after finishing the list, matching the reference that it occurs directly following the listing (526.04s)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing Case Study B, when does she begin describing Case Study C?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 561.5,
        "end": 567.5
      },
      "pred_interval": {
        "start": 570.0,
        "end": 570.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.5,
        "end": 2.5,
        "average": 5.5
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6302565932273865,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys that Case Study C begins after Case Study B (the same sequential transition), but it omits the key timing details given in the reference (start at 561.5s and end at 567.5s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the number of pupils taking Advanced Higher music in Case Study A, when does she mention the number of pupils taking qualifications in Case Study B?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 627.5,
        "end": 634.2
      },
      "pred_interval": {
        "start": 640.0,
        "end": 640.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.5,
        "end": 5.7999999999999545,
        "average": 9.149999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.5205996036529541,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that Case Study B's pupil numbers are mentioned after Case Study A (the next set), but it omits the specific timing details given in the correct answer (E1 ending at 627.5s and E2 running 627.5\u2013634.2s)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that inequality in music education was beginning in primary schools and persisting, when does she explain that the focus on performance privileges middle-class pupils?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 728.2,
        "end": 740.8
      },
      "pred_interval": {
        "start": 725.0,
        "end": 734.0
      },
      "iou": 0.3670886075949349,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.2000000000000455,
        "end": 6.7999999999999545,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21212121212121213,
        "text_similarity": 0.4944836497306824,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') between the two statements but omits the specific timestamps and duration details given in the correct answer, reducing completeness."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'What this means?' is displayed, when does the speaker state that working-class, poorer households, disabled children, and those with additional support needs are effectively excluded?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 763.3,
        "end": 771.2
      },
      "pred_interval": {
        "start": 768.0,
        "end": 779.0
      },
      "iou": 0.20382165605095773,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.7000000000000455,
        "end": 7.7999999999999545,
        "average": 6.25
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.5641156435012817,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the event occurs while the 'What this means?' slide is displayed, but it omits the key temporal details (the slide timestamps 742.0\u2013789.2s and the specific speech interval 763.3\u2013771.2s) present in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once Katie finishes saying 'Thanks very much', when does John begin thanking her?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 882.288,
        "end": 883.549
      },
      "pred_interval": {
        "start": 965.0,
        "end": 967.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 82.71199999999999,
        "end": 83.45100000000002,
        "average": 83.0815
      },
      "rationale_metrics": {
        "rouge_l": 0.16216216216216217,
        "text_similarity": 0.5021951198577881,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly conveys the core relation that John thanks Katie after she finishes, but it omits the precise timestamps and the explicit once_finished/absolute\u2192relative timing details given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the first slide of Lindsay's presentation appears on screen, when does Lindsay begin to introduce her project?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 921.97,
        "end": 989.732
      },
      "pred_interval": {
        "start": 980.0,
        "end": 982.0
      },
      "iou": 0.029515067441929128,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.02999999999997,
        "end": 7.731999999999971,
        "average": 32.88099999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2325581395348837,
        "text_similarity": 0.5310467481613159,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the temporal relation (that she begins after the first slide), but it omits the key factual details (the specific start and end timestamps) given in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "During the 'Background to study' slide, when does Lindsay state that poverty is detrimental to academic attainment?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 964.634,
        "end": 969.402
      },
      "pred_interval": {
        "start": 1005.0,
        "end": 1007.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.365999999999985,
        "end": 37.597999999999956,
        "average": 38.98199999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.19607843137254902,
        "text_similarity": 0.5304189920425415,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies that Lindsay's statement occurs during the 'Background to study' slide, matching the temporal relation, but it omits the specific start/end timestamps and interval details provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining the 'Study design' slide, when does she start discussing the 'Research Participants and School Profiles'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1085.64,
        "end": 1103.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1060.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.6400000000001,
        "end": 43.0,
        "average": 39.32000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.4848484848484849,
        "text_similarity": 0.6550602912902832,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the ordering ('after') but the timestamps are substantially incorrect (off by ~30s) and it omits the discussion end time, so it fails on factual accuracy and completeness."
      }
    },
    {
      "question_id": "001",
      "question": "After the female presenter finishes speaking about the previous research, when does she transition to the 'Reflective questions' slide?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1249.4,
        "end": 1250.5
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.40000000000009,
        "end": 10.5,
        "average": 14.950000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5730422735214233,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after'/'right after') between the speaker finishing and the slide transition, but it omits the precise timing details (1242.8s, 1249.4s, 1250.5s) present in the correct answer, reducing completeness and precision."
      }
    },
    {
      "question_id": "002",
      "question": "Once the female presenter finishes talking about the reflective questions, when does the male presenter start speaking?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1272.5,
        "end": 1273.0
      },
      "pred_interval": {
        "start": 1240.0,
        "end": 1250.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.5,
        "end": 23.0,
        "average": 27.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.4746016263961792,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys that the male speaks immediately after the female (relation once_finished) but omits the key precise timestamps (male starts at 1272.5s and first word ends at 1273.0s), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "While the first male presenter is speaking about digital exclusion, when does he mention the conditions that education systems need to meet to be successful?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1343.9,
        "end": 1346.5
      },
      "pred_interval": {
        "start": 1250.0,
        "end": 1260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 93.90000000000009,
        "end": 86.5,
        "average": 90.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.163265306122449,
        "text_similarity": 0.258830726146698,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that he mentions the conditions while discussing digital exclusion, matching the ground-truth relation ('during') even though the reference gives exact timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker says 'There you go', when does the screen transition to the presentation slide with the second speaker in a small window?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1426.2,
        "end": 1426.5
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.200000000000045,
        "end": 16.5,
        "average": 16.350000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.19999999999999998,
        "text_similarity": 0.5496194958686829,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that the transition occurs after the utterance, but incorrectly states it happens \"immediately\" and omits the key timing details (the transition begins ~5.5 seconds later at 1426.2s and completes by 1426.5s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses how many participants experienced difficulties getting up to speed with technology and having appropriate platforms, when does he talk about the positive aspects of teachers generating vast amounts of online material?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1587.0,
        "end": 1604.0
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1620.0
      },
      "iou": 0.42424242424242425,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 16.0,
        "average": 9.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.2875886559486389,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') between the two segments, but it omits the specific timestamps (1555\u20131572s and 1587\u20131604s) given in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker states that online lessons could be quite useful, when does he discuss gaining insights into pupils' lives and building better relationships with parents?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1637.5,
        "end": 1645.0
      },
      "pred_interval": {
        "start": 162.0,
        "end": 163.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1475.5,
        "end": 1482.0,
        "average": 1478.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3225806451612903,
        "text_similarity": 0.4476505517959595,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the 'after' relation right but incorrectly attributes the insights to the first speaker (they are discussed by the second) and omits the timestamps, so it contradicts key factual elements."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker finishes asking Kevin to pick up some stuff, when does Kevin begin to talk about the work being done to provide technology to young people?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1660.0,
        "end": 1676.0
      },
      "pred_interval": {
        "start": 174.0,
        "end": 175.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1486.0,
        "end": 1501.0,
        "average": 1493.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.5796164870262146,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation that Kevin speaks after the first speaker, but it omits the key factual timestamps (E1 ends at 1658.7s; E2 begins at 1660.0s and ends at 1676.0s) required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning digital inclusion, when does she begin discussing finances and support?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1787.8,
        "end": 1790.0
      },
      "pred_interval": {
        "start": 125.0,
        "end": 130.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1662.8,
        "end": 1660.0,
        "average": 1661.4
      },
      "rationale_metrics": {
        "rouge_l": 0.40740740740740733,
        "text_similarity": 0.5297812223434448,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives completely different timestamps (125.0s/126.0s vs correct 1787.5s/1787.8\u20131790.0s), so it is factually incorrect despite matching the 'immediately after' relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces the 'Key findings' section, when does she mention parents on low incomes being more concerned about money?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1815.4,
        "end": 1829.0
      },
      "pred_interval": {
        "start": 140.0,
        "end": 145.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1675.4,
        "end": 1684.0,
        "average": 1679.7
      },
      "rationale_metrics": {
        "rouge_l": 0.4705882352941177,
        "text_similarity": 0.4756939709186554,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps are completely incorrect (140.0s/141.0s versus 1814.4\u20131829.0s in the reference), omit the mention completion time, and do not match the correct temporal relation; thus it fails to align with the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that 'progress clearly being made' regarding digital inclusion, when does she mention that children on free meals are more likely to share devices?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1952.9,
        "end": 1958.5
      },
      "pred_interval": {
        "start": 205.0,
        "end": 206.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1747.9,
        "end": 1752.5,
        "average": 1750.2
      },
      "rationale_metrics": {
        "rouge_l": 0.32142857142857145,
        "text_similarity": 0.4474337697029114,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly captures the key relation that the comment about children on free meals sharing devices comes after the 'progress clearly being made' remark, preserving the original meaning without adding or contradicting details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces 'Free meal replacements', when does she discuss the importance of choice and dignity in food provision?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2003.8,
        "end": 2010.5
      },
      "pred_interval": {
        "start": 213.0,
        "end": 214.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1790.8,
        "end": 1796.5,
        "average": 1793.65
      },
      "rationale_metrics": {
        "rouge_l": 0.39999999999999997,
        "text_similarity": 0.6093510985374451,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (213.0s) directly contradicts the reference, which places the discussion after the 'Free meal replacements' introduction around 2003.8s; the prediction is incorrect and omits the correct relative timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the female speaker mentions \"cash first approaches\", when does the male speaker begin speaking?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2167.9,
        "end": 2172.6
      },
      "pred_interval": {
        "start": 2135.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.90000000000009,
        "end": 32.59999999999991,
        "average": 32.75
      },
      "rationale_metrics": {
        "rouge_l": 0.17241379310344826,
        "text_similarity": 0.4276331961154938,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted time (2135.0s) contradicts the reference: the male actually begins speaking later (around 2167.9s after the prior presenter finishes). The prediction places him inside the female's segment, omitting the correct later start, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker asks Angela Japp's question about creative approaches, when does Katie start her answer by mentioning 'the digital'?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.835,
        "end": 2259.242
      },
      "pred_interval": {
        "start": 2190.0,
        "end": 2195.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.835000000000036,
        "end": 64.24200000000019,
        "average": 55.03850000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.5547195672988892,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted start time (2190.0s) contradicts the reference (Katie actually begins saying 'the digital' at 2235.835s) and even precedes the referenced anchor segment; it also omits the end time and related context, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once Katie finishes discussing culturally valued aspects in schools, when does the male speaker thank her?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2297.355,
        "end": 2298.476
      },
      "pred_interval": {
        "start": 2260.0,
        "end": 2265.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.35500000000002,
        "end": 33.47600000000011,
        "average": 35.415500000000065
      },
      "rationale_metrics": {
        "rouge_l": 0.19354838709677416,
        "text_similarity": 0.5226657390594482,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives a completely incorrect timestamp (2260.0s) that contradicts the ground truth where the male speaker thanks Katie immediately after 2296.9s (starting at 2297.355s); it omits the correct timing and order."
      }
    },
    {
      "question_id": "001",
      "question": "After John asks whether initiatives like 'Big Noise' would impact music provision generally if targeted at deprived areas, when does Alistair start speaking?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2390.458,
        "end": 2391.922
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2315.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.45800000000008,
        "end": 76.92200000000003,
        "average": 78.69000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.6071669459342957,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives entirely different timestamps (2310.0s vs ~2398s/2390s) and incorrectly states Alistair speaks immediately after John, contradicting the correct timing and sequence; it omits key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After Alistair says that some programs are 'hugely expensive', when does he advise treating them with caution?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2406.7,
        "end": 2414.2
      },
      "pred_interval": {
        "start": 2345.0,
        "end": 2350.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.69999999999982,
        "end": 64.19999999999982,
        "average": 62.94999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298248,
        "text_similarity": 0.5663924217224121,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes he mentions expenses and then advises caution, but it gives an incorrect timestamp (2345.0s vs ~2393.7s) and an imprecise 'shortly after' instead of the actual caution interval (~2406.7\u20132414.2s) and related detail about multinational companies."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker states that recovery plans were produced by the Scottish and English governments, when does he explain what those recovery plans are about?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2499.117,
        "end": 2513.724
      },
      "pred_interval": {
        "start": 2536.0,
        "end": 2547.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.88299999999981,
        "end": 33.27599999999984,
        "average": 35.079499999999825
      },
      "rationale_metrics": {
        "rouge_l": 0.2716049382716049,
        "text_similarity": 0.5263177156448364,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (2536.0s) is outside the correct interval (2499.117\u20132513.724s) where the explanation occurs, so it is incorrect and not within the allowed tolerance."
      }
    },
    {
      "question_id": "002",
      "question": "After Sarah mentions that digital literacy for parents wasn't something they specifically looked at, when does she explain the challenges parents faced with remote learning?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2558.855,
        "end": 2578.0
      },
      "pred_interval": {
        "start": 2608.0,
        "end": 2619.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.14499999999998,
        "end": 41.0,
        "average": 45.07249999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.2925146520137787,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamp (2608.0s) falls well after the correct interval (starts 2558.855s, ends 2578.0s), so it does not match the referenced explanation and omits the specific interval/details about passing devices."
      }
    },
    {
      "question_id": "001",
      "question": "After the male host mentions a question from Katharine Reid, when does Sarah laugh?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.86,
        "end": 2741.43
      },
      "pred_interval": {
        "start": 2675.0,
        "end": 2680.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.86000000000013,
        "end": 61.429999999999836,
        "average": 63.64499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3404255319148936,
        "text_similarity": 0.6317525506019592,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (2675.0s) contradicts the correct timing (Sarah laughs at 2740.86\u20132741.43s after the host's mention at ~2726.96\u20132728.07s) and thus is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes saying 'Yes', when does she begin to explain how more money for families leads to better outcomes for children?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.15,
        "end": 2772.16
      },
      "pred_interval": {
        "start": 2700.0,
        "end": 2730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.15000000000009,
        "end": 42.159999999999854,
        "average": 43.15499999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.28070175438596495,
        "text_similarity": 0.512273907661438,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (2700.0\u20132730.0s) do not match the reference (2744.15\u20132772.16s) and occur before Sarah finishes saying 'Yes' (2741.43s), directly contradicting the 'once_finished' relation."
      }
    },
    {
      "question_id": "003",
      "question": "Once the male host mentions people working in rural areas, when does he ask Lindsay for her thoughts?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2828.315,
        "end": 2829.617
      },
      "pred_interval": {
        "start": 2790.0,
        "end": 2800.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.315000000000055,
        "end": 29.61700000000019,
        "average": 33.96600000000012
      },
      "rationale_metrics": {
        "rouge_l": 0.36,
        "text_similarity": 0.49130529165267944,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the event but gives a timestamp (2790.0s) that contradicts the correct timing (~2828.3\u20132829.6s) and omits the relation and interval details, so it is largely incorrect. "
      }
    },
    {
      "question_id": "001",
      "question": "After the woman states that all schools must be very mindful to poverty-proof themselves, when does she mention that teaching pedagogies and strategies should be transparent and inclusive?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2858.72,
        "end": 2868.63
      },
      "pred_interval": {
        "start": 2856.0,
        "end": 2874.0
      },
      "iou": 0.5505555555555728,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.7199999999998,
        "end": 5.369999999999891,
        "average": 4.044999999999845
      },
      "rationale_metrics": {
        "rouge_l": 0.03571428571428571,
        "text_similarity": 0.025961674749851227,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the event occurs after the anchor statement, but it omits the required temporal details (specific timestamps and that the target immediately follows the anchor), making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman suggests giving probationers and undergraduates more practical tools before they go into probation, when does she say that a lot can be learned from autism education?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2896.13,
        "end": 2901.89
      },
      "pred_interval": {
        "start": 2934.0,
        "end": 2946.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.86999999999989,
        "end": 44.11000000000013,
        "average": 40.99000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.12307692307692307,
        "text_similarity": 0.05410805344581604,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction fails to match the reference temporal annotation and timestamps and introduces an unrelated preceding topic (transparency and inclusivity) instead of the specified anchor; it only loosely relates by mentioning the suggestion but omits key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man reminds people about the PACT project launch, when does he describe it as a professional learning project funded by the Scottish Government?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2951.199,
        "end": 2960.769
      },
      "pred_interval": {
        "start": 2994.0,
        "end": 3006.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.80099999999993,
        "end": 45.23100000000022,
        "average": 44.016000000000076
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307691,
        "text_similarity": 0.029938094317913055,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence (he describes it after the reminder) but omits the crucial precise timing and segment details (E1/E2 timestamps and boundaries) provided in the reference, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the first speaker puts in an advert for John McKendrick, when does he praise the work of the Caledonian Club?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3049.4,
        "end": 3053.3
      },
      "pred_interval": {
        "start": 3125.0,
        "end": 3140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.59999999999991,
        "end": 86.69999999999982,
        "average": 81.14999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.3225806451612903,
        "text_similarity": 0.6439055800437927,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction names both events but the timestamps are substantially off (\u224878\u201390s later) and it fails to capture the correct immediate temporal relation (praise begins exactly when the advert finishes). These are major factual discrepancies."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first speaker finishes asking Mary a question, when does the second speaker (John) appear and begin to speak?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3079.0,
        "end": 3082.0
      },
      "pred_interval": {
        "start": 3160.0,
        "end": 3170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.0,
        "end": 88.0,
        "average": 84.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3508771929824561,
        "text_similarity": 0.6469443440437317,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that John speaks after the first speaker, but the reported timestamp (3160.0s) is far from the correct 3079.0s and it omits the completion time (3082.0s), so it is factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After Mary finishes discussing how to best support students, when does John appear on screen and comment on her questions?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3152.3,
        "end": 3159.5
      },
      "pred_interval": {
        "start": 3200.0,
        "end": 3210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.69999999999982,
        "end": 50.5,
        "average": 49.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.5216937065124512,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states John appears after Mary but gives an incorrect timestamp (3200.0s vs the correct 3152.3s) and omits the end time (3159.5s), so it fails on key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the first speaker asks if something happened and how it is going, when does he state that he will put the question to the Glasgow team first?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3213.51,
        "end": 3214.09
      },
      "pred_interval": {
        "start": 3245.0,
        "end": 3265.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.48999999999978,
        "end": 50.909999999999854,
        "average": 41.19999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.09375000000000001,
        "text_similarity": 0.2593117952346802,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies two events but gives timestamps that are far off (3245s/3265s vs. ~3213s/3214s) and omits the direct 'once_finished' relation; therefore it is largely incorrect though it preserves the general order. "
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker with the beard begins speaking, when does he mention the rollout of 50,000 plus iPads?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3232.12,
        "end": 3237.0
      },
      "pred_interval": {
        "start": 3375.0,
        "end": 3395.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 142.8800000000001,
        "end": 158.0,
        "average": 150.44000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.10169491525423728,
        "text_similarity": 0.13704146444797516,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the relative order (the mention occurs after the speaker starts) but the provided timestamps are far from the ground-truth intervals (off by ~159s), so the answer is largely incorrect on the key factual element (timing)."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman states that getting information out to all families about support is available, when does she finish her statement that this is really critical?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3390.0,
        "end": 3482.1099999999997
      },
      "gt_interval": {
        "start": 3396.5,
        "end": 3398.0
      },
      "pred_interval": {
        "start": 3475.2,
        "end": 3476.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.69999999999982,
        "end": 78.19999999999982,
        "average": 78.44999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.4886809289455414,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamp (3475.2s) is substantially different from the correct finish time (3396.5s/3398.0s), so it fails to identify the correct moment; therefore the answer is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the man states that the presenters were exemplary in their timekeeping, when does he continue to say he will be exemplary in his timekeeping?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3390.0,
        "end": 3482.1099999999997
      },
      "gt_interval": {
        "start": 3427.0,
        "end": 3431.0
      },
      "pred_interval": {
        "start": 3480.1,
        "end": 3481.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.09999999999991,
        "end": 50.09999999999991,
        "average": 51.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.11940298507462685,
        "text_similarity": 0.5384615063667297,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly implies the man's remark follows the presenters' comment, but it gives an incorrect timestamp (3480.1s vs correct ~3423.7s/3427.0s) and omits the accurate start/end times, so it is largely inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks to virtually clap, when does he physically clap his hands?",
      "video_id": "pO8HTf-ntyc",
      "video_number": "017",
      "segment": {
        "start": 3390.0,
        "end": 3482.1099999999997
      },
      "gt_interval": {
        "start": 3476.0,
        "end": 3478.0
      },
      "pred_interval": {
        "start": 3481.1,
        "end": 3482.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.099999999999909,
        "end": 4.099999999999909,
        "average": 4.599999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.2553191489361702,
        "text_similarity": 0.5138217210769653,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the clap happens after the request but gives an incorrect/ambiguous timestamp (3481.1s) that does not match the reference clap time (3476\u20133478s) and omits the detailed start/end times from the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the 'Strategic Priority 3' slide is displayed, when does the speaker mention the Alliance's 2021 to 2025 strategy?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.0,
        "end": 27.7
      },
      "pred_interval": {
        "start": 16.0,
        "end": 17.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 10.7,
        "average": 8.35
      },
      "rationale_metrics": {
        "rouge_l": 0.3137254901960784,
        "text_similarity": 0.43489426374435425,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the speaker's mention occurs during the slide display but omits the key factual details (the specific timestamps for the slide and the speaker's mention) provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the NFDHR logo and name are fully displayed, when does the text indicating its establishment appear?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 165.0,
        "end": 168.0
      },
      "pred_interval": {
        "start": 152.0,
        "end": 153.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.0,
        "end": 15.0,
        "average": 14.0
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306123,
        "text_similarity": 0.682594895362854,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the establishment text appears after the logo and name, but it omits the specific timing details (start and fully-visible timestamps) given in the reference, so key factual elements are missing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the statistics for Education, Food Security, and Health & Nutrition programs are fully displayed, when do the statistics for WASH, Peace Building, Protection & Gender, and Shelter & CCCM programs appear?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 211.0
      },
      "pred_interval": {
        "start": 164.0,
        "end": 165.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.0,
        "end": 46.0,
        "average": 44.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1388888888888889,
        "text_similarity": 0.27739664912223816,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly conveys the sequential relation (they appear right after the first set finishes) but omits the specific timing details (E1: 196.0\u2013200.0s and E2: 207.0\u2013211.0) given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the main descriptive text for the 'Education Overview 2022' slide, when do the icons and numerical statistics appear?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 237.0,
        "end": 243.0
      },
      "pred_interval": {
        "start": 170.0,
        "end": 171.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.0,
        "end": 72.0,
        "average": 69.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2647058823529412,
        "text_similarity": 0.6005440950393677,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction contradicts the ground truth by claiming the icons appear simultaneously with the main text; the correct answer specifies the text is fully displayed by 226.0s and the icons/numbers appear later (start 237.0s, fully by 243.0s), so the temporal relation is misrepresented."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes explaining that the Syrian crisis created a fragmented society unable to benefit from its expertise, when does she mention that they started working together from 2018?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 351.3,
        "end": 364.9
      },
      "pred_interval": {
        "start": 395.0,
        "end": 400.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.69999999999999,
        "end": 35.10000000000002,
        "average": 39.400000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.17391304347826086,
        "text_similarity": 0.22145798802375793,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that she states they began working together from 2018 and that this occurs after explaining the fragmented society, but it omits the precise timestamps/temporal details given in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that 2 million Syrian children are out of education and tens of thousands are in North Syrian camps, when does she begin to list the specific numbers of camps and schools?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 418.5,
        "end": 427.8
      },
      "pred_interval": {
        "start": 400.0,
        "end": 405.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.5,
        "end": 22.80000000000001,
        "average": 20.650000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.4715772271156311,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer merely restates the prompt and provides no timestamps; it fails to give the specific start time (418.5s), finish time (427.8s), or the prior finish time (418.0s) provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that IRC has invested a lot in research and social and emotional learning, when does she explain how these learnings can be used for out-of-school and in-school children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.0,
        "end": 568.9
      },
      "pred_interval": {
        "start": 510.0,
        "end": 520.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.0,
        "end": 48.89999999999998,
        "average": 44.94999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2926829268292683,
        "text_similarity": 0.4543420076370239,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction locates both events but the timestamps are substantially incorrect (about 30\u201340s earlier) and it fails to capture the full explanation interval or end time, so it does not match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces the PRIEST project as one of IRC's flagship programs, when does she state the countries where it is implemented?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.9,
        "end": 627.597
      },
      "pred_interval": {
        "start": 520.0,
        "end": 530.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 102.89999999999998,
        "end": 97.59699999999998,
        "average": 100.24849999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2903225806451613,
        "text_similarity": 0.5470943450927734,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted times are substantially incorrect: it places the anchor at 520.0s and target at 530.0s, while the ground truth anchor ends at 622.0s and the target starts at 622.9s, so the prediction fails to match the correct timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker introduces Ahlam Ahmed as the Education Programme Manager, when does Ahlam Ahmed greet the speaker?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 777.178,
        "end": 778.34
      },
      "pred_interval": {
        "start": 715.0,
        "end": 716.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.178,
        "end": 62.34000000000003,
        "average": 62.259000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.4797852337360382,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives the wrong timestamp (715.0s vs ~777.178s) and wrongly says Ahlam introduced herself, whereas the speaker introduced Ahlam and she greeted immediately after that. Only the notion of immediacy matches. "
      }
    },
    {
      "question_id": "003",
      "question": "After Ahlam Ahmed asks for the next slide, when does the slide visually change to 'Session Objectives'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 867.576,
        "end": 869.038
      },
      "pred_interval": {
        "start": 718.0,
        "end": 719.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 149.57600000000002,
        "end": 150.038,
        "average": 149.80700000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7068265676498413,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the slide follows Ahlam's request (relative order) but gives a wrong absolute time (718.0s vs ~867.6s) and thus provides incorrect/fabricated timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker asks to move to the next slide, when does the slide visually change?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 962.9,
        "end": 963.4
      },
      "pred_interval": {
        "start": 915.0,
        "end": 916.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.89999999999998,
        "end": 47.39999999999998,
        "average": 47.64999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.26086956521739135,
        "text_similarity": 0.4828892648220062,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that the slide changes immediately after the request, but it omits the precise timing details (961.2s, 962.9s, 963.4s) and the note about transition completion, which are significant facts in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states the project's duration and donor, when does she mention the number of targeted children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1031.1,
        "end": 1039.3
      },
      "pred_interval": {
        "start": 945.0,
        "end": 946.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 86.09999999999991,
        "end": 93.29999999999995,
        "average": 89.69999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.12765957446808512,
        "text_similarity": 0.15132273733615875,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly states that the mention follows immediately after the project's duration and donor (semantic relation preserved), but it omits the specific timestamps/absolute timing details provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions 'with ALP classrooms', when does she begin to introduce 'the second activity or the second intervention'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1104.5,
        "end": 1109.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1052.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.5,
        "end": 57.5,
        "average": 56.0
      },
      "rationale_metrics": {
        "rouge_l": 0.13043478260869565,
        "text_similarity": 0.24674130976200104,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction's timestamps contradict the ground truth: it places both events earlier (1050.0s and 1052.0s) instead of the anchor ending at 1054.5s and the target starting at 1104.5s, so it fails to capture the correct timing and 'after' relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes talking about 'on the safe school protocols', when does she describe how 'Temporary learning spaces will also be provided with wash facilities and essential cleaning hygiene materials'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1138.5,
        "end": 1148.0
      },
      "pred_interval": {
        "start": 1052.0,
        "end": 1054.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 86.5,
        "end": 94.0,
        "average": 90.25
      },
      "rationale_metrics": {
        "rouge_l": 0.14545454545454548,
        "text_similarity": 0.3495088815689087,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives an incorrect timestamp (1052.0s) that is earlier than the anchor end (1102.5s) and thus contradicts the correct target timing (starts 1138.5s, ends 1148.0s); it omits the correct start/end times and relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions community sensitization, when does she describe the creation of a community-based support system for children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1246.823,
        "end": 1274.838
      },
      "pred_interval": {
        "start": 1350.0,
        "end": 1360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 103.17699999999991,
        "end": 85.16200000000003,
        "average": 94.16949999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2711864406779661,
        "text_similarity": 0.3337199091911316,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (1350.0s) is far outside the correct target interval (1246.823\u20131274.838s) and lacks start/end bounds, so it does not match the reference description."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning integration into the formal learning system, when does she state the overall objective of the program?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1339.066,
        "end": 1350.221
      },
      "pred_interval": {
        "start": 1400.0,
        "end": 1410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 60.93399999999997,
        "end": 59.778999999999996,
        "average": 60.35649999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.07017543859649122,
        "text_similarity": 0.3870590329170227,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a single time of 1400.0s which does not match the annotated target window (1339.066\u20131350.221s) and thus is temporally incorrect and omits the detail that the objective immediately follows the anchor and clarifies integration."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing school referrals and observation capacity, when does she mention that guidelines for pathways and referral will be revised?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1389.248,
        "end": 1400.984
      },
      "pred_interval": {
        "start": 1420.0,
        "end": 1430.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.751999999999953,
        "end": 29.016000000000076,
        "average": 29.884000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.09090909090909091,
        "text_similarity": 0.5012911558151245,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction names the correct topic but gives a timestamp (1420.0s) that does not match the reference interval (starts at 1389.248s and ends at 1400.984s), so the timing is incorrect by ~19\u201331 seconds."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker finishes mentioning case management and referral pathways, when does she start listing additional skills training in the capacity building package?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1471.0,
        "end": 1480.5
      },
      "pred_interval": {
        "start": 1415.0,
        "end": 1420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.0,
        "end": 60.5,
        "average": 58.25
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.41623854637145996,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the event occurs after the anchor, but it omits the key factual details (the specific start/end timestamps and exact timing relative to 1470.8s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the first speaker finishes confirming the handover to the next presenter, when does the second speaker begin introducing Sundas?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.0,
        "end": 1574.5
      },
      "pred_interval": {
        "start": 1615.0,
        "end": 1620.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 92.0,
        "end": 45.5,
        "average": 68.75
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923078,
        "text_similarity": 0.6055635809898376,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the second speaker begins after the handover, but it omits the key temporal details (start at 1523.0s, end at 1574.5s) and fails to provide the required absolute-to-relative timing information, making it overly vague."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker says \"Yeah, next slide, please\" for the first time, when does the green box with the English text for the \"Commitment indicator\" appear on screen?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1634.9,
        "end": 1720.9
      },
      "pred_interval": {
        "start": 165.0,
        "end": 165.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1469.9,
        "end": 1555.9,
        "average": 1512.9
      },
      "rationale_metrics": {
        "rouge_l": 0.275,
        "text_similarity": 0.6851203441619873,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction claims the box appears exactly when the speaker says the phrase, but the reference specifies it appears later at 1634.9s (several seconds after the utterance), so the timing relation is incorrectly stated."
      }
    },
    {
      "question_id": "001",
      "question": "Once the male speaker finishes asking to move to the next slide, when does the slide actually change?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1785.53,
        "end": 1785.6
      },
      "pred_interval": {
        "start": 177.0,
        "end": 178.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1608.53,
        "end": 1607.6,
        "average": 1608.065
      },
      "rationale_metrics": {
        "rouge_l": 0.20833333333333331,
        "text_similarity": 0.5694858431816101,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the slide changes after the speaker finishes, but incorrectly claims it happens immediately; the ground truth shows a noticeable ~3.2s delay (1782.3s \u2192 1785.53s), so the timing is wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the child's achievement in the first case study, when does she ask for the next slide?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1909.926,
        "end": 1911.04
      },
      "pred_interval": {
        "start": 195.0,
        "end": 196.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1714.926,
        "end": 1715.04,
        "average": 1714.983
      },
      "rationale_metrics": {
        "rouge_l": 0.19999999999999998,
        "text_similarity": 0.58336341381073,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (she asks for the next slide immediately after finishing), but it omits the precise timestamps and event boundaries given in the correct answer, which are key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks for the next slide, when does the slide transition to the domestic violence case study?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1915.72,
        "end": 1921.8
      },
      "pred_interval": {
        "start": 196.0,
        "end": 197.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1719.72,
        "end": 1724.8,
        "average": 1722.26
      },
      "rationale_metrics": {
        "rouge_l": 0.2641509433962264,
        "text_similarity": 0.6116986870765686,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the slide changes right after the speaker's request) but omits the precise start and end timestamps and the explicit start/completion timing details given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes her detailed explanation of how they help children facing domestic violence, when does she say 'Next slide'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2003.389,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 209.0,
        "end": 209.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1794.389,
        "end": 1795.0,
        "average": 1794.6945
      },
      "rationale_metrics": {
        "rouge_l": 0.2439024390243903,
        "text_similarity": 0.4696986973285675,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (209.0s) is vastly different from the reference interval (2003.389\u20132004.0s) when the speaker says 'Next slide', so it is incorrect and does not match the relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the Arabic speaker (Sundus) finishes her conclusion about the link between protection and education, when does the English speaker thank her?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2072.045,
        "end": 2076.5
      },
      "pred_interval": {
        "start": 215.0,
        "end": 215.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1857.045,
        "end": 1861.5,
        "average": 1859.2725
      },
      "rationale_metrics": {
        "rouge_l": 0.21621621621621623,
        "text_similarity": 0.5163305997848511,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (215.0s) is completely inconsistent with the reference (around 2072.0\u20132076.5s) and omits the correct thanking interval and mention of Sahar, so it is factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the PEACE project as a multi-country project in Nigeria, Cameroon, and Niger, when does he specify the states in Nigeria where it is implemented?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2211.28,
        "end": 2223.708
      },
      "pred_interval": {
        "start": 2135.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.2800000000002,
        "end": 83.70800000000008,
        "average": 79.99400000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.24137931034482757,
        "text_similarity": 0.5534683465957642,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the specification occurs after the project introduction, but it omits key factual details\u2014no mention of the specific Nigerian states (Borno, Adamawa, Yobe) or the timing\u2014so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker states that the project has three main results, when does he begin describing the first result, 'Access'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2250.478,
        "end": 2262.09
      },
      "pred_interval": {
        "start": 2160.0,
        "end": 2165.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.47800000000007,
        "end": 97.09000000000015,
        "average": 93.7840000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.27118644067796616,
        "text_similarity": 0.6384111046791077,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the general relation that the description of 'Access' follows the statement, but it omits the precise timing and timestamps and implies immediate simultaneity rather than the specific start time (2250.478s) given in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the 'Accelerated Learning Program' for children who are out of school, when does he specify the age range of these children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2337.405,
        "end": 2348.025
      },
      "pred_interval": {
        "start": 2180.0,
        "end": 2185.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 157.4050000000002,
        "end": 163.0250000000001,
        "average": 160.21500000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.7912276983261108,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the age range is given after the program description (matches the temporal relation), but it omits the key factual detail of the specific ages (9 to 14) and the timing/timestamps provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker transitions to discussing Result 2, when does he mention 'Parenting Sessions'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.824,
        "end": 2369.824
      },
      "pred_interval": {
        "start": 2435.0,
        "end": 2440.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.17599999999993,
        "end": 70.17599999999993,
        "average": 68.17599999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.10526315789473684,
        "text_similarity": 0.1983066201210022,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the relative relation that 'Parenting Sessions' is mentioned after Result 2, but it omits the key factual details (exact anchor/target timestamps and explicit anchor/target framing) given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"Next slide,\" when does he begin asking about integrating child protection and education activities?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2755.7,
        "end": 2766.6
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2880.0
      },
      "iou": 0.051904761904762335,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 85.69999999999982,
        "end": 113.40000000000009,
        "average": 99.54999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.24000000000000002,
        "text_similarity": 0.5239329934120178,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the question occurs after 'Next slide' but gives a wrong timestamp (2670.0s vs ~2753s) and omits the actual start/end times and relation, so it is factually incomplete and inconsistent with the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker (Kunja) finishes explaining that child protection activities require more funding, when does Amanda thank him?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2899.8,
        "end": 2900.8
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 2854.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.80000000000018,
        "end": 46.80000000000018,
        "average": 48.30000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5048620700836182,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates Amanda thanks Kunja afterward, but it gives a significantly incorrect timestamp for when Kunja finishes (2850.0s vs the correct 2897.4s) and vague timing ('immediately after') rather than the actual start at 2899.8s."
      }
    },
    {
      "question_id": "002",
      "question": "Once Amanda finishes introducing Mike and hands over to him, when does Mike thank Amanda?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2938.9,
        "end": 2940.5
      },
      "pred_interval": {
        "start": 2936.0,
        "end": 2940.0
      },
      "iou": 0.24444444444442423,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.900000000000091,
        "end": 0.5,
        "average": 1.7000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962265,
        "text_similarity": 0.5708905458450317,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly states the thank-you occurs at 2936.0s (the handover end) whereas the correct answer places it at 2938.9\u20132940.5s; it gets the general order but the timing is wrong and omits the correct interval."
      }
    },
    {
      "question_id": "001",
      "question": "While the male speaker introduces the first question about project findings, when does he ask the panelists to be brief?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3039.0,
        "end": 3046.5
      },
      "pred_interval": {
        "start": 3035.0,
        "end": 3040.0
      },
      "iou": 0.08695652173913043,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 6.5,
        "average": 5.25
      },
      "rationale_metrics": {
        "rouge_l": 0.10714285714285714,
        "text_similarity": 0.30313318967819214,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted time (3035.0s) is outside the correct target interval (3039.0\u20133046.5s); although it falls within the broader introductory segment, it does not match the specified event timing."
      }
    },
    {
      "question_id": "002",
      "question": "After the male speaker thanks Ahlam for her input, when does he introduce Sundus?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3153.0,
        "end": 3159.0
      },
      "pred_interval": {
        "start": 3160.0,
        "end": 3170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 11.0,
        "average": 9.0
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981131,
        "text_similarity": 0.5162191987037659,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes he thanks Ahlam before introducing Sundus but gives a single time (3160.0s) that does not match the reference interval (starts at 3153.0s, ends 3159.0s) and omits the anchor timing and the additional remark\u2014thus the timing is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After Sundus finishes speaking in Arabic, when does Paul ask 'Can you say that again?'",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3234.7,
        "end": 3235.7
      },
      "pred_interval": {
        "start": 3200.0,
        "end": 3205.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.69999999999982,
        "end": 30.699999999999818,
        "average": 32.69999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.3724161386489868,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the event occurs after Sundus speaks but gives a wrong timestamp (3200.0s vs ~3234.7\u20133235.7s) and omits the key detail that there is an intervening introduction by the male speaker, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After Sundus finishes speaking, when does Mike thank her for her input?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3217.7,
        "end": 3221.9
      },
      "pred_interval": {
        "start": 3420.0,
        "end": 3420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 202.30000000000018,
        "end": 198.0999999999999,
        "average": 200.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.33454635739326477,
        "llm_judge_score": 0,
        "llm_judge_justification": "Completely incorrect: the prediction claims the video ends with no further dialogue, which contradicts the correct answer that Mike thanks Sundus after her line (with specific timestamps), and it omits this key event."
      }
    },
    {
      "question_id": "002",
      "question": "After Mike asks Paul to share a main finding from his project, when does Paul ask Mike to repeat the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3234.3,
        "end": 3235.5
      },
      "pred_interval": {
        "start": 3420.0,
        "end": 3420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 185.69999999999982,
        "end": 184.5,
        "average": 185.0999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306123,
        "text_similarity": 0.3397979140281677,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts and omits the ground-truth events: Paul does ask to repeat after Mike (E2 at 3234.3\u20133235.5s following E1 at 3224.6\u20133232.0s), whereas the prediction falsely claims no further dialogue and is irrelevant to the question."
      }
    },
    {
      "question_id": "003",
      "question": "Once Paul finishes explaining how the integrated approach helps children, when does Mike thank him for his insights?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3306.5,
        "end": 3307.4
      },
      "pred_interval": {
        "start": 3420.0,
        "end": 3420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 113.5,
        "end": 112.59999999999991,
        "average": 113.04999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.11538461538461539,
        "text_similarity": 0.34032368659973145,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and contradicts the reference: it claims no further dialogue while the correct answer specifies Paul finishes at 3304.8s and Mike thanks him at 3306.5\u20133307.4s (temporal relation 'once_finished')."
      }
    },
    {
      "question_id": "001",
      "question": "After Ahlam states that the first lesson involves integrating child protection with educational activities, when does she explain how child protection creates a safe environment for children?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3626.1,
        "end": 3634.8
      },
      "pred_interval": {
        "start": 3625.0,
        "end": 3645.0
      },
      "iou": 0.43500000000001365,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.099999999999909,
        "end": 10.199999999999818,
        "average": 5.649999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.33802816901408445,
        "text_similarity": 0.5255399942398071,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence (she states the lesson then explains), but it omits the crucial timing details (the specific start/end timestamps and the explicit 'after' relation) required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once Ahlam finishes speaking and says 'Thanks Mike. Over to you.', when does the host thank Ahlam for her insights?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3679.3,
        "end": 3687.5
      },
      "pred_interval": {
        "start": 3705.0,
        "end": 3715.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.699999999999818,
        "end": 27.5,
        "average": 26.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.4048811197280884,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the basic relation (the host thanks Ahlam after she finishes) but omits all required timing details and the specified relation labeling, so it is incomplete for the task."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks Sundus about the lessons learned from the monitoring system in Northern Syria, when does Sundus provide her initial lessons learned?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3570.0,
        "end": 3780.0
      },
      "gt_interval": {
        "start": 3704.2,
        "end": 3724.0
      },
      "pred_interval": {
        "start": 3735.0,
        "end": 3745.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.800000000000182,
        "end": 21.0,
        "average": 25.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.18918918918918917,
        "text_similarity": 0.3676905930042267,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that Sundus speaks after the host (captures the relation) but omits the key factual elements\u2014the precise start/end timestamps and duration details\u2014given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sundus finishes asking Mike to repeat the question, when does Mike start repeating the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3785.8,
        "end": 3796.2
      },
      "pred_interval": {
        "start": 3756.0,
        "end": 3762.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.800000000000182,
        "end": 34.19999999999982,
        "average": 32.0
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333334,
        "text_similarity": 0.6263223886489868,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are substantially different from the reference (off by ~24\u201330s) and omit the correct Mike start time and repetition end; it thus fails to match the factual timing in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After Sundus finishes providing her answer, when does Mike thank her for her input?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3851.7,
        "end": 3853.6
      },
      "pred_interval": {
        "start": 3849.0,
        "end": 3852.0
      },
      "iou": 0.06521739130438865,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.699999999999818,
        "end": 1.599999999999909,
        "average": 2.1499999999998636
      },
      "rationale_metrics": {
        "rouge_l": 0.17777777777777776,
        "text_similarity": 0.580412745475769,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that Mike thanks Sundus after her answer, but it gives an incorrect timestamp (3849.0s) that contradicts the reference times (Sundus finishes at 3850.4s; Mike begins at 3851.7s), so the timing is factually wrong and incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After Mike says he will ask Ahlam the same question, when does Ahlam ask for clarification on the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3750.0,
        "end": 3960.0
      },
      "gt_interval": {
        "start": 3864.0,
        "end": 3872.7
      },
      "pred_interval": {
        "start": 3860.0,
        "end": 3863.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 9.699999999999818,
        "average": 6.849999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.4210526315789474,
        "text_similarity": 0.6887872219085693,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction preserves the ordering (Ahlam asks after Mike) and is close in time, but it misstates Mike's and Ahlam's timestamps slightly and omits the completion time (3872.7s), so some key temporal details are missing."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman in the bottom left finishes explaining how all staff were working together, when does the male host in the top left thank Ahlam?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3937.666,
        "end": 3939.047
      },
      "pred_interval": {
        "start": 3952.0,
        "end": 3954.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.333999999999833,
        "end": 14.952999999999975,
        "average": 14.643499999999904
      },
      "rationale_metrics": {
        "rouge_l": 0.17857142857142858,
        "text_similarity": 0.42897915840148926,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the male host thanks Ahlam after the woman finishes, matching the relative order, but it omits the specific timestamp details and exact start/end times provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male host finishes asking what type of evidence ECHO asked for, when does the female speaker (Sarah) in the top middle-right start to respond?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 3981.063,
        "end": 3984.022
      },
      "pred_interval": {
        "start": 4006.0,
        "end": 4008.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.936999999999898,
        "end": 23.978000000000065,
        "average": 24.457499999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424243,
        "text_similarity": 0.5609084367752075,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (4006.0\u20134008.0s) contradict the reference (3981.063\u20133984.022s) by ~25s and thus are factually incorrect; it fails to reflect that the response starts immediately after the anchor's question."
      }
    },
    {
      "question_id": "003",
      "question": "Once Paul finishes explaining how learning is put into action and fits into different contexts, when does he say 'Thank you'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 3930.0,
        "end": 4140.0
      },
      "gt_interval": {
        "start": 4068.612,
        "end": 4069.152
      },
      "pred_interval": {
        "start": 4070.0,
        "end": 4072.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.38799999999992,
        "end": 2.8479999999999563,
        "average": 2.117999999999938
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.5935723781585693,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction is in the right general region but the timestamps are several seconds late and too long: predicted start 4070.0s is 1.388s after the true start (4068.612s) and predicted end 4072.0s is 2.848s after the true end (4069.152s), contradicting that the utterance occurs immediately after the anchor."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host says \"go ahead Paul, sorry\", when does Paul begin his response?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4123.162,
        "end": 4123.743
      },
      "pred_interval": {
        "start": 4115.0,
        "end": 4120.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.162000000000262,
        "end": 3.743000000000393,
        "average": 5.952500000000327
      },
      "rationale_metrics": {
        "rouge_l": 0.10169491525423728,
        "text_similarity": 0.47538018226623535,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives an incorrect anchor timestamp (4115.0s vs 4121.743s) and omits the precise start time for Paul, only vaguely stating 'immediately after'; it thus fails to match key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "Once Paul finishes his feedback and says \"Thank you\", when does the host respond?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4179.089,
        "end": 4183.52
      },
      "pred_interval": {
        "start": 4130.0,
        "end": 4135.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.08899999999994,
        "end": 48.52000000000044,
        "average": 48.80450000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.21818181818181817,
        "text_similarity": 0.52308189868927,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the host responds immediately, but it gives an incorrect timestamp for when Paul says 'Thank you' (4130.0s vs ~4186.96s) and omits the host's actual timing details, so key factual timing information is wrong or missing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the host explicitly says \"So thank you for that\" to Kunja, when does she transition to Lynn's question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4110.0,
        "end": 4320.0
      },
      "gt_interval": {
        "start": 4298.586,
        "end": 4300.0
      },
      "pred_interval": {
        "start": 4140.0,
        "end": 4145.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 158.58600000000024,
        "end": 155.0,
        "average": 156.79300000000012
      },
      "rationale_metrics": {
        "rouge_l": 0.1842105263157895,
        "text_similarity": 0.40708544850349426,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly timestamps the thank-you at 4140.0s, which contradicts the correct ~4295s anchor and ~4298.6s target, and it omits the quoted transition phrase and precise timing; it only vaguely notes a short delay, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker thanks the previous participant, when does he introduce a question from Lynn?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4296.586,
        "end": 4299.158
      },
      "pred_interval": {
        "start": 4325.0,
        "end": 4330.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.41399999999976,
        "end": 30.841999999999643,
        "average": 29.6279999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2325581395348837,
        "text_similarity": 0.42002978920936584,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the introduction occurs after the thanks, but the reported time (4325.0s) is significantly different from the correct interval (starts 4296.586s, ends 4299.158s) and omits the end time, so it is factually inaccurate and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes reading Lynn's question, when does he ask Sundus for her opinion?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4324.216,
        "end": 4328.945
      },
      "pred_interval": {
        "start": 4360.0,
        "end": 4370.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.78399999999965,
        "end": 41.05500000000029,
        "average": 38.41949999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428564,
        "text_similarity": 0.43848317861557007,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the question occurs after Lynn's reading, but the timestamp (4360.0s) is far outside the correct interval (starts 4324.216s, ends 4328.945s), so the timing is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After Sundus finishes stating that violence is not the only challenge, when does the speaker confirm that she answered part of the question?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4290.0,
        "end": 4500.0
      },
      "gt_interval": {
        "start": 4415.375,
        "end": 4425.293
      },
      "pred_interval": {
        "start": 4380.0,
        "end": 4390.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.375,
        "end": 35.292999999999665,
        "average": 35.33399999999983
      },
      "rationale_metrics": {
        "rouge_l": 0.19230769230769232,
        "text_similarity": 0.36639589071273804,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the correct temporal relation (confirmation occurs after Sundus's statement) but the provided timestamps are substantially inaccurate compared to the ground truth and it omits the correct segment range and exact timings."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host asks if the panelist agrees with his statement, when does Ahlam reply with 'Yes, yes, Mike'?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4470.0,
        "end": 4680.0
      },
      "gt_interval": {
        "start": 4479.36,
        "end": 4480.3
      },
      "pred_interval": {
        "start": 4562.0,
        "end": 4563.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 82.64000000000033,
        "end": 82.69999999999982,
        "average": 82.67000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.5613470673561096,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the ordering (Ahlam replies after the host), but the absolute timestamps are substantially incorrect (~83\u201384s off) and the prediction omits the reply's end time, so it fails to match key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After the host finishes asking who would like to answer the question, when does Paul Bagambe begin to speak?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4707.194,
        "end": 4709.296
      },
      "pred_interval": {
        "start": 4725.0,
        "end": 4730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.805999999999585,
        "end": 20.703999999999724,
        "average": 19.254999999999654
      },
      "rationale_metrics": {
        "rouge_l": 0.27999999999999997,
        "text_similarity": 0.40527641773223877,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives an incorrect absolute timestamp for the host (4725.0s vs. 4705.662s) and wrongly states Paul speaks 'immediately after' whereas the reference shows Paul begins ~1.5s after the host finishes (4707.194s); key timing details are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Paul Bagambe mentions 'praise singers', when does he elaborate on what they do?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4717.127,
        "end": 4732.251
      },
      "pred_interval": {
        "start": 4730.0,
        "end": 4740.0
      },
      "iou": 0.09841297599791211,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.872999999999593,
        "end": 7.748999999999796,
        "average": 10.310999999999694
      },
      "rationale_metrics": {
        "rouge_l": 0.20338983050847456,
        "text_similarity": 0.6109463572502136,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that elaboration follows the mention, but it gives an incorrect timestamp for the mention (4730.0s) that contradicts the reference intervals and omits the precise timings, so it is factually inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the host thanks Paul, when does Sindus (woman in bottom-left video) start speaking?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4650.0,
        "end": 4860.0
      },
      "gt_interval": {
        "start": 4827.512,
        "end": 4830.216
      },
      "pred_interval": {
        "start": 4820.0,
        "end": 4825.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.511999999999716,
        "end": 5.216000000000349,
        "average": 6.364000000000033
      },
      "rationale_metrics": {
        "rouge_l": 0.3404255319148936,
        "text_similarity": 0.60199373960495,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the order right (Sindus speaks after the host) but gives the wrong absolute time for the host (4820.0s vs ~4808s) and wrongly claims Sindus starts \"right after\" when she actually begins ~19 seconds later (4827.5s), so the timing details are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker (Sundus) finishes her concluding remarks in Arabic, when does the moderator thank her and explain the fast wrap-up session?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4897.7,
        "end": 4916.5
      },
      "pred_interval": {
        "start": 4830.0,
        "end": 4835.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.69999999999982,
        "end": 81.5,
        "average": 74.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.3626044988632202,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (the moderator thanks Sundus after she finishes) but omits crucial details from the reference\u2014no timestamps and no mention that the moderator introduces the fast wrap-up\u2014so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During Sarah's key message, when does she mention strengthening the existing system and training teachers?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 4830.0,
        "end": 5040.0
      },
      "gt_interval": {
        "start": 4936.0,
        "end": 4942.9
      },
      "pred_interval": {
        "start": 4960.0,
        "end": 4970.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.0,
        "end": 27.100000000000364,
        "average": 25.550000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.29629629629629634,
        "text_similarity": 0.5344685912132263,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the relation that the mention occurs during Sarah's key message, but it omits the precise timestamps and duration details given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the host asks Sundus for her key takeaway message, when does Sundus begin speaking in Arabic?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5010.0,
        "end": 5220.0
      },
      "gt_interval": {
        "start": 4985.7,
        "end": 5026.77
      },
      "pred_interval": {
        "start": 5070.0,
        "end": 5072.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 84.30000000000018,
        "end": 45.22999999999956,
        "average": 64.76499999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.2909090909090909,
        "text_similarity": 0.5199381113052368,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly timestamps the host question (5010.0s vs. ~4975\u20134979s) and falsely claims Sundus begins speaking immediately, whereas she actually starts at 4985.7s (several seconds later). It only captures the general 'after' relation but gets key timing details wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the host thanks Paul, when does Amanda, the next speaker, start speaking?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5190.0,
        "end": 5356.2699999999995
      },
      "gt_interval": {
        "start": 5251.699,
        "end": 5254.524
      },
      "pred_interval": {
        "start": 5236.0,
        "end": 5240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.698999999999614,
        "end": 14.524000000000342,
        "average": 15.111499999999978
      },
      "rationale_metrics": {
        "rouge_l": 0.30000000000000004,
        "text_similarity": 0.5150124430656433,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the reference: Amanda does not start immediately after the host (host ends at 5206.342s and Amanda begins at 5251.699s, ~45s later), so the answer is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Amanda says 'Over to you, David', when does David start speaking?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5190.0,
        "end": 5356.2699999999995
      },
      "gt_interval": {
        "start": 5287.087,
        "end": 5288.53
      },
      "pred_interval": {
        "start": 5240.0,
        "end": 5244.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.087000000000444,
        "end": 44.529999999999745,
        "average": 45.808500000000095
      },
      "rationale_metrics": {
        "rouge_l": 0.17777777777777776,
        "text_similarity": 0.48646649718284607,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that David speaks immediately after Amanda, matching the core timing, but it omits the precise start/end timestamps and exact timing detail provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After David finishes explaining about the feedback form, when does he start giving instructions about the FILO page and WELO coffee lounge?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 5190.0,
        "end": 5356.2699999999995
      },
      "gt_interval": {
        "start": 5309.965,
        "end": 5315.734
      },
      "pred_interval": {
        "start": 5244.0,
        "end": 5248.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.96500000000015,
        "end": 67.73400000000038,
        "average": 66.84950000000026
      },
      "rationale_metrics": {
        "rouge_l": 0.24137931034482757,
        "text_similarity": 0.6311049461364746,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction wrongly claims the instructions begin \"immediately,\" contradicting the reference which gives a specific start time (5309.965s) about 5.7s after the previous end, and it omits the required timestamps."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes describing the expectations for IRC Child Protection Team Members, when does he finish describing the expectations for IRC Education Team Members?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2490.27,
        "end": 2535.335
      },
      "pred_interval": {
        "start": 2536.0,
        "end": 2547.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.73000000000002,
        "end": 11.664999999999964,
        "average": 28.69749999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.17948717948717946,
        "text_similarity": 0.46426790952682495,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the correct timeline: it gives entirely different timestamps and misattributes events (saying child protection ends at ~2536s and education starts at 2547s) while the correct answer states education spans 2490.27\u20132535.335s; key temporal facts are incorrect or omitted."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says that 'cross-sector collaboration is really needed to achieve peace expectation', when does he start talking about the integration across the four education models?",
      "video_id": "ASodCu91spY",
      "video_number": "018",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2555.112,
        "end": 2569.771
      },
      "pred_interval": {
        "start": 2698.0,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 142.88799999999992,
        "end": 130.22899999999981,
        "average": 136.55849999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.1639344262295082,
        "text_similarity": 0.3165415823459625,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (2698s \u2192 2700s) are significantly different from the reference segment (E1 ends 2551.231s; E2 starts 2555.112s and ends 2569.771s), so it fails to locate the described speech; only the relative 'after' relation is preserved."
      }
    }
  ]
}