{
  "topic_id": 5,
  "topic_name": "Courtroom Proceedings",
  "num_evaluated": 13,
  "aggregated_metrics": {
    "detailed": {
      "rouge_l_mean": 0.14545318978397168,
      "rouge_l_std": 0.02672541090070346,
      "text_similarity_mean": 0.40652413150438893,
      "text_similarity_std": 0.15978500365653767,
      "llm_judge_score_mean": 1.7692307692307692,
      "llm_judge_score_std": 1.309952797378954
    },
    "short": {
      "rouge_l_mean": 0.08321978009288443,
      "rouge_l_std": 0.062110968631903705,
      "text_similarity_mean": 0.422925137843077,
      "text_similarity_std": 0.21197353893683576,
      "llm_judge_score_mean": 1.7692307692307692,
      "llm_judge_score_std": 1.2498520622516862
    },
    "cider": {
      "cider_detailed": 0.0033937890896166218,
      "cider_short": 2.8383387896276597e-09
    }
  },
  "per_entry_results": [
    {
      "video_id": "TVriGlkPexA",
      "video_number": "001",
      "detailed": {
        "rouge_l": 0.1475826972010178,
        "text_similarity": 0.44895195960998535,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies a courtroom setting and some people present, but it omits the core narrative: the sentencing hearing details, the dropped breach-of-bail charge, Frank's agitated protest/First Amendment claims and quotes, and the subsequent promotional segment about censorship and alternative platforms."
      },
      "short": {
        "rouge_l": 0.04347826086956521,
        "text_similarity": 0.28946036100387573,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the courtroom setting and that someone is speaking, but it omits virtually all key content from the reference (specific charges, defendant name and protests, attorney actions, YouTube censorship/Odyssey promotion and closing statements)."
      }
    },
    {
      "video_id": "Z_6JBsE07b8",
      "video_number": "002",
      "detailed": {
        "rouge_l": 0.12861736334405147,
        "text_similarity": 0.11281522363424301,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only describes basic courtroom visuals (an orange-jumpsuited individual, officers, seating) and omits virtually all substantive content from the correct answer\u2014no mention of the defendant's crimes, victim impact statements, emotional exchanges, or the judge's and defendant's remarks."
      },
      "short": {
        "rouge_l": 0.02702702702702703,
        "text_similarity": 0.1483909785747528,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only lists visual elements (people and an orange jumpsuit) and omits virtually all key factual content from the correct answer (criminal history, victim impact statements, defendant and judge remarks), so it fails to capture the video's substantive summary."
      }
    },
    {
      "video_id": "u0IZ4j1g25s",
      "video_number": "003",
      "detailed": {
        "rouge_l": 0.15258855585831066,
        "text_similarity": 0.46938133239746094,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the high-level premise\u2014a news segment about a guilty verdict with courtroom footage and anchors\u2014but omits nearly all key factual details (specific counts/charges, evidence like DNA/tarp/cell\u2011phone data, judge/DA statements, sentencing timeline, family reactions) and adds a speculative detail about a person in uniform."
      },
      "short": {
        "rouge_l": 0.1092896174863388,
        "text_similarity": 0.6216891407966614,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the general topic (guilty verdict, courtroom footage, discussion of charges/evidence, anchors' commentary) but omits most key specifics from the correct answer (guilty on all eight counts including two first\u2011degree homicide counts, two\u2011hour deliberation, judge's rulings and sentencing dates, DA and analyst remarks, specific evidence) and even misspells the defendant's name."
      }
    },
    {
      "video_id": "xwZ2K8b_pBw",
      "video_number": "004",
      "detailed": {
        "rouge_l": 0.16571428571428573,
        "text_similarity": 0.7105445265769958,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures high-level themes (ethical concerns, case-prediction, human element, need for oversight) but omits the central, specific anecdote about the 74-year-old using an AI-generated avatar in court and many concrete details/statistics and regulatory examples presented in the correct answer."
      },
      "short": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.7663356065750122,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures high-level themes (ethical implications, human touch, need for oversight) but omits the central factual incident (the 74-year-old man using an AI avatar in a New York courtroom, the judge stopping the video, and his admission/promotional motive) and even adds an unsupported point about predicting case outcomes."
      }
    },
    {
      "video_id": "2B_e7fvwi90",
      "video_number": "005",
      "detailed": {
        "rouge_l": 0.13953488372093023,
        "text_similarity": 0.3829055428504944,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction accurately describes the courtroom setting and emotional tone but fails to mention the central subject\u2014Lyle Menendez's testimony about sexual abuse by his father\u2014omitting the key factual element of the reference summary."
      },
      "short": {
        "rouge_l": 0.0,
        "text_similarity": 0.31134727597236633,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the courtroom setting and emotional testimony but omits key factual elements: it does not identify Lyle Menendez, mention alleged sexual abuse by his father, or situate the clip within the Menendez brothers case."
      }
    },
    {
      "video_id": "5yNgC39Q2HE",
      "video_number": "006",
      "detailed": {
        "rouge_l": 0.0960960960960961,
        "text_similarity": 0.342672735452652,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is largely unrelated and inaccurate: it omits all key details about the Hothi v. Musk court arguments, counsel identities, legal issues (public interest, constitutional malice, anti-SLAPP), and cited cases, and instead hallucinates a workplace-safety context."
      },
      "short": {
        "rouge_l": 0.03488372093023256,
        "text_similarity": 0.44463807344436646,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only vaguely notes harassment and evidence collection, which are minor aspects of the reference, but it omits the central legal context (anti-SLAPP defense, parties, specific arguments, and cited precedents) and even introduces unclear items like 'court/workplace safety' not supported by the correct answer."
      }
    },
    {
      "video_id": "9U_cQz-7sT4",
      "video_number": "007",
      "detailed": {
        "rouge_l": 0.15846994535519124,
        "text_similarity": 0.5363638401031494,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the hearing setting and participants (Sen. Cruz and Judge Jackson) but omits the core substantive content\u2014Cruz's line of questioning about legal standing and self-identification hypotheticals and Jackson's measured refusal to answer and described judicial approach\u2014so it is largely incomplete."
      },
      "short": {
        "rouge_l": 0.15517241379310343,
        "text_similarity": 0.5909773111343384,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the participants and setting (Cruz speaking, Jackson at a confirmation hearing) but fails to capture the core substance\u2014questions about self-identification, legal standing, hypotheticals about gender/race/Harvard discrimination, and Jackson's refusal and explanation of her judicial process."
      }
    },
    {
      "video_id": "gTBoJ9W8zQ8",
      "video_number": "010",
      "detailed": {
        "rouge_l": 0.19241982507288632,
        "text_similarity": 0.4878343343734741,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction shares only the superficial setting (a courtroom/witness and a hotel), but it omits and contradicts all key facts from the reference\u2014there is no admission of coercion, no mention of Detective Pettis, Lee Lankford, the promise of career advancement, the outburst and contempt finding, and the date/details are incorrect or invented."
      },
      "short": {
        "rouge_l": 0.1592920353982301,
        "text_similarity": 0.43381983041763306,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only notes a woman testifying about being at a hotel and vague questioning, but omits nearly all key facts (the threat to Gloria Dayton, that a detective asked Pettis to threaten her, identification of Detective Lee Lankford, Lankford's outburst/contempt, and the recess) and adds unsupported details (specific date and judge ordering return)."
      }
    },
    {
      "video_id": "hXN6cDKyk4g",
      "video_number": "009",
      "detailed": {
        "rouge_l": 0.11726384364820847,
        "text_similarity": 0.3531387448310852,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect and vague: it mischaracterizes the talk as about online/substantive law, international trade and IP, and omits almost all key points (civil litigation preparation, settlements, courtroom practice, language skills, witness prep, career advice, and physical fitness), thus introducing unfounded topics and missing essential details."
      },
      "short": {
        "rouge_l": 0.0398406374501992,
        "text_similarity": 0.48874935507774353,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is overly vague and only captures the minor idea of knowing specific laws; it omits almost all key details from the correct answer (pleadings, courtroom tactics, witness prep, settlement advice, time management, study recommendations, and physical fitness) and thus fails to match the reference. "
      }
    },
    {
      "video_id": "DelhQUg8eH4",
      "video_number": "011",
      "detailed": {
        "rouge_l": 0.14814814814814814,
        "text_similarity": 0.4133482575416565,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only captures a vague courtroom/evidence theme and omits nearly all key facts (names, date, drug distribution, license plate, undercover officer, injury, location of the car, forensic confirmation) and even introduces incorrect details (a 'shooting' and an exam title), so it fails to match the reference. "
      },
      "short": {
        "rouge_l": 0.060606060606060615,
        "text_similarity": 0.31462061405181885,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is largely irrelevant and incorrect: it introduces a 'shooting' and an exam context not present in the correct summary, omits key facts about cocaine distribution, the undercover officer, flight, witness plate identification, and forensic confirmation, and thus fails to match the reference."
      }
    },
    {
      "video_id": "k28NMpEkuRU",
      "video_number": "012",
      "detailed": {
        "rouge_l": 0.11929824561403508,
        "text_similarity": 0.1371879130601883,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated to the correct summary, describing an exam-style text video instead of the theft, confrontation, arrest, and identification events in the correct answer, and thus omits and contradicts all key facts."
      },
      "short": {
        "rouge_l": 0.03571428571428571,
        "text_similarity": 0.001133117824792862,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct summary, omitting all key facts about the vandalism, theft, suspect, arrest, evidence, and identification, and instead gives an irrelevant description of an exam practice document."
      }
    },
    {
      "video_id": "RHq_CJJDpUY",
      "video_number": "013",
      "detailed": {
        "rouge_l": 0.13414634146341461,
        "text_similarity": 0.3016856908798218,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated and factually contradictory to the correct summary: it describes a Zoom dispute about inheritance between Mr. A and Mr. B led by a turbaned speaker, whereas the correct answer summarizes a detailed legal lecture on criminal appeals by R.S. Cheema with specific appellate principles, cases, and anecdotes; key elements are omitted and fabricated."
      },
      "short": {
        "rouge_l": 0.05633802816901409,
        "text_similarity": 0.3574085831642151,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated and misses all key elements of the correct answer; it describes an inheritance/property dispute and police involvement, whereas the correct answer discusses criminal appeals and appellate advocacy, so it is completely incorrect."
      }
    },
    {
      "video_id": "L_dJ23CLzTo",
      "video_number": "014",
      "detailed": {
        "rouge_l": 0.19101123595505617,
        "text_similarity": 0.5879836082458496,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures high-level themes (importance of witness preparation and the role/impact of cross-examination) but misrepresents the video as a real cross-examination rather than an interview with Paul Gilbert and omits key specifics such as nervousness/unfamiliarity, closed-question challenges, the witness-familiarisation definition, and the theory-then-mock-training methodology."
      },
      "short": {
        "rouge_l": 0.1935483870967742,
        "text_similarity": 0.7294565439224243,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction touches on relevant themes (legal proceedings, cross-examination, importance of preparation) but is overly terse and omits key details from the correct answer such as witness familiarisation training, common challenges (nervousness/unfamiliarity), the negative impact of unprepared witnesses, and mock cross-examinations that build confidence."
      }
    }
  ]
}