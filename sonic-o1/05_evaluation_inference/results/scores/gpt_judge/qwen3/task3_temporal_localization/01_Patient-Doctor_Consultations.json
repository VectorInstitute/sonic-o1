{
  "topic_id": 1,
  "topic_name": "Patient-Doctor Consultations",
  "num_evaluated": 269,
  "aggregated_metrics": {
    "mean_iou": 0.05019979314086843,
    "std_iou": 0.15486742720751487,
    "median_iou": 0.0,
    "R@0.3": {
      "recall": 0.07063197026022305,
      "count": 19,
      "total": 269
    },
    "R@0.5": {
      "recall": 0.04460966542750929,
      "count": 12,
      "total": 269
    },
    "R@0.7": {
      "recall": 0.01858736059479554,
      "count": 5,
      "total": 269
    },
    "mae": {
      "start_mean": 57.058669144981415,
      "end_mean": 3533.8897063197023,
      "average_mean": 1795.474187732342
    },
    "rationale": {
      "rouge_l_mean": 0.2953847183422093,
      "rouge_l_std": 0.084970390365069,
      "text_similarity_mean": 0.6884478209851843,
      "text_similarity_std": 0.10272012602558761,
      "llm_judge_score_mean": 2.7769516728624537,
      "llm_judge_score_std": 1.6704484854810402
    },
    "rationale_cider": 0.0930178927954836
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "After the speaker welcomes viewers and introduces himself as 'Karma Medic', when does he state that he is a 'final year medical student'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 35.0,
        "end": 36.62
      },
      "pred_interval": {
        "start": 30.3,
        "end": 32.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.699999999999999,
        "end": 4.119999999999997,
        "average": 4.409999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.5168539325842696,
        "text_similarity": 0.8255774974822998,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the relation ('after') and that he says 'final year medical student', but the anchor and target timestamps are substantially different from the ground truth, so the timing information is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'Now with that lovely disclaimer out of the way, let's get right into it', when does the text 'before the history' appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.06,
        "end": 57.06
      },
      "pred_interval": {
        "start": 62.1,
        "end": 63.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.039999999999999,
        "end": 5.939999999999998,
        "average": 5.989999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3478260869565217,
        "text_similarity": 0.7575761079788208,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the sequential relation but gives significantly incorrect timestamps for both the anchor and target (off by ~5\u20136s) and different durations, thus contradicting the correct timings and including inaccurate details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'So before starting the history, there's generally two things that I try and keep in mind', when does he begin describing 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 206.36,
        "end": 207.36
      },
      "pred_interval": {
        "start": 198.0,
        "end": 200.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.360000000000014,
        "end": 7.260000000000019,
        "average": 7.8100000000000165
      },
      "rationale_metrics": {
        "rouge_l": 0.32989690721649484,
        "text_similarity": 0.7954407334327698,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly identifies the temporal relation as 'after', its timestamps for both anchor and target are substantially incorrect and it introduces extra/unverified detail (the 'WIPE' acronym), so it fails to match the key factual elements of the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the acronym 'ICE', when does he explain what it stands for?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 155.7,
        "end": 158.7
      },
      "pred_interval": {
        "start": 174.0,
        "end": 182.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.30000000000001,
        "end": 23.80000000000001,
        "average": 21.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1978021978021978,
        "text_similarity": 0.5129194855690002,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly locates both events (off by ~18s) and the predicted 'explanation' does not match the ground-truth explanation of 'ICE'; only the relation label matches, so the answer is nearly entirely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the components of the WIPER acronym, when does he start elaborating on 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 212.0
      },
      "pred_interval": {
        "start": 197.2,
        "end": 205.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.800000000000011,
        "end": 6.199999999999989,
        "average": 8.0
      },
      "rationale_metrics": {
        "rouge_l": 0.25000000000000006,
        "text_similarity": 0.5694563388824463,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mislabels and time-shifts both events (placing the 'washing your hands' segment much earlier and overlapping with the anchor) and gives an incorrect relation; it thus fails to match the correct timestamps and event roles despite referencing the correct phrase."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what brought the patient in, when does he explain what the 'history of presenting complaint' is about?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 346.0,
        "end": 351.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 333.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.0,
        "end": 17.80000000000001,
        "average": 16.900000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.27184466019417475,
        "text_similarity": 0.7244097590446472,
        "llm_judge_score": 2,
        "llm_judge_justification": "While both answers agree the relation is 'after', the predicted timings are substantially incorrect\u2014placing both events ~16 seconds earlier and stating E2 begins immediately after E1 instead of at 346.0s\u2014omitting the key temporal offsets in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "How long after the speaker says he'll put a picture of all possible questions does the \"REVIEW OF SYSTEMS\" checklist first appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 539.8,
        "end": 543.7
      },
      "pred_interval": {
        "start": 350.0,
        "end": 350.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 189.79999999999995,
        "end": 193.60000000000002,
        "average": 191.7
      },
      "rationale_metrics": {
        "rouge_l": 0.23157894736842108,
        "text_similarity": 0.5975817441940308,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps and duration contradict the reference (E1 at 350s vs 534.817s; E2 at ~350.1s vs 29.8\u201333.7s) and it hallucinates that the checklist continues to the end; major factual elements are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is giving examples of systems review questions, when does he ask about \"tummy pain\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 565.74,
        "end": 566.422
      },
      "pred_interval": {
        "start": 280.0,
        "end": 280.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 285.74,
        "end": 286.02200000000005,
        "average": 285.88100000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.19718309859154928,
        "text_similarity": 0.6469581723213196,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the target utterance and the 'during' relation, but it gives incorrect timestamps for E2 (280.0\u2013280.4s vs ground-truth 555.740\u2013556.422s) and omits the E1 interval, so the timing information is largely wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the \"JAM THREADS\" mnemonic, when does he say the name \"Sketchy Medical\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 696.0,
        "end": 699.531
      },
      "pred_interval": {
        "start": 490.0,
        "end": 490.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 206.0,
        "end": 209.13099999999997,
        "average": 207.5655
      },
      "rationale_metrics": {
        "rouge_l": 0.4642857142857143,
        "text_similarity": 0.7012438774108887,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly identifies the temporal relation as 'after', both event timestamps are substantially incorrect (predicted ~487\u2013490s vs ground truth 635.0s and 696.0\u2013699.531s), so it fails to match the reference timing information."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker describes Sketchy Medical, when does he mention drugs' mechanism of action and side effects?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 701.0,
        "end": 703.982
      },
      "pred_interval": {
        "start": 690.0,
        "end": 695.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 8.981999999999971,
        "average": 9.990999999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.3170731707317073,
        "text_similarity": 0.826166033744812,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the phrase and the 'during' relationship, but the provided timestamps for both the anchor and target are substantially incorrect compared to the ground truth, which is a key factual error."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks a general question about family health, when does he suggest being specific about asthma, diabetes, and hypertension?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 742.914,
        "end": 745.914
      },
      "pred_interval": {
        "start": 710.0,
        "end": 720.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.91399999999999,
        "end": 25.913999999999987,
        "average": 29.413999999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.205607476635514,
        "text_similarity": 0.528082013130188,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly identifies event timings and the temporal relation: it places the anchor and target ~20+ seconds earlier and treats the target as occurring during the anchor rather than after the general question. While it mentions the correct phrase, the temporal alignment and relationship conflict with the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the importance of signposting, when does he ask if the patient uses any recreational drugs?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 811.123,
        "end": 812.664
      },
      "pred_interval": {
        "start": 745.0,
        "end": 750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.12300000000005,
        "end": 62.66399999999999,
        "average": 64.39350000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.27956989247311825,
        "text_similarity": 0.7273565530776978,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the drug question immediately follows the signposting instruction, but it gives substantially incorrect timestamps (745\u2013750s vs the correct 800.85\u2013812.66s), a major factual error."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"concerns from ICE\", when does he start saying \"Just generally, if you're feeling stuck\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 880.187,
        "end": 883.471
      },
      "pred_interval": {
        "start": 898.1,
        "end": 900.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.91300000000001,
        "end": 16.62900000000002,
        "average": 17.271000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.3820224719101123,
        "text_similarity": 0.6620688438415527,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies both phrases and their temporal relation ('after'), but the provided timestamps are substantially different from the reference (off by ~17\u201318 seconds) and the anchor timing format contradicts the reference, so it is largely incorrect on the key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"golden rulebook\", when does he open both hands outwards in a gesture?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 895.8,
        "end": 897.5
      },
      "pred_interval": {
        "start": 910.1,
        "end": 912.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.300000000000068,
        "end": 14.5,
        "average": 14.400000000000034
      },
      "rationale_metrics": {
        "rouge_l": 0.32098765432098764,
        "text_similarity": 0.7003552317619324,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the temporal relation ('after') right but the timestamps for both the anchor and target events are significantly incorrect (off by ~16s and ~14s respectively) and do not match the ground truth, so it earns only minimal credit."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying \"I hope you find this video useful\", when does he say \"Peace\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 910.148,
        "end": 910.609
      },
      "pred_interval": {
        "start": 917.0,
        "end": 917.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.851999999999975,
        "end": 7.190999999999917,
        "average": 7.021499999999946
      },
      "rationale_metrics": {
        "rouge_l": 0.3777777777777777,
        "text_similarity": 0.676007091999054,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target phrases and the 'once_finished' relation, but the timestamps are significantly off (about 6\u20137 seconds later) and do not match the ground-truth intervals, so the answer is factually incorrect on timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying he has an appointment at 10 am, when does the green text 'Sure, what's your name?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 6.1,
        "end": 8.2
      },
      "pred_interval": {
        "start": 9.6,
        "end": 10.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 2.6000000000000014,
        "average": 3.0500000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.2631578947368421,
        "text_similarity": 0.8057963252067566,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly gives substantially different timestamps and labels the relation as 'after' rather than the immediate 'once_finished'; it only partially matches the ordering (target after anchor) but contradicts key timing and relation details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes stating his name, when does the green text 'Thank you, Lucas. Please take a seat...' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 11.9,
        "end": 19.0
      },
      "pred_interval": {
        "start": 18.6,
        "end": 20.0
      },
      "iou": 0.04938271604938254,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.700000000000001,
        "end": 1.0,
        "average": 3.8500000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.25000000000000006,
        "text_similarity": 0.7031123042106628,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the general ordering (target occurs after the utterance) but the timestamps are substantially incorrect (anchor 16.8s vs 10.6s; target 18.6\u201320.0s vs 11.9\u201319.0s) and the relation label differs from the specified 'once_finished', so it fails on key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'How long is the wait?', when does the green text 'About 10 minutes. Would you like some water while you wait?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 22.1,
        "end": 25.3
      },
      "pred_interval": {
        "start": 34.4,
        "end": 36.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.299999999999997,
        "end": 11.099999999999998,
        "average": 11.699999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2077922077922078,
        "text_similarity": 0.7501938343048096,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') right, but both reported timestamps are substantially incorrect compared to the ground truth (off by ~12\u201313s), so the answer is largely factually wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the video explains the 'we're a team' approach with animated graphics, when does the speaker appear at his desk looking at a computer?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 34.6,
        "end": 36.0
      },
      "pred_interval": {
        "start": 34.4,
        "end": 36.0
      },
      "iou": 0.8749999999999983,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.20000000000000284,
        "end": 0.0,
        "average": 0.10000000000000142
      },
      "rationale_metrics": {
        "rouge_l": 0.24347826086956523,
        "text_similarity": 0.6365187764167786,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction closely matches the reference times (speaker 34.4\u201336.0 vs. 34.0\u201336.0/34.6 target) and correctly links the animated segment to the speaker shot; minor issues are small timing offsets and a slight contradiction in saying the speaker appears 'after' the animation even though the predicted start (34.4s) overlaps the animation end."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker says 'take that extra bit of time to listen', when does the 'OK' hand gesture emoji appear?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 44.0,
        "end": 45.5
      },
      "pred_interval": {
        "start": 44.9,
        "end": 46.5
      },
      "iou": 0.24000000000000057,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8999999999999986,
        "end": 1.0,
        "average": 0.9499999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.34951456310679613,
        "text_similarity": 0.7721661329269409,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misreports the timing (places the spoken phrase ~2s later and the emoji ~0.9s later than the ground truth) and adds an unsupported detail about the emoji being superimposed over the mouth; although it notes concurrency, the timing errors and hallucination make it largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After Nurse Kim mentions graduating as a registered nurse, when does she talk about working for many different pharmaceutical companies?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 43.0,
        "end": 50.475
      },
      "pred_interval": {
        "start": 71.0,
        "end": 75.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.0,
        "end": 24.525,
        "average": 26.2625
      },
      "rationale_metrics": {
        "rouge_l": 0.21686746987951805,
        "text_similarity": 0.6025580167770386,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the correct 'after' relation, but the timestamps and event spans are substantially incorrect (both E1 and E2 are shifted ~40s later and the E2 interval does not match the reference), so it fails to align with the ground truth timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once Nurse Kim finishes describing her background as an 'incredible journey', when does she mention training side-by-side with Dr. Jugenberg for five years?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 149.87,
        "end": 153.25
      },
      "pred_interval": {
        "start": 161.0,
        "end": 162.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.129999999999995,
        "end": 9.25,
        "average": 10.189999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2682926829268293,
        "text_similarity": 0.6302888989448547,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the relation and the quoted phrase, but the crucial timestamps are substantially incorrect (off by ~50 seconds), so it fails to match the ground-truth temporal annotations."
      }
    },
    {
      "question_id": "001",
      "question": "While Nurse Kim explains options and possible outcomes, when does she begin examining the patient's stomach?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 157.5,
        "end": 160.5
      },
      "pred_interval": {
        "start": 150.0,
        "end": 151.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.5,
        "end": 9.5,
        "average": 8.5
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.6466341018676758,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the relative ordering (examining occurs around the time of speech) but gives substantially incorrect timestamps and durations (150.0s vs 156.8s anchor; 150.0\u2013151.0s vs 157.5\u2013160.5s target), so it is factually inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After Nurse Kim finishes discussing the benefits, risks, and possible complications of the procedure, when does she start talking about asymmetry?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 169.7,
        "end": 172.0
      },
      "pred_interval": {
        "start": 156.0,
        "end": 157.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.699999999999989,
        "end": 15.0,
        "average": 14.349999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.7957669496536255,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the order and content (asymmetry discussed after risks/benefits), but it gives substantially different timestamps (156.0s vs. correct ~169.5\u2013169.7s), so the key factual timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once Nurse Kim finishes explaining that the one-hour consultation cannot provide everything you need to know, when does she mention that they are always available?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 201.5,
        "end": 203.71
      },
      "pred_interval": {
        "start": 176.0,
        "end": 177.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.5,
        "end": 26.710000000000008,
        "average": 26.105000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.37623762376237624,
        "text_similarity": 0.55913245677948,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the phrasing and that the target follows immediately after the anchor, but the timestamps are substantially wrong (176.0s vs the ground-truth 201.5s), so the temporal localization is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces himself and the topic, when does the slide change to 'Objectives for today's lesson'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 24.379,
        "end": 24.5
      },
      "pred_interval": {
        "start": 18.7,
        "end": 19.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.679000000000002,
        "end": 5.199999999999999,
        "average": 5.439500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2456140350877193,
        "text_similarity": 0.7362719774246216,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted relation ('after') matches, but the predicted timestamps for both the end of the introduction and the slide change contradict the reference times by several seconds, so the answer is largely factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the objectives for the lesson, when does the slide change to 'Brain storming time'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 46.529,
        "end": 47.0
      },
      "pred_interval": {
        "start": 47.2,
        "end": 47.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.6709999999999994,
        "end": 0.7999999999999972,
        "average": 0.7354999999999983
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.6815528273582458,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the same events and the 'once_finished' relation, but the timestamps are noticeably off from the ground truth (E1 ~+1.4s, E2 ~+1.27s), reducing temporal accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes defining communication as the successful passage of a message from one person to another, when does he start explaining how good communication manifests in medical practice by informing patients of their diagnosis?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 153.0,
        "end": 177.0
      },
      "pred_interval": {
        "start": 166.3,
        "end": 172.4
      },
      "iou": 0.25416666666666643,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.300000000000011,
        "end": 4.599999999999994,
        "average": 8.950000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.1797752808988764,
        "text_similarity": 0.5320566892623901,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly identifies the correct thematic target (communication in medical practice) but gives substantially incorrect timestamps and labels the temporal relation as 'after' rather than the immediate follow-on specified in the ground truth, so it largely mismatches the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the 'Importance of communication' slide, when does he begin discussing that good doctor-patient communication has been linked to improved patient satisfaction?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 190.0,
        "end": 198.0
      },
      "pred_interval": {
        "start": 205.6,
        "end": 207.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.599999999999994,
        "end": 9.400000000000006,
        "average": 12.5
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962025,
        "text_similarity": 0.6120503544807434,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the target follows the anchor, but both the anchor and target timestamps are substantially wrong and it wrongly claims the target occurs immediately after the anchor rather than ~11\u201320s later as in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker starts talking about how a lot of malpractice lawsuits have been documented, when does he explicitly advise being aware of communication's importance to avoid lawsuits?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 226.0,
        "end": 271.0
      },
      "pred_interval": {
        "start": 223.7,
        "end": 224.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.3000000000000114,
        "end": 46.30000000000001,
        "average": 24.30000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.18604651162790697,
        "text_similarity": 0.709782600402832,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the content of the advice but misidentifies both event timestamps (anchor and target) and the temporal relation\u2014placing the anchor much later and the target almost immediately after, which contradicts the correct timing and relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the initial slide 'Communication is not just talking' is displayed, when does the speaker mention that physicians can improve health outcomes?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 339.28,
        "end": 346.0
      },
      "pred_interval": {
        "start": 450.0,
        "end": 451.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 110.72000000000003,
        "end": 105.0,
        "average": 107.86000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.27956989247311825,
        "text_similarity": 0.7674819231033325,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the 'after' relation but misidentifies event timings: E2 is placed at ~450s instead of the correct 339.28\u2013346.0s, and E1 is incorrectly extended to 350s; thus the target event timing is substantially incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide showing two images (bored girl vs. smiling doctor/patient), when does the speaker describe the first image as depicting a 'horribly bored' lady?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.8,
        "end": 359.0
      },
      "pred_interval": {
        "start": 500.0,
        "end": 505.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 145.2,
        "end": 146.0,
        "average": 145.6
      },
      "rationale_metrics": {
        "rouge_l": 0.17600000000000002,
        "text_similarity": 0.6259117126464844,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely fails: the target segment is mislocated (500\u2013505s vs correct 354.8\u2013359.0s), the quoted content does not match the 'horribly bored' description, and the asserted temporal relation is incorrect despite a partial overlap in the anchor timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker defines verbal communication as 'using spoken words', when is the next time they define non-verbal communication?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 428.87,
        "end": 433.596
      },
      "pred_interval": {
        "start": 520.0,
        "end": 525.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 91.13,
        "end": 91.404,
        "average": 91.267
      },
      "rationale_metrics": {
        "rouge_l": 0.13953488372093023,
        "text_similarity": 0.7372704148292542,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the semantic relation (non\u2011verbal definition immediately follows the verbal one) and the quoted content, but the provided timestamps deviate substantially from the ground truth, so the answer is factually incorrect on timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the 'golden minute', when does he describe the patient's hypothetical response?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 613.818,
        "end": 630.0
      },
      "pred_interval": {
        "start": 584.4,
        "end": 612.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.418000000000006,
        "end": 18.0,
        "average": 23.709000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3736263736263737,
        "text_similarity": 0.8031281232833862,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly states the relative relation ('after'), it substantially mislocates both events\u2014the anchor and target timestamps differ markedly from the ground truth and the predicted target does not match the referenced target interval\u2014so the prediction is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions 'Checking facts', when does he mention the next essential element of listening?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 641.157,
        "end": 642.461
      },
      "pred_interval": {
        "start": 626.4,
        "end": 636.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.757000000000062,
        "end": 5.760999999999967,
        "average": 10.259000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.3636363636363636,
        "text_similarity": 0.8083322048187256,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the next element as 'checking feelings' and that it comes after 'checking facts', but both the anchor and target timestamps are significantly inaccurate compared to the reference and the prediction adds extra phrasing not in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Before the speaker says 'So, for example, we have three main types of reflective listening', when does he explain what reflective listening involves?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 667.457,
        "end": 687.051
      },
      "pred_interval": {
        "start": 688.4,
        "end": 712.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.942999999999984,
        "end": 25.448999999999955,
        "average": 23.19599999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324323,
        "text_similarity": 0.8251643180847168,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer contradicts the ground truth: timestamps and anchor/target labels are incorrect (places the definition around 688s instead of 667\u2013672s), and it misstates the temporal relation by saying 'immediately after' rather than that the definition occurs before the examples."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the three main types of reflective listening, when does he start explaining the 'Repeating' example?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 710.0,
        "end": 737.0
      },
      "pred_interval": {
        "start": 853.4,
        "end": 868.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 143.39999999999998,
        "end": 131.0,
        "average": 137.2
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.5744546055793762,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the 'Repeating' explanation follows the mention of three types, but its timestamps conflict substantially with the ground truth (E1 predicted 853.4s vs ground truth 696.1s; E2 predicted 854.3s vs ground truth 710.0s), making it largely factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the 'Repeating' example, when does he introduce 'Rephrasing'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 720.0,
        "end": 720.4
      },
      "pred_interval": {
        "start": 891.8,
        "end": 897.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 171.79999999999995,
        "end": 176.89999999999998,
        "average": 174.34999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2247191011235955,
        "text_similarity": 0.43792784214019775,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely mismatches the ground truth: it misidentifies the anchor event (different example), gives substantially different timestamps, and only loosely matches the target label 'Rephrasing' without matching the correct phrase or timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing 'Reflection of feeling by showing empathy', when does the 'Non-verbal' slide appear?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 780.0,
        "end": 821.5
      },
      "pred_interval": {
        "start": 900.0,
        "end": 900.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 120.0,
        "end": 78.5,
        "average": 99.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3380281690140845,
        "text_similarity": 0.6177970170974731,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures that the 'Non-verbal' slide appears after the speaker finishes, but it gives incorrect timestamps (900.0s vs correct 778.5s/780.0s) and wrongly states the slide appears simultaneously with the finish rather than 1.5s later, so it is largely factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises to smile, when does he mention checking for signs of pain?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.045,
        "end": 882.0
      },
      "pred_interval": {
        "start": 870.0,
        "end": 872.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.044999999999959,
        "end": 10.0,
        "average": 6.5224999999999795
      },
      "rationale_metrics": {
        "rouge_l": 0.25316455696202533,
        "text_similarity": 0.6127620935440063,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the semantic relation (smile then check for facial pain) but has notably inaccurate timestamps (E1/E2 offsets differ by ~1\u20132+ seconds) and incorrectly shortens/omits the extended explanation (predicted E2 ends at 872.0s vs. ~882.0s in the reference)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the cultural interpretations of folding arms, when does he advise to avoid folding arms?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 932.0,
        "end": 936009.0
      },
      "pred_interval": {
        "start": 918.0,
        "end": 919.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 935090.0,
        "average": 467552.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24444444444444444,
        "text_similarity": 0.6901310086250305,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction partially matches the anchor (918s is within the 915\u2013926s window), but it incorrectly locates the advised-to-avoid folding-arms segment (predicts 918\u2013919s) whereas the correct target is 932\u2013936s, so the key timestamp is wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker instructs to introduce yourself to the patient, when does he advise to explain your role as a student or intern?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 985.0,
        "end": 990.853
      },
      "pred_interval": {
        "start": 977.0,
        "end": 982.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.0,
        "end": 8.852999999999952,
        "average": 8.426499999999976
      },
      "rationale_metrics": {
        "rouge_l": 0.2823529411764706,
        "text_similarity": 0.584095299243927,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the verbal content but gives incorrect and contradictory timestamps/order: it places both events earlier and overlapping (E2 starting at 977s and ending at 982s) instead of E1 at 982\u2013984s and E2 at 985\u2013990.1s, so the temporal relation is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"if you're in the hospital\", when does he refer to \"inpatient patients\"?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1059.6,
        "end": 1059.8
      },
      "pred_interval": {
        "start": 1072.62,
        "end": 1075.52
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.019999999999982,
        "end": 15.720000000000027,
        "average": 14.370000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.18604651162790697,
        "text_similarity": 0.5656470060348511,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target phrases and that the target follows the anchor, but the timestamps are substantially incorrect and durations/misalignment conflict with the reference, so it fails key factual alignment."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining how to start a consultation, when does he give the example \"how can I help you today?\"",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1069.0,
        "end": 1070.0
      },
      "pred_interval": {
        "start": 1084.75,
        "end": 1089.43
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.75,
        "end": 19.430000000000064,
        "average": 17.590000000000032
      },
      "rationale_metrics": {
        "rouge_l": 0.2637362637362637,
        "text_similarity": 0.7879853248596191,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase, the example, and that the example follows the instruction, but the provided timestamps and duration for both E1 and E2 are substantially different from the ground truth, so the timing information is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes explaining the 'golden minute', when does he announce the end of the lecture?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1090.0,
        "end": 1094.0
      },
      "pred_interval": {
        "start": 1101.54,
        "end": 1104.38
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.539999999999964,
        "end": 10.38000000000011,
        "average": 10.960000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.3146067415730337,
        "text_similarity": 0.7809354066848755,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the events and their order (announcement follows the 'various things' remark), but the reported timestamps and durations differ significantly from the ground truth (~11\u201312 seconds offset), so the timing is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "While Raquel is talking about the hospital providing opportunities for nurses, when is she shown smiling and opening a package?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 2.0,
        "end": 4.5
      },
      "pred_interval": {
        "start": 2.1,
        "end": 4.8
      },
      "iou": 0.8571428571428572,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.10000000000000009,
        "end": 0.2999999999999998,
        "average": 0.19999999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.3529411764705882,
        "text_similarity": 0.5706779956817627,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted timings closely match the reference (differences within a few tenths of a second) and correctly identifies the visual event as occurring during her speech, so the answers are semantically equivalent."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria finishes saying that new nurses will be nudged to become lifelong learners, when does Precious state that the teamwork is strong?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 14.321,
        "end": 16.486
      },
      "pred_interval": {
        "start": 15.2,
        "end": 16.7
      },
      "iou": 0.5405632618747379,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8789999999999996,
        "end": 0.21399999999999864,
        "average": 0.5464999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.7269350290298462,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly matches E1's end and E2's end times but significantly misstates E2's start (15.2s vs 14.321s), which alters the temporal relation; thus it partially matches but contains a key timing error."
      }
    },
    {
      "question_id": "003",
      "question": "After Reny states that the hospital does things up to a magnet level, when does Raquel say her values align with the hospital's values?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 42.854,
        "end": 50.692
      },
      "pred_interval": {
        "start": 45.1,
        "end": 47.8
      },
      "iou": 0.34447563153865723,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.246000000000002,
        "end": 2.892000000000003,
        "average": 2.5690000000000026
      },
      "rationale_metrics": {
        "rouge_l": 0.3373493975903614,
        "text_similarity": 0.6293759346008301,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence (Raquel speaks after Reny) but the timestamps are notably inaccurate (off by over 1\u20132 seconds) and it omits that Raquel's speech continues over the logo and lasts until ~50.692s, so it is factually incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that healthcare in Siem Reap is not the best, when is the Royal Angkor International Hospital first shown on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 94.0,
        "end": 99.1
      },
      "pred_interval": {
        "start": 136.8,
        "end": 141.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.80000000000001,
        "end": 42.30000000000001,
        "average": 42.55000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.30357142857142855,
        "text_similarity": 0.7822175025939941,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the ordering (visual appears after the speaker) but the timestamps are substantially incorrect and inconsistent with the reference, and it adds details (website cut) not supported by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he begin describing the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 180.289,
        "end": 185.074
      },
      "pred_interval": {
        "start": 202.0,
        "end": 203.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.711000000000013,
        "end": 18.825999999999993,
        "average": 20.268500000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.4259259259259259,
        "text_similarity": 0.8611546158790588,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction includes the correct utterance used to introduce Ly Sreyvyna II Clinic but the reported timestamps are substantially off (both E1 and E2 times differ from the ground truth), so it fails to match the key timing information."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he visited a clinic for chest congestion, when does he mention the Paschern Dental Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 209.8,
        "end": 211.4
      },
      "pred_interval": {
        "start": 286.0,
        "end": 291.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.19999999999999,
        "end": 79.6,
        "average": 77.89999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714282,
        "text_similarity": 0.6780633330345154,
        "llm_judge_score": 2,
        "llm_judge_justification": "While both answers agree the mention of the dental clinic occurs after the chest-congestion clinic, the predicted response gives completely different timestamps and does not identify the Paschern Dental Clinic (instead quoting unrelated lines), so it fails on key factual alignment."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he introduce the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.0,
        "end": 184.8
      },
      "pred_interval": {
        "start": 246.0,
        "end": 251.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.0,
        "end": 66.19999999999999,
        "average": 64.1
      },
      "rationale_metrics": {
        "rouge_l": 0.2298850574712644,
        "text_similarity": 0.679803192615509,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction has completely different timestamps and even misidentifies the clinic (Sock Bong vs Ly Sreyvyna II), so it is factually incorrect despite matching the general 'after' relation."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker introduces the Cigna International Health Policy, when is the insurance quote form displayed with personal information?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 339.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.0,
        "end": 21.0,
        "average": 21.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2528735632183908,
        "text_similarity": 0.7871614098548889,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the event types and the 'once_finished' relation right, but the reported timestamps are substantially incorrect (both start and end times differ by ~20\u201330s from the ground truth), so it fails on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the voiceover states that the Cigna policy is \"fairly typical of policies of this type\", when does the Cigna website display the form for inputting personal details to get a quote?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 352.9,
        "end": 358.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 334.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.899999999999977,
        "end": 23.600000000000023,
        "average": 23.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2692307692307693,
        "text_similarity": 0.73469078540802,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contains major factual errors: it gives incorrect timestamps for both anchor (330.0s vs correct 351.0s) and target (330.0s vs correct 352.9s\u2013358.0s), wrongly claims simultaneity/continued visibility, and contradicts the correct 'after' relationship."
      }
    },
    {
      "question_id": "003",
      "question": "After the voiceover mentions \"evacuation service, also part of Cigna plan\", when is the Global Rescue website displayed on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 384.0,
        "end": 431.0
      },
      "pred_interval": {
        "start": 367.8,
        "end": 456.0
      },
      "iou": 0.5328798185941044,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.19999999999999,
        "end": 25.0,
        "average": 20.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.23423423423423426,
        "text_similarity": 0.8136786222457886,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the key timestamps and sequence (claims both events at 367.8s and that E2 starts immediately and runs to the end), which contradicts the correct E1 at 379.0s and E2 at 384.0s (visible until 431.0s); it only correctly notes the 'after' relationship. "
      }
    },
    {
      "question_id": "001",
      "question": "After the host concludes his introduction about the fight in modern healthcare, when does he introduce Sarah?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 19.4,
        "end": 22.0
      },
      "pred_interval": {
        "start": 20.2,
        "end": 21.8
      },
      "iou": 0.6153846153846156,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8000000000000007,
        "end": 0.1999999999999993,
        "average": 0.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2115384615384615,
        "text_similarity": 0.7165266275405884,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies Sarah's introduction and the 'after' relation, and the E2 interval (20.2\u201321.8s) largely overlaps the ground-truth window; however, the predicted E1 end time (19.6s) is ~1.6s later than the reference (18.0s), a minor timing discrepancy."
      }
    },
    {
      "question_id": "002",
      "question": "While Sarah is introducing herself and her genetic condition, when does she mention having her very first surgery?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.08,
        "end": 108.8
      },
      "pred_interval": {
        "start": 100.2,
        "end": 103.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.8799999999999955,
        "end": 5.3999999999999915,
        "average": 4.6399999999999935
      },
      "rationale_metrics": {
        "rouge_l": 0.19565217391304346,
        "text_similarity": 0.7305217385292053,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the events and the 'during' relation and has a negligible E1 timing difference, but it gives a substantially incorrect time window for E2 (100.2\u2013103.4s vs. the correct 104.08\u2013108.08s), contradicting a key factual element."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sarah finishes describing her role as a volunteer patient representative for a non-profit organization, when does the static image showing her behind a 'CHILDREN'S TUMOR FOUNDATION' table appear?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 185.0,
        "end": 190.0
      },
      "pred_interval": {
        "start": 164.0,
        "end": 167.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.0,
        "end": 23.0,
        "average": 22.0
      },
      "rationale_metrics": {
        "rouge_l": 0.25925925925925924,
        "text_similarity": 0.7685264348983765,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the event order ('after') and that the anchor finishes before the image, but the timestamps and durations are substantially incorrect (anchor at 163.8s vs 150s; image at 164.0\u2013167.0s vs 185.0\u2013190.0s), so it fails on key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes explaining the purpose of the 'Shine a Light Walk' to raise money and awareness, when does the video clip showing children running at an outdoor event play?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 189.0,
        "end": 192.0
      },
      "pred_interval": {
        "start": 170.0,
        "end": 174.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.0,
        "end": 18.0,
        "average": 18.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3614457831325301,
        "text_similarity": 0.7415574789047241,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the events (Sarah explaining the walk and a children-running clip) but the timestamps and durations are significantly off and the temporal relation is imprecise, so it fails to match the key factual timing details in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once Steve asks if the 'Shine a Light Walk' goes throughout the world, when does Sarah begin to explain that the walks do not?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 253.2,
        "end": 258.88
      },
      "pred_interval": {
        "start": 181.0,
        "end": 182.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.19999999999999,
        "end": 76.88,
        "average": 74.53999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7027190923690796,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the utterances and that Sarah's reply is immediate, but the timestamps are substantially wrong (predicted ~180\u2013181s vs correct anchor at 252.5s and response starting at 253.2s), so the temporal alignment is mostly incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes asking Sarah what things in miscommunication can lead to delays or misdiagnosis, when does the woman start responding?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 362.48,
        "end": 365.44
      },
      "pred_interval": {
        "start": 357.3,
        "end": 364.3
      },
      "iou": 0.22358722358722313,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.180000000000007,
        "end": 1.1399999999999864,
        "average": 3.1599999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.1839080459770115,
        "text_similarity": 0.5793997049331665,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the timestamps (man ends at 361.920s, woman begins at 362.480s) and incorrectly claims the woman starts immediately at 357.3s; it also includes an unverified quoted utterance, so it contradicts the ground truth and hallucinates details."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman gives the example of writing 'hyperthyroid instead of hypothyroid', when does the man respond with 'That that's pretty bad'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 389.2,
        "end": 432.5
      },
      "pred_interval": {
        "start": 388.7,
        "end": 392.0
      },
      "iou": 0.06392694063926965,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.5,
        "end": 40.5,
        "average": 20.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23809523809523808,
        "text_similarity": 0.44733721017837524,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction partially locates the woman's end but incorrectly states the man responds immediately at 388.7s and gives a much shorter end time (392.0s), contradicting the ground truth that the man starts after a short pause at 389.200s and continues until 432.500s; it omits and misrepresents key timing and the \u2018after\u2019 relation."
      }
    },
    {
      "question_id": "003",
      "question": "After the man says he tried researching miscommunication problems, when does he state his finding about thousands of preventable deaths?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 446.56,
        "end": 535.68
      },
      "pred_interval": {
        "start": 411.0,
        "end": 418.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.56,
        "end": 117.07999999999993,
        "average": 76.31999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.1016949152542373,
        "text_similarity": 0.4737843871116638,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer reproduces the utterances but gives substantially incorrect timestamps (408\u2013418s vs the reference 435\u2013451s) and wrongly implies immediate succession, contradicting the ground-truth temporal separation; thus content is partially correct but timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks, \"What's in my budget to fix it?\", when does she start asking, \"How important is it to me to fix this issue?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 518.66,
        "end": 522.26
      },
      "pred_interval": {
        "start": 510.0,
        "end": 512.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.659999999999968,
        "end": 10.259999999999991,
        "average": 9.45999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.24444444444444444,
        "text_similarity": 0.7151623964309692,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two questions and their order, but the provided timestamps disagree with the reference by ~5.8\u20136.8 seconds and wrongly claims an immediate follow-up with no pause, so the timing alignment is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the man finishes saying, \"not continuing medical bills,\" when does he start asking, \"So, what does successful self-advocacy look like?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 643.04,
        "end": 646.32
      },
      "pred_interval": {
        "start": 528.9,
        "end": 531.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 114.13999999999999,
        "end": 115.12,
        "average": 114.63
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.6888836622238159,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the question occurs after the anchor, but it gives completely incorrect timestamps (off by ~105\u2013115 seconds) and wrongly asserts the question begins immediately after the anchor, contradicting the reference times and missing key temporal details."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining what a doctor's follow-up might entail, when does the woman start asking, \"Or will I actually be able to get into your office in two weeks?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 679.0,
        "end": 683.92
      },
      "pred_interval": {
        "start": 562.8,
        "end": 567.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 116.20000000000005,
        "end": 116.12,
        "average": 116.16000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.7314081192016602,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the woman's question immediately follows the man's explanation, but it gives substantially incorrect timestamps (562.7/562.8s vs. ground-truth 677.92/679.00s), so the temporal facts are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Immediately after the woman asks if she should follow up if she is still experiencing symptoms, when does the man ask what if the symptoms go away?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.38,
        "end": 707.15
      },
      "pred_interval": {
        "start": 709.367,
        "end": 713.897
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.986999999999966,
        "end": 6.747000000000071,
        "average": 8.367000000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.42857142857142855,
        "text_similarity": 0.8409838080406189,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target utterances and the 'immediately after' relation, but the provided timestamps are substantially off from the ground truth (events are shifted by roughly 6\u201311 seconds), so the timing is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying to voice symptoms and concerns clearly, when does he give an example about shoulder pain?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 734.59,
        "end": 737.0
      },
      "pred_interval": {
        "start": 723.87,
        "end": 725.22
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.720000000000027,
        "end": 11.779999999999973,
        "average": 11.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3023255813953489,
        "text_similarity": 0.7417454719543457,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct utterances and relationship but the reported start/end times are substantially incorrect (about 10s off) and it misaligns the target to begin exactly at the anchor end rather than at the correct timestamps, so key temporal facts are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes warning not to try putting a hand in an electrical outlet, when does the woman agree and say not to try that?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 810.0,
        "end": 812.0
      },
      "pred_interval": {
        "start": 733.17,
        "end": 735.59
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.83000000000004,
        "end": 76.40999999999997,
        "average": 76.62
      },
      "rationale_metrics": {
        "rouge_l": 0.3703703703703703,
        "text_similarity": 0.7719637155532837,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the utterances but gives substantially incorrect timestamps and a generic 'after' relation rather than the specified immediate-follow timing, so it fails key factual alignment."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes saying to assume benevolence of your doctor, when does the man begin to speak?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.9,
        "end": 879.1
      },
      "pred_interval": {
        "start": 872.2,
        "end": 873.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.699999999999932,
        "end": 5.899999999999977,
        "average": 6.2999999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.325,
        "text_similarity": 0.6543686985969543,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the same qualitative relation (man speaks after the woman) and provides both timestamps, but the reported times are off by ~6.9\u20136.8 seconds from the ground truth, so the answer is factually inaccurate on the key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks about trying non-surgical options first, when does the woman reply 'Yes'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 899.7,
        "end": 900.1
      },
      "pred_interval": {
        "start": 878.1,
        "end": 878.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.600000000000023,
        "end": 21.5,
        "average": 21.55000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3448275862068966,
        "text_similarity": 0.6153322458267212,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the woman's 'Yes' as an immediate response after the man's question, but the timestamps are substantially off (\u224822s earlier) and the relation label is less precise than 'once_finished', so the answer is only partly correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the man concludes his statement about how to ask for another opinion, when does the woman respond that asking for another opinion is definitely valid?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 982.0,
        "end": 988.72
      },
      "pred_interval": {
        "start": 908.6,
        "end": 911.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.39999999999998,
        "end": 77.62,
        "average": 75.50999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.4421052631578948,
        "text_similarity": 0.5778608918190002,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the verbal content and claims an 'after' relation, but it gives significantly wrong timestamps (908.6s vs correct ~976s/982s) and even lists both events at the same time, contradicting the required temporal ordering\u2014major factual errors."
      }
    },
    {
      "question_id": "001",
      "question": "After the man suggests bringing someone along if you're not feeling safe, when does the woman agree that it's advisable?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1127.0,
        "end": 1130.0
      },
      "pred_interval": {
        "start": 1100.0,
        "end": 1120.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.0,
        "end": 10.0,
        "average": 18.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3255813953488372,
        "text_similarity": 0.763042151927948,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the woman's agreement follows the man's suggestion, but it provides significantly incorrect timestamps for both events, an inaccurate event span, and adds unsupported visual details, so it fails to match the reference closely."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman talks about a doctor not trusting a patient's pain because they don't act like they're in pain, when does she give an example of a loved one vouching for the patient?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1167.68,
        "end": 1174.48
      },
      "pred_interval": {
        "start": 1160.0,
        "end": 1210.0
      },
      "iou": 0.1359999999999991,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.680000000000064,
        "end": 35.51999999999998,
        "average": 21.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923078,
        "text_similarity": 0.7070978879928589,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the loved-one example follows the doctor-skepticism remark, but the timestamps are significantly inaccurate (E1 and E2 timing mismatch and E2 end is overstated) and it adds an unsupported comment about facial expressions."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks if it is legal to be given your own medical records, when does the woman confirm that it is?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1268.6,
        "end": 1270.7
      },
      "pred_interval": {
        "start": 1404.9,
        "end": 1408.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 136.30000000000018,
        "end": 138.0999999999999,
        "average": 137.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.6008783578872681,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the dialogue content and the immediate-after relationship, but the provided timestamps do not match the ground truth (events are shifted by ~138s), so the localization is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman mentions that things have changed a lot with electronic medical records, when does the man state that bureaucracy reminds him of common barriers?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1333.0,
        "end": 1339.5
      },
      "pred_interval": {
        "start": 1430.9,
        "end": 1437.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.90000000000009,
        "end": 98.29999999999995,
        "average": 98.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.17582417582417584,
        "text_similarity": 0.7953570485115051,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the man\u2019s line as occurring after the woman\u2019s comment and provides a plausible quote, but it gives materially different absolute timestamps and implies immediate succession rather than the significant delay indicated in the ground-truth, so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks about common barriers and how to overcome them, when does the woman share her fear of ants?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.36,
        "end": 1383.7
      },
      "pred_interval": {
        "start": 1469.2,
        "end": 1471.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 91.84000000000015,
        "end": 87.5,
        "average": 89.67000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.7902765274047852,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the woman speaks about fear of ants immediately after the man's prompt and even quotes her line, but the provided anchor/target timestamps are significantly different from the ground truth, so timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says to write things down on paper and give it to the doctor, when does he mention a doctor refusing to look at the paper?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1484.96,
        "end": 1490.0
      },
      "pred_interval": {
        "start": 1449.5,
        "end": 1454.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.460000000000036,
        "end": 35.200000000000045,
        "average": 35.33000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.4233576642335766,
        "text_similarity": 0.8482961654663086,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies both utterances and their causal order, but the provided timestamps\u2014especially the target (off by ~35s)\u2014are substantially inaccurate, so factual timing is incorrect despite semantic match."
      }
    },
    {
      "question_id": "002",
      "question": "While the woman discusses prioritizing cognition, when does she state that she would rather be in pain than have her mental capacity harmed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1534.64,
        "end": 1542.24
      },
      "pred_interval": {
        "start": 1508.9,
        "end": 1513.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.74000000000001,
        "end": 28.74000000000001,
        "average": 27.24000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.48148148148148145,
        "text_similarity": 0.884284496307373,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the anchor/target content and their semantic relation (E2 occurs within the discussion of cognition), but it gives incorrect temporal boundaries\u2014E2's timestamps are substantially earlier than the ground truth and the anchor timestamps are omitted\u2014so the temporal alignment is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'Nord, what is that?', when does the woman state what NORD stands for?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.4,
        "end": 1615.4
      },
      "pred_interval": {
        "start": 1626.1,
        "end": 1629.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.699999999999818,
        "end": 14.0,
        "average": 13.349999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.3673469387755102,
        "text_similarity": 0.762418270111084,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the event order and that the woman's reply immediately follows the question, but it gives substantially different timestamps (about +13s offset) and a slightly different phrasing ('Diseases' vs 'Disease'), so it does not match the ground-truth timing and wording closely enough."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says 'I read that I need to start this at 30', when does she explain why she needs the doctor to order it?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1692.24,
        "end": 1711.28
      },
      "pred_interval": {
        "start": 1663.9,
        "end": 1666.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.339999999999918,
        "end": 45.07999999999993,
        "average": 36.70999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.42622950819672134,
        "text_similarity": 0.6958216428756714,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies an explanation following the anchor but gives incorrect timestamps and misstates the content (saying 'insurance needs to approve' rather than 'I need you to order it'), which contradicts key factual elements of the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman explains how to mirror a planned course of action, when does she suggest asking the doctor what they heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.0,
        "end": 1799.8
      },
      "pred_interval": {
        "start": 1823.8,
        "end": 1825.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.799999999999955,
        "end": 25.600000000000136,
        "average": 26.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.6958829164505005,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the events, their order ('after'), and the suggested question text, but the absolute timestamps are substantially off (predicted ~1822\u20131825s vs. reference 1789.4\u20131799.8s), so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the man advises to 'just dig' and not use a medical dictionary, when does he ask if medical language can be 'dumbed down'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1836.56,
        "end": 1841.52
      },
      "pred_interval": {
        "start": 1852.7,
        "end": 1855.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.1400000000001,
        "end": 14.079999999999927,
        "average": 15.110000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.22807017543859648,
        "text_similarity": 0.5159814953804016,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the same utterances and the 'after' relationship, but the reported timestamps are substantially off from the ground truth (each event is ~20\u201340 seconds later than the reference), so the timing information is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks what to do when doctors look rushed, when does the woman describe slowing down and capturing their attention?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1965.6,
        "end": 1973.5
      },
      "pred_interval": {
        "start": 1996.3,
        "end": 2012.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.700000000000045,
        "end": 38.59999999999991,
        "average": 34.64999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.21848739495798322,
        "text_similarity": 0.6834124326705933,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the correct events and 'after' relationship and reproduces the woman's advice about pausing and slowing down, but the provided timestamps are substantially shifted later (by ~35\u201340s) and the target end time is much longer than the reference, so the timing is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes suggesting a doctor might be having a bad day, when does the man humorously ask if doctors have bad days?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2002.5,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 2044.9,
        "end": 2047.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.40000000000009,
        "end": 43.799999999999955,
        "average": 43.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.33027522935779813,
        "text_similarity": 0.6711599230766296,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the conversational content and that the man's line follows immediately, but the timestamps are substantially different from the ground truth (off by ~43 seconds), so the key factual timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man introduces the 'five practical tips to advocate for yourself', when does the woman begin talking about writing down questions?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2195.28,
        "end": 2199.7
      },
      "pred_interval": {
        "start": 2160.0,
        "end": 2165.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.2800000000002,
        "end": 34.69999999999982,
        "average": 34.99000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2268041237113402,
        "text_similarity": 0.5797223448753357,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the relative relation ('after') and identifies the same events, but the provided timestamps are substantially earlier (by ~30\u201345s) than the ground truth, so the temporal grounding is inaccurate despite correct qualitative cues."
      }
    },
    {
      "question_id": "002",
      "question": "During the man's explanation about preparing beforehand, when does he demonstrate by pointing to his neck?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.0,
        "end": 2237.0
      },
      "pred_interval": {
        "start": 2175.0,
        "end": 2180.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 60.0,
        "end": 57.0,
        "average": 58.5
      },
      "rationale_metrics": {
        "rouge_l": 0.25225225225225223,
        "text_similarity": 0.8583614826202393,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the neck-pointing gesture and the 'during' relationship, but the provided anchor and target timestamps are substantially different from the ground-truth times, missing the key temporal alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the man describes getting dizzy when walking up and down stairs, when does the woman mention repeating back what was heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2316.0,
        "end": 2317.0
      },
      "pred_interval": {
        "start": 2491.0,
        "end": 2501.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 175.0,
        "end": 184.0,
        "average": 179.5
      },
      "rationale_metrics": {
        "rouge_l": 0.18965517241379312,
        "text_similarity": 0.7159314155578613,
        "llm_judge_score": 3,
        "llm_judge_justification": "While the predicted answer correctly identifies the relation as 'after', it mislocates both events by large time offsets, misattributes the speaker for E1, and gives a different E2 span and content, so it largely fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman expresses her inability to distract herself from the pain, when does the man advise her to be specific?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.7,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2453.0,
        "end": 2465.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 84.30000000000018,
        "end": 95.5,
        "average": 89.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7508860230445862,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and the 'after' relation and even matches quoted content, but the provided timestamps are substantially off (~80s later) compared to the reference, which is a significant factual error for a temporal question."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says 'document everything', when does the woman affirm the advice and tell viewers to take notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2504.5,
        "end": 2506.0
      },
      "pred_interval": {
        "start": 2672.2,
        "end": 2675.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 167.69999999999982,
        "end": 169.0,
        "average": 168.3499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.38461538461538464,
        "text_similarity": 0.5701209902763367,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the exchanged lines and their order ('after'), but the timestamps are substantially incorrect (predicted ~2670\u20132675s vs. ground truth 2499.9\u20132506.0s), so the temporal alignment is wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes asking if one should ask permission before recording their doctor, when does the woman respond?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2531.6,
        "end": 2533.5
      },
      "pred_interval": {
        "start": 2687.8,
        "end": 2689.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 156.20000000000027,
        "end": 155.9000000000001,
        "average": 156.05000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.2142857142857143,
        "text_similarity": 0.516857385635376,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the woman's response content and that it occurs after the man's question, but the provided timestamps differ substantially from the ground truth (off by ~155s), so the temporal localization is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman begins explaining the hope that doctors will focus more on patients with AI recording, when does she explain why she almost always checks her online appointment notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.0,
        "end": 2579.0
      },
      "pred_interval": {
        "start": 2700.2,
        "end": 2705.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 134.19999999999982,
        "end": 126.30000000000018,
        "average": 130.25
      },
      "rationale_metrics": {
        "rouge_l": 0.20202020202020202,
        "text_similarity": 0.4678767919540405,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the relationship ('after') and the quoted content, but the timestamps for both events are substantially different from the ground truth, so the answer is largely factually incorrect on timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks if one should be assertive, when does he introduce the topic of emotional intelligence?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2701.0,
        "end": 2710.0
      },
      "pred_interval": {
        "start": 3278.0,
        "end": 3284.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 577.0,
        "end": 574.0,
        "average": 575.5
      },
      "rationale_metrics": {
        "rouge_l": 0.31067961165048547,
        "text_similarity": 0.7073812484741211,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the two utterances, their semantic content and the immediate 'after' relationship, but the absolute timestamps differ from the ground truth (shifted intervals) rather than matching the provided intervals exactly."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man says 'You wanna learn some breathing control', when does he start describing box breathing?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.0,
        "end": 2747.0
      },
      "pred_interval": {
        "start": 3316.0,
        "end": 3326.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 576.0,
        "end": 579.0,
        "average": 577.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3564356435643564,
        "text_similarity": 0.7460147738456726,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the box-breathing description follows the suggestion and captures the content, but the absolute timestamps are substantially off (mismatched by several minutes) and the segment boundaries/durations disagree with the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "While the man is saying 'If you want, share your story in the comments', when is the 'COMMENT BELOW' graphic displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 2857.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.0,
        "end": 66.0,
        "average": 68.0
      },
      "rationale_metrics": {
        "rouge_l": 0.27272727272727276,
        "text_similarity": 0.6239668130874634,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation (the graphic is displayed during the speech) but the reported timestamps are substantially wrong and the anchor event timing/duration is mismatched versus the ground truth, so key factual timing details are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the thumbs up icon appears on screen, when is the next graphic ('COMMENT BELOW') displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2857.0,
        "end": 2862.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.0,
        "end": 61.0,
        "average": 62.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3296703296703297,
        "text_similarity": 0.8019254207611084,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction names the same two graphics and the relative order ('after') but the timestamps and durations are substantially incorrect (off by ~58\u201363 seconds and wrong disappearance times), so it fails to match the correct factual timing."
      }
    },
    {
      "question_id": "001",
      "question": "After Marissa Fourie introduces herself, when does she mention cross-cultural communication?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 34.2,
        "end": 36.5
      },
      "pred_interval": {
        "start": 35.0,
        "end": 37.0
      },
      "iou": 0.5357142857142863,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7999999999999972,
        "end": 0.5,
        "average": 0.6499999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.3013698630136986,
        "text_similarity": 0.7197975516319275,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the mention of 'cross-cultural communication' (timing close to the reference) and the 'after' relation, but it gives a significantly incorrect time for Marissa's introduction (16\u201317s vs. 8.1s), which is a key factual mismatch."
      }
    },
    {
      "question_id": "002",
      "question": "After mentioning cross-cultural communication, when does Marissa Fourie next mention personality-specific communication skills?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 37.0,
        "end": 39.0
      },
      "pred_interval": {
        "start": 38.0,
        "end": 40.0
      },
      "iou": 0.3333333333333333,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 1.0,
        "average": 1.0
      },
      "rationale_metrics": {
        "rouge_l": 0.35000000000000003,
        "text_similarity": 0.5818526744842529,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the two mentions and that the second follows immediately, but the reported timestamps are offset by about 1 second (E2 38.0\u201340.0s vs correct 37.0\u201339.0s) and it labels the relation 'after' rather than 'next'."
      }
    },
    {
      "question_id": "003",
      "question": "After encouraging viewers to join PhysioPlus, when does Marissa Fourie say 'See you there!'?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 62.9,
        "end": 63.7
      },
      "pred_interval": {
        "start": 68.0,
        "end": 69.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.100000000000001,
        "end": 5.299999999999997,
        "average": 5.199999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705885,
        "text_similarity": 0.6196444034576416,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the phrases, speaker, and the 'after' relation, but the timestamps are substantially inaccurate (shifted ~15s later than the ground truth), so it fails on key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes mentioning \"the dosage in each area\", when does the woman in blue gloves point to the glabella area of the patient's forehead?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 4.469,
        "end": 4.8
      },
      "pred_interval": {
        "start": 15.0,
        "end": 16.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.530999999999999,
        "end": 11.2,
        "average": 10.865499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.5776262879371643,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly identifies the 'after' relationship, its timestamps are substantially incorrect (predicted 12.0s and 15\u201316s vs ground truth 4.161s and 4.469\u20134.800s) and it omits the pointer visibility end time, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the dosage for the brow lift, when does the woman in blue gloves point to the patient's upper lip?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 12.121,
        "end": 12.5
      },
      "pred_interval": {
        "start": 37.0,
        "end": 38.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.878999999999998,
        "end": 25.5,
        "average": 25.1895
      },
      "rationale_metrics": {
        "rouge_l": 0.32098765432098764,
        "text_similarity": 0.7022867202758789,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the two events but gives timestamps that are far off (E1 34.0s vs 12.080s; E2 37\u201338s vs 12.121\u201312.500s) and weakens the relation to 'after' instead of the immediate 'once_finished', so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the dosage for the lip flip, when does the text \"TIME TO INJECT!\" appear on screen?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 18.291,
        "end": 21.0
      },
      "pred_interval": {
        "start": 59.0,
        "end": 60.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.709,
        "end": 39.0,
        "average": 39.8545
      },
      "rationale_metrics": {
        "rouge_l": 0.27027027027027023,
        "text_similarity": 0.5667853951454163,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is largely incorrect: it misidentifies the anchor event (chin dosage vs lip flip), gives times that differ dramatically (15.067s vs 57.0s for E1; 18.291s vs 59\u201360s for E2), and the duration/relation do not match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host welcomes Rich, when does Rich begin his response?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 33.015,
        "end": 34.078
      },
      "pred_interval": {
        "start": 31.8,
        "end": 32.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2149999999999999,
        "end": 1.8780000000000001,
        "average": 1.5465
      },
      "rationale_metrics": {
        "rouge_l": 0.3661971830985915,
        "text_similarity": 0.8455053567886353,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the correct temporal relation ('immediately after') but misstates both timestamps (host at 31.333s vs 31.8s predicted, and Rich at 33.015s vs 32.0s predicted) and invents an end time; these factual timing errors are significant."
      }
    },
    {
      "question_id": "002",
      "question": "While Rich is explaining how medicine may have let relationships with patients deteriorate, when does he say that scientific facts will protect us?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 89.0,
        "end": 93.76
      },
      "pred_interval": {
        "start": 102.3,
        "end": 103.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.299999999999997,
        "end": 9.83999999999999,
        "average": 11.569999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.16129032258064516,
        "text_similarity": 0.5974557995796204,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the phrase and that it occurs during Rich's explanation, but it gives an incorrect timestamp for E2 (102.3\u2013103.6s vs. reference 89.0\u201393.76s) and omits the E1 start time, so the timing alignment is wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks what trust looks like in the future with intermediaries, when does Rich first discuss the stethoscope in relation to technology in medicine?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 112.0,
        "end": 113.0
      },
      "pred_interval": {
        "start": 138.2,
        "end": 139.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.19999999999999,
        "end": 26.0,
        "average": 26.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.20454545454545456,
        "text_similarity": 0.7093721032142639,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that Rich discusses the stethoscope after the host's question and reproduces the quoted content, but the provided timestamps are substantially incorrect (predicted ~137\u2013139s vs. ground truth 106.718s and 112.700s), so the timing is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the man in glasses finishes describing the giant TV screen in a new hospital exam room, when does the video show a patient interacting with a screen in a hospital bed?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 167.6,
        "end": 177.6
      },
      "pred_interval": {
        "start": 159.0,
        "end": 168.0
      },
      "iou": 0.021505376344086332,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.599999999999994,
        "end": 9.599999999999994,
        "average": 9.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.29126213592233,
        "text_similarity": 0.8633986711502075,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the target scene (a patient interacting with a screen) and the temporal relation 'after', but the provided timestamps substantially differ from the reference (anchor end 152.8s vs 157.8s; target start 167.6s vs 159.0s; target end 177.6s vs 168.0s), so it is factually inaccurate on key timing details."
      }
    },
    {
      "question_id": "002",
      "question": "While the interviewer asks if technology can bring doctors and patients closer together, when is he holding a small white 'Trust tv' card?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 178.0,
        "end": 183.5
      },
      "pred_interval": {
        "start": 195.0,
        "end": 198.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.0,
        "end": 14.5,
        "average": 15.75
      },
      "rationale_metrics": {
        "rouge_l": 0.45833333333333337,
        "text_similarity": 0.8488697409629822,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer's time intervals and quoted speech do not match the ground truth (178.0\u2013183.5s vs 191.8\u2013195.0s/195.0\u2013198.0s), and it incorrectly asserts a 'during' relation; it therefore fails to match the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the interviewer thanks Rich and says viewers learned a lot, when does Rich respond 'It's really a pleasure'?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 210.3,
        "end": 212.1
      },
      "pred_interval": {
        "start": 215.8,
        "end": 217.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.5,
        "end": 4.900000000000006,
        "average": 5.200000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3404255319148936,
        "text_similarity": 0.8501518368721008,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies Rich's line and the 'immediately after' relation, but it mislabels the anchor utterance and gives timestamps that conflict with the ground truth (events are ~15s off), so it is largely misaligned."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions learning about 'patient rapport', when does he discuss charting and interacting with other healthcare providers?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 2.075,
        "end": 9.55
      },
      "pred_interval": {
        "start": 2.0,
        "end": 9.2
      },
      "iou": 0.943708609271523,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.07500000000000018,
        "end": 0.3500000000000014,
        "average": 0.2125000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.2921348314606742,
        "text_similarity": 0.7252269983291626,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the interaction topic follows the rapport mention and E2 roughly overlaps the ground-truth interval, but it misplaces the anchor E1 (predicts 2.0s vs 0.031\u20131.734s), shifts E2 start/end times, and uses a less precise relation label ('after' vs 'once_finished')."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker talks about developing skills like putting an IV, when does he mention getting a patient discharged?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 15.42,
        "end": 24.583
      },
      "pred_interval": {
        "start": 16.6,
        "end": 18.8
      },
      "iou": 0.24009603841536611,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.1800000000000015,
        "end": 5.782999999999998,
        "average": 3.4814999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.21153846153846154,
        "text_similarity": 0.7205772399902344,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies and swaps the anchor/target, provides incorrect timestamps and event boundaries, and labels the relation as 'after' instead of the correct 'once_finished', contradicting the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Make their problem, your problem', when does he introduce the importance of self-care?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 45.009,
        "end": 48.396
      },
      "pred_interval": {
        "start": 40.5,
        "end": 42.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.509,
        "end": 6.396000000000001,
        "average": 5.452500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.5384615384615383,
        "text_similarity": 0.7780022621154785,
        "llm_judge_score": 4,
        "llm_judge_justification": "The anchor timing is acceptable (falls within the reference span), and the relation 'after' matches, but the predicted target timestamps are significantly incorrect (41.9\u201342.0s vs. reference 45.009\u201348.396s) and even overlap the anchor, so the prediction is factually inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker's introduction of herself, when does she mention specializing in wounds?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.605,
        "end": 26.329
      },
      "pred_interval": {
        "start": 63.0,
        "end": 66.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.394999999999996,
        "end": 39.671,
        "average": 40.033
      },
      "rationale_metrics": {
        "rouge_l": 0.23376623376623376,
        "text_similarity": 0.4136009216308594,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies a statement about specializing in wounds and the 'during' relationship, but it gives entirely different timestamps and mislabels the anchor content (name vs. job title), so it fails on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of 'getting the most out of your GP consultation', when does she mention that GP practices are getting a huge injection of funding?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.82,
        "end": 75.533
      },
      "pred_interval": {
        "start": 104.0,
        "end": 114.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.18000000000001,
        "end": 38.467,
        "average": 37.3235
      },
      "rationale_metrics": {
        "rouge_l": 0.26373626373626374,
        "text_similarity": 0.6233313083648682,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer identifies the correct content (the funding mention) but gives substantially incorrect timestamps for both events and mislabels the temporal relation (its own timestamps place E2 inside E1 rather than after), so it is largely factually incorrect. "
      }
    },
    {
      "question_id": "003",
      "question": "While the slide titled 'Appointments are precious' is on screen, when does the speaker mention that GP practices are moving back towards face-to-face appointments?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 123.0,
        "end": 129.0
      },
      "pred_interval": {
        "start": 188.0,
        "end": 195.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.0,
        "end": 66.0,
        "average": 65.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3404255319148936,
        "text_similarity": 0.6956359148025513,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives entirely different timestamps and an 'after' relationship, contradicting the reference which places the slide at ~100.74s and the speaker mentioning face-to-face appointments from 123.0\u2013129.0 while the slide remains displayed; only the quoted phrase matches. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that GP practices are very different places now, when does she begin listing the specific roles in a GP practice?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.0,
        "end": 204.0
      },
      "pred_interval": {
        "start": 150.44,
        "end": 152.88
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.56,
        "end": 51.120000000000005,
        "average": 51.84
      },
      "rationale_metrics": {
        "rouge_l": 0.27522935779816515,
        "text_similarity": 0.630529522895813,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the correct utterances (the phrase about GP practices and the start of listing staff) but the timestamps are substantially incorrect and the temporal relation is mischaracterized (E2 is not at 150s nor simultaneous with E1, and 'immediately after' contradicts the correct timing)."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide displays the question 'Does it need to be a GP?', when does the speaker mention that paramedics work in primary care?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "pred_interval": {
        "start": 177.6,
        "end": 181.12
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.400000000000006,
        "end": 58.879999999999995,
        "average": 58.14
      },
      "rationale_metrics": {
        "rouge_l": 0.5116279069767442,
        "text_similarity": 0.7860102653503418,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction identifies the same utterance content and labels the relation 'after' correctly, but both event timestamps are substantially incorrect (E1 and especially E2 are far off from the ground-truth times), so the temporal alignment is unreliable."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker talks about paramedics working in primary care, when does she begin to explain the role of Advanced Clinical Practitioners?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 241.0,
        "end": 249.0
      },
      "pred_interval": {
        "start": 189.44,
        "end": 190.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.56,
        "end": 59.0,
        "average": 55.28
      },
      "rationale_metrics": {
        "rouge_l": 0.2608695652173913,
        "text_similarity": 0.7687825560569763,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer gets the relation ('after') correct, it provides substantially incorrect timestamps for both the paramedics segment and the start of the Advanced Clinical Practitioners explanation (off by ~60s), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the problem of a wound on your foot, when does she strongly advise mentioning if you are diabetic?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 337.875,
        "end": 343.0
      },
      "pred_interval": {
        "start": 346.1,
        "end": 350.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.225000000000023,
        "end": 7.600000000000023,
        "average": 7.912500000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.6546411514282227,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly timestamps both the anchor and target (off by several seconds) and contradicts the correct 'immediately follows' timing\u2014although it correctly indicates the advice comes after the problem introduction, the temporal locations are substantially wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having a new wound on your leg, when does she suggest going to a local pharmacist for simple dressings?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 363.968,
        "end": 366.552
      },
      "pred_interval": {
        "start": 383.0,
        "end": 392.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.031999999999982,
        "end": 25.74799999999999,
        "average": 22.389999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.2549019607843137,
        "text_similarity": 0.8023864030838013,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the semantic relation ('after') and the content (nurse appointment followed by visiting a pharmacist), but the provided timestamps conflict substantially with the ground truth and ignore the absolute\u2192relative timing note, so it fails on the key factual requirement of correct time spans."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker explains that a nurse's appointment is needed for long-standing wounds, when does she advise to clearly state how long the wound has been there?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 409.579,
        "end": 439.62
      },
      "pred_interval": {
        "start": 428.5,
        "end": 432.5
      },
      "iou": 0.13315135980826207,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.920999999999992,
        "end": 7.1200000000000045,
        "average": 13.020499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2476190476190476,
        "text_similarity": 0.7868416905403137,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the instruction follows the nurse-appointment statement, but the provided timestamps are substantially inaccurate and do not match the reference intervals, so the answer is largely incorrect on the key factual element (timing)."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if you feel more short of breath, when does she state that a GP or nurse practitioner might be needed the same day?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 522.783,
        "end": 525.113
      },
      "pred_interval": {
        "start": 522.4,
        "end": 525.5
      },
      "iou": 0.7516129032258141,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.3830000000000382,
        "end": 0.3869999999999436,
        "average": 0.3849999999999909
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.5399075746536255,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the target utterance and its relation (it follows the breathlessness question) and its times are close to the reference, but the anchor timestamp is off by ~6 seconds from the ground truth, so the alignment is not fully accurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to measure your ankle and calf, when does she give an example of a calf measurement that would 'perk up more interest'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.623,
        "end": 586.297
      },
      "pred_interval": {
        "start": 577.2,
        "end": 585.2
      },
      "iou": 0.17335385291854474,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.423000000000002,
        "end": 1.09699999999998,
        "average": 3.759999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.6333248615264893,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gives times that substantially differ from the ground truth (anchor ~22s off; target start/end do not match, with only minor overlap) and adds an unsupported '50cm' example, so it is mostly incorrect despite partial temporal overlap."
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Photography', when does the speaker advise to 'expect to be asked for a photo'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 670.384,
        "end": 672.807
      },
      "pred_interval": {
        "start": 699.7,
        "end": 702.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.31600000000003,
        "end": 29.692999999999984,
        "average": 29.504500000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.3448275862068966,
        "text_similarity": 0.8455098867416382,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the utterance and the 'after' relation, but the anchor and target timestamps are substantially incorrect and do not match the ground-truth intervals, so the timing alignment is largely wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions some GP practices use video consultations, when does she state that a good quality photograph is better than a video?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.278,
        "end": 717.251
      },
      "pred_interval": {
        "start": 815.0,
        "end": 825.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 100.72199999999998,
        "end": 107.74900000000002,
        "average": 104.2355
      },
      "rationale_metrics": {
        "rouge_l": 0.24000000000000005,
        "text_similarity": 0.6138424873352051,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the utterance content and that the photograph remark follows the video-consultation mention, but it gives entirely incorrect timestamps and an invented span for E2, so the crucial temporal facts are wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the slide changes to 'Photography tips', when does the speaker begin discussing taking a close-up and further-away picture?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 738.601,
        "end": 740.91
      },
      "pred_interval": {
        "start": 843.0,
        "end": 848.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 104.399,
        "end": 107.09000000000003,
        "average": 105.74450000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.34285714285714286,
        "text_similarity": 0.7090163230895996,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the relation ('once_finished') is correct, both timestamps are wrong (off by ~107s) and the predicted E2 timing contradicts the ground truth, omitting the correct temporal offset between slide change and speech."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide changes to 'General top tips- face to face appointments', when does the speaker advise to 'Go suitably dressed'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 860.136,
        "end": 860.846
      },
      "pred_interval": {
        "start": 879.0,
        "end": 883.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.864000000000033,
        "end": 22.153999999999996,
        "average": 20.509000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.25641025641025644,
        "text_similarity": 0.6879937648773193,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the ground truth on both timestamps (ground truth: E1=805.957s, E2=860.136s; prediction: both at 879.0s) and on the relation (ground truth: 'after', prediction: 'once_finished' immediate). These factual/time errors make the answer largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises not to wear tight socks, trousers, or wellies, when does she suggest wearing something with quick access to lower limbs?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.0,
        "end": 877.5
      },
      "pred_interval": {
        "start": 871.5,
        "end": 877.3
      },
      "iou": 0.7166666666666591,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.5,
        "end": 0.20000000000004547,
        "average": 0.8500000000000227
      },
      "rationale_metrics": {
        "rouge_l": 0.29268292682926833,
        "text_similarity": 0.7512258887290955,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events, the quoted phrasing, and the temporal relation 'after'; timestamps largely match the reference with only a small start-time discrepancy (1.5s) and a negligible end-time difference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes advising not to make chit-chat about the weather, when does she advise not to dodge the real problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 893.0,
        "end": 894.5
      },
      "pred_interval": {
        "start": 896.4,
        "end": 902.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.3999999999999773,
        "end": 7.5,
        "average": 5.449999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.24691358024691357,
        "text_similarity": 0.6404935121536255,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the general ordering (E1 before E2) but both event time spans are incorrect and the relation label ('after') does not match the more specific 'once_finished'; key timing details are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker advises to take a list of the medications you are actually taking, when does she advise against describing tablets by their appearance?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 948.0,
        "end": 969.0
      },
      "pred_interval": {
        "start": 936.0,
        "end": 945.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.0,
        "end": 23.200000000000045,
        "average": 17.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.2619047619047619,
        "text_similarity": 0.7111347913742065,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor utterance and the 'after' relation and paraphrases the advice accurately, but the predicted time span for E2 is substantially earlier and much shorter than the reference E2 interval, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker advises speaking to the practice in advance about a relative, when does she explain the reason for this advance arrangement due to confidentiality?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1065.0,
        "end": 1095.0
      },
      "pred_interval": {
        "start": 1149.7,
        "end": 1168.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 84.70000000000005,
        "end": 73.5,
        "average": 79.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.12962962962962962,
        "text_similarity": 0.5475280284881592,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the basic ordering (E2 occurs after E1) but the timestamps are substantially offset from the ground truth and fail to capture the immediate 'once_finished' adjacency; it also adds an extra quoted utterance and timing details that do not match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker suggests writing things down before an appointment to help structure what you say, when does she first ask 'How did it start?' regarding the leg problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1130.415,
        "end": 1131.738
      },
      "pred_interval": {
        "start": 1177.0,
        "end": 1180.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.585000000000036,
        "end": 48.46199999999999,
        "average": 47.52350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.5686929225921631,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the correct temporal relation (immediate/once_finished) and event order, but the timestamps are substantially shifted from the ground truth and it adds an unrelated detail about mouth movement, so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes advising to ask to be referred to a specialist service, when does she start introducing the referrals examples?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.105,
        "end": 1249.385
      },
      "pred_interval": {
        "start": 1426.8,
        "end": 1428.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 178.69499999999994,
        "end": 178.71499999999992,
        "average": 178.70499999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666669,
        "text_similarity": 0.47675633430480957,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly identifies the 'after' relation and the sequence of events, but the timestamp values differ substantially from the ground truth (and the predicted times appear shifted), so it fails on key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that lymphoedema services can be patchy, when does she first advise writing to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.0,
        "end": 1378.0
      },
      "pred_interval": {
        "start": 1402.7,
        "end": 1405.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.700000000000045,
        "end": 27.200000000000045,
        "average": 26.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.15555555555555556,
        "text_similarity": 0.7588352560997009,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor utterance and the 'after' relation, but timestamps are substantially off and it fails to locate the actual E2 where the speaker first advises writing to your MP, instead giving a different exhortation (finding services/proactivity)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions that a GP will assess new leg swelling for onward referral, when does she explain there are many different causes?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1429.846,
        "end": 1432.0
      },
      "pred_interval": {
        "start": 1424.5,
        "end": 1426.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.346000000000004,
        "end": 5.2000000000000455,
        "average": 5.273000000000025
      },
      "rationale_metrics": {
        "rouge_l": 0.28260869565217395,
        "text_similarity": 0.6202008724212646,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the statements and the 'after' relation, but the timestamps are inaccurate\u2014the predicted anchor is ~19.5s later than the reference and the target ~3s earlier\u2014so the temporal alignment is off."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what information you could take with you, when does she suggest looking up the National Wound Care Strategy Lower Limb Recommendations?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1465.0,
        "end": 1469.5
      },
      "pred_interval": {
        "start": 1416.4,
        "end": 1424.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.59999999999991,
        "end": 45.09999999999991,
        "average": 46.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.2201834862385321,
        "text_similarity": 0.7136647701263428,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer correctly identifies the events and their 'after' relation and captures the utterances, but the timestamps are substantially earlier (by ~40\u201350s) than the ground truth, so the temporal localization is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions escalating concerns to the practice manager, when does she mention escalating concerns to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.6,
        "end": 1525.7
      },
      "pred_interval": {
        "start": 1459.2,
        "end": 1467.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.39999999999986,
        "end": 58.700000000000045,
        "average": 61.549999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.2545454545454545,
        "text_similarity": 0.6850802302360535,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies both events and the MP quote and keeps the order, but the timestamps substantially disagree with the reference and the relation label ('after' vs 'next') differs; these factual/time errors reduce alignment."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'I'll stop sharing', when does she start reading the first question from a viewer?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1574.5,
        "end": 1578.5
      },
      "pred_interval": {
        "start": 1542.0,
        "end": 1544.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.5,
        "end": 34.09999999999991,
        "average": 33.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7242060303688049,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that she reads questions after stopping sharing and conveys similar utterances, but the timestamps are substantially offset (\u224824s earlier) and the predicted E2 interval does not match the ground truth, so the answer is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially suggests the mum needs compression hosiery, when does she mention asking for an appointment with the nurse for stronger compression?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1654.942,
        "end": 1664.2
      },
      "pred_interval": {
        "start": 1720.0,
        "end": 1730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.05799999999999,
        "end": 65.79999999999995,
        "average": 65.42899999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.33628318584070793,
        "text_similarity": 0.8992213010787964,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mentions the same general events (recommendation about compression and asking nurse) and the relation 'after', but it misidentifies event roles and gives times that are substantially different from the ground truth, so it is largely temporally and locationally incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'That is such a good question', when does she state that self-diagnosis via the internet is never a good idea?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1757.815,
        "end": 1762.821
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1778.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.184999999999945,
        "end": 15.179000000000087,
        "average": 13.682000000000016
      },
      "rationale_metrics": {
        "rouge_l": 0.5263157894736842,
        "text_similarity": 0.7973411083221436,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer preserves the correct phrases and the 'after' relation, but it misplaces both anchor and target timestamps by a large margin (anchor ~83s late, target ~12\u201315s late), so it fails to accurately locate the events."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes that approaching a GP is about framing the conversation, when does she tell the viewer not to worry about being labeled a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1795.335,
        "end": 1798.383
      },
      "pred_interval": {
        "start": 1785.0,
        "end": 1791.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.335000000000036,
        "end": 7.383000000000038,
        "average": 8.859000000000037
      },
      "rationale_metrics": {
        "rouge_l": 0.4655172413793104,
        "text_similarity": 0.79768967628479,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the reassuring line ('please don't worry about things like that') and the 'after' relation, but it mislabels the anchor utterance content and gives substantially different timestamps for both events (E2 ~10s early) which indicates temporal and contextual misalignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker first says, 'Please don't worry about things like that', when does she next advise not to worry about being labelled as a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1827.66,
        "end": 1831.19
      },
      "pred_interval": {
        "start": 1858.7,
        "end": 1863.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.039999999999964,
        "end": 31.909999999999854,
        "average": 31.47499999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.17948717948717946,
        "text_similarity": 0.695857048034668,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the same verbal phrases and the 'after' relationship, but the timestamps are significantly different from the reference (predicted ~1858\u20131863s vs correct ~1787\u20131831s), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks, 'What can I do to maintain healthy legs or feet so I don't get any problems?', when does she start listing actions like 'walk' and 'legs up'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1865.412,
        "end": 1883.383
      },
      "pred_interval": {
        "start": 1957.0,
        "end": 1960.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 91.58799999999997,
        "end": 76.61699999999996,
        "average": 84.10249999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.3409090909090909,
        "text_similarity": 0.6808631420135498,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor question, the target phrase ('Walk... legs up'), and that the target occurs after the anchor, but both reported timestamps are significantly and consistently later than the ground truth, so the key factual timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks how much is in the GP curriculum, when does she say 'I don't know'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1983.7,
        "end": 1984.201
      },
      "pred_interval": {
        "start": 2110.0,
        "end": 2112.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 126.29999999999995,
        "end": 127.79899999999998,
        "average": 127.04949999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195122,
        "text_similarity": 0.5540868043899536,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target pair and their immediate-after relationship, but the timestamps are substantially incorrect (off by ~128s) and the response adds an unnecessary claim about mouth movements not present in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'I think it is something that Legs Matter can help with', when does she discuss Legs Matter influencing GP curriculums?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2004.063,
        "end": 2009.063
      },
      "pred_interval": {
        "start": 2123.0,
        "end": 2130.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 118.9369999999999,
        "end": 120.9369999999999,
        "average": 119.9369999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2093023255813954,
        "text_similarity": 0.5820856094360352,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are far from the ground-truth (predicted 2123.0\u20132130.0 vs correct 1991.448\u20132009.063), the predicted target even starts at the same time as the anchor rather than occurring after it, and it includes unsupported details about mouth movements/audio, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks if seeing a nurse practitioner is appropriate, when does she state that nurse practitioners are 'extremely experienced clinicians'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2062.584,
        "end": 2066.851
      },
      "pred_interval": {
        "start": 2208.0,
        "end": 2212.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 145.41600000000017,
        "end": 145.1489999999999,
        "average": 145.28250000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962267,
        "text_similarity": 0.5109537839889526,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the target phrase and that it occurs immediately after the question, but the provided timestamps are substantially incorrect (\u2248149s later) compared to the reference, so the temporal alignment is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I understand the issue of smartphones and taking pictures too\", when does she first ask \"is there somebody who can help you?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2174.0,
        "end": 2176.0
      },
      "pred_interval": {
        "start": 2204.7,
        "end": 2206.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.699999999999818,
        "end": 30.699999999999818,
        "average": 30.699999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.16470588235294117,
        "text_similarity": 0.5738081932067871,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the temporal ordering (target follows anchor) but misreports the absolute timestamps and durations by a large margin (~37s), so it is factually inaccurate relative to the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "During the period when the speaker discusses the importance of planning phone calls to the GP, when does she ask, \"What am I feeling?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2197.721,
        "end": 2198.663
      },
      "pred_interval": {
        "start": 2156.8,
        "end": 2158.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.92099999999982,
        "end": 40.0630000000001,
        "average": 40.49199999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.2247191011235955,
        "text_similarity": 0.7245135307312012,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that E2 occurs during E1, but the provided timestamps do not match the ground truth: the predicted anchor is a narrower subset and the predicted target time (~2156.8\u20132158.6s) is about 39 seconds earlier than the reference (2197.721\u20132198.663s), so the timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once Dr. Angelos finishes introducing Dr. Tolchin, when does Dr. Tolchin begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.128,
        "end": 109.393
      },
      "pred_interval": {
        "start": 171.5,
        "end": 172.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.372,
        "end": 63.40700000000001,
        "average": 64.8895
      },
      "rationale_metrics": {
        "rouge_l": 0.375,
        "text_similarity": 0.7351674437522888,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the 'once_finished' relation and speaker change, but its timestamps (\u2248171.5s/172.8s) differ substantially from the ground-truth times (100.128s/105.128s), so it fails to provide the correct timing."
      }
    },
    {
      "question_id": "002",
      "question": "After Dr. Angelos describes Dr. Tolchin's research on crisis standards of care, when does he describe his research on functional neurological disorders and epilepsy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.426,
        "end": 116.456
      },
      "pred_interval": {
        "start": 134.5,
        "end": 138.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.074,
        "end": 22.34400000000001,
        "average": 50.209
      },
      "rationale_metrics": {
        "rouge_l": 0.326530612244898,
        "text_similarity": 0.702235221862793,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer largely misstates the timestamps (E1/E2 times are drastically different from the ground truth) and hallucinates details; only the qualitative 'after' relationship matches. This contradicts the correct temporal intervals and is therefore mostly incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating the second learning objective, when does he start explaining the third learning objective?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 181.0
      },
      "pred_interval": {
        "start": 291.5,
        "end": 292.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 124.5,
        "end": 111.5,
        "average": 118.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195125,
        "text_similarity": 0.47441667318344116,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is factually incorrect on timing (claims 291.5s vs reference 16.4s/17.0s), misstates the start relation, and adds unsupported details about wording and visuals, so it does not match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'Why conduct clinical ethics consultations?' is displayed, when does the speaker discuss moral distress among clinicians and staff?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.4,
        "end": 304.0
      },
      "pred_interval": {
        "start": 304.0,
        "end": 310.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.600000000000023,
        "end": 6.0,
        "average": 12.300000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.6709842681884766,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the discussion occurs during the slide, but it omits the precise start times and gives an incorrect end time (310.0s vs the correct 304.0s) and lacks the slide appearance/change timestamps, so it is incomplete and partly inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that clinical ethics consultations were helpful, when does he state that they were more likely to achieve consensus in clinical decisions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 350.2,
        "end": 357.0
      },
      "pred_interval": {
        "start": 342.4,
        "end": 349.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.800000000000011,
        "end": 7.5,
        "average": 7.650000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.3943661971830986,
        "text_similarity": 0.5684629678726196,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer has substantially incorrect timestamps for both events and even places the target starting simultaneously with the anchor (contradicting the correct temporal order), so it fails to match the reference despite agreeing on the label 'after'."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of resource utilization, when does he specifically state that there was a reduced length of stay?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 438.9,
        "end": 450.3
      },
      "pred_interval": {
        "start": 367.7,
        "end": 375.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.19999999999999,
        "end": 74.40000000000003,
        "average": 72.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.4117647058823529,
        "text_similarity": 0.7624294757843018,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly matches the anchor timing but gives entirely incorrect start/end times for the target (367.7\u2013375.9s vs. 438.9\u2013450.3s) and thus misrepresents the temporal relation; major factual timing errors make it largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'to look at disparities', when does he begin to introduce Ellen Fox's team and their survey?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 493.5,
        "end": 499.0
      },
      "pred_interval": {
        "start": 410.4,
        "end": 414.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.10000000000002,
        "end": 84.39999999999998,
        "average": 83.75
      },
      "rationale_metrics": {
        "rouge_l": 0.4383561643835616,
        "text_similarity": 0.730675220489502,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer matches the temporal relation ('immediately after'/'once_finished') but gives completely different and incorrect timestamps for both anchor and target, contradicting the ground truth and thus failing on factual timing accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'hospitals with less than 400 beds', when does he mention 'little or no growth over that two decade period'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 527.809,
        "end": 530.91
      },
      "pred_interval": {
        "start": 656.78,
        "end": 664.29
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 128.971,
        "end": 133.38,
        "average": 131.1755
      },
      "rationale_metrics": {
        "rouge_l": 0.3902439024390244,
        "text_similarity": 0.7168302536010742,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation as 'immediately after' but the reported timestamps for both events are substantially wrong compared to the reference and it introduces unsupported/casual claims (direct consequence, no visual cue), so key factual elements are incorrect or hallucinated."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide titled 'Prior Healthcare System Ethics Committees' is fully displayed, when do the images of the six hospitals with their bed counts appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.7,
        "end": 552.0
      },
      "pred_interval": {
        "start": 686.12,
        "end": 687.52
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 134.41999999999996,
        "end": 135.51999999999998,
        "average": 134.96999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.288135593220339,
        "text_similarity": 0.75356125831604,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives incorrect timestamps (686.12s vs. reference 536.2s for the anchor and 551.7\u2013552.0s for the target), wrongly states the events are simultaneous rather than the target occurring after the anchor, and adds unsupported details\u2014contradicting the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the number of ethics consults at Yale New Haven Hospital increased from 50 to 239, when does he describe this as 'approximately a five-fold increase in consult volume'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.7,
        "end": 624.7
      },
      "pred_interval": {
        "start": 708.11,
        "end": 714.41
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 85.40999999999997,
        "end": 89.70999999999992,
        "average": 87.55999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.35772357723577236,
        "text_similarity": 0.7739476561546326,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the event ordering and paraphrase right, but the timestamps are substantially wrong (off by ~93\u2013100s) and it adds an unfounded visual-cue claim, so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially mentions the 'Community Bioethics Forum', when does he start describing its community members?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 887.216,
        "end": 905.918
      },
      "pred_interval": {
        "start": 872.0,
        "end": 875.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.216000000000008,
        "end": 30.918000000000006,
        "average": 23.067000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.23655913978494622,
        "text_similarity": 0.8763405084609985,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the anchor phrase and that the speaker then describes community members (relation 'after'), but it gives significantly incorrect timestamps for both the anchor and target compared to the ground truth, failing on key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that the primary focus of the Center for Clinical Ethics has been ethics education, when does he start listing 'Systemwide Ethics Forum and Newsletter'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1055.54,
        "end": 1069.28
      },
      "pred_interval": {
        "start": 877.0,
        "end": 880.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 178.53999999999996,
        "end": 189.27999999999997,
        "average": 183.90999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.1836734693877551,
        "text_similarity": 0.8709816336631775,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gets only the temporal relation ('after') correct but misidentifies both the anchor and target timestamps and even the target content, inventing unrelated dialogue and times rather than the specified segments."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker lists 'ICU Walk Rounds', when does he mention 'HEC-C Certification'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1048.0,
        "end": 1052.0
      },
      "pred_interval": {
        "start": 885.0,
        "end": 888.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 163.0,
        "end": 164.0,
        "average": 163.5
      },
      "rationale_metrics": {
        "rouge_l": 0.26804123711340205,
        "text_similarity": 0.8843541145324707,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction mentions similar items but gives completely incorrect timestamps (885s vs 1042\u20131052s), alters the anchor wording, overlaps the anchor and target times, and mislabels the temporal relation, so it does not match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"ethics consultation services,\" when does he start talking about collecting feedback?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.8,
        "end": 1249.8
      },
      "pred_interval": {
        "start": 1245.8,
        "end": 1247.0
      },
      "iou": 0.13333333333333838,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 2.7999999999999545,
        "average": 3.8999999999999773
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424246,
        "text_similarity": 0.49658891558647156,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the ground truth timings and relation: it shifts the anchor from 1238.9s to 1245.8s, misstates the target start time (1245.8s vs 1240.8s), and changes the relation to 'immediately after' while adding unwarranted detail about online surveys."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that participant satisfaction is not the \"be-all and end-all,\" when does he say they have begun the survey process with clinicians?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.3,
        "end": 1282.8
      },
      "pred_interval": {
        "start": 1284.2,
        "end": 1287.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.900000000000091,
        "end": 4.7000000000000455,
        "average": 5.300000000000068
      },
      "rationale_metrics": {
        "rouge_l": 0.3023255813953488,
        "text_similarity": 0.5317538380622864,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the event content but misstates both timestamps (should be 1275.0s and 1278.3s) and even lists the anchor and target starting at the same time, and the relation label differs, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes describing the first pie chart about helpful advice/guidance, when does the second pie chart about communication appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1367.5,
        "end": 1367.9
      },
      "pred_interval": {
        "start": 1317.2,
        "end": 1318.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.299999999999955,
        "end": 49.80000000000018,
        "average": 50.05000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.5691599249839783,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer mis-timestamps both events by large margins (E1: 1317.2s vs 1356.0s; E2: ~1317.2\u20131318.1s vs 1376.5s) and even places the second chart effectively simultaneous with E1 rather than ~20.5s afterward; although it implies a sequential relation, the substantial timing errors and contradictory E2 placement make it largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he wants to turn to some of the organizational ethics consultation work, when does the slide showing the 'Organizational ethics consultations' table appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1472.0,
        "end": 1472.5
      },
      "pred_interval": {
        "start": 1424.7,
        "end": 1427.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.299999999999955,
        "end": 45.299999999999955,
        "average": 46.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.25742574257425743,
        "text_similarity": 0.6528182029724121,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timings differ substantially from the ground truth (E1 ~9s early, E2 ~48s early) and it mischaracterizes the relationship by placing the slide during the speaker's introduction rather than after it, so the answer is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining that organizational ethics work is new to them, when do they state that it began during the COVID pandemic?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1469.5,
        "end": 1472.0
      },
      "pred_interval": {
        "start": 1464.3,
        "end": 1468.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.2000000000000455,
        "end": 3.2999999999999545,
        "average": 4.25
      },
      "rationale_metrics": {
        "rouge_l": 0.24742268041237114,
        "text_similarity": 0.6843104958534241,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys the temporal order (E1 before E2) but the event timestamps are substantially off (E1 ~15s early; E2 start/end several seconds early) and it fails to capture the immediacy/consecutive timing indicated in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the 'Organizational ethics consultations' table, when does the speaker mention the 'Blood products scarcity protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1510.0,
        "end": 1513.0
      },
      "pred_interval": {
        "start": 1480.8,
        "end": 1484.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.200000000000045,
        "end": 28.200000000000045,
        "average": 28.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.2268041237113402,
        "text_similarity": 0.6404856443405151,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states a 'during' relationship but misidentifies and swaps the events and their times (speaker mention is at 1510\u20131513 in the reference, not ~1480.8s, and the table is shown 1474\u20131573, not 1480.8\u20131484.8), so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the 'sequential organ failure assessment or SOFA score', when does he begin to explain what it is?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1647.6,
        "end": 1697.0
      },
      "pred_interval": {
        "start": 1629.2,
        "end": 1637.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.399999999999864,
        "end": 59.299999999999955,
        "average": 38.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.18749999999999997,
        "text_similarity": 0.5775415301322937,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer superficially matches the relationship (explanation follows introduction) but the timestamps are substantially incorrect (predicted E1/E2 around 1629\u20131637s vs reference 1621\u20131629s and 1647.6\u20131697s) and it includes extra/unverified visual/audio cues, so it fails factual alignment."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that '70% of publicly available crisis standards of care used either the SOFA score or a modified version', when does he mention the SOFA score being used in Alaska?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1726.0,
        "end": 1733.0
      },
      "pred_interval": {
        "start": 1668.0,
        "end": 1677.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.0,
        "end": 56.0,
        "average": 57.0
      },
      "rationale_metrics": {
        "rouge_l": 0.20183486238532108,
        "text_similarity": 0.5411398410797119,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the target (Alaska) and the temporal relation as 'after', but the provided timestamps for both anchor and target differ substantially from the reference (1664.2/1668.0s vs. 1705.0\u20131712.0s and 1726.0\u20131733.0s), so it fails to match the correct events and timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the 'SOFA Disparities' slide appears, when does the speaker begin discussing concerns about the score's accuracy and contributions to disparities?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1770.0,
        "end": 1776.606
      },
      "pred_interval": {
        "start": 1777.0,
        "end": 1800.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 23.394000000000005,
        "average": 15.197000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.732356071472168,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction names the same events but gives significantly different timestamps and wrongly asserts they occur simultaneously; it places the anchor at 1777.0s (correct 1762.0s) and the target at 1777.0s (correct 1770.0\u20131776.606s), so the temporal relationship and timings are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that the center was able to test the triage protocol before it was used, when does he state that they developed a SOFA calculation system?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1799.553,
        "end": 1807.997
      },
      "pred_interval": {
        "start": 1787.5,
        "end": 1798.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.053000000000111,
        "end": 9.497000000000071,
        "average": 10.775000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.31111111111111117,
        "text_similarity": 0.6916042566299438,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly identifies both anchor and target timestamps and their temporal relationship (predicting overlap/during), whereas the reference places E2 after E1 with specific later times; this contradicts the ground truth. The only commonality is mention of a SOFA system, but timing and relation are wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the retrospective cohort study, when does he detail the demographic breakdown of the patients?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1846.122,
        "end": 1858.077
      },
      "pred_interval": {
        "start": 1837.0,
        "end": 1857.0
      },
      "iou": 0.5161076054466921,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.122000000000071,
        "end": 1.0769999999999982,
        "average": 5.099500000000035
      },
      "rationale_metrics": {
        "rouge_l": 0.2619047619047619,
        "text_similarity": 0.6415582299232483,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction has major timing errors: it places E1 at 1837.0s versus the true end at 1787.983s, and it incorrectly starts E2 at 1837.0s instead of 1846.122s (E2 end is close). It also states the demographics occur 'during' the same sentence, contradicting the correct 'after' relationship."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker highlights that non-Hispanic Black patients had greater odds of an elevated SOFA score, when does he state that no significant difference by race in mortality was found when controlling for other factors?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.642,
        "end": 1879.694
      },
      "pred_interval": {
        "start": 1878.0,
        "end": 1892.0
      },
      "iou": 0.09227584704215953,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.357999999999947,
        "end": 12.30600000000004,
        "average": 8.331999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.574575662612915,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer captures the same semantic content (no significant difference in mortality when controlling for covariates) but the timestamps and event segmentation are substantially incorrect and it misstates the relationship by conflating/overlapping E1 and E2, contradicting the provided temporal boundaries."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the early small cohort out of Wuhan, China, when does he state that subsequent larger cohorts in the United States did not show such high accuracy rates?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.0,
        "end": 1966.5
      },
      "pred_interval": {
        "start": 2010.0,
        "end": 2018.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.0,
        "end": 51.5,
        "average": 51.25
      },
      "rationale_metrics": {
        "rouge_l": 0.23931623931623935,
        "text_similarity": 0.8370654582977295,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the semantic relation (the target follows the anchor) and the quoted target statement, but both event timestamps and boundaries are substantially incorrect compared to the reference, so it fails on factual temporal alignment."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'This graph here is a calibration curve', when does he explain that the diagonal line shows a perfectly calibrated predictor of mortality?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2014.0,
        "end": 2020.0
      },
      "pred_interval": {
        "start": 2101.4,
        "end": 2109.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 87.40000000000009,
        "end": 89.0,
        "average": 88.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.25423728813559326,
        "text_similarity": 0.824726939201355,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the explanation immediately follows the graph identification, but the reported timestamps are substantially different from the ground truth (off by roughly 80\u201390 seconds), so the timing information is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that SOFA predicted mortality with less accuracy than age in their own COVID cohort, when does he mention that SOFA predicted mortality with better accuracy than age in the pre-COVID eICU cohort?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2066.0,
        "end": 2069.0
      },
      "pred_interval": {
        "start": 2124.5,
        "end": 2128.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.5,
        "end": 59.30000000000018,
        "average": 58.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.7449460029602051,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the content and temporal order (the contrast statement follows the COVID-cohort statement) but the provided timestamps for both anchor and target are substantially different from the ground truth, so the answer is factually incorrect on the requested timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the Omicron surge increasing, when does he talk about working with the healthcare system's legal team?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2153.6,
        "end": 2174.93
      },
      "pred_interval": {
        "start": 2175.7,
        "end": 2183.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.09999999999991,
        "end": 8.070000000000164,
        "average": 15.085000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.10526315789473684,
        "text_similarity": 0.3771160840988159,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the correct content (mention of the healthcare system's legal team) but the timestamps and anchor/target alignment are substantially off from the ground truth (predicted segments are ~20\u201340s later), so the timing is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the policy was active until late February of 2022, when does the first 'Scope of protocol' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2194.0,
        "end": 2234.0
      },
      "pred_interval": {
        "start": 2217.4,
        "end": 2219.4
      },
      "iou": 0.05,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.40000000000009,
        "end": 14.599999999999909,
        "average": 19.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3428571428571428,
        "text_similarity": 0.8060412406921387,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the order and relative 2s gap right but gives incorrect absolute timestamps (about 25s later than the reference) and omits the slide's end time, so it is factually inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the second 'Scope of protocol' slide appears, when does the speaker mention 'renal replacement therapy'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2263.679,
        "end": 2254.733
      },
      "pred_interval": {
        "start": 2248.4,
        "end": 2251.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.278999999999996,
        "end": 3.2330000000001746,
        "average": 9.256000000000085
      },
      "rationale_metrics": {
        "rouge_l": 0.32911392405063294,
        "text_similarity": 0.7845103740692139,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the phrase and that it occurs after the slide, but both timestamps are substantially inaccurate (E1 is ~15.7s off and E2's start/end and interval do not match the reference), so it fails to match the ground-truth timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that goals of care discussions significantly changed, when does the speaker mention that patients were more likely to choose limited life-sustaining interventions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2320.0,
        "end": 2327.0
      },
      "pred_interval": {
        "start": 2325.0,
        "end": 2334.0
      },
      "iou": 0.14285714285714285,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 7.0,
        "average": 6.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3529411764705882,
        "text_similarity": 0.5974690914154053,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events, their quoted content, and the 'after' relation; timestamps are slightly off (E1 by ~3s, E2 start by ~5s and an unnecessary end time), but no factual contradictions or hallucinations."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states he wants to highlight some takeaway points, when does the first takeaway point appear on the screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "pred_interval": {
        "start": 2355.0,
        "end": 2358.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.0,
        "end": 42.0,
        "average": 41.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24,
        "text_similarity": 0.672856330871582,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase and the first takeaway text and their order, but the provided timestamps and durations are substantially different from the ground truth (off by ~40+ seconds), so the timing information is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I'll stop and take questions,\" when does an audience member begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2541.6,
        "end": 2544.0
      },
      "pred_interval": {
        "start": 2702.2,
        "end": 2703.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 160.5999999999999,
        "end": 159.0999999999999,
        "average": 159.8499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.35616438356164387,
        "text_similarity": 0.7021051645278931,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives incorrect timestamps for both events and incorrectly claims an immediate, seamless transition; it contradicts the reference which shows the audience begins speaking ~23.7s after the speaker. These factual timing errors make the answer nearly entirely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the audience member finishes complimenting the center, when does he ask a specific question about local hospital ethics committees?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2571.5,
        "end": 2580.5
      },
      "pred_interval": {
        "start": 2724.2,
        "end": 2726.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 152.69999999999982,
        "end": 146.4000000000001,
        "average": 149.54999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.7613776922225952,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct events and a similar 'after' relation, but the timestamps and durations are substantially incorrect (off by ~158s and E2 much shorter), so it fails factual alignment with the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the audience member mentions the low numbers of ethics consultations, when does the speaker begin to answer the question?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2624.0,
        "end": 2634.8
      },
      "pred_interval": {
        "start": 2737.4,
        "end": 2739.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 113.40000000000009,
        "end": 104.19999999999982,
        "average": 108.79999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.27906976744186046,
        "text_similarity": 0.5575212240219116,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer's timestamps (2737.4s) are far off from the ground truth (E1=2621.0s, E2=2624.0s) and it misidentifies the event boundaries and adds the word 'Right'; while both indicate the speaker responds after the question, the timing and details are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the listener asks about assessing the quality of care across the system, when does the speaker respond by calling it a 'great question'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.1,
        "end": 2745.7
      },
      "pred_interval": {
        "start": 2706.0,
        "end": 2711.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.09999999999991,
        "end": 34.69999999999982,
        "average": 36.399999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.3368421052631579,
        "text_similarity": 0.633128821849823,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two events and their temporal relation ('after') and paraphrases the speaker's phrase, but the timestamps are substantially incorrect (predicted ~2704\u20132711s vs correct ~2739\u20132744s), so key factual timing is wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions starting to survey clinicians for feedback, when does he mention planning to survey patients and families?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2807.8,
        "end": 2821.6
      },
      "pred_interval": {
        "start": 2823.0,
        "end": 2835.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.199999999999818,
        "end": 13.400000000000091,
        "average": 14.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.47787610619469023,
        "text_similarity": 0.6101728081703186,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer correctly captures the quoted content and that the patient/family survey is mentioned after the clinician survey, but it gives substantially incorrect timestamps (E1 is placed ~17s late and E2 start is slightly after the true interval), misaligning the events temporally."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that hospitals in the healthcare system can join together, when does he state that they will preferentially present cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2854.49,
        "end": 2856.13
      },
      "pred_interval": {
        "start": 2859.8,
        "end": 2868.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.3100000000004,
        "end": 12.569999999999709,
        "average": 8.940000000000055
      },
      "rationale_metrics": {
        "rouge_l": 0.3191489361702127,
        "text_similarity": 0.7896403074264526,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target phrases and the 'after' relationship, but the reported timestamps substantially differ from the reference, so the timing information is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces 'a third method of feedback', when does he describe it as 'formal needs assessments'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2877.53,
        "end": 2879.53
      },
      "pred_interval": {
        "start": 2906.0,
        "end": 2913.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.4699999999998,
        "end": 33.66999999999962,
        "average": 31.06999999999971
      },
      "rationale_metrics": {
        "rouge_l": 0.37499999999999994,
        "text_similarity": 0.8164608478546143,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target phrases and their 'after' relationship, but the provided timestamps are substantially different from the ground truth (both start/end times and durations), indicating misalignment in temporal localization."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'the overwhelming response was number one', when does he specify the first response as 'a lack of ethics education'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2901.56,
        "end": 2903.46
      },
      "pred_interval": {
        "start": 3002.4,
        "end": 3007.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 100.84000000000015,
        "end": 103.63999999999987,
        "average": 102.24000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.46808510638297873,
        "text_similarity": 0.8504452705383301,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target utterances and the 'after' relationship, but its timestamps differ substantially from the reference. "
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"The more medically complex cases tend to transfer,\" when does he start listing examples of such cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3044.3,
        "end": 3048.2
      },
      "pred_interval": {
        "start": 3040.8,
        "end": 3045.8
      },
      "iou": 0.20270270270271268,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5,
        "end": 2.399999999999636,
        "average": 2.949999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.23999999999999996,
        "text_similarity": 0.6786841154098511,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor utterance (3039.4s falls within the ground-truth anchor interval) and the presence of examples, but it gives an incorrect and earlier start time for the examples (3040.8s vs ground-truth 3044.3s) and a mismatched end time, so the timing is significantly off."
      }
    },
    {
      "question_id": "002",
      "question": "After the questioner asks about the 'escalation of care policy', when does the slide titled 'Escalation of Care Protocol' appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3114.8,
        "end": 3117.8
      },
      "pred_interval": {
        "start": 3086.8,
        "end": 3088.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.0,
        "end": 29.40000000000009,
        "average": 28.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.380952380952381,
        "text_similarity": 0.6762862205505371,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps differ drastically from the reference (about 28 seconds earlier) and the predicted slide end time contradicts the reference's end-of-video timing; although both keep the same event order, the temporal details are largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions \"boarding 190 patients in the emergency department\", when does he discuss concerns about the level of care?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3154.983,
        "end": 3143.945
      },
      "pred_interval": {
        "start": 3092.8,
        "end": 3098.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.18299999999999,
        "end": 45.945000000000164,
        "average": 54.06400000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.23809523809523808,
        "text_similarity": 0.7777593731880188,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor line and that the concern discussion follows immediately, but the absolute timestamps are incorrect (off by ~58s) and the E1/E2 intervals do not match the ground truth, so it is partially but not fully accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker mentions 'in all 26 of those cases', when does he then talk about 'many more cases'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3214.9,
        "end": 3215.4
      },
      "pred_interval": {
        "start": 3212.4,
        "end": 3214.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5,
        "end": 1.2000000000002728,
        "average": 1.8500000000001364
      },
      "rationale_metrics": {
        "rouge_l": 0.4109589041095891,
        "text_similarity": 0.5932934284210205,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies both events and the 'after' relation and E1 time is very close, but E2's start/end times are substantially earlier than the ground truth (predicted 3212.4\u20133214.2s vs correct 3214.9\u20133215.4s), so the timing is notably inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker states that the 'escalation of care protocol' was nice, when does he mention a 'SOFA-based protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3246.0,
        "end": 3249.0
      },
      "pred_interval": {
        "start": 3228.9,
        "end": 3232.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.09999999999991,
        "end": 17.0,
        "average": 17.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.3703703703703704,
        "text_similarity": 0.7892359495162964,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same two events and the same 'after' relation, but the timestamps are substantially off (especially E2, ~17s earlier than the reference and overlapping E1), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the second speaker says 'SOFA is horrendous', when does he mention 'SOFA's AUC goes up'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3322.32,
        "end": 3324.71
      },
      "pred_interval": {
        "start": 3295.2,
        "end": 3301.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.120000000000346,
        "end": 23.610000000000127,
        "average": 25.365000000000236
      },
      "rationale_metrics": {
        "rouge_l": 0.4615384615384615,
        "text_similarity": 0.7292965054512024,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies both events and the 'after' relation, but the timestamps are substantially off (\u224827\u201330 seconds earlier) compared to the ground truth, so the temporal information is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the question about equity monitoring is asked, when does the speaker begin explaining the logging process for patient cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3401.583,
        "end": 3406.09
      },
      "pred_interval": {
        "start": 3399.0,
        "end": 3401.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.5830000000000837,
        "end": 5.0900000000001455,
        "average": 3.8365000000001146
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.7287085056304932,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events but the timestamps are substantially shifted and the temporal ordering is incorrect: predicted times place E1 before E2 (despite claiming 'after'), so it fails to match the ground-truth timing and relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the 'Escalation of Care Protocol', when does the 'Conscientious Practice Policy' slide appear on screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3429.8,
        "end": 3430.5
      },
      "pred_interval": {
        "start": 3405.0,
        "end": 3406.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.800000000000182,
        "end": 24.5,
        "average": 24.65000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.4090909090909091,
        "text_similarity": 0.7506289482116699,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives substantially different timestamps for both events (E1 at ~3404s vs correct 3424.0s; E2 at 3405.0s vs correct 3429.8s), contradicting the ground truth timing despite matching the relationship, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Conscientious Practice Policy' slide appears, when does the speaker mention tracking outcomes and looking back retrospectively for this policy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3444.0,
        "end": 3492.0
      },
      "pred_interval": {
        "start": 3416.0,
        "end": 3418.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.0,
        "end": 74.0,
        "average": 51.0
      },
      "rationale_metrics": {
        "rouge_l": 0.619718309859155,
        "text_similarity": 0.7584493160247803,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gets the relation correct but the timestamps for both E1 and E2 are substantially wrong compared to the reference (3434.0 vs 3405.0 for E1; 3444.0\u20133492.0 vs 3416.0\u20133418.0 for E2), so it fails to match key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions an increasing disparity over time, when does he discuss how they can provide support to all hospitals?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 707.399,
        "end": 742.972
      },
      "pred_interval": {
        "start": 690.0,
        "end": 720.0
      },
      "iou": 0.2378803896398098,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.399,
        "end": 22.97199999999998,
        "average": 20.18549999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3238095238095238,
        "text_similarity": 0.8658647537231445,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mentions the same general topic (support for hospitals) but misidentifies the anchor/target content and timestamps, places the anchor much earlier and with the wrong utterance, and reports an incorrect temporal relationship\u2014thus largely incorrect despite topical overlap."
      }
    },
    {
      "question_id": "002",
      "question": "While the organizational chart for the Center for Clinical Ethics is displayed, when does the speaker describe the Ethics Education program?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.177,
        "end": 786.763
      },
      "pred_interval": {
        "start": 740.0,
        "end": 770.0
      },
      "iou": 0.017599384128477183,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.17700000000002,
        "end": 16.763000000000034,
        "average": 22.970000000000027
      },
      "rationale_metrics": {
        "rouge_l": 0.33999999999999997,
        "text_similarity": 0.4544406831264496,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation ('during') right but the timestamps are substantially inaccurate: it misstates the slide display (690\u2013900s vs correct 749\u2013810s) and the description interval (740\u2013770s vs correct 769.177\u2013786.763s), so it does not correctly match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says he will go into depth on the programs, when does he first mention the Yale Interdisciplinary Center for Bioethics?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 837.605,
        "end": 845.26
      },
      "pred_interval": {
        "start": 840.0,
        "end": 850.0
      },
      "iou": 0.4243646631706332,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.394999999999982,
        "end": 4.740000000000009,
        "average": 3.5674999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.5438596491228069,
        "text_similarity": 0.768848180770874,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') and approximates the target mention times, but it gives a significantly incorrect anchor timestamp (830.0s vs. the correct ~805.8s), so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the title 'Systemwide Ethics Forum and Newsletter', when does he describe it as a hybrid meeting?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1070.5,
        "end": 1076.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1110.0
      },
      "iou": 0.1,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.5,
        "end": 33.5,
        "average": 27.0
      },
      "rationale_metrics": {
        "rouge_l": 0.35643564356435636,
        "text_similarity": 0.6942951083183289,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the temporal relation: the correct relation is 'after' while the prediction labels it 'during' (and even implies overlapping spans), contradicting the ground truth; timestamps aside, the predicted answer fails to preserve the key temporal relation and adds incorrect span details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining that they looked through the 26 specific patient cases individually, when does the slide transition to 'Scope of protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3425.8,
        "end": 3429.0
      },
      "pred_interval": {
        "start": 3448.7,
        "end": 3450.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.899999999999636,
        "end": 21.40000000000009,
        "average": 22.149999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.24657534246575347,
        "text_similarity": 0.7104275226593018,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly reports both event timestamps (off by ~30s) and the slide timing (says visible until 3450.4s and transitions immediately), which contradicts the reference times; it only correctly captures the coarse 'after' relation. "
      }
    },
    {
      "question_id": "002",
      "question": "Once the 'Scope of protocol' slide finishes being displayed, when does the 'Conscientious Practice Policy' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3429.0,
        "end": 3519.5
      },
      "pred_interval": {
        "start": 3458.6,
        "end": 3461.0
      },
      "iou": 0.026519337016575592,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.59999999999991,
        "end": 58.5,
        "average": 44.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.761876106262207,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation (the Conscientious Practice Policy slide appears immediately after the previous slide) but gives incorrect and contradictory timestamps (3458.6s/3461.0s vs. correct 3429.0s and 3429.0\u20133519.5s) and confuses which slide/speaker event is ending, so it is largely factually wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes discussing the tracking of equity, socioeconomic status, and other demographic characteristics, when is the presentation window minimized?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3530.0,
        "end": 3531.0
      },
      "pred_interval": {
        "start": 3546.5,
        "end": 3547.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.5,
        "end": 16.199999999999818,
        "average": 16.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.36065573770491804,
        "text_similarity": 0.6568954586982727,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys the order (minimization happens after the speaker finishes) but the timestamps are substantially incorrect (predicted 3546.5/3547.2 vs reference 3508.5 and 3530.0\u20133531.0), so it is factually mismatched."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the audience will be on mute, when does he mention that the live event can be paused?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 38.524,
        "end": 43.729
      },
      "pred_interval": {
        "start": 37.8,
        "end": 41.3
      },
      "iou": 0.4682071175577661,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7240000000000038,
        "end": 2.429000000000002,
        "average": 1.576500000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.2191780821917808,
        "text_similarity": 0.7767950892448425,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the qualitative relation ('after') and roughly locates the pausing remark, but it misplaces the anchor event by ~4.1s (33.102s vs 37.2s) and gives an incorrect target span (37.8\u201341.3s vs the correct 38.524\u201343.729s), omitting key timing accuracy."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses changing the speed of presentations and speakers, when does he advise on what to do if Wi-Fi or connection is lost?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 55.563,
        "end": 59.787
      },
      "pred_interval": {
        "start": 67.4,
        "end": 75.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.837000000000003,
        "end": 15.713000000000001,
        "average": 13.775000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.16091954022988506,
        "text_similarity": 0.6736788153648376,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the advisory content and the 'after' relation, but both anchor and target timestamps (and the described anchor event) are significantly off from the reference; timing and event identification errors make it largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the presenter mentions Tom Gardner in the background, when does he mention Stephanie Fraser joining in place of Jane Preston?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.258,
        "end": 171.201
      },
      "pred_interval": {
        "start": 177.4,
        "end": 180.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.141999999999996,
        "end": 9.099000000000018,
        "average": 9.120500000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.7494193315505981,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction completely misidentifies the anchor event and timestamps (177.4s vs correct 12.30s), conflates anchor and target as the same utterance, and gives no matching timing for the target (correct ~18.8s\u201321.6s), so it contradicts the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male presenter finishes introducing Stephanie Fraser, when does Stephanie Fraser begin speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 223.86,
        "end": 224.8
      },
      "pred_interval": {
        "start": 180.3,
        "end": 181.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.56,
        "end": 42.900000000000006,
        "average": 43.230000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.37142857142857144,
        "text_similarity": 0.7692281603813171,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that Stephanie speaks right after the presenter and captures her utterance, but the absolute timestamps are substantially wrong (predicted 180.3/181.9s vs correct 222.0/223.86s) and the relation labeling ('immediately after' vs the reference 'after') is inconsistent."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker is discussing the recent research undertaken by the Neurological Alliance of Scotland, when does she state that 57% of respondents reported not being able to access a face-to-face appointment?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 433.0,
        "end": 434.9
      },
      "pred_interval": {
        "start": 257.0,
        "end": 277.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 176.0,
        "end": 157.89999999999998,
        "average": 166.95
      },
      "rationale_metrics": {
        "rouge_l": 0.2018348623853211,
        "text_similarity": 0.48495590686798096,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives timestamps that are hundreds of seconds off from the ground truth, so the key factual timing is incorrect; although it labels the relationship as 'during', the predicted target and anchor times contradict the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that nearly two-thirds of respondents had not had a video appointment, when does she state that telephone appointments were the most common way to access care?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.8,
        "end": 452.9
      },
      "pred_interval": {
        "start": 290.0,
        "end": 302.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 157.8,
        "end": 150.89999999999998,
        "average": 154.35
      },
      "rationale_metrics": {
        "rouge_l": 0.20224719101123598,
        "text_similarity": 0.689045786857605,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer references the correct events but the timestamps differ substantially from the ground truth (anchor predicted ~288\u2013290s vs reference 346.8s; target predicted 290\u2013302s vs reference 447.8\u2013452.9), so the temporal alignment is incorrect despite both claiming 'immediately after.'"
      }
    },
    {
      "question_id": "003",
      "question": "After the blue slide with the speaker's title disappears, when does the speaker begin to mention what factors clinicians should consider for appointment formats?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 479.3,
        "end": 480.3
      },
      "pred_interval": {
        "start": 317.0,
        "end": 320.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 162.3,
        "end": 160.3,
        "average": 161.3
      },
      "rationale_metrics": {
        "rouge_l": 0.2631578947368421,
        "text_similarity": 0.657900869846344,
        "llm_judge_score": 1,
        "llm_judge_justification": "While the prediction correctly states the target occurs after the anchor, both the anchor (312.0s vs 476.3s) and target timestamps (317.0s vs 479.3s) are far from the ground truth, so the timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stephanie finishes speaking and hands over to Mark, when does Mark begin to speak?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 606.5,
        "end": 607.0
      },
      "pred_interval": {
        "start": 704.0,
        "end": 708.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.5,
        "end": 101.0,
        "average": 99.25
      },
      "rationale_metrics": {
        "rouge_l": 0.31578947368421056,
        "text_similarity": 0.6440074443817139,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives completely different timestamps (704.0s vs ~593.7\u2013607.0s) and asserts Mark starts immediately at the same time Stephanie ends, which contradicts the reference that Mark begins ~12.5s later; key factual timing and relation are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Mark finishes introducing Calum Duncan, when does Calum Duncan start speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 638.3,
        "end": 639.3
      },
      "pred_interval": {
        "start": 720.0,
        "end": 724.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 81.70000000000005,
        "end": 84.70000000000005,
        "average": 83.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.6492544412612915,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives completely different timestamps and even claims Calum starts at the same time Mark finishes (720.0s), which contradicts the reference times (Mark ends ~636.3\u2013636.6s; Calum starts ~638.3\u2013639.3s). The relation and timing are therefore incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once Calum Duncan says 'Next slide please', when does the second presentation slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 685.7,
        "end": 686.0
      },
      "pred_interval": {
        "start": 736.0,
        "end": 740.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.299999999999955,
        "end": 54.0,
        "average": 52.14999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.37500000000000006,
        "text_similarity": 0.6319434642791748,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer misreports the timestamps (original events occur at ~684.4\u2013686.0s vs prediction at 736.0s), collapses two distinct events into a single simultaneous time, and contradicts the correct 'once_finished' relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 'near me is what we're going to focus on today', when does he describe it as 'internet-based'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 702.7,
        "end": 703.5
      },
      "pred_interval": {
        "start": 704.6,
        "end": 705.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.8999999999999773,
        "end": 1.6000000000000227,
        "average": 1.75
      },
      "rationale_metrics": {
        "rouge_l": 0.26315789473684215,
        "text_similarity": 0.7344368100166321,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the content (speaker labels and that he calls it 'internet-based') and the direction ('after'), but the timestamps are substantially incorrect (anchor predicted at 704.6s vs 699.8s, target at 704.6\u2013705.1s vs 702.7s) and it incorrectly claims an immediate transition; these factual timing errors reduce correctness."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states there were '330 consultations per week' before the pandemic, when does he mention it went up to '10,000'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 737.0,
        "end": 739.0
      },
      "pred_interval": {
        "start": 715.0,
        "end": 717.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.0,
        "end": 21.299999999999955,
        "average": 21.649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.23376623376623373,
        "text_similarity": 0.5973043441772461,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer gets the temporal relation ('after') right but the timestamps are substantially incorrect and even overlap (predicted E1/E2 around 715s vs. ground truth ~731.5\u2013739s), so it fails to match key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' for the first time, when does he point to the map on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.0,
        "end": 767.5
      },
      "pred_interval": {
        "start": 744.8,
        "end": 745.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.200000000000045,
        "end": 22.200000000000045,
        "average": 22.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7549440860748291,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the two events (saying 'Next slide, please' and pointing to the map) but gives timestamps that contradict the ground truth (744.8\u2013745.3s vs. 756.0s and 767.0s) and incorrectly characterizes the temporal relation as 'immediately after' rather than the later time reported, so it is largely incorrect on timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'go back to the next slide', when does the slide titled 'Video consulting using near me via attend anywhere platform' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 874.0,
        "end": 874.1
      },
      "pred_interval": {
        "start": 890.8,
        "end": 893.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.799999999999955,
        "end": 19.399999999999977,
        "average": 18.099999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.2826086956521739,
        "text_similarity": 0.7824962139129639,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer captures the qualitative relationship (slide appears immediately upon the command) but the timestamps are substantially wrong (~17s later) and it adds an unsupported duration for the slide, so it is factually inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that 'Stephanie Fraser has talked about' the survey, when does he then say 'Back to next slide, Mark, please'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 884.0
      },
      "pred_interval": {
        "start": 903.6,
        "end": 905.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.600000000000023,
        "end": 21.700000000000045,
        "average": 21.150000000000034
      },
      "rationale_metrics": {
        "rouge_l": 0.13793103448275865,
        "text_similarity": 0.6286827325820923,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') but gives wrong event IDs and substantially incorrect timestamps (off by ~20s and different event labels), so it fails to match the key factual timing details in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'Next slide, please' at the 42-second mark, when does the slide titled 'Clinician and patient experience - Scotland' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 913.0,
        "end": 913.1
      },
      "pred_interval": {
        "start": 931.7,
        "end": 934.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.700000000000045,
        "end": 21.199999999999932,
        "average": 19.94999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.21176470588235294,
        "text_similarity": 0.6991434097290039,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misaligns the timestamps by ~19s (931.7s vs 912.0s anchor and 931.7/934.3s vs 913.0s target) and incorrectly states the events are simultaneous, whereas the correct answer indicates the slide appears 1s after the instruction; thus the timing relationship is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "During the discussion of what works well with video calls, when does the speaker express finding it much easier to interact with groups on a video call than on the telephone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1053.0,
        "end": 1062.5
      },
      "pred_interval": {
        "start": 122.0,
        "end": 126.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 931.0,
        "end": 936.5,
        "average": 933.75
      },
      "rationale_metrics": {
        "rouge_l": 0.17142857142857143,
        "text_similarity": 0.657802164554596,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the general contrast between video and telephone but it gives incorrect timestamps and the wrong temporal relation ('after' vs correct 'during'), so it fails on key factual alignment."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions technical issues with patient bandwidth, when does he advise to choose patients correctly to avoid those difficulties?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1134.0,
        "end": 1135.5
      },
      "pred_interval": {
        "start": 154.0,
        "end": 157.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 980.0,
        "end": 978.5,
        "average": 979.25
      },
      "rationale_metrics": {
        "rouge_l": 0.36734693877551017,
        "text_similarity": 0.7735857963562012,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly captures the semantic relation and paraphrases the advice, but it gives incorrect/missing temporal annotations (E2 at 154\u2013157s vs reference 1134\u20131135.5s and no E1 timestamp), so it fails on factual completeness of the timestamps."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' to introduce the smart phone camera, when does he specifically point out his wife's iPhone on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1213.0,
        "end": 1215.0
      },
      "pred_interval": {
        "start": 265.0,
        "end": 268.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 948.0,
        "end": 947.0,
        "average": 947.5
      },
      "rationale_metrics": {
        "rouge_l": 0.32380952380952377,
        "text_similarity": 0.727752685546875,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the same events (requesting the next slide and pointing out his wife's iPhone) and their order, but the timestamps differ substantially and it wrongly characterizes the timing as 'immediately after' rather than the ~10-second gap in the reference, so key factual details are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying 'Next slide please', when does the 'Sharing content' slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.574,
        "end": 1249.574
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1230.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.57400000000007,
        "end": 18.774000000000115,
        "average": 18.674000000000092
      },
      "rationale_metrics": {
        "rouge_l": 0.32967032967032966,
        "text_similarity": 0.8033841252326965,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the ordering ('after') but the timestamps are significantly incorrect (anchor and target times are off by ~17 seconds) and thus it fails to match the key factual timing details from the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'You can share things', when does he point towards the screen showing the brain scan?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1252.25,
        "end": 1252.85
      },
      "pred_interval": {
        "start": 1243.6,
        "end": 1244.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.650000000000091,
        "end": 8.849999999999909,
        "average": 8.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3658536585365854,
        "text_similarity": 0.762053370475769,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the pointing occurs after the speech, but the provided timestamps are substantially wrong (anchor 1243.6s vs 1249.255s; target 1244.0s vs 1252.250s), and it adds an unverified detail about pointing location."
      }
    },
    {
      "question_id": "003",
      "question": "During the discussion about poor picture quality, when does the speaker suggest clearing browser history?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1313.823,
        "end": 1315.286
      },
      "pred_interval": {
        "start": 1278.8,
        "end": 1279.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.02300000000014,
        "end": 36.28600000000006,
        "average": 35.6545000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2696629213483146,
        "text_similarity": 0.6809310913085938,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the phrase and that the target occurs after the anchor, but the reported timestamps are substantially different (off by ~28\u201335s) and the target is identified by a gesture rather than the correct spoken interval, so it is factually misaligned and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying \"Thank you very much for that\", when does he state he is handing over to Jane?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.837,
        "end": 1430.682
      },
      "pred_interval": {
        "start": 1548.4,
        "end": 1556.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 119.5630000000001,
        "end": 125.71800000000007,
        "average": 122.64050000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.3272727272727273,
        "text_similarity": 0.6210646629333496,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the utterances and that the handover follows the 'thank you', but the timestamps and duration are substantially wrong (off by ~121s and the target event timing/length contradicts the ground truth), so it does not match the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman (Jane) describes the challenges of managing patients over the telephone, when does she mention that they had a pilot of 'Near Me' even prior to Covid?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1609.855,
        "end": 1624.692
      },
      "pred_interval": {
        "start": 1602.4,
        "end": 1612.4
      },
      "iou": 0.11416651713619605,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.454999999999927,
        "end": 12.291999999999916,
        "average": 9.873499999999922
      },
      "rationale_metrics": {
        "rouge_l": 0.36036036036036034,
        "text_similarity": 0.596025824546814,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the utterance content (mentioning piloting Near Me prior to Covid) but gives incorrect and inconsistent timestamps (E1/E2 both at 1602.4s, E2 ends much earlier than ground truth) and misrepresents the temporal relation, so the temporal alignment is largely wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that using 'Near Me' felt quite adventurous, when does she state that its use became vital to their whole service?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1636.0,
        "end": 1643.0
      },
      "pred_interval": {
        "start": 1607.2,
        "end": 1612.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.799999999999955,
        "end": 30.799999999999955,
        "average": 29.799999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.3064516129032258,
        "text_similarity": 0.5867253541946411,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies E1 (wrong quote and timestamps), gives incorrect timestamps for E2, and adds an extra 'during' relation and causal detail not in the reference; only the phrase about Near Me becoming vital partially matches, so overall it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes asking Mark to go back to the previous slide, when does she say 'Thank you'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1676.54,
        "end": 1678.02
      },
      "pred_interval": {
        "start": 1638.3,
        "end": 1641.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.24000000000001,
        "end": 36.61999999999989,
        "average": 37.42999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.32653061224489793,
        "text_similarity": 0.7864196300506592,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and that 'Thank you' follows the request, but the timestamps/spans are substantially incorrect and the relation labeling/timing contradicts the ground truth, so it fails on key factual alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the 'Training and preparation' slide appears, when does the speaker mention the 'Level 1' training?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1791.0,
        "end": 1791.5
      },
      "pred_interval": {
        "start": 1805.0,
        "end": 1809.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 17.5,
        "average": 15.75
      },
      "rationale_metrics": {
        "rouge_l": 0.28260869565217395,
        "text_similarity": 0.6328133344650269,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction identifies the correct events and the 'after' relation, but the timestamps are inaccurate (E1 ~4s off and E2 ~14s late relative to the ground truth), so the timing is significantly incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing tele-swallowing partners as 'our eyes and our hands and our ears', when does she start talking about preparing the clinical room?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1897.0,
        "end": 1901.0
      },
      "pred_interval": {
        "start": 1857.0,
        "end": 1861.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.0,
        "end": 40.0,
        "average": 40.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3595505617977528,
        "text_similarity": 0.6075044870376587,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the correct events and a similar sequencing idea, but the timestamps are off by ~38 seconds and the relation is changed to 'immediately after/simultaneous,' which contradicts the reference timing ('once_finished'); therefore it is only a weak match."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses tele-swallowing partners preparing the clinical room, when does she next talk about them providing reassurance to patients?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1906.0,
        "end": 1910.0
      },
      "pred_interval": {
        "start": 1881.0,
        "end": 1888.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.0,
        "end": 22.0,
        "average": 23.5
      },
      "rationale_metrics": {
        "rouge_l": 0.40476190476190477,
        "text_similarity": 0.6287574768066406,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies both events and their order (reassurance occurs after preparing), but the provided timestamps substantially differ from the reference and the relation is labeled as merely 'after' rather than the immediate 'next', so key temporal details are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning emergency procedures in place onsite, when does the slide change to 'Technology/equipment'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1971.6,
        "end": 1972.0
      },
      "pred_interval": {
        "start": 2070.0,
        "end": 2070.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 98.40000000000009,
        "end": 98.5,
        "average": 98.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962025,
        "text_similarity": 0.6407616138458252,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly preserves the order (slide follows the speaker finishing), but the timestamps are off by about 100 seconds and the event boundaries/details (start/end times) do not match the reference, producing a major factual mismatch despite similar relation wording."
      }
    },
    {
      "question_id": "002",
      "question": "During the time the 'Technology/equipment' slide is displayed, when does the speaker discuss the need for a device with a webcam and microphone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2024.079,
        "end": 2026.579
      },
      "pred_interval": {
        "start": 2086.0,
        "end": 2087.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.92100000000005,
        "end": 60.92100000000005,
        "average": 61.42100000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2424242424242424,
        "text_similarity": 0.6880506873130798,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly identifies the relationship as 'during', both the anchor and target timestamps are substantially different from the ground truth (predicted times are off by dozens to over a hundred seconds), so the answer is largely factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the general category of 'certain resources' for teleswallow sessions, when does she mention 'appropriate diet and fluid consistencies'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.952,
        "end": 2061.952
      },
      "pred_interval": {
        "start": 2139.0,
        "end": 2144.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.04799999999977,
        "end": 82.04799999999977,
        "average": 81.04799999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.2716049382716049,
        "text_similarity": 0.6161028742790222,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the correct ordering (the target follows the anchor) but the timestamps are substantially incorrect (off by ~85s) and the relation label ('after') is less precise than the ground truth ('next'), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that remote swallowing assessments are not intended to fully replace face-to-face assessments, when does she mention that they are a very useful addition?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2159.677,
        "end": 2162.619
      },
      "pred_interval": {
        "start": 2205.0,
        "end": 2210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.322999999999865,
        "end": 47.38099999999986,
        "average": 46.35199999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.7156763076782227,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the prediction correctly identifies the relationship as 'immediately after', its timestamps differ substantially from the reference (2205.0s vs 2159.0s) and it adds unsupported details (mouth open, end time), so it does not match the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning gathering feedback from those who completed the training, when does she start talking about evaluating quantitative data?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2164.643,
        "end": 2186.427
      },
      "pred_interval": {
        "start": 2225.0,
        "end": 2230.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 60.35699999999997,
        "end": 43.572999999999865,
        "average": 51.96499999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.2558139534883721,
        "text_similarity": 0.7573227286338806,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction does not match the reference timestamps (off by ~39\u201340s) and incorrectly states the target starts concurrently with the anchor rather than ~1s after; it also adds irrelevant visual detail. These factual timing errors make it largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes her presentation by saying 'thank you very much for listening', when does the video visually transition to the male presenter?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2257.0,
        "end": 2258.0
      },
      "pred_interval": {
        "start": 2246.0,
        "end": 2250.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 8.0,
        "average": 9.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3291139240506329,
        "text_similarity": 0.8105765581130981,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the ordering ('after') right but both timestamps are incorrect (E1 2246s vs 2256s, E2 2250s vs 2257s) and it fails to capture that the male presenter immediately follows the anchor's speech."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that picking up cues is difficult, when does she start talking about 'points to consider' for virtual technology?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2491.8,
        "end": 2498.2
      },
      "pred_interval": {
        "start": 2505.7,
        "end": 2507.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.899999999999636,
        "end": 8.900000000000091,
        "average": 11.399999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.24742268041237114,
        "text_similarity": 0.6134712100028992,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the 'once_finished' relation but gives substantially incorrect timestamps (~14s later) and the wrong target utterance (mentions a sprint audit instead of 'points to consider'), so it fails to match the key facts in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions conducting a 'sprint audit' with patients, when does she state that 'most were very satisfied' with the virtual appointments?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2515.0,
        "end": 2516.0
      },
      "pred_interval": {
        "start": 2541.5,
        "end": 2543.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.5,
        "end": 27.699999999999818,
        "average": 27.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306126,
        "text_similarity": 0.5474440455436707,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mismatches the reference times and event assignments (places the key phrase much later and swaps events), and introduces a different line ('most found it easy to log in'), so it fails to correctly locate or label the referenced utterances despite preserving a loose topical similarity."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that patients found virtual technology 'more acceptable', when does she say 'So moving on to the next slide'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2638.0,
        "end": 2639.3
      },
      "pred_interval": {
        "start": 2571.0,
        "end": 2572.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.0,
        "end": 67.30000000000018,
        "average": 67.15000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.2884615384615385,
        "text_similarity": 0.6147533655166626,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the target phrase 'So moving on to the next slide' but gives timestamps that are ~66s earlier and a different anchor phrase than the reference; the relation label and timing substantially contradict the ground truth, so the match is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing confidentiality, when does she begin to mention the subtlety of the therapeutic relationship?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2693.583,
        "end": 2697.126
      },
      "pred_interval": {
        "start": 2717.4,
        "end": 2722.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.817000000000007,
        "end": 24.873999999999796,
        "average": 24.3454999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.22535211267605634,
        "text_similarity": 0.602044939994812,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mentions the correct topic phrase but gives entirely incorrect timestamps and wrongly asserts an immediate transition; it contradicts the ground-truth timing (2688.583 \u2192 2693.583) and omits the ~5s gap, so it is mostly inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'It all comes down to Wi-Fi', when does she state that 'delivery of remote therapy is very, very difficult'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.0,
        "end": 2729.0
      },
      "pred_interval": {
        "start": 2744.0,
        "end": 2749.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.0,
        "end": 20.0,
        "average": 18.5
      },
      "rationale_metrics": {
        "rouge_l": 0.45454545454545453,
        "text_similarity": 0.553078293800354,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the correct relative ordering (target occurs after the anchor) but gives substantially incorrect absolute timestamps and an incorrect duration/temporal relationship (claims immediate succession and different times), so key factual timing details are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'So next slide', when does the slide visually change to 'Practical considerations'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2884.0,
        "end": 2884.2
      },
      "pred_interval": {
        "start": 2853.81,
        "end": 2854.46
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.190000000000055,
        "end": 29.73999999999978,
        "average": 29.964999999999918
      },
      "rationale_metrics": {
        "rouge_l": 0.4235294117647059,
        "text_similarity": 0.7328175902366638,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the events, their content, and that the visual change occurs immediately after the verbal cue, but the provided timestamps are substantially off (~29 seconds earlier) compared to the reference, so the temporal accuracy is poor."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing 'Practical considerations', when does she first mention 'increasing reflective feedback'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2913.483,
        "end": 2916.268
      },
      "pred_interval": {
        "start": 2872.41,
        "end": 2874.97
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.07300000000032,
        "end": 41.29800000000023,
        "average": 41.185500000000275
      },
      "rationale_metrics": {
        "rouge_l": 0.26373626373626374,
        "text_similarity": 0.6753958463668823,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets E1 approximately right (\u22483.8s off) and correctly states the mention occurs during the slide, but it places E2 about 41 seconds earlier than the reference (2872\u20132875s vs. 2913.483s), a significant factual discrepancy."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"for the patients\", when does the slide change to \"WHERE WE ARE NOW\"?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3067.769,
        "end": 3068.2
      },
      "pred_interval": {
        "start": 3033.1,
        "end": 3033.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.66899999999987,
        "end": 34.29999999999973,
        "average": 34.4844999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3943661971830986,
        "text_similarity": 0.6978758573532104,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the slide change occurs after the spoken phrase, but the timestamps are off by ~33 seconds (3033.1s vs correct 3067.769s) and it misstates the timing/details of full visibility, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says \"open up for some discussion\", when does the discussion slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3163.435,
        "end": 3163.7
      },
      "pred_interval": {
        "start": 3096.2,
        "end": 3097.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.23500000000013,
        "end": 66.69999999999982,
        "average": 66.96749999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.6088048815727234,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction's timestamps contradict the ground truth by tens of seconds (3096s vs 3120s and 3096.2s vs 3163.435s) and incorrectly states the slide appears almost immediately, so it fails to match the correct temporal relations and values."
      }
    },
    {
      "question_id": "001",
      "question": "After the first male speaker asks about attendees' experience with Near Me, when does the second male speaker begin talking about starting to use NearMe?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.9,
        "end": 3312.0
      },
      "pred_interval": {
        "start": 3212.1,
        "end": 3213.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.80000000000018,
        "end": 98.69999999999982,
        "average": 77.75
      },
      "rationale_metrics": {
        "rouge_l": 0.23809523809523808,
        "text_similarity": 0.4919385313987732,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the order (second speaker speaks after the first) but gives completely different timestamps (\u22483212s vs correct 3248.8s/3268.9s) and wrongly characterizes the relation as 'immediately after' despite the actual ~20s gap, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second male speaker finishes stating the advantages and utility of NearMe, when does he mention supplementing normal activities?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.4,
        "end": 3293.32
      },
      "pred_interval": {
        "start": 3257.9,
        "end": 3260.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.5,
        "end": 33.120000000000346,
        "average": 31.810000000000173
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324326,
        "text_similarity": 0.5128803253173828,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the general 'after' ordering but the timestamps are substantially wrong (anchor 3257.8 vs 3283.4; target start 3257.9 vs 3288.4), it wrongly asserts an almost-immediate follow-up and invents an end time\u2014so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the first man finishes reading Jenny's chat message, when does he ask the audience if they would find guidance helpful?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3411.0,
        "end": 3415.0
      },
      "pred_interval": {
        "start": 3413.12,
        "end": 3416.18
      },
      "iou": 0.36293436293439546,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.119999999999891,
        "end": 1.1799999999998363,
        "average": 1.6499999999998636
      },
      "rationale_metrics": {
        "rouge_l": 0.2894736842105263,
        "text_similarity": 0.7134456634521484,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') correct but the timestamps disagree substantially with the reference (E1 predicted 3412.94s vs 3407.6s reference; predicted E2 span 3413.12\u20133416.18s vs reference 3411.0\u20133415.0), so the answer is factually inaccurate/incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first man finishes reading John Hogan's comment about clinical interviewing, when does he state he was quite skeptical?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3434.9,
        "end": 3437.7
      },
      "pred_interval": {
        "start": 3452.52,
        "end": 3453.82
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.61999999999989,
        "end": 16.120000000000346,
        "average": 16.87000000000012
      },
      "rationale_metrics": {
        "rouge_l": 0.37037037037037035,
        "text_similarity": 0.7641258239746094,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events but gives substantially different timestamps and a different temporal relation label; the predicted spans/times do not match the reference target spans, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the second woman mentions neuropsychology bringing out guidance, when is the next time a woman speaks about professional guidance?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3511.043,
        "end": 3528.447
      },
      "pred_interval": {
        "start": 3501.12,
        "end": 3502.88
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.92300000000023,
        "end": 25.567000000000007,
        "average": 17.74500000000012
      },
      "rationale_metrics": {
        "rouge_l": 0.25287356321839083,
        "text_similarity": 0.8793590068817139,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction partially identifies the same utterances but gives substantially different timestamps for E1 and E2, mislabels the temporal relation as 'after' instead of 'next', and does not match the target span\u2014thus it is largely incorrect on key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 36 people joined the session, when does he talk about taking the next steps with Richard and the team?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3574.7,
        "end": 3576.5
      },
      "pred_interval": {
        "start": 3575.1,
        "end": 3579.2
      },
      "iou": 0.3111111111111313,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.40000000000009095,
        "end": 2.699999999999818,
        "average": 1.5499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.2954545454545454,
        "text_similarity": 0.8276124000549316,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor start and places the target clearly after it with a near-identical target start time; minor discrepancies exist in the reported end times and the anchor end time from the reference is not exactly matched."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker makes a plea to fill in the survey, when does he ask if listeners would like to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3592.9,
        "end": 3594.1
      },
      "pred_interval": {
        "start": 3583.8,
        "end": 3588.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.099999999999909,
        "end": 6.0,
        "average": 7.5499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.38636363636363635,
        "text_similarity": 0.8050047755241394,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation as 'after', but the reported time spans are substantially wrong (anchor and target start/end times differ by several seconds) and the anchor end is omitted, so key factual timing details are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes thanking everyone for joining the session today, when does he mention that the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3599.8,
        "end": 3603.2
      },
      "pred_interval": {
        "start": 3598.0,
        "end": 3603.7
      },
      "iou": 0.5964912280701307,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.800000000000182,
        "end": 0.5,
        "average": 1.150000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.34146341463414637,
        "text_similarity": 0.8510004878044128,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the recording is mentioned shortly after, with roughly similar timestamps, but it misaligns the exact start/end times (notably E2 starts earlier than the reference) and omits the key detail that resources will be provided."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'where did we start?', when does she mention considering moving to Near Me for patient contacts?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2332.719,
        "end": 2336.344
      },
      "pred_interval": {
        "start": 2379.0,
        "end": 2386.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.28099999999995,
        "end": 49.65599999999995,
        "average": 47.96849999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.4086021505376344,
        "text_similarity": 0.7512526512145996,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the target is a direct follow-up to the anchor, but the reported timestamps are substantially wrong (anchor 2379.0s vs 2320.0s; target 2379.0\u20132386.0s vs 2332.719\u20132336.344s) and even places the target start at the same time as the anchor, so the temporal localization is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says the pandemic came along, when does she mention adopting Near Me as their default for routine people?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2367.217,
        "end": 2412.045
      },
      "pred_interval": {
        "start": 2442.0,
        "end": 2452.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.7829999999999,
        "end": 39.95499999999993,
        "average": 57.368999999999915
      },
      "rationale_metrics": {
        "rouge_l": 0.2708333333333333,
        "text_similarity": 0.750329852104187,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly identifies the semantic relation ('after') and the action, but the anchor and target timestamps are substantially different from the ground truth (no overlap with the given intervals), so the temporal localization is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the results of the focus groups for the qualitative study, when does she introduce the quotes from the participants?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2511.0,
        "end": 2512.0
      },
      "pred_interval": {
        "start": 2493.0,
        "end": 2497.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.0,
        "end": 15.0,
        "average": 16.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3655913978494624,
        "text_similarity": 0.8007407188415527,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the transition to participant quotes but misplaces both anchor and target timestamps by large margins (errors of ~15\u201340 seconds), so it fails to match the correct temporal locations despite getting the general relationship right."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks to fill in the survey, when does he ask if listeners want to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3591.7,
        "end": 3595.8
      },
      "pred_interval": {
        "start": 3590.7,
        "end": 3601.6
      },
      "iou": 0.3761467889908559,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0,
        "end": 5.799999999999727,
        "average": 3.3999999999998636
      },
      "rationale_metrics": {
        "rouge_l": 0.3838383838383838,
        "text_similarity": 0.5637692213058472,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies both events and that the target occurs after the anchor; the provided time intervals differ slightly from the reference (both are broader and shifted) but still overlap the ground-truth spans and preserve the temporal relation."
      }
    },
    {
      "question_id": "002",
      "question": "Before the speaker thanks the speakers for their expertise, when does he mention the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3599.9,
        "end": 3603.7
      },
      "pred_interval": {
        "start": 3597.8,
        "end": 3605.0
      },
      "iou": 0.5277777777777533,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.099999999999909,
        "end": 1.300000000000182,
        "average": 1.7000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.49438202247191015,
        "text_similarity": 0.6437667608261108,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (target before the thank-you) but gives significantly different and inconsistent timestamps (target extended earlier and through 3605.0, and the thank-you shifted later to 3606.0\u20133611.5), so key factual timing details are inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker initially thanks the audience for joining, when does he deliver his final 'thank you very much' for the session?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3614.6,
        "end": 3615.4
      },
      "pred_interval": {
        "start": 3612.6,
        "end": 3616.4
      },
      "iou": 0.21052631578951148,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 1.0,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3047619047619048,
        "text_similarity": 0.4752183258533478,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both the initial and final 'thank you' and their order, but the reported timestamps differ from the reference (initial ~1\u20132s early and final window is broader/starts ~2s earlier), so minor timing inaccuracies reduce the score."
      }
    },
    {
      "question_id": "001",
      "question": "After Mark introduces Dr. John Mckeown and Dr. Naomi Dow, when does he ask Dr. Dow to describe how they've been using Near Me?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.48,
        "end": 34.4
      },
      "pred_interval": {
        "start": 104.1,
        "end": 106.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.61999999999999,
        "end": 72.1,
        "average": 72.35999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3370786516853933,
        "text_similarity": 0.6703619956970215,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the prediction correctly states the relation is 'after' and gives a broad anchor window, it substantially mislocates the target event (31.48\u201334.4s in ground truth vs 104.1\u2013106.5s predicted), so the timing is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Dr. Naomi Dow finishes explaining how students take part in consultations, when does Mark ask Dr. Mckeown about the impact on the teaching team?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.96,
        "end": 124.4
      },
      "pred_interval": {
        "start": 144.6,
        "end": 147.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.64,
        "end": 22.69999999999999,
        "average": 24.169999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.35714285714285715,
        "text_similarity": 0.7875995635986328,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events and relation type, but both event time spans and the E2 target are substantially misaligned with the reference (wrong timings and different utterance/recipient), so it is largely incorrect despite matching the relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker introduces the concept of emotions in the session, when does the female speaker first mention 'real patients'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.9,
        "end": 202.6
      },
      "pred_interval": {
        "start": 167.1,
        "end": 168.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.80000000000001,
        "end": 34.5,
        "average": 34.650000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.2365591397849462,
        "text_similarity": 0.7509725689888,
        "llm_judge_score": 3,
        "llm_judge_justification": "E1 matches the ground truth time, but E2 is incorrectly placed (predicted 167.1\u2013168.1s vs ground truth 201.9\u2013202.6s), so the key factual timing of the 'real patients' mention is wrong even though the 'after' relation remains true."
      }
    },
    {
      "question_id": "002",
      "question": "Once the interviewer finishes asking the question about comparing models, when does the female speaker finish explaining the advantages of 'Near Me' regarding real patients and capacity?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 198.7,
        "end": 306.9
      },
      "pred_interval": {
        "start": 241.3,
        "end": 242.5
      },
      "iou": 0.011090573012938898,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.60000000000002,
        "end": 64.39999999999998,
        "average": 53.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23157894736842105,
        "text_similarity": 0.6447346210479736,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer's timestamps for both E1 and E2 and the duration of the female's explanation contradict the ground truth (186.4s vs 241.3s for E1; 198.7\u2013306.9s vs 241.3\u2013242.5s for E2) and misstates the relation, so it is almost entirely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the man is speaking on screen, when does he mention 'Near Me'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 342.0,
        "end": 344.0
      },
      "pred_interval": {
        "start": 347.2,
        "end": 348.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.199999999999989,
        "end": 4.0,
        "average": 4.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.7305325269699097,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same events and the 'during' relation, but the reported time intervals are substantially incorrect (E2 at 347.2\u2013348.0 vs. ground truth 342.0\u2013344.0, and E1 bounds also differ), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying 'Thank you and goodbye', when do the 'NHS Scotland' and 'Near Me' logos appear with text links?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 360.0,
        "end": 361.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.0,
        "end": 1.0,
        "average": 5.0
      },
      "rationale_metrics": {
        "rouge_l": 0.40384615384615385,
        "text_similarity": 0.6648545861244202,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relation ('once_finished') and that the logos appear immediately after the speech, but it gives significantly different and incorrect timestamps and durations for both events compared to the ground truth, omitting the precise timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the initial voiceover concludes with 'patient that day', when does the man on screen begin to say 'Thanks very much John and Amy'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 336.4,
        "end": 341.6
      },
      "pred_interval": {
        "start": 359.0,
        "end": 360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.600000000000023,
        "end": 18.399999999999977,
        "average": 20.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3564356435643565,
        "text_similarity": 0.7648299336433411,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps and duration (359.0\u2013360.0s) conflict with the ground truth (E1 ends 334.40s; E2 begins 336.40s\u2013341.6s), and the relation ('once_finished' implying instantaneous transition) contradicts the correct 'after' relation; overall the prediction is largely incorrect and contains hallucinated timings."
      }
    }
  ]
}