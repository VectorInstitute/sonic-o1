{
  "topic_id": 5,
  "topic_name": "Courtroom Proceedings",
  "num_evaluated": 13,
  "aggregated_metrics": {
    "detailed": {
      "rouge_l_mean": 0.12007832951347945,
      "rouge_l_std": 0.032411563158773006,
      "text_similarity_mean": 0.30363231668105495,
      "text_similarity_std": 0.12051570441965244,
      "llm_judge_score_mean": 1.0769230769230769,
      "llm_judge_score_std": 0.8284868934053083
    },
    "short": {
      "rouge_l_mean": 0.10077751611809081,
      "rouge_l_std": 0.04100332051522902,
      "text_similarity_mean": 0.2546549536860906,
      "text_similarity_std": 0.14259497118041542,
      "llm_judge_score_mean": 0.6153846153846154,
      "llm_judge_score_std": 0.737820234355803
    },
    "cider": {
      "cider_detailed": 0.00830682938327168,
      "cider_short": 0.0008744609866139489
    }
  },
  "per_entry_results": [
    {
      "video_id": "TVriGlkPexA",
      "video_number": "001",
      "detailed": {
        "rouge_l": 0.13953488372093023,
        "text_similarity": 0.3972212076187134,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only gives generic visual details of a courtroom scene and misses almost all key factual elements from the correct answer (the sentencing hearing, attorney Iworski, Frank's objections and First Amendment claims, the dropped breach charge, and the promotional segment about censorship), so it is minimally aligned. "
      },
      "short": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.19311359524726868,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only lists basic courtroom visuals (people, a man sitting/standing, judge) and fails to capture the video's key events, dialogue, and themes\u2014such as the attorney dropping a bail charge, Frank's protest about First Amendment/disorderly conduct, and the video's focus on YouTube censorship and promotion of Odyssey."
      }
    },
    {
      "video_id": "Z_6JBsE07b8",
      "video_number": "002",
      "detailed": {
        "rouge_l": 0.1317365269461078,
        "text_similarity": 0.2109474390745163,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only describes superficial visual details (people, clothing, movement) and omits virtually all key factual elements from the correct answer\u2014no mention of the defendant's crimes, victim impact statements, lack of remorse, or the judge's remarks\u2014making it nearly entirely incomplete."
      },
      "short": {
        "rouge_l": 0.10300429184549356,
        "text_similarity": 0.10624108463525772,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction only gives superficial visual details about people and clothing and omits all substantive content from the correct summary\u2014no mention of Skolman's criminal history, victim impact statements, his lack of remorse, or the judge's remarks."
      }
    },
    {
      "video_id": "u0IZ4j1g25s",
      "video_number": "003",
      "detailed": {
        "rouge_l": 0.1134020618556701,
        "text_similarity": 0.36959701776504517,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only notes generic breaking-news and courtroom visuals but omits almost all key factual elements from the reference (guilty verdict on eight counts, detailed evidence, judge/DA statements, motions and sentencing timeline, family reaction), and adds incidental visual details that do not substitute for the missing substantive content."
      },
      "short": {
        "rouge_l": 0.09615384615384616,
        "text_similarity": 0.40802767872810364,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only notes generic visuals and that it is breaking news about a murder trial, but it omits nearly all key factual elements (guilty verdict on eight charges, sentencing info, DA and analyst statements, evidence details, and jury/judge actions) and includes irrelevant visual details not present in the reference."
      }
    },
    {
      "video_id": "xwZ2K8b_pBw",
      "video_number": "004",
      "detailed": {
        "rouge_l": 0.16445623342175067,
        "text_similarity": 0.5234987139701843,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely misrepresents the video's content\u2014portraying it as political satire about the Supreme Court\u2014while omitting the central story of a 74-year-old using an AI-generated avatar in a New York courtroom and the ensuing judicial reaction and discussion of legal AI implications."
      },
      "short": {
        "rouge_l": 0.17333333333333334,
        "text_similarity": 0.5138459205627441,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misses almost all key facts (AI-generated lawyer avatar, judge stopping the video, the man's admission and promotion of his startup, and ensuing ethical/legal discussion) and adds unrelated elements (humorous political take); only a vague court reference overlaps. "
      }
    },
    {
      "video_id": "2B_e7fvwi90",
      "video_number": "005",
      "detailed": {
        "rouge_l": 0.060000000000000005,
        "text_similarity": 0.31928014755249023,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only describes a generic courtroom testimony scene and correctly infers a formal proceeding, but it omits the key facts that this is Lyle Menendez's testimony and his claims of sexual abuse by his father, making it largely incomplete relative to the correct answer."
      },
      "short": {
        "rouge_l": 0.0,
        "text_similarity": 0.12771357595920563,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only lists superficial visual elements and omits the key factual content\u2014the video is about Lyle Menendez's testimony of alleged sexual abuse and its context within the Menendez Brothers case\u2014so it fails to capture the main points."
      }
    },
    {
      "video_id": "5yNgC39Q2HE",
      "video_number": "006",
      "detailed": {
        "rouge_l": 0.07669616519174041,
        "text_similarity": 0.14634039998054504,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is a generic visual description of people in a video conference and omits all substantive content: it fails to mention the Hothi v. Musk hearing, the parties, legal issues, cited cases, or the courtroom arguments described in the correct answer."
      },
      "short": {
        "rouge_l": 0.10679611650485438,
        "text_similarity": 0.1908528208732605,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer describes generic visual elements of a video conference and omits all substantive legal content\u2014parties, arguments, anti-SLAPP issues, and case citations\u2014so it does not match the correct summary at all."
      }
    },
    {
      "video_id": "9U_cQz-7sT4",
      "video_number": "007",
      "detailed": {
        "rouge_l": 0.11987381703470032,
        "text_similarity": 0.4887981414794922,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction accurately notes the speaker's identity and basic visual/audio details but omits the core substantive content: Senator Cruz's questioning about legal standing and self-identification, the hypothetical scenarios, and Judge Jackson's measured refusal to opine on abstract hypotheticals."
      },
      "short": {
        "rouge_l": 0.12307692307692307,
        "text_similarity": 0.5486985445022583,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only gives a brief visual description and names Judge Ketanji Brown Jackson, but it omits the substantive content: Senator Cruz's questions about self-identification and standing, the hypotheticals about gender/race, and Judge Jackson's refusal and explanation of her judicial process."
      }
    },
    {
      "video_id": "gTBoJ9W8zQ8",
      "video_number": "010",
      "detailed": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.28242677450180054,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives only vague, unrelated visual descriptions and omits all key factual elements (Pettis's admission, Lankford's accusation and contempt, the motive and deal, and the adjournment), so it fails to match the correct answer's substance."
      },
      "short": {
        "rouge_l": 0.08196721311475409,
        "text_similarity": 0.242730975151062,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction provides only generic visual descriptions and omits all key factual elements from the correct answer (threat admission, involvement of Detective Lee Lankford, contempt and recess), so it fails to capture the video's content."
      }
    },
    {
      "video_id": "hXN6cDKyk4g",
      "video_number": "009",
      "detailed": {
        "rouge_l": 0.07407407407407407,
        "text_similarity": 0.24004340171813965,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction only describes visual shots of a man speaking and omits virtually all substantive content from the correct answer (legal advice, settlement encouragement, courtroom practice, research and management recommendations, career guidance, and emphasis on fitness)."
      },
      "short": {
        "rouge_l": 0.07352941176470587,
        "text_similarity": 0.21452957391738892,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer only describes visual shots of the speaker and omits all substantive content about legal preparation, litigation tactics, advice on practice, settlements, and other key points in the correct summary."
      }
    },
    {
      "video_id": "DelhQUg8eH4",
      "video_number": "011",
      "detailed": {
        "rouge_l": 0.14583333333333331,
        "text_similarity": 0.22900307178497314,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated, describing a Texas Translation Agency video about translation services and visuals, while the correct answer details a criminal incident, witnesses, evidence, and charges; it omits all key facts and introduces unrelated content."
      },
      "short": {
        "rouge_l": 0.13903743315508021,
        "text_similarity": 0.2226260006427765,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct summary: it describes a translation agency and visual elements, whereas the correct answer details a prosecutor's case against Carl Miller involving cocaine distribution, flight, assault on an officer, eyewitnesses, a license plate lead, and forensic confirmation."
      }
    },
    {
      "video_id": "k28NMpEkuRU",
      "video_number": "012",
      "detailed": {
        "rouge_l": 0.16814159292035402,
        "text_similarity": 0.11621640622615814,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the reference: it describes a translation/document video and courtroom visuals, while the correct answer details a specific theft, identification, and arrest incident involving Walter Merchant; there is no factual overlap."
      },
      "short": {
        "rouge_l": 0.15151515151515152,
        "text_similarity": 0.10403509438037872,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is largely unrelated, describing on-screen documents and a courtroom speaker while omitting all key facts about the vandalism, theft, Walter Merchant, his resistance/arrest, the found items, and Mendoza's identification, so it fails to match the correct summary."
      }
    },
    {
      "video_id": "RHq_CJJDpUY",
      "video_number": "013",
      "detailed": {
        "rouge_l": 0.10370370370370371,
        "text_similarity": 0.22774067521095276,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely different and factually inconsistent with the correct summary: it describes a turbaned man recounting Air Force and KC work in a book-lined room, whereas the correct answer details R.S. Cheema's substantive discussion of criminal appeals, drafting, evidence and advocacy; the prediction omits all key content and introduces hallucinated facts."
      },
      "short": {
        "rouge_l": 0.09836065573770493,
        "text_similarity": 0.30019694566726685,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is largely unrelated and factually incorrect compared to the correct summary: it introduces a different speaker and biographical details not present in the reference and omits all key points about appellate advocacy, case examples, and legal guidance."
      }
    },
    {
      "video_id": "L_dJ23CLzTo",
      "video_number": "014",
      "detailed": {
        "rouge_l": 0.13023255813953488,
        "text_similarity": 0.3961067199707031,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only describes visual details and branding (e.g., Bond Solon, sign) and thus only minimally hints at the video's topic; it fails to capture the substantive interview content, key points about witness familiarisation, cross-examination challenges, examples, or the training methodology described in the correct answer."
      },
      "short": {
        "rouge_l": 0.08,
        "text_similarity": 0.13790258765220642,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer only lists visual details and briefly shows a 'Bond Solon' logo, but it fails to convey the video's main points about witness preparation, challenges, impacts on trials, or familiarisation training and mock cross-examinations."
      }
    }
  ]
}