{
  "topic_id": 1,
  "topic_name": "Patient-Doctor Consultations",
  "num_evaluated": 269,
  "aggregated_metrics": {
    "mean_iou": 0.03588117872708754,
    "std_iou": 0.10356923606935646,
    "median_iou": 0.0,
    "R@0.3": {
      "recall": 0.06691449814126393,
      "count": 18,
      "total": 269
    },
    "R@0.5": {
      "recall": 0.0037174721189591076,
      "count": 1,
      "total": 269
    },
    "R@0.7": {
      "recall": 0.0037174721189591076,
      "count": 1,
      "total": 269
    },
    "mae": {
      "start_mean": 44.67959479553904,
      "end_mean": 3522.731657992564,
      "average_mean": 1783.7056263940517
    },
    "rationale": {
      "rouge_l_mean": 0.27414241356242214,
      "rouge_l_std": 0.08056796029774979,
      "text_similarity_mean": 0.6610488641217739,
      "text_similarity_std": 0.12747023879656674,
      "llm_judge_score_mean": 2.684014869888476,
      "llm_judge_score_std": 1.5641680852885957
    },
    "rationale_cider": 0.14118843005657747
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "After the speaker welcomes viewers and introduces himself as 'Karma Medic', when does he state that he is a 'final year medical student'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 35.0,
        "end": 36.62
      },
      "pred_interval": {
        "start": 32.6,
        "end": 33.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.3999999999999986,
        "end": 2.719999999999999,
        "average": 2.5599999999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.4509803921568628,
        "text_similarity": 0.8931902647018433,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly detects the phrase 'I am a final year medical student' but gives substantially different timestamps and misidentifies the anchor; its temporal relation ('during'/'immediately after') contradicts the reference 'after', so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'Now with that lovely disclaimer out of the way, let's get right into it', when does the text 'before the history' appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.06,
        "end": 57.06
      },
      "pred_interval": {
        "start": 34.5,
        "end": 35.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.560000000000002,
        "end": 21.560000000000002,
        "average": 21.560000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.27368421052631575,
        "text_similarity": 0.761261522769928,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the immediate/once-finished relationship and duration pattern, but the reported timestamps (~34.5\u201335.5s) contradict the ground truth (~56.03\u201357.06s), a significant factual error on key temporal details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'So before starting the history, there's generally two things that I try and keep in mind', when does he begin describing 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 206.36,
        "end": 207.36
      },
      "pred_interval": {
        "start": 104.9,
        "end": 106.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 101.46000000000001,
        "end": 100.86000000000001,
        "average": 101.16000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.36170212765957444,
        "text_similarity": 0.8588064908981323,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps for both anchor and target conflict with the ground truth by a large margin and the claim that 'washing your hands' occurs immediately after is incorrect; it thus misrepresents the temporal relationship and includes a false audio-cue assertion."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the acronym 'ICE', when does he explain what it stands for?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 155.7,
        "end": 158.7
      },
      "pred_interval": {
        "start": 150.0,
        "end": 160.0
      },
      "iou": 0.3,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.699999999999989,
        "end": 1.3000000000000114,
        "average": 3.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1388888888888889,
        "text_similarity": 0.47799214720726013,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the high-level relation ('after') right but is largely incorrect: timestamps do not match the reference, the identified utterances are wrong (it mislabels the acronym mention and the explanation) and it introduces unrelated content, so it fails on factual alignment."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the components of the WIPER acronym, when does he start elaborating on 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 212.0
      },
      "pred_interval": {
        "start": 270.0,
        "end": 280.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.0,
        "end": 68.0,
        "average": 65.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2894736842105263,
        "text_similarity": 0.7273387908935547,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the general ordering (explanation follows the listing) but gives substantially incorrect timestamps (270s/280s vs 205s/207\u2013212s), uses a less specific relation ('after' vs 'once_finished'), and omits the end time for E2, so it is mostly inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what brought the patient in, when does he explain what the 'history of presenting complaint' is about?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 346.0,
        "end": 351.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 337.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.0,
        "end": 14.0,
        "average": 15.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3170731707317073,
        "text_similarity": 0.6432391405105591,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor event and the 'after' relation and labels the phrase for E2, but the timecodes are substantially inaccurate (E2 is ~9s earlier and much shorter than the reference) and the E1 end time is omitted, so it only partially matches the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "How long after the speaker says he'll put a picture of all possible questions does the \"REVIEW OF SYSTEMS\" checklist first appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 539.8,
        "end": 543.7
      },
      "pred_interval": {
        "start": 510.0,
        "end": 510.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.799999999999955,
        "end": 33.200000000000045,
        "average": 31.5
      },
      "rationale_metrics": {
        "rouge_l": 0.20454545454545456,
        "text_similarity": 0.6315979957580566,
        "llm_judge_score": 0,
        "llm_judge_justification": "Both E1 and E2 timestamps in the prediction are substantially different from the ground truth (predicted E1 510.0s vs 534.817s; predicted E2 510.5s vs 29.8\u201333.7s), so the temporal relation and times are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is giving examples of systems review questions, when does he ask about \"tummy pain\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 565.74,
        "end": 566.422
      },
      "pred_interval": {
        "start": 651.0,
        "end": 652.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 85.25999999999999,
        "end": 85.57799999999997,
        "average": 85.41899999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.589598536491394,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gets the relation right but is largely incorrect: both E1 and E2 timestamps are far from the ground truth and the predicted E2 question ('are your bowels working normally?') does not match the ground-truth 'tummy pain.' These are key factual mismatches."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the \"JAM THREADS\" mnemonic, when does he say the name \"Sketchy Medical\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 696.0,
        "end": 699.531
      },
      "pred_interval": {
        "start": 704.0,
        "end": 704.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.0,
        "end": 4.969000000000051,
        "average": 6.4845000000000255
      },
      "rationale_metrics": {
        "rouge_l": 0.27692307692307694,
        "text_similarity": 0.703599214553833,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation ('after') right but is largely incorrect: it gives wrong timestamps for both events (704.0s/704.5s vs. 635.0s and 696.0\u2013699.531s) and falsely states the name occurs immediately after the mnemonic, omitting the ~61s gap in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker describes Sketchy Medical, when does he mention drugs' mechanism of action and side effects?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 701.0,
        "end": 703.982
      },
      "pred_interval": {
        "start": 690.0,
        "end": 730.0
      },
      "iou": 0.07454999999999927,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 26.01800000000003,
        "average": 18.509000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.35616438356164387,
        "text_similarity": 0.8208047747612,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the relation ('during') but misreports both the anchor and target timestamps by large margins (E1: 690.0s vs 697.491s; E2: 715.0\u2013730.0s vs 701.0\u2013703.982s), so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks a general question about family health, when does he suggest being specific about asthma, diabetes, and hypertension?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 742.914,
        "end": 745.914
      },
      "pred_interval": {
        "start": 730.0,
        "end": 770.0
      },
      "iou": 0.075,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.913999999999987,
        "end": 24.086000000000013,
        "average": 18.5
      },
      "rationale_metrics": {
        "rouge_l": 0.32941176470588235,
        "text_similarity": 0.624956488609314,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relationship and roughly locates E1, but the E2 timing is significantly displaced and its duration is incorrect compared to the reference, so the temporal alignment is not accurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the importance of signposting, when does he ask if the patient uses any recreational drugs?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 811.123,
        "end": 812.664
      },
      "pred_interval": {
        "start": 810.0,
        "end": 840.0
      },
      "iou": 0.051366666666664666,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.1230000000000473,
        "end": 27.336000000000013,
        "average": 14.22950000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.25316455696202533,
        "text_similarity": 0.7242916226387024,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is largely incorrect: its timestamps differ substantially from the reference (anchor 810.0s vs ~802.6s; target 825.0s\u2013840.0s vs ~811.1s\u2013812.7s) and it omits the key detail that the question immediately follows the explanation, merely stating 'after.'"
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"concerns from ICE\", when does he start saying \"Just generally, if you're feeling stuck\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 880.187,
        "end": 883.471
      },
      "pred_interval": {
        "start": 870.0,
        "end": 871.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.187000000000012,
        "end": 11.971000000000004,
        "average": 11.079000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.379746835443038,
        "text_similarity": 0.6671851277351379,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the relation as 'after' but the timestamps are substantially wrong (predicted anchor ~870\u2013871.5s and target start 871.5s vs correct 879.986s anchor and 880.187s target), so the temporal alignment is incorrect and the extra audiovisual cues are unnecessary/hallucinated."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"golden rulebook\", when does he open both hands outwards in a gesture?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 895.8,
        "end": 897.5
      },
      "pred_interval": {
        "start": 871.5,
        "end": 872.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.299999999999955,
        "end": 25.0,
        "average": 24.649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.3880597014925373,
        "text_similarity": 0.6735484600067139,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction identifies the same events and an 'after' relation, but the timestamps are substantially incorrect (off by ~21 seconds) and the target span does not match the reference; additionally it adds an unsupported 'immediately after' qualifier. These factual timing errors make the answer largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying \"I hope you find this video useful\", when does he say \"Peace\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 910.148,
        "end": 910.609
      },
      "pred_interval": {
        "start": 898.0,
        "end": 899.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.148000000000025,
        "end": 11.109000000000037,
        "average": 11.628500000000031
      },
      "rationale_metrics": {
        "rouge_l": 0.36585365853658536,
        "text_similarity": 0.6515185236930847,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates that 'Peace' follows the prior sentence, but the timestamps are off by about 11 seconds (anchor and target do not match the ground truth), so the key temporal information is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying he has an appointment at 10 am, when does the green text 'Sure, what's your name?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 6.1,
        "end": 8.2
      },
      "pred_interval": {
        "start": 5.8,
        "end": 6.4
      },
      "iou": 0.12500000000000033,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.2999999999999998,
        "end": 1.799999999999999,
        "average": 1.0499999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.380952380952381,
        "text_similarity": 0.7952483296394348,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target and the 'immediately after' relation, and the reported times are very close to the ground truth (5.8s vs 5.9s and 6.4s vs 6.1s); it omits the target's end time but otherwise matches semantically."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes stating his name, when does the green text 'Thank you, Lucas. Please take a seat...' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 11.9,
        "end": 19.0
      },
      "pred_interval": {
        "start": 10.2,
        "end": 11.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.700000000000001,
        "end": 8.0,
        "average": 4.8500000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.225,
        "text_similarity": 0.5778083205223083,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the green text appears shortly after, but the reported times differ from the reference (10.2s vs 10.6s and 11.0s vs 11.9s), it omits the target's end time/duration, and it adds extra text not present in the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'How long is the wait?', when does the green text 'About 10 minutes. Would you like some water while you wait?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 22.1,
        "end": 25.3
      },
      "pred_interval": {
        "start": 20.0,
        "end": 20.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.1000000000000014,
        "end": 4.5,
        "average": 3.3000000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.1839080459770115,
        "text_similarity": 0.7063432931900024,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor and the green text content, but the reported timestamps differ notably (predicts E2 at 20.8s vs ground truth 22.1s) and changes the relation from a slight pause to 'immediately after', so it is factually inaccurate on timing and relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the video explains the 'we're a team' approach with animated graphics, when does the speaker appear at his desk looking at a computer?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 34.6,
        "end": 36.0
      },
      "pred_interval": {
        "start": 43.0,
        "end": 44.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.399999999999999,
        "end": 8.0,
        "average": 8.2
      },
      "rationale_metrics": {
        "rouge_l": 0.2909090909090909,
        "text_similarity": 0.7782109379768372,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction roughly captures the speaker-at-desk timing (35.0\u201337.0 overlaps the true ~34.6\u201336.0) but misidentifies E1's timing (21.1\u201322.8 vs actual 29.5\u201334.6) and incorrectly states the temporal relation ('after' instead of overlapping), so key temporal facts are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker says 'take that extra bit of time to listen', when does the 'OK' hand gesture emoji appear?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 44.0,
        "end": 45.5
      },
      "pred_interval": {
        "start": 40.6,
        "end": 41.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.3999999999999986,
        "end": 3.8999999999999986,
        "average": 3.6499999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.5208333333333334,
        "text_similarity": 0.8238082528114319,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events and their temporal relation ('during'), but the timestamps are significantly offset from the ground truth (about 2.8\u20133s earlier) and the emoji duration is understated, so the timing details are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After Nurse Kim mentions graduating as a registered nurse, when does she talk about working for many different pharmaceutical companies?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 43.0,
        "end": 50.475
      },
      "pred_interval": {
        "start": 17.3,
        "end": 27.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.7,
        "end": 22.875,
        "average": 24.2875
      },
      "rationale_metrics": {
        "rouge_l": 0.12121212121212122,
        "text_similarity": 0.614167332649231,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the 'after' relation but misidentifies and mis-times both events (E1 content/time and E2 start time differ substantially from the ground truth), and adds an irrelevant visual cue; thus it is largely incorrect despite the correct ordering."
      }
    },
    {
      "question_id": "002",
      "question": "Once Nurse Kim finishes describing her background as an 'incredible journey', when does she mention training side-by-side with Dr. Jugenberg for five years?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 149.87,
        "end": 153.25
      },
      "pred_interval": {
        "start": 55.3,
        "end": 60.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 94.57000000000001,
        "end": 92.35,
        "average": 93.46000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.11475409836065574,
        "text_similarity": 0.5122306942939758,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the ordering (background finishes before mention of training) but gives completely incorrect timestamps and interval boundaries compared to the reference, and thus fails to match the key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "While Nurse Kim explains options and possible outcomes, when does she begin examining the patient's stomach?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 157.5,
        "end": 160.5
      },
      "pred_interval": {
        "start": 150.0,
        "end": 155.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.5,
        "end": 5.5,
        "average": 6.5
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.7112712860107422,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct events but gives substantially incorrect timestamps and an incorrect temporal relation: ground truth has E2 starting at 157.5s during E1 (156.8s), whereas the prediction shifts both events earlier and states E2 occurs 'after' E1, contradicting the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After Nurse Kim finishes discussing the benefits, risks, and possible complications of the procedure, when does she start talking about asymmetry?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 169.7,
        "end": 172.0
      },
      "pred_interval": {
        "start": 169.0,
        "end": 175.0
      },
      "iou": 0.38333333333333525,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.6999999999999886,
        "end": 3.0,
        "average": 1.8499999999999943
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6740771532058716,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly labels the relationship as 'after' but gets the key timings wrong: the reference has E2 at ~169.7s (immediately after E1 ~169.5s) while the prediction places E2 at 175.0s and introduces an unsupported overlay detail; this omission/mis-timing makes it largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once Nurse Kim finishes explaining that the one-hour consultation cannot provide everything you need to know, when does she mention that they are always available?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 201.5,
        "end": 203.71
      },
      "pred_interval": {
        "start": 200.0,
        "end": 205.0
      },
      "iou": 0.4420000000000016,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5,
        "end": 1.289999999999992,
        "average": 1.394999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.25287356321839083,
        "text_similarity": 0.6631737947463989,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same utterances but gives incorrect timestamps (E1 at 200.0s vs 201.5s, E2 at 205.0s vs 201.5s) and wrongly states the relation is 'after' instead of an immediate transition, so it is largely incorrect. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces himself and the topic, when does the slide change to 'Objectives for today's lesson'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 24.379,
        "end": 24.5
      },
      "pred_interval": {
        "start": 21.0,
        "end": 21.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.3790000000000013,
        "end": 3.5,
        "average": 3.4395000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.20895522388059704,
        "text_similarity": 0.7174106240272522,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates both event times (E1 ends at ~14.6s vs predicted 21.0s; E2 occurs at 24.379s vs predicted 21.0s) and incorrectly claims the slide appears immediately/ simultaneously rather than later, so it contradicts the ground truth despite broadly noting a following relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the objectives for the lesson, when does the slide change to 'Brain storming time'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 46.529,
        "end": 47.0
      },
      "pred_interval": {
        "start": 43.0,
        "end": 43.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.5290000000000035,
        "end": 4.0,
        "average": 3.7645000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.2028985507246377,
        "text_similarity": 0.5555973052978516,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct events but gives significantly incorrect timestamps (43.0s vs 45.800s and 46.529s) and incorrectly asserts they occur simultaneously rather than after completion, contradicting the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes defining communication as the successful passage of a message from one person to another, when does he start explaining how good communication manifests in medical practice by informing patients of their diagnosis?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 153.0,
        "end": 177.0
      },
      "pred_interval": {
        "start": 160.0,
        "end": 170.0
      },
      "iou": 0.4166666666666667,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 7.0,
        "average": 7.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2926829268292683,
        "text_similarity": 0.5730993151664734,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer correctly identifies the anchor at 150.0s, but it misstates the target start (160.0s vs. ground-truth 153.0s) and fails to reflect that the target immediately follows the anchor; it also adds unconfirmed details about slides/reading. "
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the 'Importance of communication' slide, when does he begin discussing that good doctor-patient communication has been linked to improved patient satisfaction?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 190.0,
        "end": 198.0
      },
      "pred_interval": {
        "start": 165.0,
        "end": 170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.0,
        "end": 28.0,
        "average": 26.5
      },
      "rationale_metrics": {
        "rouge_l": 0.22499999999999998,
        "text_similarity": 0.6568439602851868,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies both event timestamps (placing them ~17\u201325s earlier) and the anchor/target spans do not match the ground truth; it also adds an unsupported claim about reading the slide, so it is largely incorrect despite preserving the 'after' relation."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker starts talking about how a lot of malpractice lawsuits have been documented, when does he explicitly advise being aware of communication's importance to avoid lawsuits?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 226.0,
        "end": 271.0
      },
      "pred_interval": {
        "start": 180.0,
        "end": 185.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.0,
        "end": 86.0,
        "average": 66.0
      },
      "rationale_metrics": {
        "rouge_l": 0.25806451612903225,
        "text_similarity": 0.8106499314308167,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures a similar 'after'/causal relation and that advice follows a remark about lawsuits, but it misidentifies both events' timings and even misstates the anchor content (saying a 'decrease' vs documented malpractice); these factual and temporal errors make it largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the initial slide 'Communication is not just talking' is displayed, when does the speaker mention that physicians can improve health outcomes?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 339.28,
        "end": 346.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 332.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.279999999999973,
        "end": 13.5,
        "average": 11.389999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.27848101265822783,
        "text_similarity": 0.7222365140914917,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor slide and the 'after' relationship, but it misstates the target start time (332.5s vs the reference 339.28s) and omits the target end time, so the timing is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide showing two images (bored girl vs. smiling doctor/patient), when does the speaker describe the first image as depicting a 'horribly bored' lady?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.8,
        "end": 359.0
      },
      "pred_interval": {
        "start": 351.0,
        "end": 354.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.8000000000000114,
        "end": 4.5,
        "average": 4.150000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424243,
        "text_similarity": 0.6545364856719971,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the slide and nearly matches the speaker's description start time (354.5s vs 354.8s), but it mislabels the temporal relation as 'after' instead of 'during', gives an inaccurate slide start time, and omits end times."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker defines verbal communication as 'using spoken words', when is the next time they define non-verbal communication?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 428.87,
        "end": 433.596
      },
      "pred_interval": {
        "start": 390.0,
        "end": 392.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.870000000000005,
        "end": 41.096000000000004,
        "average": 39.983000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.2682926829268293,
        "text_similarity": 0.7591712474822998,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the non\u2011verbal definition follows the verbal one and paraphrases the audio, but the provided timestamps are substantially different from the reference (off by tens of seconds) and thus the timing information is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the 'golden minute', when does he describe the patient's hypothetical response?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 613.818,
        "end": 630.0
      },
      "pred_interval": {
        "start": 510.0,
        "end": 516.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 103.81799999999998,
        "end": 113.39999999999998,
        "average": 108.60899999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3541666666666667,
        "text_similarity": 0.8639324903488159,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly states the temporal relation ('after'), it gives entirely incorrect timestamps for both events and misidentifies the target content, so it fails on key factual alignment with the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions 'Checking facts', when does he mention the next essential element of listening?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 641.157,
        "end": 642.461
      },
      "pred_interval": {
        "start": 522.0,
        "end": 528.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 119.15700000000004,
        "end": 114.46100000000001,
        "average": 116.80900000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.32098765432098764,
        "text_similarity": 0.8091970682144165,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly names 'Checking feelings' as the next element and the immediate-after relationship, but it gives significantly incorrect timestamps (522\u2013526s vs. the reference ~613\u2013641s), so it fails on the key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Before the speaker says 'So, for example, we have three main types of reflective listening', when does he explain what reflective listening involves?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 667.457,
        "end": 687.051
      },
      "pred_interval": {
        "start": 545.0,
        "end": 555.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 122.457,
        "end": 132.05100000000004,
        "average": 127.25400000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1956521739130435,
        "text_similarity": 0.8379136323928833,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the high-level relation right (definition occurs before examples) but mislabels the events and gives incorrect timestamps (does not match the ground-truth E1/E2 timing and roles), so it contains major factual errors."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the three main types of reflective listening, when does he start explaining the 'Repeating' example?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 710.0,
        "end": 737.0
      },
      "pred_interval": {
        "start": 706.0,
        "end": 707.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 30.0,
        "average": 17.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.6432790160179138,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the key timestamps (E1 and E2 differ by ~10\u201314s from the reference), incorrectly asserts an 'immediately after' relation instead of the longer gap, and omits the provided end time, so it fails to match the reference. "
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the 'Repeating' example, when does he introduce 'Rephrasing'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 720.0,
        "end": 720.4
      },
      "pred_interval": {
        "start": 727.0,
        "end": 728.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 7.600000000000023,
        "average": 7.300000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.19780219780219782,
        "text_similarity": 0.5166207551956177,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the general ordering (introduction occurs after the prior example) but misidentifies the anchor example, gives times that conflict significantly with the reference, and reports a different phrasing for the 'Rephrasing' introduction, so key factual elements are incorrect or hallucinated."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing 'Reflection of feeling by showing empathy', when does the 'Non-verbal' slide appear?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 780.0,
        "end": 821.5
      },
      "pred_interval": {
        "start": 742.0,
        "end": 743.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.0,
        "end": 78.5,
        "average": 58.25
      },
      "rationale_metrics": {
        "rouge_l": 0.27848101265822783,
        "text_similarity": 0.6622258424758911,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation as 'after' but the reported timestamps (742.0s \u2192 743.0s) conflict substantially with the ground truth times (778.5s \u2192 780.0s), so the key temporal anchors are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises to smile, when does he mention checking for signs of pain?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.045,
        "end": 882.0
      },
      "pred_interval": {
        "start": 870.0,
        "end": 877.0
      },
      "iou": 0.3295833333333367,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.044999999999959,
        "end": 5.0,
        "average": 4.0224999999999795
      },
      "rationale_metrics": {
        "rouge_l": 0.2631578947368421,
        "text_similarity": 0.6739322543144226,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly captures the order and that checking for pain is advised immediately after smiling, but the provided timestamps are slightly off (by ~0.9\u20131.5s) and it omits the later explanation/conclusion time (~882.0s)."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the cultural interpretations of folding arms, when does he advise to avoid folding arms?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 932.0,
        "end": 936009.0
      },
      "pred_interval": {
        "start": 898.0,
        "end": 903.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 935106.0,
        "average": 467570.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3098591549295775,
        "text_similarity": 0.7406502962112427,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misstates both timestamps and temporal relation: the ground truth places the discussion at ~915\u2013926s and the advice at ~932\u2013936s, whereas the prediction gives 898.0s and 899.5s and claims the advice occurs immediately after, which contradicts the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker instructs to introduce yourself to the patient, when does he advise to explain your role as a student or intern?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 985.0,
        "end": 990.853
      },
      "pred_interval": {
        "start": 914.0,
        "end": 920.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 71.0,
        "end": 70.85299999999995,
        "average": 70.92649999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3513513513513513,
        "text_similarity": 0.5235587954521179,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the sequence right (introduce first, then explain role/consent) but the timestamps are substantially incorrect (predicted ~914\u2013915.5s vs. correct ~982\u2013990s), so it fails to match the key temporal facts."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"if you're in the hospital\", when does he refer to \"inpatient patients\"?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1059.6,
        "end": 1059.8
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1121.0
      },
      "iou": 0.002816901408451345,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.599999999999909,
        "end": 61.200000000000045,
        "average": 35.39999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.19718309859154928,
        "text_similarity": 0.6213005781173706,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives wrong timestamps for both anchor and target (anchor reported much earlier, target given as an extended interval) and states the target overlaps the anchor, whereas the ground truth places the target after the anchor."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining how to start a consultation, when does he give the example \"how can I help you today?\"",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1069.0,
        "end": 1070.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1121.0
      },
      "iou": 0.014084507042253521,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.0,
        "end": 51.0,
        "average": 35.0
      },
      "rationale_metrics": {
        "rouge_l": 0.24691358024691357,
        "text_similarity": 0.752650260925293,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps are substantially incorrect (E1 given at 1050.0s vs 1064.5\u20131067.5s and E2 spanning 1050.0\u20131121.0s vs 1069.0\u20131070.0s) and it wrongly claims E2 occurs during E1, so the prediction contradicts and hallucinates timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes explaining the 'golden minute', when does he announce the end of the lecture?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1090.0,
        "end": 1094.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1121.0
      },
      "iou": 0.056338028169014086,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.0,
        "end": 27.0,
        "average": 33.5
      },
      "rationale_metrics": {
        "rouge_l": 0.27027027027027023,
        "text_similarity": 0.7951973080635071,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misconstrues all key timing information and their relation: it places E1 at 1050s (vs 1089s), expands E2 to 1050\u20131121s (vs 1090\u20131094s), and incorrectly claims overlap rather than E2 occurring after E1, introducing hallucinated durations."
      }
    },
    {
      "question_id": "001",
      "question": "While Raquel is talking about the hospital providing opportunities for nurses, when is she shown smiling and opening a package?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 2.0,
        "end": 4.5
      },
      "pred_interval": {
        "start": 0.0,
        "end": 2.7
      },
      "iou": 0.15555555555555559,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 1.7999999999999998,
        "average": 1.9
      },
      "rationale_metrics": {
        "rouge_l": 0.2571428571428571,
        "text_similarity": 0.30529874563217163,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the key relation that the smiling/opening visual happens during her speech, but it gives substantially different and incorrect timestamps (misstating the speech start and shifting/shortening the visual event), so the temporal details do not match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria finishes saying that new nurses will be nudged to become lifelong learners, when does Precious state that the teamwork is strong?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 14.321,
        "end": 16.486
      },
      "pred_interval": {
        "start": 9.7,
        "end": 12.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.621,
        "end": 4.486000000000001,
        "average": 4.5535000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.5139941573143005,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the ordering (Precious speaks after Maria) but the reported timestamps are significantly incorrect (Maria end 9.7s vs 14.301s; Precious start 12.0s vs 14.321s) and the predicted answer omits Precious's end time, so it fails on factual accuracy and completeness."
      }
    },
    {
      "question_id": "003",
      "question": "After Reny states that the hospital does things up to a magnet level, when does Raquel say her values align with the hospital's values?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 42.854,
        "end": 50.692
      },
      "pred_interval": {
        "start": 38.5,
        "end": 41.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.353999999999999,
        "end": 9.091999999999999,
        "average": 6.722999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.13157894736842105,
        "text_similarity": 0.44995802640914917,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the ordering (Raquel speaks after Reny) but the timestamps are significantly inaccurate (Reny off by ~4s, Raquel start off by ~1.25s) and the Raquel end time is omitted, so it fails to match the reference precisely."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that healthcare in Siem Reap is not the best, when is the Royal Angkor International Hospital first shown on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 94.0,
        "end": 99.1
      },
      "pred_interval": {
        "start": 16.7,
        "end": 16.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.3,
        "end": 82.19999999999999,
        "average": 79.75
      },
      "rationale_metrics": {
        "rouge_l": 0.22535211267605634,
        "text_similarity": 0.539269745349884,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives entirely different timestamps and describes a website cut at ~16.9s, which contradicts the reference that the Royal Angkor visual appears at 94.0s (speaker finishes at 82.215s and begins describing at 99.100s); key temporal facts are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he begin describing the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 180.289,
        "end": 185.074
      },
      "pred_interval": {
        "start": 78.1,
        "end": 78.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 102.189,
        "end": 106.77400000000002,
        "average": 104.48150000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2631578947368421,
        "text_similarity": 0.7134670615196228,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction names the same clinic but gives vastly incorrect timestamps (\u224878s vs correct 165.611s start and 180.289s description) and wrongly asserts an immediate transition; it therefore contradicts the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he visited a clinic for chest congestion, when does he mention the Paschern Dental Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 209.8,
        "end": 211.4
      },
      "pred_interval": {
        "start": 170.0,
        "end": 170.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.80000000000001,
        "end": 41.400000000000006,
        "average": 40.60000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.18666666666666668,
        "text_similarity": 0.5685423016548157,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect: it misidentifies both events and times, claims the Paschern Dental Clinic mention is the same event as the chest-congestion clinic and gives wrong timestamps, contradicting the ground truth that the dental mention occurs after the chest-congestion visit."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he introduce the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.0,
        "end": 184.8
      },
      "pred_interval": {
        "start": 240.0,
        "end": 240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.0,
        "end": 55.19999999999999,
        "average": 55.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.4285714285714286,
        "text_similarity": 0.6808847188949585,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives incorrect timestamps (both at 240.0s vs. 182.0s and 184.0\u2013184.8s) and even states both events occur simultaneously while claiming an 'immediately after' relation, so it fails on factual timing and relation accuracy."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker introduces the Cigna International Health Policy, when is the insurance quote form displayed with personal information?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 290.0,
        "end": 310.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.0,
        "end": 50.0,
        "average": 55.5
      },
      "rationale_metrics": {
        "rouge_l": 0.325,
        "text_similarity": 0.7185284495353699,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction identifies the two events but gives times that differ greatly from the ground truth and states the wrong temporal relation ('after' vs. 'once_finished'), so it is largely incorrect. "
      }
    },
    {
      "question_id": "002",
      "question": "After the voiceover states that the Cigna policy is \"fairly typical of policies of this type\", when does the Cigna website display the form for inputting personal details to get a quote?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 352.9,
        "end": 358.0
      },
      "pred_interval": {
        "start": 368.7,
        "end": 371.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.800000000000011,
        "end": 13.199999999999989,
        "average": 14.5
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.8590914607048035,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target events and their 'after' relationship, but both provided timestamps are substantially (\u224817\u201318s) later than the ground truth, so the timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the voiceover mentions \"evacuation service, also part of Cigna plan\", when is the Global Rescue website displayed on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 384.0,
        "end": 431.0
      },
      "pred_interval": {
        "start": 385.5,
        "end": 387.2
      },
      "iou": 0.03617021276595721,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5,
        "end": 43.80000000000001,
        "average": 22.650000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.2921348314606742,
        "text_similarity": 0.898792028427124,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') right but the timestamps are substantially off (E1 predicted 385.5s vs correct 379.0s; E2 387.2s vs 384.0s) and it omits the page scroll/display duration to 431.0s while adding an unverified visual cue. These are significant factual omissions/errors. "
      }
    },
    {
      "question_id": "001",
      "question": "After the host concludes his introduction about the fight in modern healthcare, when does he introduce Sarah?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 19.4,
        "end": 22.0
      },
      "pred_interval": {
        "start": 10.2,
        "end": 10.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.2,
        "end": 11.4,
        "average": 10.3
      },
      "rationale_metrics": {
        "rouge_l": 0.1590909090909091,
        "text_similarity": 0.4334322214126587,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives substantially different timestamps (10.2s/10.6s vs correct 18.0s/19.4\u201322.0s) and thus does not match the ground-truth temporal alignment; while it correctly indicates a sequential transition, the key timing information is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While Sarah is introducing herself and her genetic condition, when does she mention having her very first surgery?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.08,
        "end": 108.8
      },
      "pred_interval": {
        "start": 60.6,
        "end": 61.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.48,
        "end": 47.5,
        "average": 45.489999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.12244897959183672,
        "text_similarity": 0.580536961555481,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that Sarah mentions her first surgery immediately after introducing her condition, but the timestamps are substantially incorrect (57.5s/60.6s vs ground-truth 95.0s/104.08s), so it fails to answer the asked timing accurately."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sarah finishes describing her role as a volunteer patient representative for a non-profit organization, when does the static image showing her behind a 'CHILDREN'S TUMOR FOUNDATION' table appear?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 185.0,
        "end": 190.0
      },
      "pred_interval": {
        "start": 240.0,
        "end": 250.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.0,
        "end": 60.0,
        "average": 57.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3428571428571428,
        "text_similarity": 0.7439827919006348,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the static image follows Sarah's speech, but it gives completely different and incorrect timestamps (238.8s/250.0s vs. the reference 150s and 185.0\u2013190.0s), so key factual timing details are contradicted."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes explaining the purpose of the 'Shine a Light Walk' to raise money and awareness, when does the video clip showing children running at an outdoor event play?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 189.0,
        "end": 192.0
      },
      "pred_interval": {
        "start": 272.0,
        "end": 282.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.0,
        "end": 90.0,
        "average": 86.5
      },
      "rationale_metrics": {
        "rouge_l": 0.27272727272727276,
        "text_similarity": 0.7064381241798401,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the ordering ('after') and transition cue right but is largely incorrect: timestamps and clip duration differ substantially (predicted ~90s later and a 10s clip vs correct 179.0s and 189.0\u2013192.0s), and it contradicts the 'immediately follows' timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once Steve asks if the 'Shine a Light Walk' goes throughout the world, when does Sarah begin to explain that the walks do not?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 253.2,
        "end": 258.88
      },
      "pred_interval": {
        "start": 303.0,
        "end": 310.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.80000000000001,
        "end": 51.120000000000005,
        "average": 50.46000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.32989690721649484,
        "text_similarity": 0.7591489553451538,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the prediction correctly labels Sarah's response as 'immediately after' Steve's question, the timestamps are substantially off (predicted E1 at 300.0s vs correct 252.5s; predicted E2 start 303.0s vs correct 253.2s) and thus it contradicts the key factual timing information."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes asking Sarah what things in miscommunication can lead to delays or misdiagnosis, when does the woman start responding?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 362.48,
        "end": 365.44
      },
      "pred_interval": {
        "start": 380.0,
        "end": 384.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.519999999999982,
        "end": 18.560000000000002,
        "average": 18.039999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.24691358024691357,
        "text_similarity": 0.5993898510932922,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the woman speaks after the man, but the timestamps are significantly incorrect (predicted 380.0/384.0s vs reference 356.48/362.48s) and it mischaracterizes the timing (a ~4s gap vs an almost immediate ~0.56s gap), so it omits key factual details and is less precise than the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman gives the example of writing 'hyperthyroid instead of hypothyroid', when does the man respond with 'That that's pretty bad'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 389.2,
        "end": 432.5
      },
      "pred_interval": {
        "start": 402.0,
        "end": 406.0
      },
      "iou": 0.092378752886836,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.800000000000011,
        "end": 26.5,
        "average": 19.650000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.21686746987951808,
        "text_similarity": 0.6516396999359131,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') and that there's a short pause, but its reported timecodes are substantially off from the ground truth (predicted ~402\u2013406s vs actual ~385\u2013389s), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "003",
      "question": "After the man says he tried researching miscommunication problems, when does he state his finding about thousands of preventable deaths?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 446.56,
        "end": 535.68
      },
      "pred_interval": {
        "start": 630.0,
        "end": 634.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 183.44,
        "end": 98.32000000000005,
        "average": 140.88000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1443298969072165,
        "text_similarity": 0.4858663082122803,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal order ('after') and paraphrases the speech, but the provided timestamps are significantly off from the ground-truth intervals and misalign the events, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks, \"What's in my budget to fix it?\", when does she start asking, \"How important is it to me to fix this issue?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 518.66,
        "end": 522.26
      },
      "pred_interval": {
        "start": 40.0,
        "end": 41.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 478.65999999999997,
        "end": 481.26,
        "average": 479.96
      },
      "rationale_metrics": {
        "rouge_l": 0.1518987341772152,
        "text_similarity": 0.269708514213562,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the order (the target question follows the anchor) but gives incorrect start times and wrongly states the second question begins almost immediately; this contradicts the reference timing and omits the correct span."
      }
    },
    {
      "question_id": "002",
      "question": "After the man finishes saying, \"not continuing medical bills,\" when does he start asking, \"So, what does successful self-advocacy look like?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 643.04,
        "end": 646.32
      },
      "pred_interval": {
        "start": 70.0,
        "end": 71.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 573.04,
        "end": 575.32,
        "average": 574.1800000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.13157894736842105,
        "text_similarity": 0.2805747389793396,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps (69.8s\u219270.0s) conflict strongly with the reference times (anchor ends 634.36s; target starts 643.04s\u2013646.32s), and the prediction adds unsupported detail about audio fading out; therefore it is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining what a doctor's follow-up might entail, when does the woman start asking, \"Or will I actually be able to get into your office in two weeks?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 679.0,
        "end": 683.92
      },
      "pred_interval": {
        "start": 72.0,
        "end": 73.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 607.0,
        "end": 610.92,
        "average": 608.96
      },
      "rationale_metrics": {
        "rouge_l": 0.12658227848101267,
        "text_similarity": 0.4609781503677368,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the woman's question follows the man's explanation, but the timestamps are substantially incorrect and it omits the end time; it also wrongly claims no pause while the reference shows a ~1.08s gap. These factual errors make it largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Immediately after the woman asks if she should follow up if she is still experiencing symptoms, when does the man ask what if the symptoms go away?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.38,
        "end": 707.15
      },
      "pred_interval": {
        "start": 697.3,
        "end": 701.9
      },
      "iou": 0.2558375634517742,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.080000000000041,
        "end": 5.25,
        "average": 3.6650000000000205
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.784213662147522,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the correct utterances and that the man speaks after the woman, but the reported timestamps differ substantially from the reference (target start 701.9s vs 699.38s) and it fails to state the immediate-follow relationship, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying to voice symptoms and concerns clearly, when does he give an example about shoulder pain?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 734.59,
        "end": 737.0
      },
      "pred_interval": {
        "start": 727.8,
        "end": 730.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.790000000000077,
        "end": 6.2000000000000455,
        "average": 6.495000000000061
      },
      "rationale_metrics": {
        "rouge_l": 0.18823529411764706,
        "text_similarity": 0.7715263366699219,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the example and that it follows the anchor, but the provided timestamps are several seconds earlier than the ground truth (E1: 727.8s vs 733.68s; E2: 730.8s vs 734.59s), so the temporal localization is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes warning not to try putting a hand in an electrical outlet, when does the woman agree and say not to try that?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 810.0,
        "end": 812.0
      },
      "pred_interval": {
        "start": 767.2,
        "end": 769.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.799999999999955,
        "end": 42.5,
        "average": 42.64999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.23880597014925375,
        "text_similarity": 0.7788964509963989,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the dialogue sequence (man warns, woman immediately agrees) but the provided timestamps conflict substantially with the reference (predicted ~767\u2013769s vs. reference ~808\u2013812s), so the timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes saying to assume benevolence of your doctor, when does the man begin to speak?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.9,
        "end": 879.1
      },
      "pred_interval": {
        "start": 870.0,
        "end": 871.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.899999999999977,
        "end": 7.5,
        "average": 8.199999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.4404613971710205,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly preserves the temporal relation that the man speaks after the woman, but the reported timestamps are significantly off (870.0s/871.6s vs. 878.0s/878.9s) and it adds a quoted continuation not present in the reference, so it's only partially accurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks about trying non-surgical options first, when does the woman reply 'Yes'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 899.7,
        "end": 900.1
      },
      "pred_interval": {
        "start": 920.2,
        "end": 922.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.5,
        "end": 21.899999999999977,
        "average": 21.19999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.36111111111111116,
        "text_similarity": 0.4989222586154938,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that the woman replies 'Yes' after the man's question, but the timestamps are substantially wrong (predicted 922.0s vs. reference 899.7s), so it fails on the key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the man concludes his statement about how to ask for another opinion, when does the woman respond that asking for another opinion is definitely valid?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 982.0,
        "end": 988.72
      },
      "pred_interval": {
        "start": 984.2,
        "end": 986.6
      },
      "iou": 0.3571428571428523,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.2000000000000455,
        "end": 2.1200000000000045,
        "average": 2.160000000000025
      },
      "rationale_metrics": {
        "rouge_l": 0.16363636363636364,
        "text_similarity": 0.3590473532676697,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly preserves the dialog relation (woman affirms the man's point) and the woman\u2019s affirmative intent, but it misstates both timestamps and the man\u2019s quoted phrasing, and introduces unsupported dialogue for the man, so key factual elements are incorrect or hallucinated."
      }
    },
    {
      "question_id": "001",
      "question": "After the man suggests bringing someone along if you're not feeling safe, when does the woman agree that it's advisable?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1127.0,
        "end": 1130.0
      },
      "pred_interval": {
        "start": 1110.0,
        "end": 1125.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.0,
        "end": 5.0,
        "average": 11.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2558139534883721,
        "text_similarity": 0.5320087671279907,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the woman agrees immediately after the man's suggestion, but the reported timestamps are substantially off from the reference (man: 1095s vs 1120s; woman: 1110s vs 1127s), so the timing information is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman talks about a doctor not trusting a patient's pain because they don't act like they're in pain, when does she give an example of a loved one vouching for the patient?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1167.68,
        "end": 1174.48
      },
      "pred_interval": {
        "start": 1150.0,
        "end": 1165.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.680000000000064,
        "end": 9.480000000000018,
        "average": 13.580000000000041
      },
      "rationale_metrics": {
        "rouge_l": 0.2903225806451613,
        "text_similarity": 0.6177339553833008,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the same illustrative content but gives substantially incorrect timestamps (off by ~20+ seconds) and adds a quoted phrasing not present in the reference, so it fails on factual timing and may hallucinate wording."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks if it is legal to be given your own medical records, when does the woman confirm that it is?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1268.6,
        "end": 1270.7
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1237.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.59999999999991,
        "end": 32.90000000000009,
        "average": 35.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2823529411764706,
        "text_similarity": 0.5802191495895386,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the woman's confirmation follows and directly answers the man's question, but the provided anchor/target timestamps are substantially incorrect (off by ~30 seconds), so the timing information is factually wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman mentions that things have changed a lot with electronic medical records, when does the man state that bureaucracy reminds him of common barriers?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1333.0,
        "end": 1339.5
      },
      "pred_interval": {
        "start": 1367.0,
        "end": 1381.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 41.5,
        "average": 37.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2476190476190476,
        "text_similarity": 0.739609956741333,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the relative relation ('after') but misplaces both anchor and target timestamps and misattributes the woman's utterance, so the key factual timing details are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks about common barriers and how to overcome them, when does the woman share her fear of ants?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.36,
        "end": 1383.7
      },
      "pred_interval": {
        "start": 1418.0,
        "end": 1429.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 40.6400000000001,
        "end": 45.700000000000045,
        "average": 43.17000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.23300970873786406,
        "text_similarity": 0.7997928857803345,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the woman shares her fear and that this occurs 'after' the man's question, but it gives substantially wrong absolute timestamps (both anchor and target) and omits the target end time, so it fails to match the key temporal details in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says to write things down on paper and give it to the doctor, when does he mention a doctor refusing to look at the paper?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1484.96,
        "end": 1490.0
      },
      "pred_interval": {
        "start": 1461.0,
        "end": 1477.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.960000000000036,
        "end": 13.0,
        "average": 18.480000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.3235294117647059,
        "text_similarity": 0.4273582398891449,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the event order (target after anchor) but the timestamps are substantially off and do not match the reference (predicted anchor ~1457 vs reference 1438.1, predicted target 1461\u20131477 vs reference 1484.96\u20131490.0), so the timing is incorrect and thus incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "While the woman discusses prioritizing cognition, when does she state that she would rather be in pain than have her mental capacity harmed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1534.64,
        "end": 1542.24
      },
      "pred_interval": {
        "start": 1516.0,
        "end": 1525.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.6400000000001,
        "end": 17.24000000000001,
        "average": 17.940000000000055
      },
      "rationale_metrics": {
        "rouge_l": 0.368,
        "text_similarity": 0.6522016525268555,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly quotes the target sentence but gives significantly incorrect timestamps (places it ~9\u201318s earlier than the reference) and misidentifies the anchor timing; it also adds unsupported details about audio/expressions, so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'Nord, what is that?', when does the woman state what NORD stands for?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.4,
        "end": 1615.4
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.40000000000009,
        "end": 15.400000000000091,
        "average": 19.40000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.6805239915847778,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly timestamps both events (1590s vs 1611\u20131615s), misquotes the anchor, omits the word 'National' and adds extraneous phrasing, though it correctly conveys an immediate-response relationship; overall the factual and temporal details do not match."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says 'I read that I need to start this at 30', when does she explain why she needs the doctor to order it?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1692.24,
        "end": 1711.28
      },
      "pred_interval": {
        "start": 1600.0,
        "end": 1610.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 92.24000000000001,
        "end": 101.27999999999997,
        "average": 96.75999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.33766233766233766,
        "text_similarity": 0.6378458738327026,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the semantic continuation and quotes the target phrase, but it gives substantially incorrect timestamps and adds unsupported visual/audio cues; timing errors are critical for this video-based task."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman explains how to mirror a planned course of action, when does she suggest asking the doctor what they heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.0,
        "end": 1799.8
      },
      "pred_interval": {
        "start": 1800.0,
        "end": 1820.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 20.200000000000045,
        "average": 11.600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.20833333333333334,
        "text_similarity": 0.6369668841362,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction captures the main advice and correct ordering (the ask follows the explanation), but it misstates the precise timestamps and greatly overestimates the target duration, and it adds unverified visual/audio details; these timing and detail inaccuracies reduce its correctness for a video-timestamp task."
      }
    },
    {
      "question_id": "002",
      "question": "After the man advises to 'just dig' and not use a medical dictionary, when does he ask if medical language can be 'dumbed down'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1836.56,
        "end": 1841.52
      },
      "pred_interval": {
        "start": 1870.0,
        "end": 1880.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.440000000000055,
        "end": 38.48000000000002,
        "average": 35.960000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322035,
        "text_similarity": 0.5959773063659668,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor utterance and the question content, but the timestamps are substantially incorrect, the temporal relation ('immediately after') contradicts the reference, and it adds unverified visual/audio cues\u2014making it largely unreliable for timing alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks what to do when doctors look rushed, when does the woman describe slowing down and capturing their attention?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1965.6,
        "end": 1973.5
      },
      "pred_interval": {
        "start": 1992.5,
        "end": 2002.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.90000000000009,
        "end": 28.5,
        "average": 27.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.406435489654541,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the woman's quoted advice and the correct ordering (anchor then target), but the reported timestamps are substantially later than the reference (off by ~27\u201329 seconds), so the temporal localization is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes suggesting a doctor might be having a bad day, when does the man humorously ask if doctors have bad days?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2002.5,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 2041.5,
        "end": 2047.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 43.0,
        "average": 41.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3829787234042553,
        "text_similarity": 0.49460017681121826,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly conveys that the man speaks after the woman, but the reported timestamps are wildly off (\u224830\u201340s discrepancy) and the quoted line differs from the ground truth, so the temporal and verbal details are largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man introduces the 'five practical tips to advocate for yourself', when does the woman begin talking about writing down questions?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2195.28,
        "end": 2199.7
      },
      "pred_interval": {
        "start": 2340.0,
        "end": 2350.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 144.7199999999998,
        "end": 150.30000000000018,
        "average": 147.51
      },
      "rationale_metrics": {
        "rouge_l": 0.1978021978021978,
        "text_similarity": 0.5919184684753418,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the target event (woman discussing writing down questions) occurs after the anchor and references the same content, but the provided timestamps are substantially different from the ground-truth intervals, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "During the man's explanation about preparing beforehand, when does he demonstrate by pointing to his neck?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.0,
        "end": 2237.0
      },
      "pred_interval": {
        "start": 2340.0,
        "end": 2350.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 105.0,
        "end": 113.0,
        "average": 109.0
      },
      "rationale_metrics": {
        "rouge_l": 0.28235294117647064,
        "text_similarity": 0.7757152318954468,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the events and the 'during' relationship, but both the anchor and target timestamps are substantially incorrect (off by ~115 seconds), so the temporal alignment is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the man describes getting dizzy when walking up and down stairs, when does the woman mention repeating back what was heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2316.0,
        "end": 2317.0
      },
      "pred_interval": {
        "start": 2370.0,
        "end": 2380.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.0,
        "end": 63.0,
        "average": 58.5
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615383,
        "text_similarity": 0.6750560998916626,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') and approximates the target content, but it misidentifies the anchor event (wrong speaker) and both event timestamps are substantially incorrect, omitting the correct time spans."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman expresses her inability to distract herself from the pain, when does the man advise her to be specific?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.7,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2330.0,
        "end": 2340.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.69999999999982,
        "end": 29.5,
        "average": 34.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.2181818181818182,
        "text_similarity": 0.7104285955429077,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') and the gist of the utterances, but the E1 and E2 timestamps and durations are substantially misaligned with the reference (off by ~24\u201338 seconds), so the answer is factually incorrect in timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says 'document everything', when does the woman affirm the advice and tell viewers to take notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2504.5,
        "end": 2506.0
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2495.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.5,
        "end": 11.0,
        "average": 12.75
      },
      "rationale_metrics": {
        "rouge_l": 0.28888888888888886,
        "text_similarity": 0.6070235967636108,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') right but both event timestamps are off by ~10\u201312s and the woman's quoted utterance differs from the reference, so it fails to match the correct timing and content."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes asking if one should ask permission before recording their doctor, when does the woman respond?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2531.6,
        "end": 2533.5
      },
      "pred_interval": {
        "start": 2502.0,
        "end": 2503.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.59999999999991,
        "end": 30.5,
        "average": 30.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.27906976744186046,
        "text_similarity": 0.6894634366035461,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('immediately after') but has substantially incorrect timestamps (off by ~30s) and the quoted response content/duration contradicts the reference, so it is largely inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman begins explaining the hope that doctors will focus more on patients with AI recording, when does she explain why she almost always checks her online appointment notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.0,
        "end": 2579.0
      },
      "pred_interval": {
        "start": 2522.0,
        "end": 2525.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.0,
        "end": 54.0,
        "average": 49.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3218390804597701,
        "text_similarity": 0.6841428279876709,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps and event descriptions do not match the reference: both anchor and target times are about 40s earlier and the target start/end boundaries differ substantially, so the prediction is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks if one should be assertive, when does he introduce the topic of emotional intelligence?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2701.0,
        "end": 2710.0
      },
      "pred_interval": {
        "start": 2816.4,
        "end": 2835.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 115.40000000000009,
        "end": 125.30000000000018,
        "average": 120.35000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.2260869565217391,
        "text_similarity": 0.6313866376876831,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relationship ('immediately after'), but both event timestamps are substantially different from the ground truth and it introduces an unsupported detail about the woman's response being cut short."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man says 'You wanna learn some breathing control', when does he start describing box breathing?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.0,
        "end": 2747.0
      },
      "pred_interval": {
        "start": 2844.8,
        "end": 2851.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 104.80000000000018,
        "end": 104.09999999999991,
        "average": 104.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7182149887084961,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the events and that the description follows immediately after, but the absolute timestamps are significantly incorrect (off by ~115 seconds), so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "While the man is saying 'If you want, share your story in the comments', when is the 'COMMENT BELOW' graphic displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2875.0,
        "end": 2878.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.0,
        "end": 45.0,
        "average": 45.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21568627450980393,
        "text_similarity": 0.5824117660522461,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relationship (the graphic is displayed during the man's speech), but its timestamps are significantly off from the reference (shifted by ~45s and with incorrect endpoints), so the key factual timing information is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the thumbs up icon appears on screen, when is the next graphic ('COMMENT BELOW') displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2878.0,
        "end": 2882.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.0,
        "end": 41.0,
        "average": 41.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.642731249332428,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives entirely different timestamps and states E2 appears simultaneously with E1, which contradicts the ground-truth timings (E1 at 2862.0s, E2 at 2920.0\u20132923.0). It omits the correct sequence and hallucinates event timings, so it is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After Marissa Fourie introduces herself, when does she mention cross-cultural communication?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 34.2,
        "end": 36.5
      },
      "pred_interval": {
        "start": 27.2,
        "end": 27.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0000000000000036,
        "end": 8.7,
        "average": 7.850000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2592592592592593,
        "text_similarity": 0.669619619846344,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer roughly matches the introduction (7s vs 8.1s) and the relation 'after', but the reported time for 'cross-cultural communication' (27.2\u201327.8s) is significantly earlier than the correct interval (34.2\u201336.5s), so the key timing is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After mentioning cross-cultural communication, when does Marissa Fourie next mention personality-specific communication skills?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 37.0,
        "end": 39.0
      },
      "pred_interval": {
        "start": 37.2,
        "end": 37.7
      },
      "iou": 0.25,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.20000000000000284,
        "end": 1.2999999999999972,
        "average": 0.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3492063492063492,
        "text_similarity": 0.515326976776123,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the second mention (~37.2s) and the ordering, but it misstates the initial 'cross-cultural communication' time (27.2s vs. reference 34.2s) and omits the end time for E2."
      }
    },
    {
      "question_id": "003",
      "question": "After encouraging viewers to join PhysioPlus, when does Marissa Fourie say 'See you there!'?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 62.9,
        "end": 63.7
      },
      "pred_interval": {
        "start": 58.2,
        "end": 58.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.699999999999996,
        "end": 5.200000000000003,
        "average": 4.949999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322032,
        "text_similarity": 0.5057611465454102,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction identifies both events and their order but the timestamps are off by several seconds (encouragement at 54s vs 48.6s; 'See you there!' at 58.2s vs 62.9\u201363.7s) and incorrectly characterizes the second phrase as occurring 'immediately after' the encouragement when there is a ~14s gap."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes mentioning \"the dosage in each area\", when does the woman in blue gloves point to the glabella area of the patient's forehead?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 4.469,
        "end": 4.8
      },
      "pred_interval": {
        "start": 4.0,
        "end": 4.6
      },
      "iou": 0.1637499999999992,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.4690000000000003,
        "end": 0.20000000000000018,
        "average": 0.33450000000000024
      },
      "rationale_metrics": {
        "rouge_l": 0.24175824175824173,
        "text_similarity": 0.5408840179443359,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timings conflict with the reference: it places E2 at 4.0s (before the correct 4.469s) and ends E1 at 4.0s (vs 4.161s), implying overlap/incorrect ordering. The relation and visual-cue timing therefore contradict the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the dosage for the brow lift, when does the woman in blue gloves point to the patient's upper lip?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 12.121,
        "end": 12.5
      },
      "pred_interval": {
        "start": 9.0,
        "end": 9.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.1210000000000004,
        "end": 2.9000000000000004,
        "average": 3.0105000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.22448979591836735,
        "text_similarity": 0.6213276386260986,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the sequence (speaker then point) but the timestamps are substantially wrong (E1/E2 off by ~3.1s) and it introduces a likely hallucinated quote and incorrect durations, so it is largely inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the dosage for the lip flip, when does the text \"TIME TO INJECT!\" appear on screen?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 18.291,
        "end": 21.0
      },
      "pred_interval": {
        "start": 16.2,
        "end": 16.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.091000000000001,
        "end": 4.600000000000001,
        "average": 3.3455000000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.23255813953488372,
        "text_similarity": 0.6111928224563599,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the text appears after the speaker finishes, but it gives incorrect timestamps (predicts E1 ends at 16.2s vs reference 15.067s and E2 at 16.2s vs reference 18.291s) and omits that the text remains until the end, so it contradicts and is incomplete on key facts."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host welcomes Rich, when does Rich begin his response?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 33.015,
        "end": 34.078
      },
      "pred_interval": {
        "start": 18.6,
        "end": 22.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.415,
        "end": 11.778000000000002,
        "average": 13.0965
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.8523696660995483,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that Rich's response immediately follows the host's welcome, but it provides substantially incorrect timestamps (18.6s/22.3s vs. the ground-truth 31.333s/33.015s), so key factual details are wrong."
      }
    },
    {
      "question_id": "002",
      "question": "While Rich is explaining how medicine may have let relationships with patients deteriorate, when does he say that scientific facts will protect us?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 89.0,
        "end": 93.76
      },
      "pred_interval": {
        "start": 71.4,
        "end": 72.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.599999999999994,
        "end": 21.560000000000002,
        "average": 19.58
      },
      "rationale_metrics": {
        "rouge_l": 0.1794871794871795,
        "text_similarity": 0.5449897050857544,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly places both timestamps: E1 is off by ~2.2s and E2 is far earlier (72.2s) than the reference (89.0\u201393.76s), and it wrongly claims the phrase is a direct continuation rather than occurring later within the broader explanation."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks what trust looks like in the future with intermediaries, when does Rich first discuss the stethoscope in relation to technology in medicine?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 112.0,
        "end": 113.0
      },
      "pred_interval": {
        "start": 68.1,
        "end": 68.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.900000000000006,
        "end": 44.3,
        "average": 44.1
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962025,
        "text_similarity": 0.7807376980781555,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that Rich's mention occurs after the host's question, but the timestamps are substantially wrong (68s vs. 106\u2013112s in the reference) and the claim of an immediate follow-up is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the man in glasses finishes describing the giant TV screen in a new hospital exam room, when does the video show a patient interacting with a screen in a hospital bed?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 167.6,
        "end": 177.6
      },
      "pred_interval": {
        "start": 150.0,
        "end": 155.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.599999999999994,
        "end": 22.599999999999994,
        "average": 20.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2696629213483146,
        "text_similarity": 0.7975608706474304,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the target occurs after the anchor, but it gives substantially incorrect timestamps and wrongly asserts the patient scene appears immediately after the description; thus the timing details are largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the interviewer asks if technology can bring doctors and patients closer together, when is he holding a small white 'Trust tv' card?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 178.0,
        "end": 183.5
      },
      "pred_interval": {
        "start": 198.0,
        "end": 201.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.0,
        "end": 17.5,
        "average": 18.75
      },
      "rationale_metrics": {
        "rouge_l": 0.39999999999999997,
        "text_similarity": 0.8594813346862793,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the 'during' relationship and that the interviewer holds the card while asking, but it gives substantially different timestamps (197.8s / 198.0\u2013201.0s) and treats the anchor as an instant rather than the correct interval 178.0\u2013183.5s, so the temporal facts contradict the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the interviewer thanks Rich and says viewers learned a lot, when does Rich respond 'It's really a pleasure'?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 210.3,
        "end": 212.1
      },
      "pred_interval": {
        "start": 209.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3000000000000114,
        "end": 2.0999999999999943,
        "average": 1.7000000000000028
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.854164183139801,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the ground truth by misattributing the line to the interviewer, giving incorrect timestamps, and swapping anchor/target roles; it therefore fails to match the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions learning about 'patient rapport', when does he discuss charting and interacting with other healthcare providers?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 2.075,
        "end": 9.55
      },
      "pred_interval": {
        "start": 2.7,
        "end": 5.3
      },
      "iou": 0.3478260869565217,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.625,
        "end": 4.250000000000001,
        "average": 2.4375000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.34210526315789475,
        "text_similarity": 0.7465662956237793,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies both events and their temporal order (E2 follows E1) and E2's interval falls within the reference span, but the E1 boundaries are shifted/extended beyond the ground-truth and E2 is shortened, so timing is slightly inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker talks about developing skills like putting an IV, when does he mention getting a patient discharged?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 15.42,
        "end": 24.583
      },
      "pred_interval": {
        "start": 10.6,
        "end": 13.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.82,
        "end": 11.182999999999998,
        "average": 8.0015
      },
      "rationale_metrics": {
        "rouge_l": 0.20454545454545456,
        "text_similarity": 0.7274949550628662,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the speaker mentions both putting an IV and patient discharge, but the timestamps are significantly inaccurate (E1 is truncated/early and E2 is placed inside the reference E1 span) and the relation is mislabeled ('after' vs. the correct 'once_finished')."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Make their problem, your problem', when does he introduce the importance of self-care?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 45.009,
        "end": 48.396
      },
      "pred_interval": {
        "start": 34.8,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.209000000000003,
        "end": 11.796,
        "average": 11.002500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.7121740579605103,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies both event time spans and quoted content: neither E1 nor E2 match the reference timestamps or the self-care line (E2), so despite matching the 'after' relation, the answer is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker's introduction of herself, when does she mention specializing in wounds?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.605,
        "end": 26.329
      },
      "pred_interval": {
        "start": 0.0,
        "end": 210.0
      },
      "iou": 0.017733333333333334,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.605,
        "end": 183.671,
        "average": 103.13799999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2247191011235955,
        "text_similarity": 0.49559926986694336,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that she states she specializes in wounds during her introduction, but both provided timestamps (E1 at 0.0s and E2 at 11.0s) contradict the ground-truth times (0:18.120 and 0:22.605\u20130:26.329), so key factual timing details are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of 'getting the most out of your GP consultation', when does she mention that GP practices are getting a huge injection of funding?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.82,
        "end": 75.533
      },
      "pred_interval": {
        "start": 0.0,
        "end": 210.0
      },
      "iou": 0.036728571428571465,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.82,
        "end": 134.46699999999998,
        "average": 101.14349999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.30769230769230765,
        "text_similarity": 0.6013509035110474,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly anchors the introduction at 0.0s rather than 62.0\u201365.0 and wrongly asserts that the funding statement is absent, which contradicts the reference that the funding is mentioned from 67.82\u201375.533; therefore it fails to match the key facts."
      }
    },
    {
      "question_id": "003",
      "question": "While the slide titled 'Appointments are precious' is on screen, when does the speaker mention that GP practices are moving back towards face-to-face appointments?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 123.0,
        "end": 129.0
      },
      "pred_interval": {
        "start": 64.0,
        "end": 65.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.0,
        "end": 64.0,
        "average": 61.5
      },
      "rationale_metrics": {
        "rouge_l": 0.43636363636363634,
        "text_similarity": 0.7001247406005859,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the speaker's content and that the statement occurs while the slide is displayed, but it gives substantially incorrect timestamps (anchor at 64.0s vs ~100.74s and target at 64.0s vs 123\u2013129s), so timing alignment is largely wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that GP practices are very different places now, when does she begin listing the specific roles in a GP practice?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.0,
        "end": 204.0
      },
      "pred_interval": {
        "start": 179.5,
        "end": 181.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.5,
        "end": 22.5,
        "average": 23.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2150537634408602,
        "text_similarity": 0.5771568417549133,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction wrongly timestamps all events (claiming the list starts around 181s) and contradicts the reference timing (list begins at 203.0s); it only correctly identifies that the list starts with 'GPs', so it merits minimal partial credit."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide displays the question 'Does it need to be a GP?', when does the speaker mention that paramedics work in primary care?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "pred_interval": {
        "start": 183.5,
        "end": 185.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.5,
        "end": 54.5,
        "average": 53.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3116883116883117,
        "text_similarity": 0.6861237287521362,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the slide timing roughly, but it incorrectly states the speaker mentions 'Paramedics' at 183.5s while the reference places the full remark about paramedics working in primary care much later (235\u2013240s); this is a substantive temporal and content mismatch."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker talks about paramedics working in primary care, when does she begin to explain the role of Advanced Clinical Practitioners?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 241.0,
        "end": 249.0
      },
      "pred_interval": {
        "start": 188.0,
        "end": 190.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.0,
        "end": 59.0,
        "average": 56.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2816901408450704,
        "text_similarity": 0.5465086698532104,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the ordering right (ACP follows paramedics) but the timestamps are substantially incorrect (predicted ~183\u2013190s vs. correct ~238.5\u2013249s), so it largely fails to match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the problem of a wound on your foot, when does she strongly advise mentioning if you are diabetic?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 337.875,
        "end": 343.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 351.0
      },
      "iou": 0.24404761904761904,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.875,
        "end": 8.0,
        "average": 7.9375
      },
      "rationale_metrics": {
        "rouge_l": 0.22807017543859648,
        "text_similarity": 0.5359860062599182,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the content (the advice to mention diabetes) but gives incorrect timestamps and wrongly labels the relation as 'simultaneous' rather than immediately following; thus it is semantically imprecise on timing and temporal relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having a new wound on your leg, when does she suggest going to a local pharmacist for simple dressings?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 363.968,
        "end": 366.552
      },
      "pred_interval": {
        "start": 382.0,
        "end": 408.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.031999999999982,
        "end": 41.44799999999998,
        "average": 29.73999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2702702702702703,
        "text_similarity": 0.6816383600234985,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the advice content and the 'after' relationship, but the reported timestamps deviate substantially from the ground-truth (and the anchor end time is incorrect/missing), so key temporal details are wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker explains that a nurse's appointment is needed for long-standing wounds, when does she advise to clearly state how long the wound has been there?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 409.579,
        "end": 439.62
      },
      "pred_interval": {
        "start": 432.0,
        "end": 453.0
      },
      "iou": 0.17549112180742052,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.420999999999992,
        "end": 13.379999999999995,
        "average": 17.900499999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.24299065420560748,
        "text_similarity": 0.674803614616394,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the semantic relation and advice but the timestamps are substantially inaccurate and inconsistent with the reference (anchor/target boundaries differ by several seconds), and it adds an unsupported visual-cue detail; therefore partially correct but factually imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if you feel more short of breath, when does she state that a GP or nurse practitioner might be needed the same day?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 522.783,
        "end": 525.113
      },
      "pred_interval": {
        "start": 570.0,
        "end": 600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.216999999999985,
        "end": 74.88699999999994,
        "average": 61.051999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.6282130479812622,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the advisory follows the question, but the timestamps are substantially incorrect and the duration is exaggerated; it also adds an unsupported visual-cue claim. These factual errors make it largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to measure your ankle and calf, when does she give an example of a calf measurement that would 'perk up more interest'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.623,
        "end": 586.297
      },
      "pred_interval": {
        "start": 660.0,
        "end": 690.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.37699999999995,
        "end": 103.70299999999997,
        "average": 90.03999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.27906976744186046,
        "text_similarity": 0.6722555160522461,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer is largely incorrect: the reported anchor/target times (660\u2013690s) do not match the reference (555.028s and 583.623\u2013586.297s), and it introduces a likely hallucinated quote and wrong visual cue; only the 'after' relationship aligns. "
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Photography', when does the speaker advise to 'expect to be asked for a photo'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 670.384,
        "end": 672.807
      },
      "pred_interval": {
        "start": 730.0,
        "end": 750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.615999999999985,
        "end": 77.19299999999998,
        "average": 68.40449999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.34782608695652173,
        "text_similarity": 0.7850102782249451,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer contradicts the correct timestamps by a large margin and invents a long duration and visual cue not supported by the reference; while it correctly links the target to the new slide, the factual timing is wrong, so it largely fails to match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions some GP practices use video consultations, when does she state that a good quality photograph is better than a video?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.278,
        "end": 717.251
      },
      "pred_interval": {
        "start": 690.0,
        "end": 700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.27800000000002,
        "end": 17.250999999999976,
        "average": 20.764499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413793,
        "text_similarity": 0.5808340311050415,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction reproduces the same utterance content but misstates the timestamps and temporal relation: it places both events around 690\u2013700s and labels them 'simultaneous', whereas the ground truth positions them at 708.98s and 714.278s with an 'after' relation, so key factual alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the slide changes to 'Photography tips', when does the speaker begin discussing taking a close-up and further-away picture?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 738.601,
        "end": 740.91
      },
      "pred_interval": {
        "start": 750.0,
        "end": 760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.399000000000001,
        "end": 19.090000000000032,
        "average": 15.244500000000016
      },
      "rationale_metrics": {
        "rouge_l": 0.25641025641025644,
        "text_similarity": 0.6495680809020996,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the content of the tip and the immediate-after relation, but the reported timestamps are significantly incorrect (predicted 750.0s vs correct 736.057s and 738.601s) and it wrongly aligns the anchor and target as simultaneous, so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide changes to 'General top tips- face to face appointments', when does the speaker advise to 'Go suitably dressed'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 860.136,
        "end": 860.846
      },
      "pred_interval": {
        "start": 810.0,
        "end": 820.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.13599999999997,
        "end": 40.846000000000004,
        "average": 45.490999999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324326,
        "text_similarity": 0.6953482031822205,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the slide change time roughly close but places the key utterance ~50s earlier (810\u2013820s vs 860.136s) and asserts it occurs immediately after the slide change, contradicting the reference that it comes later after other tips; it also invents an end time."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises not to wear tight socks, trousers, or wellies, when does she suggest wearing something with quick access to lower limbs?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.0,
        "end": 877.5
      },
      "pred_interval": {
        "start": 870.0,
        "end": 880.0
      },
      "iou": 0.45,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 2.5,
        "average": 2.75
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705885,
        "text_similarity": 0.714195728302002,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the semantic relation ('after') and the content of both events, but it alters the timestamps and durations (shifting E2 later and inventing E1's end), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes advising not to make chit-chat about the weather, when does she advise not to dodge the real problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 893.0,
        "end": 894.5
      },
      "pred_interval": {
        "start": 920.0,
        "end": 930.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.0,
        "end": 35.5,
        "average": 31.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3488372093023256,
        "text_similarity": 0.6581834554672241,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: event times do not match the reference, it incorrectly merges/changes the utterances (claims she both advises to dodge and to say your worries), and it contradicts the correct 'once_finished' relation by altering the content and timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker advises to take a list of the medications you are actually taking, when does she advise against describing tablets by their appearance?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 948.0,
        "end": 969.0
      },
      "pred_interval": {
        "start": 970.0,
        "end": 980.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.0,
        "end": 11.0,
        "average": 16.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3023255813953488,
        "text_similarity": 0.7026925086975098,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the events and their 'after' relation, but the time intervals are substantially incorrect (both E1 and E2 are shifted much later than the ground truth), which is a major factual mismatch."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker advises speaking to the practice in advance about a relative, when does she explain the reason for this advance arrangement due to confidentiality?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1065.0,
        "end": 1095.0
      },
      "pred_interval": {
        "start": 1202.0,
        "end": 1212.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 137.0,
        "end": 117.0,
        "average": 127.0
      },
      "rationale_metrics": {
        "rouge_l": 0.140625,
        "text_similarity": 0.5718518495559692,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the same topical content (confidentiality reason) but gives incorrect timestamps and temporal relation \u2014 it marks E2 as starting simultaneously and 'during' E1 at 1202s, whereas the reference has E1 ending at 1055s and E2 starting later at 1065s with an 'once_finished' relation. These timing and relation errors make the prediction semantically incorrect for alignment."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker suggests writing things down before an appointment to help structure what you say, when does she first ask 'How did it start?' regarding the leg problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1130.415,
        "end": 1131.738
      },
      "pred_interval": {
        "start": 1233.0,
        "end": 1236.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 102.58500000000004,
        "end": 104.26199999999994,
        "average": 103.42349999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.23636363636363636,
        "text_similarity": 0.6008553504943848,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the question 'How did it start?' follows the advice to write things down and matches the utterance content, but it gives substantially incorrect timestamps, mislabels the temporal relation (says 'after' vs. 'once_finished'), and adds an unsupported visual cue; these factual errors reduce its correctness."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes advising to ask to be referred to a specialist service, when does she start introducing the referrals examples?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.105,
        "end": 1249.385
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1234.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.105000000000018,
        "end": 15.384999999999991,
        "average": 16.745000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.136986301369863,
        "text_similarity": 0.44567930698394775,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the relative order (advice then examples) but the timestamps are significantly inaccurate (off by several seconds) and it adds an unsupported claim about the slide appearance as the trigger, so it fails to match the reference details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that lymphoedema services can be patchy, when does she first advise writing to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.0,
        "end": 1378.0
      },
      "pred_interval": {
        "start": 1287.0,
        "end": 1305.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.0,
        "end": 73.0,
        "average": 81.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2597402597402597,
        "text_similarity": 0.7447937726974487,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly identifies the relation ('after') and the utterances (patchy services \u2192 'write to your MP'), but both E1 and E2 timestamps are substantially inaccurate compared to the reference, so it fails on key factual alignment."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions that a GP will assess new leg swelling for onward referral, when does she explain there are many different causes?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1429.846,
        "end": 1432.0
      },
      "pred_interval": {
        "start": 1390.0,
        "end": 1411.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.846000000000004,
        "end": 21.0,
        "average": 30.423000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2592592592592593,
        "text_similarity": 0.6225163340568542,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the ordering (E2 after E1) but the timestamps are significantly incorrect (~15\u201320s off) and it wrongly asserts an 'immediately after' relation and adds unsupported narrative, so it does not accurately match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what information you could take with you, when does she suggest looking up the National Wound Care Strategy Lower Limb Recommendations?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1465.0,
        "end": 1469.5
      },
      "pred_interval": {
        "start": 1446.18,
        "end": 1450.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.819999999999936,
        "end": 19.5,
        "average": 19.159999999999968
      },
      "rationale_metrics": {
        "rouge_l": 0.26530612244897955,
        "text_similarity": 0.7411822080612183,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relation and the quoted phrasing, but the reported timestamps for both E1 and E2 conflict substantially with the ground truth (events are placed much earlier and the target window is wrong), so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions escalating concerns to the practice manager, when does she mention escalating concerns to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.6,
        "end": 1525.7
      },
      "pred_interval": {
        "start": 1462.9,
        "end": 1465.78
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 60.69999999999982,
        "end": 59.92000000000007,
        "average": 60.309999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.2622950819672131,
        "text_similarity": 0.682959794998169,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the semantic order and paraphrases of the two mentions (practice manager then MP), but the reported timestamps differ substantially from the reference and the temporal relation is labeled differently ('after' vs 'next'), so key temporal boundary information is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'I'll stop sharing', when does she start reading the first question from a viewer?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1574.5,
        "end": 1578.5
      },
      "pred_interval": {
        "start": 1614.42,
        "end": 1615.08
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.92000000000007,
        "end": 36.57999999999993,
        "average": 38.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3434343434343435,
        "text_similarity": 0.8096333146095276,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence and relation (she begins reading immediately after stopping), but the timestamps and durations are substantially different from the ground truth (off by ~50 seconds and mismatched intervals), so the answer is factually incorrect on key details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially suggests the mum needs compression hosiery, when does she mention asking for an appointment with the nurse for stronger compression?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1654.942,
        "end": 1664.2
      },
      "pred_interval": {
        "start": 1620.0,
        "end": 1630.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.94200000000001,
        "end": 34.200000000000045,
        "average": 34.571000000000026
      },
      "rationale_metrics": {
        "rouge_l": 0.46341463414634143,
        "text_similarity": 0.8770418763160706,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the correct utterances and the 'after' relation, but the provided timestamps are substantially off (both E1 and E2 start times differ notably from the reference) and the predicted answer omits E2's end time, so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'That is such a good question', when does she state that self-diagnosis via the internet is never a good idea?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1757.815,
        "end": 1762.821
      },
      "pred_interval": {
        "start": 1660.0,
        "end": 1670.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.81500000000005,
        "end": 92.82099999999991,
        "average": 95.31799999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.5789473684210528,
        "text_similarity": 0.8076022863388062,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction matches the quoted phrases and the 'after' relation but gives substantially incorrect timestamps for both anchor and target (off by ~33s and ~98s), failing the key factual requirement about timings."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes that approaching a GP is about framing the conversation, when does she tell the viewer not to worry about being labeled a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1795.335,
        "end": 1798.383
      },
      "pred_interval": {
        "start": 1710.0,
        "end": 1720.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 85.33500000000004,
        "end": 78.38300000000004,
        "average": 81.85900000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.34146341463414637,
        "text_similarity": 0.7433479428291321,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the relation and paraphrases both lines, but the timestamps are substantially off from the reference (both anchor and target are ~80\u2013100s earlier) and the predicted answer omits the target end time, so it is not well aligned temporally."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker first says, 'Please don't worry about things like that', when does she next advise not to worry about being labelled as a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1827.66,
        "end": 1831.19
      },
      "pred_interval": {
        "start": 1867.5,
        "end": 1873.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.83999999999992,
        "end": 41.809999999999945,
        "average": 40.82499999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.20454545454545456,
        "text_similarity": 0.6142032146453857,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction matches the semantic relation ('after') and the content, but the timestamps for both the anchor and the next instance are significantly incorrect compared to the reference, so it fails on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks, 'What can I do to maintain healthy legs or feet so I don't get any problems?', when does she start listing actions like 'walk' and 'legs up'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1865.412,
        "end": 1883.383
      },
      "pred_interval": {
        "start": 1896.0,
        "end": 1897.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.587999999999965,
        "end": 14.116999999999962,
        "average": 22.352499999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.6776517629623413,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps are wholly different from the reference (off by ~48s) and the stated relationship ('immediately after') contradicts the correct timing, which shows a ~12s gap before the action list begins."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks how much is in the GP curriculum, when does she say 'I don't know'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1983.7,
        "end": 1984.201
      },
      "pred_interval": {
        "start": 1979.0,
        "end": 1982.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.7000000000000455,
        "end": 2.201000000000022,
        "average": 3.4505000000000337
      },
      "rationale_metrics": {
        "rouge_l": 0.2325581395348837,
        "text_similarity": 0.6159732341766357,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct utterances but the timestamp ranges are substantially different from the reference (off by several seconds) and even imply overlap rather than the target immediately following the anchor, so the temporal relation and timings are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'I think it is something that Legs Matter can help with', when does she discuss Legs Matter influencing GP curriculums?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2004.063,
        "end": 2009.063
      },
      "pred_interval": {
        "start": 2028.0,
        "end": 2051.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.936999999999898,
        "end": 41.9369999999999,
        "average": 32.9369999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1616161616161616,
        "text_similarity": 0.5732238292694092,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps differ substantially from the reference (anchor 1991.448\u20131993.914 vs predicted 2026.0\u20132030.0; target 2004.063\u20132009.063 vs predicted 2028.0\u20132051.0) and it misstates the temporal relation (reference: target occurs after anchor; prediction implies overlap), so the answer is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks if seeing a nurse practitioner is appropriate, when does she state that nurse practitioners are 'extremely experienced clinicians'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2062.584,
        "end": 2066.851
      },
      "pred_interval": {
        "start": 2078.0,
        "end": 2085.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.416000000000167,
        "end": 18.148999999999887,
        "average": 16.782500000000027
      },
      "rationale_metrics": {
        "rouge_l": 0.1473684210526316,
        "text_similarity": 0.48018285632133484,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answers correctly identify the anchor/target content and their semantic relationship (E2 as a direct response), but the timestamps are substantially off (~15\u201316 seconds later than the ground-truth), so key factual timing information is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I understand the issue of smartphones and taking pictures too\", when does she first ask \"is there somebody who can help you?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2174.0,
        "end": 2176.0
      },
      "pred_interval": {
        "start": 2136.0,
        "end": 2140.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.0,
        "end": 36.0,
        "average": 37.0
      },
      "rationale_metrics": {
        "rouge_l": 0.26966292134831465,
        "text_similarity": 0.6061487197875977,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the question occurs after the anchor, but the timestamps are significantly incorrect (off by ~35 seconds) and it mischaracterizes the timing as an immediate continuation rather than after the anchor finishes as in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "During the period when the speaker discusses the importance of planning phone calls to the GP, when does she ask, \"What am I feeling?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2197.721,
        "end": 2198.663
      },
      "pred_interval": {
        "start": 2226.0,
        "end": 2230.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.278999999999996,
        "end": 31.33699999999999,
        "average": 29.807999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5423721075057983,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer incorrectly gives both anchor and target timestamps (off by ~20\u201330s) so the target is not within the stated anchor; it only correctly identifies the \u2018during\u2019 relationship/context but fails on the key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "Once Dr. Angelos finishes introducing Dr. Tolchin, when does Dr. Tolchin begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.128,
        "end": 109.393
      },
      "pred_interval": {
        "start": 10.0,
        "end": 15.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 95.128,
        "end": 94.393,
        "average": 94.76050000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.35789473684210527,
        "text_similarity": 0.7317097187042236,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the qualitative relation (Tolchin speaks shortly/immediately after Angelos) but the timestamps are wildly incorrect (10.0s/15.0s vs 100.128s/105.128s) and it adds an unsupported detail about a slide, so it is largely factually wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After Dr. Angelos describes Dr. Tolchin's research on crisis standards of care, when does he describe his research on functional neurological disorders and epilepsy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.426,
        "end": 116.456
      },
      "pred_interval": {
        "start": 15.0,
        "end": 20.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.426,
        "end": 96.456,
        "average": 68.941
      },
      "rationale_metrics": {
        "rouge_l": 0.2745098039215686,
        "text_similarity": 0.6919652223587036,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives incorrect timestamps (15.0s and 20.0s vs. the reference 44.732\u201354.143s and 56.426\u2013116.456s) and wrongly characterizes the timing as 'immediately after' while adding unsupported details, so it fails to match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating the second learning objective, when does he start explaining the third learning objective?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 181.0
      },
      "pred_interval": {
        "start": 210.0,
        "end": 220.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.0,
        "end": 39.0,
        "average": 41.0
      },
      "rationale_metrics": {
        "rouge_l": 0.297029702970297,
        "text_similarity": 0.647051215171814,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the events (anchor vs target) and the 'after' relation, but the timestamps are wildly incorrect (210s/220s vs 16.4s/17.0s) and it adds unverified visual/audio cues, so it does not match the reference timings or details."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'Why conduct clinical ethics consultations?' is displayed, when does the speaker discuss moral distress among clinicians and staff?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.4,
        "end": 304.0
      },
      "pred_interval": {
        "start": 240.0,
        "end": 260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.39999999999998,
        "end": 44.0,
        "average": 44.69999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3469387755102041,
        "text_similarity": 0.8276458382606506,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer preserves the 'during' relation but gives substantially incorrect timing intervals for both anchor and target (target 240\u2013260s vs correct 285.4\u2013304.0s) and adds an unsupported quoted audio cue, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that clinical ethics consultations were helpful, when does he state that they were more likely to achieve consensus in clinical decisions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 350.2,
        "end": 357.0
      },
      "pred_interval": {
        "start": 377.0,
        "end": 384.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.80000000000001,
        "end": 27.0,
        "average": 26.900000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5334758758544922,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the semantic relationship ('after') and the content of E2, but the provided timestamps materially contradict the reference (predicted times are ~35\u201340s later than ground truth), so it is factually inaccurate on the key timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of resource utilization, when does he specifically state that there was a reduced length of stay?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 438.9,
        "end": 450.3
      },
      "pred_interval": {
        "start": 439.0,
        "end": 442.0
      },
      "iou": 0.2631578947368413,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.10000000000002274,
        "end": 8.300000000000011,
        "average": 4.200000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.649441123008728,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly identifies the 'after' relationship and roughly the target start time, but it misplaces the anchor substantially (predicted E1 ~435\u2013438s vs correct finish at 369.0s), so key timing information is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'to look at disparities', when does he begin to introduce Ellen Fox's team and their survey?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 493.5,
        "end": 499.0
      },
      "pred_interval": {
        "start": 532.0,
        "end": 535.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.5,
        "end": 36.0,
        "average": 37.25
      },
      "rationale_metrics": {
        "rouge_l": 0.25581395348837205,
        "text_similarity": 0.7065416574478149,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the mention of Ellen Fox's team follows the 'to look at disparities' sentence, but it gives completely different timestamps (530.0s/532.0s vs. 393.0s/493.5s\u2013499.0s) and misrepresents the temporal alignment, so it fails to match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'hospitals with less than 400 beds', when does he mention 'little or no growth over that two decade period'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 527.809,
        "end": 530.91
      },
      "pred_interval": {
        "start": 520.0,
        "end": 535.0
      },
      "iou": 0.20673333333333327,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.808999999999969,
        "end": 4.090000000000032,
        "average": 5.9495000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.4230769230769231,
        "text_similarity": 0.8290814161300659,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the content and the immediate-after relationship, but the timestamps are notably inaccurate (anchor given ~5s early and target end extended ~4s beyond the reference), so it is only an approximate match."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide titled 'Prior Healthcare System Ethics Committees' is fully displayed, when do the images of the six hospitals with their bed counts appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.7,
        "end": 552.0
      },
      "pred_interval": {
        "start": 580.0,
        "end": 585.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.299999999999955,
        "end": 33.0,
        "average": 30.649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.3137254901960784,
        "text_similarity": 0.7803376317024231,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor (slide title) and target (hospital images) but gives substantially incorrect timestamps (580.0s/585.0s vs correct 536.2s/551.7\u2013552.0s), mischaracterizes the timing relationship, and adds unsupported commentary about the speaker."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the number of ethics consults at Yale New Haven Hospital increased from 50 to 239, when does he describe this as 'approximately a five-fold increase in consult volume'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.7,
        "end": 624.7
      },
      "pred_interval": {
        "start": 600.0,
        "end": 615.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.700000000000045,
        "end": 9.700000000000045,
        "average": 16.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.47058823529411764,
        "text_similarity": 0.8935787677764893,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer captures the same semantic elements (the numbers and phrase) but gives substantially incorrect timestamps and the wrong temporal relationship\u2014so it fails to match the anchor/target timing and order in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially mentions the 'Community Bioethics Forum', when does he start describing its community members?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 887.216,
        "end": 905.918
      },
      "pred_interval": {
        "start": 940.0,
        "end": 945.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.78399999999999,
        "end": 39.081999999999994,
        "average": 45.93299999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.18604651162790697,
        "text_similarity": 0.3940874934196472,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly locates both the mention and the description (timestamps are ~57s later than the reference) and hallucinates details ('Yale' and a quoted line); only the vague relation that description follows the mention is correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that the primary focus of the Center for Clinical Ethics has been ethics education, when does he start listing 'Systemwide Ethics Forum and Newsletter'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1055.54,
        "end": 1069.28
      },
      "pred_interval": {
        "start": 930.0,
        "end": 935.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 125.53999999999996,
        "end": 134.27999999999997,
        "average": 129.90999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.24719101123595505,
        "text_similarity": 0.48236095905303955,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly labels the temporal relation as 'after', the provided timestamps are substantially incorrect (both anchor and target times differ markedly from the reference), so the prediction is factually inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker lists 'ICU Walk Rounds', when does he mention 'HEC-C Certification'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1048.0,
        "end": 1052.0
      },
      "pred_interval": {
        "start": 970.0,
        "end": 980.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.0,
        "end": 72.0,
        "average": 75.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2528735632183908,
        "text_similarity": 0.5727541446685791,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly recognizes that HEC-C is mentioned after the ICU rounds and paraphrases the content, but it gives significantly incorrect timestamps, a different relation label ('after' vs 'next'), and alters the anchor phrasing\u2014major factual errors."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"ethics consultation services,\" when does he start talking about collecting feedback?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.8,
        "end": 1249.8
      },
      "pred_interval": {
        "start": 1245.8,
        "end": 1248.7
      },
      "iou": 0.32222222222223235,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.0,
        "end": 1.099999999999909,
        "average": 3.0499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.35135135135135137,
        "text_similarity": 0.674042820930481,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction preserves the order and relation (E2 occurs immediately after E1) but the absolute timestamps are incorrect\u2014both events are shifted by about +7 seconds from the ground truth\u2014so it is only a partial match."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that participant satisfaction is not the \"be-all and end-all,\" when does he say they have begun the survey process with clinicians?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.3,
        "end": 1282.8
      },
      "pred_interval": {
        "start": 1280.7,
        "end": 1282.2
      },
      "iou": 0.3333333333333333,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.400000000000091,
        "end": 0.599999999999909,
        "average": 1.5
      },
      "rationale_metrics": {
        "rouge_l": 0.36585365853658536,
        "text_similarity": 0.6013164520263672,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (E2 follows E1) and the content, but the reported timestamps differ from the ground truth by several seconds (E1 and E2 are both later than reference), so it is not fully accurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes describing the first pie chart about helpful advice/guidance, when does the second pie chart about communication appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1367.5,
        "end": 1367.9
      },
      "pred_interval": {
        "start": 1323.2,
        "end": 1328.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.299999999999955,
        "end": 39.90000000000009,
        "average": 42.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.367816091954023,
        "text_similarity": 0.6366808414459229,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (E2 occurs after E1), but both reported timestamps are significantly incorrect compared to the ground truth (1323.2 vs 1356.0 and 1328.0 vs 1376.5), so key factual timing is wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he wants to turn to some of the organizational ethics consultation work, when does the slide showing the 'Organizational ethics consultations' table appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1472.0,
        "end": 1472.5
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1410.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.0,
        "end": 62.5,
        "average": 62.25
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.4515398144721985,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the speaker timestamp (1410.0s vs correct 1433.9\u20131437.8s), omits the slide's actual time (1472.0\u20131472.5s), and incorrectly claims the table appears 'immediately after' when it actually appears ~35s later; it gets only the general 'after' relation right."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining that organizational ethics work is new to them, when do they state that it began during the COVID pandemic?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1469.5,
        "end": 1472.0
      },
      "pred_interval": {
        "start": 1412.6,
        "end": 1413.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.90000000000009,
        "end": 58.90000000000009,
        "average": 57.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.34782608695652173,
        "text_similarity": 0.545207679271698,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the order and that E2 follows immediately, but the timestamps are substantially incorrect (about 56 seconds earlier than the ground truth) and it omits E2's end time, making it factually incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the 'Organizational ethics consultations' table, when does the speaker mention the 'Blood products scarcity protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1510.0,
        "end": 1513.0
      },
      "pred_interval": {
        "start": 1419.6,
        "end": 1420.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.40000000000009,
        "end": 93.0,
        "average": 91.70000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.30379746835443033,
        "text_similarity": 0.6817495822906494,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction swaps the anchor/target labels and gives a completely different time window (1419.6\u20131420.0s) that does not overlap the correct table display (1474\u20131573s) nor the correct mention interval (1510\u20131513s), so it contradicts the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the 'sequential organ failure assessment or SOFA score', when does he begin to explain what it is?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1647.6,
        "end": 1697.0
      },
      "pred_interval": {
        "start": 1627.0,
        "end": 1628.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.59999999999991,
        "end": 68.5,
        "average": 44.549999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.5886759757995605,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase timing (within the correct interval) but gives an incorrect/too-early timestamp for the explanation and thus misstates the timing relationship; key timing of the target (1647.6s) is not matched."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that '70% of publicly available crisis standards of care used either the SOFA score or a modified version', when does he mention the SOFA score being used in Alaska?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1726.0,
        "end": 1733.0
      },
      "pred_interval": {
        "start": 1715.5,
        "end": 1718.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.5,
        "end": 15.0,
        "average": 12.75
      },
      "rationale_metrics": {
        "rouge_l": 0.23404255319148934,
        "text_similarity": 0.5695135593414307,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer identifies the correct content (the Alaska SOFA example) but gives incorrect timestamps for both the anchor and target (each several seconds off and the target is placed much earlier than the true segment), so it is factually inaccurate on timing."
      }
    },
    {
      "question_id": "003",
      "question": "Once the 'SOFA Disparities' slide appears, when does the speaker begin discussing concerns about the score's accuracy and contributions to disparities?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1770.0,
        "end": 1776.606
      },
      "pred_interval": {
        "start": 1774.0,
        "end": 1776.0
      },
      "iou": 0.302755071147442,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 0.6059999999999945,
        "average": 2.3029999999999973
      },
      "rationale_metrics": {
        "rouge_l": 0.325,
        "text_similarity": 0.7956393957138062,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction incorrectly states both anchor and target timestamps (1762.0 vs 1774.0 for E1; 1770.0 vs 1776.0 for E2), and it introduces an unsupported detail about a 'retrospective cohort of 2320 patients'; it does, however, correctly convey that the speaker begins discussing the slide immediately."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that the center was able to test the triage protocol before it was used, when does he state that they developed a SOFA calculation system?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1799.553,
        "end": 1807.997
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1775.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.55300000000011,
        "end": 32.99700000000007,
        "average": 31.27500000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.31111111111111117,
        "text_similarity": 0.6253255605697632,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the temporal relation ('after') but the provided timestamps are factually incorrect (1770/1775s vs the correct 1795.5/1799.553s), a significant error in this timing-focused task."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the retrospective cohort study, when does he detail the demographic breakdown of the patients?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1846.122,
        "end": 1858.077
      },
      "pred_interval": {
        "start": 1785.0,
        "end": 1795.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.12200000000007,
        "end": 63.077,
        "average": 62.099500000000035
      },
      "rationale_metrics": {
        "rouge_l": 0.367816091954023,
        "text_similarity": 0.6050254702568054,
        "llm_judge_score": 3,
        "llm_judge_justification": "While the prediction correctly states the demographics occur after the study introduction, the timestamps are significantly off (demographics predicted at 1795.0s vs ground truth start 1846.122s) and it adds specific percentage details not present in the reference, so it is largely inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker highlights that non-Hispanic Black patients had greater odds of an elevated SOFA score, when does he state that no significant difference by race in mortality was found when controlling for other factors?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.642,
        "end": 1879.694
      },
      "pred_interval": {
        "start": 1825.0,
        "end": 1835.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.64200000000005,
        "end": 44.69399999999996,
        "average": 46.668000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.38775510204081637,
        "text_similarity": 0.7678419947624207,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the relative order (the mortality statement comes after the SOFA finding) but the reported timestamps are substantially incorrect and do not match the precise segment boundaries given in the reference, so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the early small cohort out of Wuhan, China, when does he state that subsequent larger cohorts in the United States did not show such high accuracy rates?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.0,
        "end": 1966.5
      },
      "pred_interval": {
        "start": 2004.5,
        "end": 2008.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.5,
        "end": 42.0,
        "average": 43.75
      },
      "rationale_metrics": {
        "rouge_l": 0.20618556701030927,
        "text_similarity": 0.7149226665496826,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the semantic relation (that the larger US cohorts came after and showed lower accuracy) but gives significantly incorrect timestamps for both anchor and target events, so it fails to locate the events accurately as required."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'This graph here is a calibration curve', when does he explain that the diagonal line shows a perfectly calibrated predictor of mortality?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2014.0,
        "end": 2020.0
      },
      "pred_interval": {
        "start": 2026.0,
        "end": 2033.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.0,
        "end": 13.0,
        "average": 12.5
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.810597836971283,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the explanation follows immediately after the graph introduction, but the provided anchor and target timestamps are substantially later than the ground truth (both event intervals do not match and the target actually occurs earlier than the predicted times)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that SOFA predicted mortality with less accuracy than age in their own COVID cohort, when does he mention that SOFA predicted mortality with better accuracy than age in the pre-COVID eICU cohort?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2066.0,
        "end": 2069.0
      },
      "pred_interval": {
        "start": 2052.5,
        "end": 2061.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.5,
        "end": 7.5,
        "average": 10.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23008849557522124,
        "text_similarity": 0.7794857025146484,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the qualitative contrast ('In contrast') and that the target occurs after the anchor, but the provided timestamps for both E1 and E2 are substantially incorrect (off by many seconds) and do not match the ground-truth temporal annotations."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the Omicron surge increasing, when does he talk about working with the healthcare system's legal team?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2153.6,
        "end": 2174.93
      },
      "pred_interval": {
        "start": 2155.8,
        "end": 2164.3
      },
      "iou": 0.3984997655883745,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.200000000000273,
        "end": 10.629999999999654,
        "average": 6.414999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.21874999999999997,
        "text_similarity": 0.6505910158157349,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly places the legal-team comment within the ground-truth E2 window and preserves the 'after' relation, but it mislocates the Omicron mention substantially (predicted ~2155.8s vs ground-truth ~2132.0s), a significant timing error."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the policy was active until late February of 2022, when does the first 'Scope of protocol' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2194.0,
        "end": 2234.0
      },
      "pred_interval": {
        "start": 2226.3,
        "end": 2229.4
      },
      "iou": 0.07749999999999772,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.30000000000018,
        "end": 4.599999999999909,
        "average": 18.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7303614020347595,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the 'Scope of protocol' slide occurring shortly after the utterance (predicted E2 falls within the correct E2 interval), but the anchor time for when the speaker finished stating the policy is incorrect (2192.0s vs predicted 2226.3s), so the key event timing is mismatched."
      }
    },
    {
      "question_id": "003",
      "question": "After the second 'Scope of protocol' slide appears, when does the speaker mention 'renal replacement therapy'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2263.679,
        "end": 2254.733
      },
      "pred_interval": {
        "start": 2253.2,
        "end": 2255.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.47900000000027,
        "end": 0.3669999999997344,
        "average": 5.423000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.7881289720535278,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction substantially misplaces the anchor (2253.2s vs reference 2230.0s) and incorrectly states the events are simultaneous; the predicted E2 window only marginally overlaps the reference timing, so key temporal relationships are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that goals of care discussions significantly changed, when does the speaker mention that patients were more likely to choose limited life-sustaining interventions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2320.0,
        "end": 2327.0
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2320.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 7.0,
        "average": 8.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3611111111111111,
        "text_similarity": 0.6206576824188232,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction preserves the correct semantic relation and quoted content, but the event timestamps are slightly inaccurate (E1 off by 3s and E2 off by 5s), so not a perfect temporal match."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states he wants to highlight some takeaway points, when does the first takeaway point appear on the screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "pred_interval": {
        "start": 2330.0,
        "end": 2340.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.0,
        "end": 60.0,
        "average": 62.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2950819672131147,
        "text_similarity": 0.7037990093231201,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct events and their temporal relation ('immediately after'), but the timestamps are substantially wrong (predicted ~2330\u20132332s vs ground truth ~2392\u20132395s) and it omits the correct end times, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I'll stop and take questions,\" when does an audience member begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2541.6,
        "end": 2544.0
      },
      "pred_interval": {
        "start": 2497.8,
        "end": 2499.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.79999999999973,
        "end": 44.59999999999991,
        "average": 44.19999999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.3170731707317073,
        "text_similarity": 0.7001582980155945,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the order right but the timestamps are substantially incorrect (speaker at 2497.8s vs 2517.9s; audience at 2499.4s vs 2541.6s) and wrongly claims the audience spoke immediately after, omitting the audience end time\u2014so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the audience member finishes complimenting the center, when does he ask a specific question about local hospital ethics committees?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2571.5,
        "end": 2580.5
      },
      "pred_interval": {
        "start": 2505.9,
        "end": 2508.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.59999999999991,
        "end": 71.90000000000009,
        "average": 68.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2650602409638554,
        "text_similarity": 0.5913281440734863,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps differ drastically from the ground truth (off by ~60s) and give a much shorter, immediate question duration, contradicting the correct start/end times and relation; therefore the prediction is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the audience member mentions the low numbers of ethics consultations, when does the speaker begin to answer the question?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2624.0,
        "end": 2634.8
      },
      "pred_interval": {
        "start": 2515.0,
        "end": 2517.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 109.0,
        "end": 117.80000000000018,
        "average": 113.40000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.35714285714285715,
        "text_similarity": 0.5286046266555786,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the speaker begins after the audience and cites an audio cue, but the timestamps (around 2515/2517s) are roughly 106 seconds earlier than the ground truth (2621/2624s) and it omits the speaker's end time, so the answer is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the listener asks about assessing the quality of care across the system, when does the speaker respond by calling it a 'great question'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.1,
        "end": 2745.7
      },
      "pred_interval": {
        "start": 2700.0,
        "end": 2702.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.09999999999991,
        "end": 43.69999999999982,
        "average": 43.899999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.7813458442687988,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction contradicts the ground truth by giving a substantially incorrect timestamp (2700.0s vs 2744.1s) and claiming the listener's question is not heard while the reference specifies it occurs at 2739.0\u20132743.0s; thus it is largely incorrect despite mentioning the phrase."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions starting to survey clinicians for feedback, when does he mention planning to survey patients and families?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2807.8,
        "end": 2821.6
      },
      "pred_interval": {
        "start": 2730.0,
        "end": 2735.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.80000000000018,
        "end": 86.59999999999991,
        "average": 82.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.3220338983050847,
        "text_similarity": 0.5780477523803711,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('after') but the provided timestamps and durations are substantially incorrect compared to the reference, omitting the key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that hospitals in the healthcare system can join together, when does he state that they will preferentially present cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2854.49,
        "end": 2856.13
      },
      "pred_interval": {
        "start": 2867.2,
        "end": 2873.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.710000000000036,
        "end": 16.9699999999998,
        "average": 14.839999999999918
      },
      "rationale_metrics": {
        "rouge_l": 0.29850746268656714,
        "text_similarity": 0.7598165273666382,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target events and their temporal relation ('after'), but the reported timestamps differ significantly from the ground-truth times (and the ground truth specifies precise end/start ranges), so it's partially correct but not fully accurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces 'a third method of feedback', when does he describe it as 'formal needs assessments'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2877.53,
        "end": 2879.53
      },
      "pred_interval": {
        "start": 2880.6,
        "end": 2884.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.069999999999709,
        "end": 4.4699999999998,
        "average": 3.7699999999997544
      },
      "rationale_metrics": {
        "rouge_l": 0.39436619718309857,
        "text_similarity": 0.8348932266235352,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target and the 'after' relationship, but the absolute timestamps are shifted by about 4 seconds from the ground truth, so the timing is not precisely aligned."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'the overwhelming response was number one', when does he specify the first response as 'a lack of ethics education'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2901.56,
        "end": 2903.46
      },
      "pred_interval": {
        "start": 2885.0,
        "end": 2889.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.559999999999945,
        "end": 14.360000000000127,
        "average": 15.460000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.42666666666666664,
        "text_similarity": 0.8618034720420837,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly identifies the temporal relation ('after') but the reported timestamps are substantially off from the reference (\u224815\u201316s earlier) and do not match the specified event intervals, so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"The more medically complex cases tend to transfer,\" when does he start listing examples of such cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3044.3,
        "end": 3048.2
      },
      "pred_interval": {
        "start": 3067.3,
        "end": 3071.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.0,
        "end": 23.40000000000009,
        "average": 23.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.23809523809523808,
        "text_similarity": 0.6131527423858643,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the list immediately follows the anchor, but it gives incorrect absolute timestamps (~3067\u20133068s vs correct 3038.7\u20133048.2s), contradicting key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the questioner asks about the 'escalation of care policy', when does the slide titled 'Escalation of Care Protocol' appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3114.8,
        "end": 3117.8
      },
      "pred_interval": {
        "start": 3106.8,
        "end": 3112.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.0,
        "end": 5.400000000000091,
        "average": 6.7000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.26804123711340205,
        "text_similarity": 0.7429486513137817,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the qualitative relation (slide appears after the question) but the timestamps for both the question and slide are substantially incorrect (off by several seconds), and the predicted timing/phrase coincidence contradicts the ground truth, so it is largely factually wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions \"boarding 190 patients in the emergency department\", when does he discuss concerns about the level of care?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3154.983,
        "end": 3143.945
      },
      "pred_interval": {
        "start": 3137.0,
        "end": 3143.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.983000000000175,
        "end": 0.2450000000003456,
        "average": 9.11400000000026
      },
      "rationale_metrics": {
        "rouge_l": 0.21978021978021978,
        "text_similarity": 0.7980314493179321,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target utterances and their immediate 'after' relationship, but the provided timestamps are off by roughly 13\u201316 seconds from the reference and it adds an unsupported causal claim, so it does not match the ground truth timing or content precisely."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker mentions 'in all 26 of those cases', when does he then talk about 'many more cases'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3214.9,
        "end": 3215.4
      },
      "pred_interval": {
        "start": 3248.2,
        "end": 3250.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.29999999999973,
        "end": 35.40000000000009,
        "average": 34.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.4242424242424243,
        "text_similarity": 0.6384310722351074,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same utterances and the correct 'after' relation, but the timestamps are substantially off (~+38s) compared to the reference and it omits E2's end time, so it is factually incorrect on key details."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker states that the 'escalation of care protocol' was nice, when does he mention a 'SOFA-based protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3246.0,
        "end": 3249.0
      },
      "pred_interval": {
        "start": 3278.0,
        "end": 3281.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.0,
        "end": 32.80000000000018,
        "average": 32.40000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.7904182076454163,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and their temporal relation ('after'), but the reported timestamps are significantly off (\u224847s later) and do not match the reference intervals, so timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the second speaker says 'SOFA is horrendous', when does he mention 'SOFA's AUC goes up'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3322.32,
        "end": 3324.71
      },
      "pred_interval": {
        "start": 3370.4,
        "end": 3374.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.07999999999993,
        "end": 49.690000000000055,
        "average": 48.88499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.4225352112676056,
        "text_similarity": 0.758999764919281,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the same events and the 'after' relation, but the provided timestamps are substantially off (~+50s) compared to the ground truth and the prediction omits E2's end time, so the timing information is inaccurate/incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the question about equity monitoring is asked, when does the speaker begin explaining the logging process for patient cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3401.583,
        "end": 3406.09
      },
      "pred_interval": {
        "start": 3426.4,
        "end": 3443.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.817000000000007,
        "end": 37.309999999999945,
        "average": 31.063499999999976
      },
      "rationale_metrics": {
        "rouge_l": 0.24175824175824176,
        "text_similarity": 0.7662256360054016,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives substantially different timestamps, reverses the temporal order (reference has logging before the question; prediction has it after), and adds conflicting relations ('during'), so it contradicts the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the 'Escalation of Care Protocol', when does the 'Conscientious Practice Policy' slide appear on screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3429.8,
        "end": 3430.5
      },
      "pred_interval": {
        "start": 3444.1,
        "end": 3447.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.299999999999727,
        "end": 17.0,
        "average": 15.649999999999864
      },
      "rationale_metrics": {
        "rouge_l": 0.425,
        "text_similarity": 0.7246118187904358,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly captures that the slide follows the explanation, but the timestamps are substantially incorrect (predicted 3444.1s vs correct 3424.0s and 3429.8s) and it contradictorily places both end of explanation and slide onset at the same time, making it factually inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Conscientious Practice Policy' slide appears, when does the speaker mention tracking outcomes and looking back retrospectively for this policy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3444.0,
        "end": 3492.0
      },
      "pred_interval": {
        "start": 3467.8,
        "end": 3483.8
      },
      "iou": 0.3333333333333333,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.800000000000182,
        "end": 8.199999999999818,
        "average": 16.0
      },
      "rationale_metrics": {
        "rouge_l": 0.25000000000000006,
        "text_similarity": 0.7857497334480286,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction partly matches E2 (its interval lies within the reference window) but gives an incorrect E1 time (3467.8s vs 3434.0s) and a wrong relation ('during' vs 'after'), so key facts are misstated."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions an increasing disparity over time, when does he discuss how they can provide support to all hospitals?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 707.399,
        "end": 742.972
      },
      "pred_interval": {
        "start": 735.8,
        "end": 745.0
      },
      "iou": 0.1907396079891499,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.400999999999954,
        "end": 2.02800000000002,
        "average": 15.214499999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.2423590123653412,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly timestamps the anchor (places the disparity at ~735.8s instead of 698.3\u2013707.379s) and misplaces the target start (~737.9s vs. correct 707.399s\u2013742.972s), and it adds specific program details not present in the reference; it only matches the general sequential relationship. "
      }
    },
    {
      "question_id": "002",
      "question": "While the organizational chart for the Center for Clinical Ethics is displayed, when does the speaker describe the Ethics Education program?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.177,
        "end": 786.763
      },
      "pred_interval": {
        "start": 770.5,
        "end": 792.0
      },
      "iou": 0.7125706524120426,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 1.322999999999979,
        "end": 5.236999999999966,
        "average": 3.2799999999999727
      },
      "rationale_metrics": {
        "rouge_l": 0.35555555555555557,
        "text_similarity": 0.8451926708221436,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly locates the speaker's description start (~770s) but misstates the slide's display interval (703.8\u2013842.8s vs 749\u2013810s), omits the precise end time (786.763s), and adds extra visual/audio details not in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says he will go into depth on the programs, when does he first mention the Yale Interdisciplinary Center for Bioethics?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 837.605,
        "end": 845.26
      },
      "pred_interval": {
        "start": 880.1,
        "end": 892.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.495000000000005,
        "end": 47.639999999999986,
        "average": 45.067499999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.34615384615384615,
        "text_similarity": 0.767815887928009,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the Yale center is mentioned after the anchor remark, but the provided timestamps are substantially wrong and it incorrectly claims the mention occurs immediately after the anchor, so it is largely factually inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the title 'Systemwide Ethics Forum and Newsletter', when does he describe it as a hybrid meeting?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1070.5,
        "end": 1076.5
      },
      "pred_interval": {
        "start": 1080.0,
        "end": 1095.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.5,
        "end": 18.5,
        "average": 14.0
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.6077136397361755,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the hybrid description occurs after the title, but it adds an unsupported detail ('meets monthly') and gives differing timing specifics, so it partly aligns but includes a hallucination and timing inaccuracies."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining that they looked through the 26 specific patient cases individually, when does the slide transition to 'Scope of protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3425.8,
        "end": 3429.0
      },
      "pred_interval": {
        "start": 3405.8,
        "end": 3413.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.0,
        "end": 15.5,
        "average": 17.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3055555555555556,
        "text_similarity": 0.7157961130142212,
        "llm_judge_score": 3,
        "llm_judge_justification": "While the temporal relation 'after' is correct, the predicted timestamps for E1 and E2 are each ~12 seconds early, it omits the actual slide transition time (3429.0s), and incorrectly claims an immediate transition, so the timing details are inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the 'Scope of protocol' slide finishes being displayed, when does the 'Conscientious Practice Policy' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3429.0,
        "end": 3519.5
      },
      "pred_interval": {
        "start": 3413.5,
        "end": 3428.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.5,
        "end": 91.0,
        "average": 53.25
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.754021167755127,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly identifies the event relation and near-identical start time and notes an immediate transition, but it misstates both timestamps by 0.5s (3428.5s vs 3429.0s) and omits the E2 end time (3519.5s) present in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes discussing the tracking of equity, socioeconomic status, and other demographic characteristics, when is the presentation window minimized?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3530.0,
        "end": 3531.0
      },
      "pred_interval": {
        "start": 3535.8,
        "end": 3537.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.800000000000182,
        "end": 6.5,
        "average": 6.150000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.7440083622932434,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the events and the 'after' relation, but the timestamps are substantially off (predicted ~3536\u20133538s vs. ground truth 3508.5s and 3530\u20133531s) and it adds an unverified visual cue (mouse click), so it does not align with the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the audience will be on mute, when does he mention that the live event can be paused?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 38.524,
        "end": 43.729
      },
      "pred_interval": {
        "start": 14.5,
        "end": 16.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.024,
        "end": 27.229,
        "average": 25.6265
      },
      "rationale_metrics": {
        "rouge_l": 0.20224719101123598,
        "text_similarity": 0.7569235563278198,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the semantic relation (pausing follows mentioning mute) but the timestamps and target span are substantially incorrect and do not match the ground truth, so the answer is largely misaligned."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses changing the speed of presentations and speakers, when does he advise on what to do if Wi-Fi or connection is lost?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 55.563,
        "end": 59.787
      },
      "pred_interval": {
        "start": 124.0,
        "end": 126.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 68.437,
        "end": 66.713,
        "average": 67.57499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.6929686069488525,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the relation (advice 'just wait' follows the connectivity issue) but misidentifies the anchor event and gives entirely different timestamps/spans (124s vs. correct 44.7s and 55.6s), so it fails on alignment and timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the presenter mentions Tom Gardner in the background, when does he mention Stephanie Fraser joining in place of Jane Preston?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.258,
        "end": 171.201
      },
      "pred_interval": {
        "start": 190.0,
        "end": 191.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.74199999999999,
        "end": 20.599000000000018,
        "average": 21.170500000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.37113402061855677,
        "text_similarity": 0.8690984845161438,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target and their 'after' relation, but the provided timestamps are grossly incorrect (\u2248190s vs correct \u224812\u201319s) and the target end time is omitted, so the answer is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male presenter finishes introducing Stephanie Fraser, when does Stephanie Fraser begin speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 223.86,
        "end": 224.8
      },
      "pred_interval": {
        "start": 200.0,
        "end": 200.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.860000000000014,
        "end": 24.80000000000001,
        "average": 24.330000000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.7785533666610718,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation (Stephanie speaks after the presenter) but gives completely different timestamps and identifies the wrong anchor event (saying 'Stephanie Fraser' vs 'Thank you'), and incorrectly asserts 'immediately after'; overall the timing and event details are largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker is discussing the recent research undertaken by the Neurological Alliance of Scotland, when does she state that 57% of respondents reported not being able to access a face-to-face appointment?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 433.0,
        "end": 434.9
      },
      "pred_interval": {
        "start": 362.4,
        "end": 373.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.60000000000002,
        "end": 61.69999999999999,
        "average": 66.15
      },
      "rationale_metrics": {
        "rouge_l": 0.14876033057851237,
        "text_similarity": 0.4785531163215637,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives a completely different time window (~362\u2013373s) and visual cues, contradicting the reference which places the spoken '57%' at ~433.0\u2013434.9s during the 383.3\u2013443.3s segment."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that nearly two-thirds of respondents had not had a video appointment, when does she state that telephone appointments were the most common way to access care?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.8,
        "end": 452.9
      },
      "pred_interval": {
        "start": 379.2,
        "end": 391.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 68.60000000000002,
        "end": 61.099999999999966,
        "average": 64.85
      },
      "rationale_metrics": {
        "rouge_l": 0.1941747572815534,
        "text_similarity": 0.47784459590911865,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps and sequence contradict the reference: the predicted finish/start/end times differ substantially from the ground truth and it falsely asserts the telephone statement immediately follows with no pause."
      }
    },
    {
      "question_id": "003",
      "question": "After the blue slide with the speaker's title disappears, when does the speaker begin to mention what factors clinicians should consider for appointment formats?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 479.3,
        "end": 480.3
      },
      "pred_interval": {
        "start": 428.4,
        "end": 442.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.900000000000034,
        "end": 37.5,
        "average": 44.20000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.20370370370370372,
        "text_similarity": 0.3753528594970703,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction gives entirely different anchor/target timestamps and a different quoted phrase, contradicting the ground-truth (E1 at 476.3s and E2 at 479.3s). It omits the correct timing and content, so it is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stephanie finishes speaking and hands over to Mark, when does Mark begin to speak?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 606.5,
        "end": 607.0
      },
      "pred_interval": {
        "start": 510.0,
        "end": 520.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 96.5,
        "end": 87.0,
        "average": 91.75
      },
      "rationale_metrics": {
        "rouge_l": 0.17073170731707316,
        "text_similarity": 0.5878520011901855,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives entirely different timestamps (510.0s vs 593.7\u2013607.0s), claims no gap/\u2018immediately after\u2019 whereas the reference indicates Mark starts much later, and includes unsupported details (exact phrase), so it fails to match key facts."
      }
    },
    {
      "question_id": "002",
      "question": "Once Mark finishes introducing Calum Duncan, when does Calum Duncan start speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 638.3,
        "end": 639.3
      },
      "pred_interval": {
        "start": 520.0,
        "end": 530.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 118.29999999999995,
        "end": 109.29999999999995,
        "average": 113.79999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666669,
        "text_similarity": 0.656491756439209,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that Calum speaks after Mark, but it gives entirely wrong timestamps (520.0s vs. 636.3\u2013639.3s) and even claims both events occur at the same time/immediately, contradicting the ground-truth temporal gap; thus it's largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once Calum Duncan says 'Next slide please', when does the second presentation slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 685.7,
        "end": 686.0
      },
      "pred_interval": {
        "start": 530.0,
        "end": 540.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 155.70000000000005,
        "end": 146.0,
        "average": 150.85000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2528735632183908,
        "text_similarity": 0.64865642786026,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events but gives completely different timestamps (530.0s vs ~684\u2013686s) and incorrectly states the slide appears immediately at 530.0s (E2 at same time as E1), contradicting the reference timing and relation; it also adds unsupported audio/visual cues. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 'near me is what we're going to focus on today', when does he describe it as 'internet-based'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 702.7,
        "end": 703.5
      },
      "pred_interval": {
        "start": 690.0,
        "end": 705.0
      },
      "iou": 0.053333333333330304,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.700000000000045,
        "end": 1.5,
        "average": 7.100000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.10666666666666667,
        "text_similarity": 0.3590359091758728,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction gets the temporal relation correct and roughly approximates the target time, but the anchor time is off by about 10s and the prediction adds an unsupported detail about 'attend anywhere' software, so it is only partially aligned with the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states there were '330 consultations per week' before the pandemic, when does he mention it went up to '10,000'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 737.0,
        "end": 739.0
      },
      "pred_interval": {
        "start": 735.0,
        "end": 745.0
      },
      "iou": 0.2,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 6.0,
        "average": 4.0
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.2340756058692932,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') but the timestamps are inaccurate and do not match the reference intervals (predicted 735.0s and 745.0s vs correct 731.5\u2013733.0s and 737.0\u2013739.0s), and it also reports single time points instead of the given spans."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' for the first time, when does he point to the map on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.0,
        "end": 767.5
      },
      "pred_interval": {
        "start": 750.0,
        "end": 765.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.0,
        "end": 2.5,
        "average": 9.75
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.5079031586647034,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the 'after' relation but gives inaccurate timestamps for both events (predicted 750s vs gold 756s for the anchor, and 765s vs 767s for the pointing), so it merits partial credit."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'go back to the next slide', when does the slide titled 'Video consulting using near me via attend anywhere platform' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 874.0,
        "end": 874.1
      },
      "pred_interval": {
        "start": 960.0,
        "end": 961.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 86.0,
        "end": 86.89999999999998,
        "average": 86.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3835616438356164,
        "text_similarity": 0.7972493171691895,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the immediate 'after' relationship, but both absolute timestamps are substantially wrong (predicted ~960/961s vs correct 873.91/874.0s), so the key factual timing is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that 'Stephanie Fraser has talked about' the survey, when does he then say 'Back to next slide, Mark, please'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 884.0
      },
      "pred_interval": {
        "start": 926.0,
        "end": 929.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.0,
        "end": 45.0,
        "average": 44.0
      },
      "rationale_metrics": {
        "rouge_l": 0.20289855072463767,
        "text_similarity": 0.7129380702972412,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') and immediate succession, but the timestamps and event labels differ substantially from the reference (correct ~883s vs predicted 926\u2013929s), so the answer is largely factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'Next slide, please' at the 42-second mark, when does the slide titled 'Clinician and patient experience - Scotland' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 913.0,
        "end": 913.1
      },
      "pred_interval": {
        "start": 887.0,
        "end": 888.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.0,
        "end": 25.100000000000023,
        "average": 25.55000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3384615384615384,
        "text_similarity": 0.7457815408706665,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the slide appears immediately after the verbal cue, but the timestamps (887/888s vs. 912/913s) and event IDs are substantially incorrect, so the answer is factually inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "During the discussion of what works well with video calls, when does the speaker express finding it much easier to interact with groups on a video call than on the telephone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1053.0,
        "end": 1062.5
      },
      "pred_interval": {
        "start": 1068.3,
        "end": 1073.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.299999999999955,
        "end": 10.700000000000045,
        "average": 13.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2178217821782178,
        "text_similarity": 0.5954717993736267,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the quoted content and the anchor start at 1050.0s, but the target event timing (1068.3\u20131073.2s) substantially disagrees with the reference (1053.0\u20131062.5s), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions technical issues with patient bandwidth, when does he advise to choose patients correctly to avoid those difficulties?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1134.0,
        "end": 1135.5
      },
      "pred_interval": {
        "start": 1088.8,
        "end": 1095.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.200000000000045,
        "end": 39.90000000000009,
        "average": 42.55000000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367346,
        "text_similarity": 0.592544674873352,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the content (speaker raises bandwidth issues and advises to 'choose patients correctly'), but it gives incorrect timestamps and wrongly states the advice occurs immediately/shortly after the anchor\u2014contradicting the ground-truth times (1119.0s \u2192 1134.0\u20131135.5s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' to introduce the smart phone camera, when does he specifically point out his wife's iPhone on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1213.0,
        "end": 1215.0
      },
      "pred_interval": {
        "start": 1157.4,
        "end": 1161.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.59999999999991,
        "end": 53.799999999999955,
        "average": 54.69999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571433,
        "text_similarity": 0.7106418013572693,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies both events and the correct temporal relation (pointing occurs after the slide request) but the timestamps are substantially and factually incorrect (predicted ~1155\u20131161s vs reference 1203\u20131215s) and include unfounded timing details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying 'Next slide please', when does the 'Sharing content' slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.574,
        "end": 1249.574
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1235.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.57400000000007,
        "end": 14.57400000000007,
        "average": 16.57400000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.29885057471264365,
        "text_similarity": 0.75469571352005,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the ordering right but the timestamps are significantly incorrect (off by ~17s from the reference) and the precise timing/duration of the slide appearance is wrong, so it fails to match the key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'You can share things', when does he point towards the screen showing the brain scan?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1252.25,
        "end": 1252.85
      },
      "pred_interval": {
        "start": 1240.0,
        "end": 1245.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.25,
        "end": 7.849999999999909,
        "average": 10.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.2278481012658228,
        "text_similarity": 0.6276214122772217,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the gesture occurs after the utterance, but both reported timestamps are substantially incorrect (utterance off by ~9s, gesture off by ~7s) and thus contradict the precise ground-truth timing and interval."
      }
    },
    {
      "question_id": "003",
      "question": "During the discussion about poor picture quality, when does the speaker suggest clearing browser history?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1313.823,
        "end": 1315.286
      },
      "pred_interval": {
        "start": 1255.0,
        "end": 1260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.82300000000009,
        "end": 55.28600000000006,
        "average": 57.054500000000075
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.6299833655357361,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the suggested action (clear browser history) but gives completely incorrect timestamps (1255\u20131260s vs. 1313.823\u20131315.286s) and adds unsupported audio/visual details, so it fails on the key timing and includes hallucinated cues."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying \"Thank you very much for that\", when does he state he is handing over to Jane?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.837,
        "end": 1430.682
      },
      "pred_interval": {
        "start": 1453.22,
        "end": 1453.22
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.383000000000038,
        "end": 22.53800000000001,
        "average": 23.460500000000025
      },
      "rationale_metrics": {
        "rouge_l": 0.39024390243902435,
        "text_similarity": 0.500292956829071,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the sequence (thank-you then handover) but gives incorrect timestamps (1453.22 vs 1427.0 and misses the correct start/end 1428.837\u20131430.682) and wrongly states the handover occurs immediately at the same moment, contradicting key timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman (Jane) describes the challenges of managing patients over the telephone, when does she mention that they had a pilot of 'Near Me' even prior to Covid?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1609.855,
        "end": 1624.692
      },
      "pred_interval": {
        "start": 1509.0,
        "end": 1512.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 100.85500000000002,
        "end": 112.69200000000001,
        "average": 106.77350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.09876543209876541,
        "text_similarity": 0.4526119828224182,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly states a pre-Covid pilot existed but gives the wrong timing and location (slide at 1509\u20131512s) rather than Jane's verbal mention at ~1609.855\u20131624.692s after finishing the telephone-challenges comment, so it fails on key temporal alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that using 'Near Me' felt quite adventurous, when does she state that its use became vital to their whole service?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1636.0,
        "end": 1643.0
      },
      "pred_interval": {
        "start": 1714.0,
        "end": 1728.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.0,
        "end": 85.0,
        "average": 81.5
      },
      "rationale_metrics": {
        "rouge_l": 0.25806451612903225,
        "text_similarity": 0.44250455498695374,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the coarse 'after' relation but is largely incorrect: both event timestamps and the anchor wording differ significantly from the reference, and it introduces an unsupported 'after the pandemic' context. These substantive mismatches warrant a very low score."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes asking Mark to go back to the previous slide, when does she say 'Thank you'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1676.54,
        "end": 1678.02
      },
      "pred_interval": {
        "start": 1794.0,
        "end": 1798.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 117.46000000000004,
        "end": 119.98000000000002,
        "average": 118.72000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.2988505747126437,
        "text_similarity": 0.7663275003433228,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly links the 'Thank you' to the request but gives substantially different timestamps and a different relation label; key factual elements (correct times/target span) are incorrect, so it only minimally matches the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the 'Training and preparation' slide appears, when does the speaker mention the 'Level 1' training?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1791.0,
        "end": 1791.5
      },
      "pred_interval": {
        "start": 1805.0,
        "end": 1808.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 17.0,
        "average": 15.5
      },
      "rationale_metrics": {
        "rouge_l": 0.27499999999999997,
        "text_similarity": 0.591505765914917,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly conveys that 'Level 1' is mentioned after the slide appears but gives incorrect timestamps (1770.0s and 1805.0s vs. 1774.4s and 1791.0s) and adds unsupported details about bullets, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing tele-swallowing partners as 'our eyes and our hands and our ears', when does she start talking about preparing the clinical room?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1897.0,
        "end": 1901.0
      },
      "pred_interval": {
        "start": 1858.2,
        "end": 1861.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.799999999999955,
        "end": 40.0,
        "average": 39.39999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.25806451612903225,
        "text_similarity": 0.5787582993507385,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the sequence right (discussion of preparing the room follows the metaphor), but the timestamps are substantially incorrect (about 36\u201340 seconds earlier than the reference) and thus fail to match the ground-truth temporal annotations; the relation label 'after' is compatible but timing errors make the answer largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses tele-swallowing partners preparing the clinical room, when does she next talk about them providing reassurance to patients?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1906.0,
        "end": 1910.0
      },
      "pred_interval": {
        "start": 1871.5,
        "end": 1873.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.5,
        "end": 37.0,
        "average": 35.75
      },
      "rationale_metrics": {
        "rouge_l": 0.27272727272727276,
        "text_similarity": 0.47259753942489624,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target content and notes the immediate continuation (matching the 'next' relation), but it omits the required timestamps and does not explicitly give the temporal intervals provided in the reference, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning emergency procedures in place onsite, when does the slide change to 'Technology/equipment'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1971.6,
        "end": 1972.0
      },
      "pred_interval": {
        "start": 2079.0,
        "end": 2080.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 107.40000000000009,
        "end": 108.0,
        "average": 107.70000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.15217391304347824,
        "text_similarity": 0.48205631971359253,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the reference times (predicted ~2079\u20132080s vs ground truth ~1962.6\u20131972.0s) and wrongly asserts an immediate transition, whereas the ground truth shows a ~5s gap; thus the temporal details and timing relation are incorrect despite noting a sequential relation."
      }
    },
    {
      "question_id": "002",
      "question": "During the time the 'Technology/equipment' slide is displayed, when does the speaker discuss the need for a device with a webcam and microphone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2024.079,
        "end": 2026.579
      },
      "pred_interval": {
        "start": 2092.0,
        "end": 2094.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.92100000000005,
        "end": 67.42100000000005,
        "average": 67.67100000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2105263157894737,
        "text_similarity": 0.5912634134292603,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation right (the mention occurs during the slide) but the actual timestamps are incorrect and do not match the reference (predicted anchor and target times are shifted much later than the ground truth), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the general category of 'certain resources' for teleswallow sessions, when does she mention 'appropriate diet and fluid consistencies'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.952,
        "end": 2061.952
      },
      "pred_interval": {
        "start": 2115.0,
        "end": 2116.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.047999999999774,
        "end": 54.047999999999774,
        "average": 55.047999999999774
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.595503568649292,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the item is listed after the Resources introduction and that the relation is 'anchor precedes target', but it gives incorrect anchor/target timestamps (off by ~62 seconds) and mismatches the specified time ranges, so key factual timing details are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that remote swallowing assessments are not intended to fully replace face-to-face assessments, when does she mention that they are a very useful addition?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2159.677,
        "end": 2162.619
      },
      "pred_interval": {
        "start": 2247.6,
        "end": 2253.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 87.92299999999977,
        "end": 90.38099999999986,
        "average": 89.15199999999982
      },
      "rationale_metrics": {
        "rouge_l": 0.33684210526315794,
        "text_similarity": 0.7523247003555298,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the 'immediately after' relationship, but it gives significantly incorrect timestamps (2247.6s vs the reference 2159.0\u20132159.677s), so it fails on the key factual timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning gathering feedback from those who completed the training, when does she start talking about evaluating quantitative data?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2164.643,
        "end": 2186.427
      },
      "pred_interval": {
        "start": 2266.2,
        "end": 2270.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 101.55699999999979,
        "end": 84.37300000000005,
        "average": 92.96499999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.23300970873786406,
        "text_similarity": 0.7408269643783569,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly notes the target follows immediately and is about quantitative evaluation, but the timestamps are substantially off (~80s later) and it incorrectly sets E1 and E2 to the same time; it also adds an unsupported visual cue, so it is largely factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes her presentation by saying 'thank you very much for listening', when does the video visually transition to the male presenter?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2257.0,
        "end": 2258.0
      },
      "pred_interval": {
        "start": 2288.4,
        "end": 2293.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.40000000000009,
        "end": 35.0,
        "average": 33.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.24444444444444444,
        "text_similarity": 0.8420814275741577,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is largely incorrect: it gives significantly different timestamps (2288.4s vs 2256.0s/2257.0s) and asserts a 'simultaneous' transition, whereas the reference states the visual cut occurs 1 second after the speaker finishes. Key factual elements (correct times and temporal relation) are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that picking up cues is difficult, when does she start talking about 'points to consider' for virtual technology?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2491.8,
        "end": 2498.2
      },
      "pred_interval": {
        "start": 2700.0,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 208.19999999999982,
        "end": 201.80000000000018,
        "average": 205.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21359223300970875,
        "text_similarity": 0.5132211446762085,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the immediate 'once finished' relation but gives substantially incorrect timestamps (2699.8/2700.0s vs. 2491.8s) and adds an unverified slide-change visual cue, so it contradicts key factual details in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions conducting a 'sprint audit' with patients, when does she state that 'most were very satisfied' with the virtual appointments?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2515.0,
        "end": 2516.0
      },
      "pred_interval": {
        "start": 2578.0,
        "end": 2588.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.0,
        "end": 72.0,
        "average": 67.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3218390804597701,
        "text_similarity": 0.6657092571258545,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and their temporal relation (the satisfaction remark occurs after the audit), but the provided timestamps are substantially incorrect compared to the reference, so it fails on key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that patients found virtual technology 'more acceptable', when does she say 'So moving on to the next slide'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2638.0,
        "end": 2639.3
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2671.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.0,
        "end": 31.699999999999818,
        "average": 31.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.4802219271659851,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the relation and sentence ordering (the transition follows immediately), but the reported timestamps are factually incorrect\u2014each is about 32 seconds later than the reference\u2014so it does not match the ground-truth timing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing confidentiality, when does she begin to mention the subtlety of the therapeutic relationship?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2693.583,
        "end": 2697.126
      },
      "pred_interval": {
        "start": 2760.0,
        "end": 2760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.41699999999992,
        "end": 62.873999999999796,
        "average": 64.64549999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.21176470588235297,
        "text_similarity": 0.7319547533988953,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the sequence right (confidentiality then therapeutic relationship) but the timestamps are substantially incorrect (E1 predicted at 2760.0s vs. 2688.583s; E2 predicted at 2760.0s vs. 2693.583s) and it wrongly asserts an immediate transition and adds unsupported audiovisual claims, so it contradicts key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'It all comes down to Wi-Fi', when does she state that 'delivery of remote therapy is very, very difficult'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.0,
        "end": 2729.0
      },
      "pred_interval": {
        "start": 2780.0,
        "end": 2780.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.0,
        "end": 51.0,
        "average": 52.0
      },
      "rationale_metrics": {
        "rouge_l": 0.42,
        "text_similarity": 0.7777013778686523,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates both timestamps and the temporal relation: the reference has the anchor at 2722.041s and the target ~5s later (2727\u20132729s), whereas the prediction places both at 2780s and claims an immediate/consecutive transition, contradicting the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'So next slide', when does the slide visually change to 'Practical considerations'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2884.0,
        "end": 2884.2
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 2850.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 34.19999999999982,
        "average": 34.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.49275362318840576,
        "text_similarity": 0.7659485936164856,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the slide title and that the visual change is immediate with the verbal cue, but it gives substantially incorrect timestamps (2850.0s vs. 2883.0/2884.0s), so it fails on the key factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing 'Practical considerations', when does she first mention 'increasing reflective feedback'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2913.483,
        "end": 2916.268
      },
      "pred_interval": {
        "start": 2861.0,
        "end": 2862.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.483000000000175,
        "end": 54.26800000000003,
        "average": 53.3755000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.32786885245901637,
        "text_similarity": 0.7299447655677795,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the start of 'Practical considerations' (2850.0s) but gives the wrong time for 'increasing reflective feedback' (2861.0s vs the reference 2913.483s) and adds a quoted phrase not supported by the ground truth, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"for the patients\", when does the slide change to \"WHERE WE ARE NOW\"?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3067.769,
        "end": 3068.2
      },
      "pred_interval": {
        "start": 3094.0,
        "end": 3095.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.231000000000222,
        "end": 26.800000000000182,
        "average": 26.515500000000202
      },
      "rationale_metrics": {
        "rouge_l": 0.4225352112676056,
        "text_similarity": 0.6846905946731567,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the slide change occurs immediately after the utterance, but the timestamps are significantly off (~27s later) and it omits the precise 'fully visible by 3068.2s' detail, so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says \"open up for some discussion\", when does the discussion slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3163.435,
        "end": 3163.7
      },
      "pred_interval": {
        "start": 3158.0,
        "end": 3159.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.434999999999945,
        "end": 4.699999999999818,
        "average": 5.067499999999882
      },
      "rationale_metrics": {
        "rouge_l": 0.3939393939393939,
        "text_similarity": 0.6504356861114502,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the discussion slide appears after the utterance, but the timestamps are significantly off (E1: 3120s vs 3158s; E2: 3163.435s vs 3159.0s) and it incorrectly labels the change as 'immediately after' despite a substantial delay in the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the first male speaker asks about attendees' experience with Near Me, when does the second male speaker begin talking about starting to use NearMe?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.9,
        "end": 3312.0
      },
      "pred_interval": {
        "start": 3210.0,
        "end": 3210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.90000000000009,
        "end": 102.0,
        "average": 80.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.32941176470588235,
        "text_similarity": 0.650351881980896,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation as 'after' but the provided timestamps for both E1 and E2 differ substantially from the ground truth (major factual mismatch). It also adds visual/audio cues not supported by the reference, so key factual elements are incorrect or hallucinated."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second male speaker finishes stating the advantages and utility of NearMe, when does he mention supplementing normal activities?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.4,
        "end": 3293.32
      },
      "pred_interval": {
        "start": 3230.0,
        "end": 3230.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.40000000000009,
        "end": 63.320000000000164,
        "average": 60.86000000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.24999999999999994,
        "text_similarity": 0.5806315541267395,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation right ('after') but the reported timestamps are substantially incorrect (off by ~53\u201355s) and it adds an unsupported 'audio cue' detail, so it fails to match the key temporal facts."
      }
    },
    {
      "question_id": "001",
      "question": "After the first man finishes reading Jenny's chat message, when does he ask the audience if they would find guidance helpful?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3411.0,
        "end": 3415.0
      },
      "pred_interval": {
        "start": 3457.2,
        "end": 3459.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.19999999999982,
        "end": 44.40000000000009,
        "average": 45.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.7540634274482727,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the temporal relation ('after'/'immediately after') right but the timestamps and spans are significantly incorrect and inconsistent (anchor 3457.2s vs reference 3407.6s; target span 3457.2\u20133459.4s vs reference 3411.0\u20133415.0s), so it fails to match the correct timing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first man finishes reading John Hogan's comment about clinical interviewing, when does he state he was quite skeptical?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3434.9,
        "end": 3437.7
      },
      "pred_interval": {
        "start": 3478.8,
        "end": 3482.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.90000000000009,
        "end": 44.30000000000018,
        "average": 44.100000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.8306728005409241,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives completely different timestamps for both events and an incorrect target span relative to the gold (off by ~45s), and it misrepresents the temporal relation timing; only the quoted phrase matches, so overall it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the second woman mentions neuropsychology bringing out guidance, when is the next time a woman speaks about professional guidance?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3511.043,
        "end": 3528.447
      },
      "pred_interval": {
        "start": 3512.6,
        "end": 3518.2
      },
      "iou": 0.32176511146862274,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.556999999999789,
        "end": 10.247000000000298,
        "average": 5.902000000000044
      },
      "rationale_metrics": {
        "rouge_l": 0.32098765432098764,
        "text_similarity": 0.8493003845214844,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misidentifies E1 timing (3512.6s vs correct 3422.0s) and thus the anchor is incorrect; the predicted E2 partially overlaps the correct target span but its timing differs and the relation label is imprecise, so overall it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 36 people joined the session, when does he talk about taking the next steps with Richard and the team?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3574.7,
        "end": 3576.5
      },
      "pred_interval": {
        "start": 3579.0,
        "end": 3582.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.300000000000182,
        "end": 5.5,
        "average": 4.900000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.27272727272727276,
        "text_similarity": 0.7983416318893433,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase and the 'after' relationship, but the timestamp boundaries are inaccurate\u2014its anchor end and target start (3579.0s) are later than the ground-truth times and misalign the segments."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker makes a plea to fill in the survey, when does he ask if listeners would like to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3592.9,
        "end": 3594.1
      },
      "pred_interval": {
        "start": 3592.0,
        "end": 3595.0
      },
      "iou": 0.39999999999993935,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.900000000000091,
        "end": 0.900000000000091,
        "average": 0.900000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.3488372093023256,
        "text_similarity": 0.7726566791534424,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction captures the correct utterances and that the target occurs after the anchor, but the timestamps are notably imprecise\u2014the anchor is extended to 3592.0s (should end at 3588.0s) and the target start is about 0.9s early, causing overlap/temporal inaccuracy."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes thanking everyone for joining the session today, when does he mention that the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3599.8,
        "end": 3603.2
      },
      "pred_interval": {
        "start": 3612.0,
        "end": 3618.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.199999999999818,
        "end": 14.800000000000182,
        "average": 13.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2150537634408602,
        "text_similarity": 0.7965719699859619,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys that the speaker says the session will be recorded and resources shared right after thanking attendees, but the provided timestamps are off by ~8\u201312 seconds and it omits that the remark immediately follows the thank-you, so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'where did we start?', when does she mention considering moving to Near Me for patient contacts?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2332.719,
        "end": 2336.344
      },
      "pred_interval": {
        "start": 2429.0,
        "end": 2450.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 96.28099999999995,
        "end": 113.65599999999995,
        "average": 104.96849999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.3287671232876712,
        "text_similarity": 0.686559796333313,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the correct utterance and relation ('after') but the anchor and target timestamps are significantly incorrect (off by ~109s) and the target span does not match the reference, so temporal alignment is wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says the pandemic came along, when does she mention adopting Near Me as their default for routine people?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2367.217,
        "end": 2412.045
      },
      "pred_interval": {
        "start": 2461.0,
        "end": 2480.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 93.7829999999999,
        "end": 67.95499999999993,
        "average": 80.86899999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7614914178848267,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly identifies the 'after' relationship, it mislocates both the anchor and target timecodes (off by ~100\u2013110 seconds) and thus fails to match the correct segments."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the results of the focus groups for the qualitative study, when does she introduce the quotes from the participants?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2511.0,
        "end": 2512.0
      },
      "pred_interval": {
        "start": 2500.0,
        "end": 2510.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 2.0,
        "average": 6.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3116883116883117,
        "text_similarity": 0.7567017078399658,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the quote introduction follows the results description, but the reported timestamps are substantially off from the reference (anchor 2469.0s vs 2500.0s; target 2511.0s vs 2501.0s) and it adds an unsupported quoted phrase and visual detail, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks to fill in the survey, when does he ask if listeners want to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3591.7,
        "end": 3595.8
      },
      "pred_interval": {
        "start": 3588.6,
        "end": 3592.0
      },
      "iou": 0.041666666666690354,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.099999999999909,
        "end": 3.800000000000182,
        "average": 3.4500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.4036697247706422,
        "text_similarity": 0.8218021392822266,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies both events and their temporal relation (target after anchor), but the timestamping is imprecise: the anchor time is shifted and the predicted target interval starts earlier and omits the latter portion of the correct span."
      }
    },
    {
      "question_id": "002",
      "question": "Before the speaker thanks the speakers for their expertise, when does he mention the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3599.9,
        "end": 3603.7
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3573.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.90000000000009,
        "end": 30.199999999999818,
        "average": 30.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.8020740151405334,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation ('before') correct, but it mislabels anchor/target, gives substantially incorrect timestamps (~30s off), and contradicts the ground-truth event assignments, so it is largely factually incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker initially thanks the audience for joining, when does he deliver his final 'thank you very much' for the session?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3614.6,
        "end": 3615.4
      },
      "pred_interval": {
        "start": 3614.4,
        "end": 3617.0
      },
      "iou": 0.3076923076923884,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.1999999999998181,
        "end": 1.599999999999909,
        "average": 0.8999999999998636
      },
      "rationale_metrics": {
        "rouge_l": 0.4333333333333333,
        "text_similarity": 0.8080264329910278,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the final 'thank you' and the 'after' relationship, and E2 timing is close to the ground truth, but the anchor (E1) timestamp is substantially off (~27s earlier) and E2's end time is overstated, so the answer is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "After Mark introduces Dr. John Mckeown and Dr. Naomi Dow, when does he ask Dr. Dow to describe how they've been using Near Me?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.48,
        "end": 34.4
      },
      "pred_interval": {
        "start": 16.3,
        "end": 17.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.18,
        "end": 16.599999999999998,
        "average": 15.889999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3243243243243243,
        "text_similarity": 0.7951884865760803,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly locates the anchor (\u224815.7s) and labels the relation as 'after', but the target interval is placed ~15s earlier than the reference (16.3\u201317.8s vs 31.48\u201334.4s) and incorrectly asserts it directly follows, so it is largely temporally inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once Dr. Naomi Dow finishes explaining how students take part in consultations, when does Mark ask Dr. Mckeown about the impact on the teaching team?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.96,
        "end": 124.4
      },
      "pred_interval": {
        "start": 21.2,
        "end": 22.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.75999999999999,
        "end": 101.5,
        "average": 99.63
      },
      "rationale_metrics": {
        "rouge_l": 0.34210526315789475,
        "text_similarity": 0.7265418767929077,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the two events and their semantic order, but the timestamps and durations are completely incorrect (20s vs ~118s), and the relation label is only roughly equivalent; major factual timing errors warrant a very low score."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker introduces the concept of emotions in the session, when does the female speaker first mention 'real patients'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.9,
        "end": 202.6
      },
      "pred_interval": {
        "start": 360.0,
        "end": 360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 158.1,
        "end": 157.4,
        "average": 157.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3132530120481928,
        "text_similarity": 0.6830281019210815,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives incorrect timestamps (claims 360.0s and that the female starts at 150.0s) which contradict the reference (female says 'real patients' at 201.9\u2013202.6s) and introduces unsupported details, so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the interviewer finishes asking the question about comparing models, when does the female speaker finish explaining the advantages of 'Near Me' regarding real patients and capacity?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 198.7,
        "end": 306.9
      },
      "pred_interval": {
        "start": 360.0,
        "end": 360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 161.3,
        "end": 53.10000000000002,
        "average": 107.20000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.1764705882352941,
        "text_similarity": 0.5416679382324219,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timings (360.0s) and the claimed 'immediately after' relation contradict the ground-truth times (interviewer at 186.4s; speaker 198.7\u2013306.9s). The prediction fabricates incorrect timestamps and an incorrect temporal relation."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the man is speaking on screen, when does he mention 'Near Me'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 342.0,
        "end": 344.0
      },
      "pred_interval": {
        "start": 340.0,
        "end": 341.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0,
        "end": 2.5,
        "average": 2.25
      },
      "rationale_metrics": {
        "rouge_l": 0.25641025641025644,
        "text_similarity": 0.7734456062316895,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only matches the 'during' relation but the temporal annotations are incorrect (E1 given as a single time and with wrong boundaries; E2 is earlier and shorter than the reference 342.0\u2013344.0). It also adds an unsupported detail ('looking at the camera'), which is a hallucination."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying 'Thank you and goodbye', when do the 'NHS Scotland' and 'Near Me' logos appear with text links?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 354.0,
        "end": 357.0
      },
      "iou": 0.3333333333333333,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 3.0,
        "average": 3.0
      },
      "rationale_metrics": {
        "rouge_l": 0.19354838709677416,
        "text_similarity": 0.6185023784637451,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly reflects the 'immediately after/once finished' relation, but the provided timestamps and durations differ notably from the reference (E1 should be ~350.0\u2013350.7 vs predicted 354.0; E2 should be 351.0\u2013360.0 vs predicted 354.0\u2013357.0), so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the initial voiceover concludes with 'patient that day', when does the man on screen begin to say 'Thanks very much John and Amy'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 336.4,
        "end": 341.6
      },
      "pred_interval": {
        "start": 346.0,
        "end": 347.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.600000000000023,
        "end": 5.899999999999977,
        "average": 7.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3870967741935484,
        "text_similarity": 0.7631020545959473,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same utterances but gives significantly incorrect timestamps (E1 predicted 346.0s vs correct 334.40s; E2 predicted 346.0\u2013347.5s vs correct 336.40\u2013341.6s) and mischaracterizes the temporal relation (predicts no delay/immediate after vs the correct answer shows a 2s gap), so it is largely incorrect."
      }
    }
  ]
}