{
  "topic_id": 1,
  "topic_name": "Patient-Doctor Consultations",
  "num_evaluated": 266,
  "aggregated_metrics": {
    "mean_iou": 0.03940291939748842,
    "std_iou": 0.0962203654582832,
    "median_iou": 0.004761904761904762,
    "R@0.3": {
      "recall": 0.03383458646616541,
      "count": 9,
      "total": 266
    },
    "R@0.5": {
      "recall": 0.018796992481203006,
      "count": 5,
      "total": 266
    },
    "R@0.7": {
      "recall": 0.0037593984962406013,
      "count": 1,
      "total": 266
    },
    "mae": {
      "start_mean": 170.01943233082704,
      "end_mean": 3724.0714812030074,
      "average_mean": 1947.0454567669171
    },
    "rationale": {
      "rouge_l_mean": 0.2328729385077344,
      "rouge_l_std": 0.11288352576780235,
      "text_similarity_mean": 0.4552626983801785,
      "text_similarity_std": 0.19847592530939134,
      "llm_judge_score_mean": 2.601503759398496,
      "llm_judge_score_std": 2.1882799563307938
    },
    "rationale_cider": 0.26596667247401795
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "After the speaker welcomes viewers and introduces himself as 'Karma Medic', when does he state that he is a 'final year medical student'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 35.0,
        "end": 36.62
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.050922978994271215,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.8,
        "end": 0.01999999999999602,
        "average": 14.909999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.8115942028985507,
        "text_similarity": 0.9635060429573059,
        "llm_judge_score": 9,
        "llm_judge_justification": "The predicted answer correctly identifies the target utterance timing and the 'after' relationship; the only minor issue is the anchor start time (5.2s vs correct 3.54s), a small temporal discrepancy but not altering the semantic alignment."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'Now with that lovely disclaimer out of the way, let's get right into it', when does the text 'before the history' appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.06,
        "end": 57.06
      },
      "pred_interval": {
        "start": 35.0,
        "end": 40.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.060000000000002,
        "end": 16.46,
        "average": 18.76
      },
      "rationale_metrics": {
        "rouge_l": 0.27586206896551724,
        "text_similarity": 0.7682825326919556,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the reference on all key facts: the reported timestamps for both events are incorrect and the temporal relation ('before' vs. 'once_finished') is wrong, so it fails to match the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'So before starting the history, there's generally two things that I try and keep in mind', when does he begin describing 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 206.36,
        "end": 207.36
      },
      "pred_interval": {
        "start": 40.6,
        "end": 60.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 165.76000000000002,
        "end": 147.36,
        "average": 156.56
      },
      "rationale_metrics": {
        "rouge_l": 0.32432432432432434,
        "text_similarity": 0.8863785266876221,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misidentifies and swaps the anchor and target timestamps and incorrectly locates when 'washing your hands' begins; only the stated 'after' relationship matches the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the acronym 'ICE', when does he explain what it stands for?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 155.7,
        "end": 158.7
      },
      "pred_interval": {
        "start": 153.6,
        "end": 204.9
      },
      "iou": 0.05847953216374268,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0999999999999943,
        "end": 46.20000000000002,
        "average": 24.150000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.6007453203201294,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction vaguely recognizes an explanation but gives substantially incorrect timing (starts earlier and extends far beyond the true 155.7\u2013158.7s window) and fails to report the correct mention time, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the components of the WIPER acronym, when does he start elaborating on 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 212.0
      },
      "pred_interval": {
        "start": 207.3,
        "end": 258.6
      },
      "iou": 0.0910852713178292,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.30000000000001137,
        "end": 46.60000000000002,
        "average": 23.450000000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.3018867924528302,
        "text_similarity": 0.5975227355957031,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the speaker begins explaining 'washing your hands' just after listing (start ~207s), but it omits the E1 timestamp (205.0s) and severely overestimates the end time (258.6s vs correct 212.0s), introducing substantial incorrect detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what brought the patient in, when does he explain what the 'history of presenting complaint' is about?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 346.0,
        "end": 351.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 540.0
      },
      "iou": 0.023809523809523808,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.0,
        "end": 189.0,
        "average": 102.5
      },
      "rationale_metrics": {
        "rouge_l": 0.29411764705882354,
        "text_similarity": 0.6572513580322266,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer misidentifies both event timestamps and descriptions (giving unrelated intro statements at ~5\u201336s) while the reference specifies events at ~332\u2013351s; only the temporal relation 'after' matches, so the prediction is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "How long after the speaker says he'll put a picture of all possible questions does the \"REVIEW OF SYSTEMS\" checklist first appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 539.8,
        "end": 543.7
      },
      "pred_interval": {
        "start": 510.0,
        "end": 720.0
      },
      "iou": 0.018571428571429006,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.799999999999955,
        "end": 176.29999999999995,
        "average": 103.04999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818185,
        "text_similarity": 0.3882063329219818,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly implies the checklist appears after the speaker but the 210s figure is far from the referenced timings (starts at 29.8s and fully visible by 33.7s) and it omits the distinct start vs fully-visible times, so it is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is giving examples of systems review questions, when does he ask about \"tummy pain\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 565.74,
        "end": 566.422
      },
      "pred_interval": {
        "start": 510.0,
        "end": 720.0
      },
      "iou": 0.0032476190476191254,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.74000000000001,
        "end": 153.57799999999997,
        "average": 104.65899999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.29629629629629634,
        "text_similarity": 0.45992401242256165,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a single timestamp of 210s which contradicts the correct interval (555.740\u2013556.422s) and omits the relation and precise interval details; thus it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the \"JAM THREADS\" mnemonic, when does he say the name \"Sketchy Medical\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 696.0,
        "end": 699.531
      },
      "pred_interval": {
        "start": 510.0,
        "end": 720.0
      },
      "iou": 0.016814285714285473,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 186.0,
        "end": 20.46900000000005,
        "average": 103.23450000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3404255319148936,
        "text_similarity": 0.5883309841156006,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp is wrong and contradicts the ground truth: the speaker says 'Sketchy Medical' at ~696\u2013699.5s (after 'JAM THREADS' at 635s), not at 210s."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker describes Sketchy Medical, when does he mention drugs' mechanism of action and side effects?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 701.0,
        "end": 703.982
      },
      "pred_interval": {
        "start": 690.0,
        "end": 894.5
      },
      "iou": 0.014581907090464405,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 190.51800000000003,
        "average": 100.75900000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.47505658864974976,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys that the mechanism and side effects are mentioned in relation to Sketchy Medical (after its introduction), but it omits the precise time interval (701.0s\u2013703.982s) and the exact start timestamp, so it is incomplete on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks a general question about family health, when does he suggest being specific about asthma, diabetes, and hypertension?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 742.914,
        "end": 745.914
      },
      "pred_interval": {
        "start": 894.5,
        "end": 900.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 151.586,
        "end": 154.086,
        "average": 152.836
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290322,
        "text_similarity": 0.3954246938228607,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the temporal relation that the specificity about asthma, diabetes, and hypertension comes after the general family-health question, but it omits the specific timing details (the provided timestamps and interval) included in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the importance of signposting, when does he ask if the patient uses any recreational drugs?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 811.123,
        "end": 812.664
      },
      "pred_interval": {
        "start": 900.0,
        "end": 906.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 88.87699999999995,
        "end": 93.33600000000001,
        "average": 91.10649999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962265,
        "text_similarity": 0.5611132383346558,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the question occurs after the explanation, but it omits the key temporal details (the specific timestamps and the note that the question immediately follows the explanation), making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"concerns from ICE\", when does he start saying \"Just generally, if you're feeling stuck\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 880.187,
        "end": 883.471
      },
      "pred_interval": {
        "start": 870.0,
        "end": 913.0
      },
      "iou": 0.07637209302325562,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.187000000000012,
        "end": 29.528999999999996,
        "average": 19.858000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.4000000000000001,
        "text_similarity": 0.38902950286865234,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a start time of 9.4s which is vastly different from the correct start (~880.187s) and omits the target's end time; while it implies 'after', the timing is incorrect, so the answer is essentially wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"golden rulebook\", when does he open both hands outwards in a gesture?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 895.8,
        "end": 897.5
      },
      "pred_interval": {
        "start": 875.0,
        "end": 918.0
      },
      "iou": 0.03953488372093129,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.799999999999955,
        "end": 20.5,
        "average": 20.649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.5109162330627441,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct gesture but gives a single start time (34.6s) that is far from the correct interval (895.8\u2013897.5s relative to the anchor at 892.849s) and fails to preserve the temporal relation; therefore the timing is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying \"I hope you find this video useful\", when does he say \"Peace\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 910.148,
        "end": 910.609
      },
      "pred_interval": {
        "start": 879.0,
        "end": 923.0
      },
      "iou": 0.010477272727273017,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.148000000000025,
        "end": 12.390999999999963,
        "average": 21.769499999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.34615384615384615,
        "text_similarity": 0.4648137390613556,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives a vastly incorrect timestamp (38.0s) whereas the ground truth places 'Peace.' around 910.148\u2013910.609s after the anchor at 909.546s, so the timing and temporal detail are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying he has an appointment at 10 am, when does the green text 'Sure, what's your name?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 6.1,
        "end": 8.2
      },
      "pred_interval": {
        "start": 5.2,
        "end": 35.0
      },
      "iou": 0.0704697986577181,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8999999999999995,
        "end": 26.8,
        "average": 13.85
      },
      "rationale_metrics": {
        "rouge_l": 0.24000000000000002,
        "text_similarity": 0.41929861903190613,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction only conveys a vague temporal relation (the text appears after he mentions the time) but omits the precise timing and relation details given in the ground truth (6.1s\u20138.2s, immediately after finishing at 5.9s) and adds irrelevant phrasing about when he starts speaking."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes stating his name, when does the green text 'Thank you, Lucas. Please take a seat...' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 11.9,
        "end": 19.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.1,
        "end": 17.6,
        "average": 20.35
      },
      "rationale_metrics": {
        "rouge_l": 0.10256410256410256,
        "text_similarity": 0.25833332538604736,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction vaguely indicates the caption appears after his introduction (before he asks about the wait) but omits the precise times and explicit 'once_finished' relation given in the correct answer and adds an unverified detail, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'How long is the wait?', when does the green text 'About 10 minutes. Would you like some water while you wait?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 22.1,
        "end": 25.3
      },
      "pred_interval": {
        "start": 36.6,
        "end": 41.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.5,
        "end": 16.099999999999998,
        "average": 15.299999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.2543618977069855,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits all timing details; it also implies the text appears immediately 'while he waits' rather than after a slight pause as specified, so it does not match the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the video explains the 'we're a team' approach with animated graphics, when does the speaker appear at his desk looking at a computer?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 34.6,
        "end": 36.0
      },
      "pred_interval": {
        "start": 48.9,
        "end": 58.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.299999999999997,
        "end": 22.5,
        "average": 18.4
      },
      "rationale_metrics": {
        "rouge_l": 0.17500000000000002,
        "text_similarity": 0.6037391424179077,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer is largely incorrect: it misidentifies the anchor event and gives timestamps ~20\u201325s later than the ground truth (48.9s/58.5s vs. 29.5\u201334.6s and 34.0s), and thus fails to match the correct event timing and descriptions despite loosely stating a 'before' relationship."
      }
    },
    {
      "question_id": "001",
      "question": "After Nurse Kim mentions graduating as a registered nurse, when does she talk about working for many different pharmaceutical companies?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 43.0,
        "end": 50.475
      },
      "pred_interval": {
        "start": 3.5,
        "end": 18.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.5,
        "end": 31.775000000000002,
        "average": 35.6375
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714288,
        "text_similarity": 0.31434279680252075,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the order (she mentions graduating before talking about pharmaceutical companies) but omits the key temporal details (the specific timestamps and interval) provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once Nurse Kim finishes describing her background as an 'incredible journey', when does she mention training side-by-side with Dr. Jugenberg for five years?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 149.87,
        "end": 153.25
      },
      "pred_interval": {
        "start": 48.5,
        "end": 108.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 101.37,
        "end": 44.75,
        "average": 73.06
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814817,
        "text_similarity": 0.33718496561050415,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (she mentions training after finishing the 'incredible journey'), but it omits the key factual details from the reference\u2014specific timestamps for E1 and E2 and the start/end times of the 5-year training\u2014so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "While Nurse Kim explains options and possible outcomes, when does she begin examining the patient's stomach?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 157.5,
        "end": 160.5
      },
      "pred_interval": {
        "start": 152.7,
        "end": 169.8
      },
      "iou": 0.17543859649122784,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.800000000000011,
        "end": 9.300000000000011,
        "average": 7.050000000000011
      },
      "rationale_metrics": {
        "rouge_l": 0.2758620689655173,
        "text_similarity": 0.5784127712249756,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the reference: the ground truth states Nurse Kim begins examining the stomach at 157.5s while she is speaking, but the prediction claims it happens after Dr. Smith's discussion and gives no timing, omitting key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "After Nurse Kim finishes discussing the benefits, risks, and possible complications of the procedure, when does she start talking about asymmetry?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 169.7,
        "end": 172.0
      },
      "pred_interval": {
        "start": 163.8,
        "end": 180.8
      },
      "iou": 0.13529411764705948,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.899999999999977,
        "end": 8.800000000000011,
        "average": 7.349999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290322,
        "text_similarity": 0.5040226578712463,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states that Nurse Kim discusses asymmetry after covering benefits/risks/complications, but it omits the key detail that this occurs immediately afterward with specific timestamps (169.5s \u2192 169.7s)."
      }
    },
    {
      "question_id": "003",
      "question": "Once Nurse Kim finishes explaining that the one-hour consultation cannot provide everything you need to know, when does she mention that they are always available?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 201.5,
        "end": 203.71
      },
      "pred_interval": {
        "start": 181.8,
        "end": 200.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.69999999999999,
        "end": 2.9099999999999966,
        "average": 11.304999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.24615384615384617,
        "text_similarity": 0.4124414920806885,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that she mentions availability after that explanation, but it omits the key factual details from the reference\u2014namely the precise timestamp (201.5s) and that the mention is an immediate transition\u2014making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces himself and the topic, when does the slide change to 'Objectives for today's lesson'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 24.379,
        "end": 24.5
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.003853503184713333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.179000000000002,
        "end": 12.100000000000001,
        "average": 15.639500000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6774170994758606,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly labels the temporal relation as 'after' and gives an acceptable start for E1, but it omits E1's end time and completely misstates E2 (slide change) timing and content (35.0s vs the correct 24.379s), so the key factual element is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the objectives for the lesson, when does the slide change to 'Brain storming time'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 46.529,
        "end": 47.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.529000000000003,
        "end": 10.399999999999999,
        "average": 10.964500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.14545454545454545,
        "text_similarity": 0.5378491878509521,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is entirely mismatched: it lists different events and incorrect timestamps (5.2s/35.0\u201336.6s) instead of the objective-list end at 45.800s and slide change at 46.529s, and the relation ('after') contradicts the correct 'once_finished'."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes defining communication as the successful passage of a message from one person to another, when does he start explaining how good communication manifests in medical practice by informing patients of their diagnosis?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 153.0,
        "end": 177.0
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 147.8,
        "end": 140.4,
        "average": 144.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.06666666666666667,
        "text_similarity": 0.03845293074846268,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to answer the temporal question and omits the required timestamps; it also describes a different content (patient satisfaction) rather than the target topic (informing patients of their diagnosis), so it does not match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the 'Importance of communication' slide, when does he begin discussing that good doctor-patient communication has been linked to improved patient satisfaction?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 190.0,
        "end": 198.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 155.0,
        "end": 161.4,
        "average": 158.2
      },
      "rationale_metrics": {
        "rouge_l": 0.07017543859649122,
        "text_similarity": 0.0933329164981842,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates the content but omits the key factual elements (the precise timestamps and the anchor\u2192target timing relation); it lacks the temporal details required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker starts talking about how a lot of malpractice lawsuits have been documented, when does he explicitly advise being aware of communication's importance to avoid lawsuits?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 226.0,
        "end": 271.0
      },
      "pred_interval": {
        "start": 180.0,
        "end": 210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.0,
        "end": 61.0,
        "average": 53.5
      },
      "rationale_metrics": {
        "rouge_l": 0.09375,
        "text_similarity": 0.26086002588272095,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that he advises being aware of communication to avoid lawsuits but fails to provide the required timing (198.0s-212.0s and 226.0s-271.0s) and the anchor/target relation, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the initial slide 'Communication is not just talking' is displayed, when does the speaker mention that physicians can improve health outcomes?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 339.28,
        "end": 346.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 420.0
      },
      "iou": 0.07466666666666696,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.279999999999973,
        "end": 74.0,
        "average": 41.639999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.24,
        "text_similarity": 0.2003803253173828,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the content that physicians can improve outcomes but fails to provide the required timing/temporal relation (the event at 339.28\u2013346.0s after the 330.0s slide) and adds an unsupported detail about specific techniques."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide showing two images (bored girl vs. smiling doctor/patient), when does the speaker describe the first image as depicting a 'horribly bored' lady?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.8,
        "end": 359.0
      },
      "pred_interval": {
        "start": 420.0,
        "end": 540.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.19999999999999,
        "end": 181.0,
        "average": 123.1
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.5274916291236877,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timeframe (420.0\u2013540.0s) is far outside the correct interval (354.8\u2013359.0s) and even after the slide ends (410.7s), so it contradicts the reference and is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker defines verbal communication as 'using spoken words', when is the next time they define non-verbal communication?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 428.87,
        "end": 433.596
      },
      "pred_interval": {
        "start": 540.0,
        "end": 750.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 111.13,
        "end": 316.404,
        "average": 213.767
      },
      "rationale_metrics": {
        "rouge_l": 0.11764705882352941,
        "text_similarity": 0.4879826307296753,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timeframe (540.0\u2013750.0s) is incorrect and far later than the reference, which places the non-verbal definition at ~428.87\u2013433.6s immediately after the verbal definition; the prediction contradicts the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the 'golden minute', when does he describe the patient's hypothetical response?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 613.818,
        "end": 630.0
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 608.6179999999999,
        "end": 593.4,
        "average": 601.009
      },
      "rationale_metrics": {
        "rouge_l": 0.24657534246575344,
        "text_similarity": 0.6441881656646729,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer is largely incorrect: both anchor and target timestamps and the described target content do not match the ground truth (it wrongly identifies a speaker self-introduction instead of the patient's hypothetical response). Only the temporal relation ('after') coincidentally matches."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions 'Checking facts', when does he mention the next essential element of listening?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 641.157,
        "end": 642.461
      },
      "pred_interval": {
        "start": 35.0,
        "end": 71.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 606.157,
        "end": 571.061,
        "average": 588.609
      },
      "rationale_metrics": {
        "rouge_l": 0.20000000000000004,
        "text_similarity": 0.6311218738555908,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction completely mismatches the correct anchor and target (wrong timestamps and different utterances), contradicting the reference that the next element after 'Checking facts' is 'Checking feelings'."
      }
    },
    {
      "question_id": "003",
      "question": "Before the speaker says 'So, for example, we have three main types of reflective listening', when does he explain what reflective listening involves?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 667.457,
        "end": 687.051
      },
      "pred_interval": {
        "start": 51.6,
        "end": 71.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 615.857,
        "end": 615.6510000000001,
        "average": 615.754
      },
      "rationale_metrics": {
        "rouge_l": 0.14925373134328357,
        "text_similarity": 0.594840407371521,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely incorrect: it gives unrelated timestamps and content ('Motivation of the patient') that do not match the correct events or timing, and fails to identify the definition of reflective listening occurring before the examples."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the three main types of reflective listening, when does he start explaining the 'Repeating' example?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 710.0,
        "end": 737.0
      },
      "pred_interval": {
        "start": 690.0,
        "end": 738.4
      },
      "iou": 0.5578512396694217,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.0,
        "end": 1.3999999999999773,
        "average": 10.699999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.19999999999999998,
        "text_similarity": 0.49509871006011963,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relative relation ('after') but omits the key factual details (the specific start time 710.0s, end time 737.0s, and the initial mention time 696.1s) required by the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the 'Repeating' example, when does he introduce 'Rephrasing'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 720.0,
        "end": 720.4
      },
      "pred_interval": {
        "start": 738.4,
        "end": 784.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.399999999999977,
        "end": 64.39999999999998,
        "average": 41.39999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.6515618562698364,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation that 'Rephrasing' follows the 'Repeating' example, but it omits the specific timestamps (698.0s and 720.0s) and the quoted phrase, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing 'Reflection of feeling by showing empathy', when does the 'Non-verbal' slide appear?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 780.0,
        "end": 821.5
      },
      "pred_interval": {
        "start": 784.8,
        "end": 816.0
      },
      "iou": 0.7518072289156638,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 4.7999999999999545,
        "end": 5.5,
        "average": 5.149999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.27906976744186046,
        "text_similarity": 0.6039236783981323,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the slide appears after the empathy discussion) but omits the key factual elements of the correct answer\u2014specifically the precise timestamps (778.5s and 780.0s) and the absolute\u2192relative timing detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises to smile, when does he mention checking for signs of pain?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.045,
        "end": 882.0
      },
      "pred_interval": {
        "start": 870.0,
        "end": 960.0
      },
      "iou": 0.09950000000000045,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.044999999999959,
        "end": 78.0,
        "average": 40.52249999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.40816326530612246,
        "text_similarity": 0.6185621023178101,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gets the sequence right (smile then check for pain) but gives a completely incorrect time (1 minute) versus the correct ~873.0\u2013882.0 seconds, so it fails to match the key factual timing."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the cultural interpretations of folding arms, when does he advise to avoid folding arms?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 932.0,
        "end": 936009.0
      },
      "pred_interval": {
        "start": 960.0,
        "end": 1080.0
      },
      "iou": 0.00012833167749821674,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.0,
        "end": 934929.0,
        "average": 467478.5
      },
      "rationale_metrics": {
        "rouge_l": 0.4444444444444444,
        "text_similarity": 0.6278690099716187,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly notes the speaker transitions from cultural interpretations to advising against folding arms, but it omits the specific timing and incorrectly asserts this occurs 'at the end of the video' instead of around 932.0\u2013936.0s, so it lacks the key factual detail and is temporally imprecise."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker instructs to introduce yourself to the patient, when does he advise to explain your role as a student or intern?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 985.0,
        "end": 990.853
      },
      "pred_interval": {
        "start": 870.0,
        "end": 1080.0
      },
      "iou": 0.027871428571428342,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 115.0,
        "end": 89.14700000000005,
        "average": 102.07350000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.29090909090909095,
        "text_similarity": 0.4627891182899475,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly states the advice occurs 'throughout the video' and provides no timing; the correct answer specifies a brief interval (985.0s\u2013990.1s). This is factually wrong and omits the key temporal detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"if you're in the hospital\", when does he refer to \"inpatient patients\"?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1059.6,
        "end": 1059.8
      },
      "pred_interval": {
        "start": 10.5,
        "end": 21.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1049.1,
        "end": 1038.2,
        "average": 1043.65
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.035769350826740265,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction does not answer the timing question or provide any of the required timestamps/relative ordering; it gives an unrelated description about starting a consultation rather than when 'inpatient patients' is referred to."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining how to start a consultation, when does he give the example \"how can I help you today?\"",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1069.0,
        "end": 1070.0
      },
      "pred_interval": {
        "start": 34.8,
        "end": 47.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1034.2,
        "end": 1022.6,
        "average": 1028.4
      },
      "rationale_metrics": {
        "rouge_l": 0.09999999999999999,
        "text_similarity": 0.16427430510520935,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the speaker gives an example question during a consultation, but it omits the exact timestamps and the link to open-ended questions and introduces an unverified detail ('after the golden minute'), so it is incomplete and partially inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes explaining the 'golden minute', when does he announce the end of the lecture?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1090.0,
        "end": 1094.0
      },
      "pred_interval": {
        "start": 58.5,
        "end": 70.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1031.5,
        "end": 1024.0,
        "average": 1027.75
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.09091342985630035,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction does not provide the required timing information and replaces precise timestamps with unrelated content (a patient consultation example), omitting key factual elements about the anchor/target times and sequence; therefore it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "While Raquel is talking about the hospital providing opportunities for nurses, when is she shown smiling and opening a package?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 2.0,
        "end": 4.5
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.2,
        "end": 32.1,
        "average": 17.650000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.36923076923076925,
        "text_similarity": 0.710332453250885,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps and relation contradict the reference: the correct visual event occurs at 2.0\u20134.5s during the speech (0.031\u20135.0s), whereas the prediction gives 35.0\u201336.6s and labels it 'after', so it is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria finishes saying that new nurses will be nudged to become lifelong learners, when does Precious state that the teamwork is strong?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 14.321,
        "end": 16.486
      },
      "pred_interval": {
        "start": 35.0,
        "end": 47.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.679000000000002,
        "end": 30.913999999999998,
        "average": 25.7965
      },
      "rationale_metrics": {
        "rouge_l": 0.31746031746031744,
        "text_similarity": 0.6104460954666138,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives entirely different timestamps and speaker cues that contradict the ground truth timings and durations; the only minor match is stating the target comes after the anchor, so it is mostly incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After Reny states that the hospital does things up to a magnet level, when does Raquel say her values align with the hospital's values?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 42.854,
        "end": 50.692
      },
      "pred_interval": {
        "start": 45.6,
        "end": 53.0
      },
      "iou": 0.5018726591760297,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.746000000000002,
        "end": 2.308,
        "average": 2.527000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2535211267605634,
        "text_similarity": 0.5069393515586853,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives substantially different and incorrect timestamps and misidentifies the anchor/target boundaries; it only correctly captures the relative 'after' relationship but not the accurate times."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that healthcare in Siem Reap is not the best, when is the Royal Angkor International Hospital first shown on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 94.0,
        "end": 99.1
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 88.8,
        "end": 62.49999999999999,
        "average": 75.64999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.19444444444444442,
        "text_similarity": 0.6010741591453552,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is fundamentally incorrect: it gives entirely different timestamps and event descriptions that do not match the reference (E1 at 82.215s and E2 at 94.0s/99.100s), misidentifying the events and durations."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he begin describing the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 180.289,
        "end": 185.074
      },
      "pred_interval": {
        "start": 35.0,
        "end": 48.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 145.289,
        "end": 136.674,
        "average": 140.98149999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.11428571428571428,
        "text_similarity": 0.45257657766342163,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives entirely different timestamps and event descriptions that do not match the reference (165.611s to 180.289\u2013185.074s) and thus contradicts the correct timing and content."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he visited a clinic for chest congestion, when does he mention the Paschern Dental Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 209.8,
        "end": 211.4
      },
      "pred_interval": {
        "start": 150.0,
        "end": 210.0
      },
      "iou": 0.0032573289902278276,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.80000000000001,
        "end": 1.4000000000000057,
        "average": 30.60000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705885,
        "text_similarity": 0.5831872224807739,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the Paschern Dental Clinic is mentioned after the chest-congestion clinic), but it omits the specific time spans/timestamps and detailed event annotations provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he introduce the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.0,
        "end": 184.8
      },
      "pred_interval": {
        "start": 210.0,
        "end": 360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.0,
        "end": 175.2,
        "average": 100.6
      },
      "rationale_metrics": {
        "rouge_l": 0.30434782608695654,
        "text_similarity": 0.5096081495285034,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the clinic is introduced after Neak Tep Hospital) but omits the key factual details\u2014specific timestamps (182.0s and 184.0\u2013184.8s) and the required timing information from the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker introduces the Cigna International Health Policy, when is the insurance quote form displayed with personal information?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 360.0,
        "end": 570.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.0,
        "end": 210.0,
        "average": 109.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1923076923076923,
        "text_similarity": 0.6407079696655273,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys that the form appears after the Cigna policy is introduced, matching the relation, but it omits the specific timestamps (350.0\u2013352.8s and 351.0\u2013360.0s) and the explicit 'once_finished' timing detail."
      }
    },
    {
      "question_id": "002",
      "question": "After the voiceover states that the Cigna policy is \"fairly typical of policies of this type\", when does the Cigna website display the form for inputting personal details to get a quote?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 352.9,
        "end": 358.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 456.0
      },
      "iou": 0.04047619047619066,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.899999999999977,
        "end": 98.0,
        "average": 60.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290322,
        "text_similarity": 0.4891699552536011,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the form appears after the voiceover (matches the anchor relationship) but omits the key temporal details (exact start time 352.9s, end 358.0s and anchor at 351.0s), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the voiceover mentions \"evacuation service, also part of Cigna plan\", when is the Global Rescue website displayed on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 384.0,
        "end": 431.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 456.0
      },
      "iou": 0.373015873015873,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.0,
        "end": 25.0,
        "average": 39.5
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413793,
        "text_similarity": 0.6910871863365173,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the website appears after the voiceover, but it omits all key factual details from the reference (exact timestamps, the 384.0s appearance, the scroll and display until 431.0s, and the anchor/target timing)."
      }
    },
    {
      "question_id": "001",
      "question": "After the host concludes his introduction about the fight in modern healthcare, when does he introduce Sarah?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 19.4,
        "end": 22.0
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.08280254777070067,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.2,
        "end": 14.600000000000001,
        "average": 14.4
      },
      "rationale_metrics": {
        "rouge_l": 0.25396825396825395,
        "text_similarity": 0.7138630151748657,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gets the temporal relation right but misidentifies and mis-times both events (wrong start/end times and event descriptions), so it fails to match the key factual elements of the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While Sarah is introducing herself and her genetic condition, when does she mention having her very first surgery?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.08,
        "end": 108.8
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 69.08,
        "end": 72.19999999999999,
        "average": 70.63999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.21875,
        "text_similarity": 0.6257012486457825,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect \u2014 it gives wrong timestamps, the wrong speaker/events, and a different relation ('because') versus the reference which places the events at ~95\u2013108s with relation='during'."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sarah finishes describing her role as a volunteer patient representative for a non-profit organization, when does the static image showing her behind a 'CHILDREN'S TUMOR FOUNDATION' table appear?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 185.0,
        "end": 190.0
      },
      "pred_interval": {
        "start": 150.0,
        "end": 360.0
      },
      "iou": 0.023809523809523808,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.0,
        "end": 170.0,
        "average": 102.5
      },
      "rationale_metrics": {
        "rouge_l": 0.20689655172413793,
        "text_similarity": 0.4559486508369446,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states a static image follows Sarah's description and describes the image content, but it omits the crucial timing details (E1 at 150s and E2 from 185\u2013190s) and the immediate-follow relationship specified in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes explaining the purpose of the 'Shine a Light Walk' to raise money and awareness, when does the video clip showing children running at an outdoor event play?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 189.0,
        "end": 192.0
      },
      "pred_interval": {
        "start": 150.0,
        "end": 360.0
      },
      "iou": 0.014285714285714285,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 168.0,
        "average": 103.5
      },
      "rationale_metrics": {
        "rouge_l": 0.16216216216216214,
        "text_similarity": 0.38568034768104553,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction fails to identify the correct clip (children running) and provides no timestamps; it only vaguely states the clip occurs after Sarah finishes, so it is mostly incorrect and incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once Steve asks if the 'Shine a Light Walk' goes throughout the world, when does Sarah begin to explain that the walks do not?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 253.2,
        "end": 258.88
      },
      "pred_interval": {
        "start": 150.0,
        "end": 360.0
      },
      "iou": 0.02704761904761908,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 103.19999999999999,
        "end": 101.12,
        "average": 102.16
      },
      "rationale_metrics": {
        "rouge_l": 0.12345679012345678,
        "text_similarity": 0.2121294140815735,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to answer the timing question and provides irrelevant, possibly incorrect details instead of the required timestamps; it does not state when Sarah begins her immediate response to Steve."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes asking Sarah what things in miscommunication can lead to delays or misdiagnosis, when does the woman start responding?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 362.48,
        "end": 365.44
      },
      "pred_interval": {
        "start": 330.0,
        "end": 540.0
      },
      "iou": 0.014095238095237998,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.48000000000002,
        "end": 174.56,
        "average": 103.52000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.11363636363636363,
        "text_similarity": 0.24923256039619446,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to provide the timing information or 'once_finished' relation in the reference, misstates speaker roles (saying the man responds rather than the woman), and adds irrelevant/hallucinated background detail."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman gives the example of writing 'hyperthyroid instead of hypothyroid', when does the man respond with 'That that's pretty bad'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 389.2,
        "end": 432.5
      },
      "pred_interval": {
        "start": 330.0,
        "end": 540.0
      },
      "iou": 0.20619047619047626,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.19999999999999,
        "end": 107.5,
        "average": 83.35
      },
      "rationale_metrics": {
        "rouge_l": 0.13186813186813187,
        "text_similarity": 0.2791777551174164,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction describes the exchange but provides no timing or the required 'after' relation from the correct answer and adds irrelevant visual detail (bookcase), omitting the key factual timestamps\u2014thus failing to answer when."
      }
    },
    {
      "question_id": "003",
      "question": "After the man says he tried researching miscommunication problems, when does he state his finding about thousands of preventable deaths?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 446.56,
        "end": 535.68
      },
      "pred_interval": {
        "start": 330.0,
        "end": 540.0
      },
      "iou": 0.42438095238095214,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 116.56,
        "end": 4.32000000000005,
        "average": 60.440000000000026
      },
      "rationale_metrics": {
        "rouge_l": 0.06382978723404256,
        "text_similarity": 0.19469845294952393,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer fails to address the asked timing or mention the man's finding about thousands of preventable deaths; it only gives a general scene description and unrelated dialogue, so it does not match the reference timestamps or content."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks, \"What's in my budget to fix it?\", when does she start asking, \"How important is it to me to fix this issue?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 518.66,
        "end": 522.26
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 513.4599999999999,
        "end": 485.65999999999997,
        "average": 499.55999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.28125,
        "text_similarity": 0.6585016250610352,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer's timestamps and quoted utterances do not match the ground truth (both anchor and target times and content are incorrect); only the temporal relation ('after') coincidentally matches, so the prediction is largely wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the man finishes saying, \"not continuing medical bills,\" when does he start asking, \"So, what does successful self-advocacy look like?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 643.04,
        "end": 646.32
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 608.04,
        "end": 609.72,
        "average": 608.88
      },
      "rationale_metrics": {
        "rouge_l": 0.23880597014925375,
        "text_similarity": 0.714682936668396,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives completely different timestamps and incorrect utterances for both anchor and target (mentions a speaker intro and 'I am a final year medical student' rather than the question about self-advocacy); only the generic temporal relation 'after' matches, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining what a doctor's follow-up might entail, when does the woman start asking, \"Or will I actually be able to get into your office in two weeks?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 679.0,
        "end": 683.92
      },
      "pred_interval": {
        "start": 36.6,
        "end": 48.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 642.4,
        "end": 635.92,
        "average": 639.16
      },
      "rationale_metrics": {
        "rouge_l": 0.21538461538461537,
        "text_similarity": 0.6693563461303711,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives entirely different timestamps and wrong segment content/speakers compared to the reference (predicted ~5\u201336s vs correct ~678\u2013684s), so it is incorrect; only the vague relation 'after' matches. "
      }
    },
    {
      "question_id": "001",
      "question": "Immediately after the woman asks if she should follow up if she is still experiencing symptoms, when does the man ask what if the symptoms go away?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.38,
        "end": 707.15
      },
      "pred_interval": {
        "start": 690.0,
        "end": 735.0
      },
      "iou": 0.17266666666666627,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.379999999999995,
        "end": 27.850000000000023,
        "average": 18.61500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.28125,
        "text_similarity": 0.38294053077697754,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that the man's question follows the woman's, but it omits the key factual details and precise timing (the events and timestamps and that the target immediately follows the anchor) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying to voice symptoms and concerns clearly, when does he give an example about shoulder pain?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 734.59,
        "end": 737.0
      },
      "pred_interval": {
        "start": 735.0,
        "end": 840.0
      },
      "iou": 0.018973531922967465,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.40999999999996817,
        "end": 103.0,
        "average": 51.704999999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.3679908514022827,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the specific timing given in the reference (start/end timestamps and that the target immediately follows the anchor); it also adds an unsupported detail about the woman's agreement, so it fails to match the key factual elements."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes warning not to try putting a hand in an electrical outlet, when does the woman agree and say not to try that?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 810.0,
        "end": 812.0
      },
      "pred_interval": {
        "start": 840.0,
        "end": 900.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.0,
        "end": 88.0,
        "average": 59.0
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298245,
        "text_similarity": 0.1948869526386261,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the woman speaks after the man, but it omits the precise timing (808s, 810\u2013812s) and the note that the target immediately follows the anchor, so key factual details are missing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes saying to assume benevolence of your doctor, when does the man begin to speak?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.9,
        "end": 879.1
      },
      "pred_interval": {
        "start": 870.0,
        "end": 1080.0
      },
      "iou": 0.0009523809523811689,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.899999999999977,
        "end": 200.89999999999998,
        "average": 104.89999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.14583333333333331,
        "text_similarity": 0.35681748390197754,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to provide the required timing or the 'once_finished' relation and instead offers unrelated scene description and unverified dialogue details, omitting the key factual timestamps from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks about trying non-surgical options first, when does the woman reply 'Yes'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 899.7,
        "end": 900.1
      },
      "pred_interval": {
        "start": 1080.0,
        "end": 1290.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 180.29999999999995,
        "end": 389.9,
        "average": 285.09999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.11382113821138211,
        "text_similarity": 0.3712892234325409,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction fails to provide the required timing relation and specific timestamps; it only paraphrases the interaction and introduces unsupported details (second opinions, scene cuts), so it does not match the correct, time-based answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the man concludes his statement about how to ask for another opinion, when does the woman respond that asking for another opinion is definitely valid?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 982.0,
        "end": 988.72
      },
      "pred_interval": {
        "start": 1290.0,
        "end": 1500.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 308.0,
        "end": 511.28,
        "average": 409.64
      },
      "rationale_metrics": {
        "rouge_l": 0.05555555555555555,
        "text_similarity": 0.3069751560688019,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction fails to provide the required timing information or the specified temporal relation; it gives a vague scene description rather than the precise timestamps and 'after' relation requested."
      }
    },
    {
      "question_id": "001",
      "question": "After the man suggests bringing someone along if you're not feeling safe, when does the woman agree that it's advisable?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1127.0,
        "end": 1130.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.014285714285714285,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 77.0,
        "end": 130.0,
        "average": 103.5
      },
      "rationale_metrics": {
        "rouge_l": 0.25925925925925924,
        "text_similarity": 0.43842488527297974,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the semantic content (man suggests bringing someone; woman agrees) but omits the crucial temporal details and event timestamps specified in the correct answer, making it incomplete for the task."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman talks about a doctor not trusting a patient's pain because they don't act like they're in pain, when does she give an example of a loved one vouching for the patient?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1167.68,
        "end": 1174.48
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.03238095238095216,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 117.68000000000006,
        "end": 85.51999999999998,
        "average": 101.60000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.555921196937561,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that she gives an example but fails to provide the requested timing details (1167.68\u20131174.48), omitting the key factual element of when this occurs."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks if it is legal to be given your own medical records, when does the woman confirm that it is?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1268.6,
        "end": 1270.7
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.010000000000000649,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.59999999999991,
        "end": 169.29999999999995,
        "average": 103.94999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.06752678751945496,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that the woman's confirmation follows the man's question, but it omits the specific timestamps and the E1/E2 alignment given in the reference, which are key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman mentions that things have changed a lot with electronic medical records, when does the man state that bureaucracy reminds him of common barriers?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1333.0,
        "end": 1339.5
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.030952380952380953,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 103.0,
        "end": 100.5,
        "average": 101.75
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290325,
        "text_similarity": 0.28382283449172974,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relative ordering (the man's remark occurs after the woman's comment) but omits the key specifics from the reference\u2014exact timestamps and the note that it occurs significantly later\u2014making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks about common barriers and how to overcome them, when does the woman share her fear of ants?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.36,
        "end": 1383.7
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.030190476190476885,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 147.3599999999999,
        "end": 56.299999999999955,
        "average": 101.82999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.326530612244898,
        "text_similarity": 0.2614273428916931,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction accurately states that the woman shares her fear after the man asks about barriers, matching the correct answer's relative timing and intent; no factual contradictions or extraneous details are introduced."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says to write things down on paper and give it to the doctor, when does he mention a doctor refusing to look at the paper?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1484.96,
        "end": 1490.0
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1620.0
      },
      "iou": 0.023999999999999827,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.96000000000004,
        "end": 130.0,
        "average": 102.48000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.14906832298136646,
        "text_similarity": 0.1430048644542694,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer does not address the asked utterances or timing and instead describes unrelated events (a call glitch and emotional reaction), so it fails to match the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the woman discusses prioritizing cognition, when does she state that she would rather be in pain than have her mental capacity harmed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1534.64,
        "end": 1542.24
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1620.0
      },
      "iou": 0.03619047619047576,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 124.6400000000001,
        "end": 77.75999999999999,
        "average": 101.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.07643312101910828,
        "text_similarity": 0.14129216969013214,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated to the question: it provides a narrative scene that omits the required anchor/target timestamps and the quoted statement, and includes irrelevant/hallucinated details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'Nord, what is that?', when does the woman state what NORD stands for?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.4,
        "end": 1615.4
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1800.0
      },
      "iou": 0.009523809523809525,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.40000000000009,
        "end": 184.5999999999999,
        "average": 104.0
      },
      "rationale_metrics": {
        "rouge_l": 0.13793103448275862,
        "text_similarity": 0.5535197854042053,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction fails to state when the woman gives the answer or what she says; it is vague and does not match the reference which specifies the exact response ('National Organization for Rare Disease') and timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says 'I read that I need to start this at 30', when does she explain why she needs the doctor to order it?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1692.24,
        "end": 1711.28
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1800.0
      },
      "iou": 0.09066666666666649,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 102.24000000000001,
        "end": 88.72000000000003,
        "average": 95.48000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.18666666666666668,
        "text_similarity": 0.39332571625709534,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and does not provide the timing or content the reference specifies; it only notes that a question precedes an explanation rather than identifying when the woman explains why she needs the doctor to order it (the explicit time interval and continuation of her advocacy example)."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman explains how to mirror a planned course of action, when does she suggest asking the doctor what they heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.0,
        "end": 1799.8
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1791.8,
        "end": 1763.2,
        "average": 1777.5
      },
      "rationale_metrics": {
        "rouge_l": 0.0923076923076923,
        "text_similarity": 0.09001074731349945,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction is vague and omits the key detail that the target follows the anchor after a brief explanation about miscommunication; it also adds an unstated claim that it occurs when the man begins to respond and omits the provided timestamps, so it does not align with the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the man advises to 'just dig' and not use a medical dictionary, when does he ask if medical language can be 'dumbed down'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1836.56,
        "end": 1841.52
      },
      "pred_interval": {
        "start": 148.5,
        "end": 208.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1688.06,
        "end": 1633.12,
        "average": 1660.59
      },
      "rationale_metrics": {
        "rouge_l": 0.05714285714285714,
        "text_similarity": -0.07352802157402039,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates the event but omits the required precise timing (1812.5\u20131816.0 and 1836.560\u20131841.520) and key temporal sequencing; it is vague and fails to provide the factual timestamps requested."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks what to do when doctors look rushed, when does the woman describe slowing down and capturing their attention?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1965.6,
        "end": 1973.5
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1960.3999999999999,
        "end": 1936.9,
        "average": 1948.65
      },
      "rationale_metrics": {
        "rouge_l": 0.20289855072463767,
        "text_similarity": 0.4944531321525574,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer identifies completely different anchor and target events and inaccurate timestamps, only matching the temporal relation ('after'); it therefore fails to match the key events and times in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes suggesting a doctor might be having a bad day, when does the man humorously ask if doctors have bad days?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2002.5,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 184.5,
        "end": 208.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1818.0,
        "end": 1795.5,
        "average": 1806.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2285714285714286,
        "text_similarity": 0.6020007133483887,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer's time spans are largely inconsistent with the ground truth (orders of magnitude different) and the anchor/target boundaries do not match; it also fails to show the immediate adjacency (predicted only says 'after'), so it does not capture the key factual timing relationship."
      }
    },
    {
      "question_id": "001",
      "question": "After the man introduces the 'five practical tips to advocate for yourself', when does the woman begin talking about writing down questions?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2195.28,
        "end": 2199.7
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.02104761904761723,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.2800000000002,
        "end": 140.30000000000018,
        "average": 102.79000000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.1263157894736842,
        "text_similarity": 0.15561296045780182,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the temporal relationship (the woman speaks after the man) but omits the required timestamps and mischaracterizes the anchor content (mentions preparing for a meeting instead of the 'five practical tips'), and includes irrelevant scene details."
      }
    },
    {
      "question_id": "002",
      "question": "During the man's explanation about preparing beforehand, when does he demonstrate by pointing to his neck?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.0,
        "end": 2237.0
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.009523809523809525,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 105.0,
        "end": 103.0,
        "average": 104.0
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.3531654179096222,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly states the pointing occurs after he finishes explaining, whereas the ground truth specifies the point to the neck happens during his explanation (2235\u20132237s); it also adds unrelated, potentially hallucinated scene details."
      }
    },
    {
      "question_id": "001",
      "question": "After the man describes getting dizzy when walking up and down stairs, when does the woman mention repeating back what was heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2316.0,
        "end": 2317.0
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2520.0
      },
      "iou": 0.004761904761904762,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 203.0,
        "average": 104.5
      },
      "rationale_metrics": {
        "rouge_l": 0.13333333333333333,
        "text_similarity": 0.4498963952064514,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the key temporal relation ('after') between the events and does not introduce errors, but it omits the precise timestamps and event labels provided in the reference, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman expresses her inability to distract herself from the pain, when does the man advise her to be specific?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.7,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2520.0
      },
      "iou": 0.0038095238095246756,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.69999999999982,
        "end": 150.5,
        "average": 104.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.19607843137254902,
        "text_similarity": 0.39475157856941223,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the 'after' relation between the two events, but it omits the specific timing information (the provided timestamps and event labels), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says 'document everything', when does the woman affirm the advice and tell viewers to take notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2504.5,
        "end": 2506.0
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2700.0
      },
      "iou": 0.007142857142857143,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.5,
        "end": 194.0,
        "average": 104.25
      },
      "rationale_metrics": {
        "rouge_l": 0.04347826086956522,
        "text_similarity": 0.25608211755752563,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and incorrect: it gives no timing, omits the specific utterance, and mischaracterizes the interaction (the man said 'document everything' rather than asking a question), so it fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes asking if one should ask permission before recording their doctor, when does the woman respond?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2531.6,
        "end": 2533.5
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2700.0
      },
      "iou": 0.009047619047619481,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 41.59999999999991,
        "end": 166.5,
        "average": 104.04999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.382756769657135,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction is factually correct in sequence (the woman responds after the man), but it omits the key timing details and explicit timestamps provided in the correct answer, so it is incomplete for the required precision."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman begins explaining the hope that doctors will focus more on patients with AI recording, when does she explain why she almost always checks her online appointment notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.0,
        "end": 2579.0
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2700.0
      },
      "iou": 0.06190476190476191,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.0,
        "end": 121.0,
        "average": 98.5
      },
      "rationale_metrics": {
        "rouge_l": 0.15625,
        "text_similarity": 0.4169825613498688,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction wrongly anchors her explanation to the man's question about permission to record rather than the timeline given in the reference (she explains checking online notes ~10s after beginning the AI/notes comment). It fails to match the specified timestamps and introduces an unrelated event."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks if one should be assertive, when does he introduce the topic of emotional intelligence?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2701.0,
        "end": 2710.0
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2880.0
      },
      "iou": 0.04285714285714286,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.0,
        "end": 170.0,
        "average": 100.5
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333334,
        "text_similarity": 0.7126544713973999,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is overly vague and omits the key timing details and the short-pause relationship; it also adds an unsupported claim about the woman speaking, though it correctly notes the topic is introduced later."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man says 'You wanna learn some breathing control', when does he start describing box breathing?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.0,
        "end": 2747.0
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2880.0
      },
      "iou": 0.03333333333333333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.0,
        "end": 133.0,
        "average": 101.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1492537313432836,
        "text_similarity": 0.5295143723487854,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction fails to provide the timestamps or the correct temporal relation (starts at 2740.0s right after 2735.0s) and instead introduces an unrelated phrase ('boss of one's body') and a visual gesture cue that are not in the reference, so it does not match the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "While the man is saying 'If you want, share your story in the comments', when is the 'COMMENT BELOW' graphic displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 2992.0
      },
      "iou": 0.02112676056338028,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.0,
        "end": 69.0,
        "average": 69.5
      },
      "rationale_metrics": {
        "rouge_l": 0.125,
        "text_similarity": 0.5715488791465759,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the ground truth temporal relation\u2014correct answer states the graphic is displayed continuously during the man's speech (overlap), while the prediction says the graphic appears 'after'. It also adds unrelated/hallucinated visual details not supported by the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After Marissa Fourie introduces herself, when does she mention cross-cultural communication?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 34.2,
        "end": 36.5
      },
      "pred_interval": {
        "start": 23.4,
        "end": 39.8
      },
      "iou": 0.14024390243902424,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.800000000000004,
        "end": 3.299999999999997,
        "average": 7.050000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.380952380952381,
        "text_similarity": 0.6563621759414673,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is largely incorrect: it hallucinates an extra mention (23.4s) that does not match the ground-truth event (34.2\u201336.5s) and gives a second timestamp (39.8s) outside the correct interval; only the general 'after' relation is preserved."
      }
    },
    {
      "question_id": "002",
      "question": "After mentioning cross-cultural communication, when does Marissa Fourie next mention personality-specific communication skills?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 37.0,
        "end": 39.0
      },
      "pred_interval": {
        "start": 56.4,
        "end": 68.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.4,
        "end": 29.400000000000006,
        "average": 24.400000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.36,
        "text_similarity": 0.6019230484962463,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction references the correct topic but gives a completely different time interval (56.4\u201368.4s) than the ground truth (37.0\u201339.0s), so it is factually incorrect about when the next mention occurs."
      }
    },
    {
      "question_id": "003",
      "question": "After encouraging viewers to join PhysioPlus, when does Marissa Fourie say 'See you there!'?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 62.9,
        "end": 63.7
      },
      "pred_interval": {
        "start": 68.4,
        "end": 71.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.500000000000007,
        "end": 8.099999999999994,
        "average": 6.800000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.24000000000000005,
        "text_similarity": 0.5111135244369507,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the phrase occurs after earlier content, but the provided timestamps (68.4s and 71.8s) do not match the ground truth (62.9\u201363.7s), it omits the correct earlier prompt ('So, join me on PhysioPlus' at 48.6s) and adds an incorrect extra occurrence."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes mentioning \"the dosage in each area\", when does the woman in blue gloves point to the glabella area of the patient's forehead?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 4.469,
        "end": 4.8
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.7309999999999999,
        "end": 31.8,
        "average": 16.2655
      },
      "rationale_metrics": {
        "rouge_l": 0.2592592592592593,
        "text_similarity": 0.4006865918636322,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the ordering (the woman points after the speaker) but omits all required timestamps and the pointer visibility duration, thus missing key factual details from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the dosage for the brow lift, when does the woman in blue gloves point to the patient's upper lip?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 12.121,
        "end": 12.5
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.878999999999998,
        "end": 24.1,
        "average": 23.4895
      },
      "rationale_metrics": {
        "rouge_l": 0.32142857142857145,
        "text_similarity": 0.5169327259063721,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the sequence (she points after the speaker finishes) but omits all precise timestamps and the pointer visibility duration specified in the ground truth, making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the dosage for the lip flip, when does the text \"TIME TO INJECT!\" appear on screen?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 18.291,
        "end": 21.0
      },
      "pred_interval": {
        "start": 36.6,
        "end": 41.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.309,
        "end": 20.799999999999997,
        "average": 19.554499999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.28,
        "text_similarity": 0.5125731825828552,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the causal relation (the text appears after the explanation) but omits the key factual details\u2014the specific timestamps (15.067s and 18.291s) and that the text remains until the end\u2014so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host welcomes Rich, when does Rich begin his response?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 33.015,
        "end": 34.078
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.03385350318471345,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.815,
        "end": 2.5219999999999985,
        "average": 15.1685
      },
      "rationale_metrics": {
        "rouge_l": 0.16666666666666666,
        "text_similarity": 0.5387439727783203,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys that Rich speaks after the host's introduction, but it omits the key factual details\u2014specific timestamps (31.333s and 33.015s) and that Rich's response immediately follows the anchor's completion."
      }
    },
    {
      "question_id": "002",
      "question": "While Rich is explaining how medicine may have let relationships with patients deteriorate, when does he say that scientific facts will protect us?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 89.0,
        "end": 93.76
      },
      "pred_interval": {
        "start": 35.0,
        "end": 47.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.0,
        "end": 46.36000000000001,
        "average": 50.18000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.043478260869565216,
        "text_similarity": 0.14876948297023773,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the relative ordering (the phrase comes after that discussion) but omits the key factual details requested\u2014specifically the timestamps (E1 start at 73.611s and the phrase at 89.0\u201393.760s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks what trust looks like in the future with intermediaries, when does Rich first discuss the stethoscope in relation to technology in medicine?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 112.0,
        "end": 113.0
      },
      "pred_interval": {
        "start": 81.9,
        "end": 109.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.099999999999994,
        "end": 3.200000000000003,
        "average": 16.65
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.3404194414615631,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that Rich discusses the stethoscope after the host's question (matching the relative ordering), but it omits the key factual details of the exact timestamps provided in the reference (106.718s and 112.700s)."
      }
    },
    {
      "question_id": "001",
      "question": "After the man in glasses finishes describing the giant TV screen in a new hospital exam room, when does the video show a patient interacting with a screen in a hospital bed?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 167.6,
        "end": 177.6
      },
      "pred_interval": {
        "start": 150.0,
        "end": 228.0
      },
      "iou": 0.1282051282051282,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.599999999999994,
        "end": 50.400000000000006,
        "average": 34.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.4540618062019348,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states that the patient interaction occurs after the man in glasses finishes, but it omits the key temporal details (the anchor ending at 152.8s and the target spanning 167.6\u2013177.6s) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "While the interviewer asks if technology can bring doctors and patients closer together, when is he holding a small white 'Trust tv' card?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 178.0,
        "end": 183.5
      },
      "pred_interval": {
        "start": 183.6,
        "end": 228.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.599999999999994,
        "end": 44.5,
        "average": 25.049999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.12698412698412698,
        "text_similarity": 0.29298439621925354,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states he is holding the card while asking, but it omits the key temporal information (178.0s\u2013183.5s) and the explicit anchor/target alignment required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the interviewer thanks Rich and says viewers learned a lot, when does Rich respond 'It's really a pleasure'?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 210.3,
        "end": 212.1
      },
      "pred_interval": {
        "start": 228.0,
        "end": 228.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.69999999999999,
        "end": 15.900000000000006,
        "average": 16.799999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2580645161290322,
        "text_similarity": 0.48099231719970703,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states that Rich speaks after the interviewer thanks him and says viewers learned a lot, but it omits the key temporal details from the reference (the immediate follow and the exact timestamps 210.3s\u2013212.1s), making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions learning about 'patient rapport', when does he discuss charting and interacting with other healthcare providers?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 2.075,
        "end": 9.55
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.12599565532223028,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.125,
        "end": 27.05,
        "average": 15.0875
      },
      "rationale_metrics": {
        "rouge_l": 0.40740740740740744,
        "text_similarity": 0.6751091480255127,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates that discussion of charting follows patient rapport, but it omits the specific timestamps (0.031\u20131.734s and 2.075\u20139.550s) and the explicit 'once_finished' relation, making it incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker talks about developing skills like putting an IV, when does he mention getting a patient discharged?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 15.42,
        "end": 24.583
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.58,
        "end": 12.017000000000003,
        "average": 15.7985
      },
      "rationale_metrics": {
        "rouge_l": 0.27692307692307694,
        "text_similarity": 0.43951931595802307,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures that discharge is mentioned after the IV comment, but it omits the specific timestamps and the explicit 'once_finished' (immediately follows) relation given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Make their problem, your problem', when does he introduce the importance of self-care?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 45.009,
        "end": 48.396
      },
      "pred_interval": {
        "start": 43.8,
        "end": 59.4
      },
      "iou": 0.21711538461538463,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2090000000000032,
        "end": 11.003999999999998,
        "average": 6.1065000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.27692307692307694,
        "text_similarity": 0.616675853729248,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies that the importance of self-care is introduced after the 'Make their problem, your problem' remark, but it omits the specific timestamps and the quoted follow-up line provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker's introduction of herself, when does she mention specializing in wounds?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.605,
        "end": 26.329
      },
      "pred_interval": {
        "start": 2.5,
        "end": 4.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.105,
        "end": 21.529,
        "average": 20.817
      },
      "rationale_metrics": {
        "rouge_l": 0.24000000000000002,
        "text_similarity": 0.5786304473876953,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states she mentions specializing in wounds during her introduction, but it is vague and omits the specific timestamps (0:22.605\u20130:26.329) and the related name mention at 0:18.120, so it lacks key factual detail."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of 'getting the most out of your GP consultation', when does she mention that GP practices are getting a huge injection of funding?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.82,
        "end": 75.533
      },
      "pred_interval": {
        "start": 6.3,
        "end": 10.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.519999999999996,
        "end": 64.733,
        "average": 63.1265
      },
      "rationale_metrics": {
        "rouge_l": 0.2608695652173913,
        "text_similarity": 0.5065481066703796,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the relative order (the funding mention occurs after the topic introduction), but it omits the specific timestamps and precise timing details given in the reference answer."
      }
    },
    {
      "question_id": "003",
      "question": "While the slide titled 'Appointments are precious' is on screen, when does the speaker mention that GP practices are moving back towards face-to-face appointments?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 123.0,
        "end": 129.0
      },
      "pred_interval": {
        "start": 12.6,
        "end": 15.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 110.4,
        "end": 113.2,
        "average": 111.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.53125,
        "text_similarity": 0.8228057026863098,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the speaker mentions GP practices moving back to face-to-face appointments while the slide is on screen, but it fails to provide the required timing details (123.0\u2013129.0) and the slide onset timestamp, omitting key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that GP practices are very different places now, when does she begin listing the specific roles in a GP practice?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.0,
        "end": 204.0
      },
      "pred_interval": {
        "start": 150.0,
        "end": 210.0
      },
      "iou": 0.016666666666666666,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 53.0,
        "end": 6.0,
        "average": 29.5
      },
      "rationale_metrics": {
        "rouge_l": 0.24137931034482757,
        "text_similarity": 0.533011257648468,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the listing occurs after the remark), but it omits crucial factual details from the reference such as the precise timing (starts at 203.0s, spans 203.0\u2013204.0s) and that the list begins with 'GP's'."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide displays the question 'Does it need to be a GP?', when does the speaker mention that paramedics work in primary care?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "pred_interval": {
        "start": 210.0,
        "end": 280.0
      },
      "iou": 0.07142857142857142,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.0,
        "end": 40.0,
        "average": 32.5
      },
      "rationale_metrics": {
        "rouge_l": 0.27118644067796616,
        "text_similarity": 0.581807017326355,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the relative relation (the speaker's remark occurs after the slide), but it omits the key factual details from the reference\u2014specifically the exact timestamps and the quoted time interval of the speaker's remark\u2014making it incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker talks about paramedics working in primary care, when does she begin to explain the role of Advanced Clinical Practitioners?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 241.0,
        "end": 249.0
      },
      "pred_interval": {
        "start": 280.0,
        "end": 360.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 111.0,
        "average": 75.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2608695652173913,
        "text_similarity": 0.4659784436225891,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the discussion of Advanced Clinical Practitioners occurs after the paramedics remark, but it omits the requested timing details (start time ~241.0s and end ~249.0s) and thus fails to answer the 'when' component."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the problem of a wound on your foot, when does she strongly advise mentioning if you are diabetic?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 337.875,
        "end": 343.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 480.0
      },
      "iou": 0.034166666666666665,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.875,
        "end": 137.0,
        "average": 72.4375
      },
      "rationale_metrics": {
        "rouge_l": 0.13793103448275862,
        "text_similarity": 0.0304306298494339,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction says the advice comes 'after 10 seconds,' which contradicts the reference showing the advice immediately follows the problem introduction (target begins ~0.6\u20132.7s after the anchor); the timing is therefore incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having a new wound on your leg, when does she suggest going to a local pharmacist for simple dressings?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 363.968,
        "end": 366.552
      },
      "pred_interval": {
        "start": 480.0,
        "end": 690.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 116.03199999999998,
        "end": 323.448,
        "average": 219.73999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.12698412698412698,
        "text_similarity": 0.25933927297592163,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the pharmacist advice follows the wound discussion, but the timestamp is incorrect (21s vs the correct ~34\u201336.6s) and it omits the note that this advice comes after discussing nurse appointments, so it is largely inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker explains that a nurse's appointment is needed for long-standing wounds, when does she advise to clearly state how long the wound has been there?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 409.579,
        "end": 439.62
      },
      "pred_interval": {
        "start": 690.0,
        "end": 900.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 280.421,
        "end": 460.38,
        "average": 370.40049999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.08823529411764706,
        "text_similarity": 0.35790956020355225,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect: the reference states the advice follows immediately after the nurse-appointment comment (with specific timestamps), whereas the prediction falsely asserts a 30-second delay and introduces an unsupported detail."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if you feel more short of breath, when does she state that a GP or nurse practitioner might be needed the same day?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 522.783,
        "end": 525.113
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 517.583,
        "end": 488.51300000000003,
        "average": 503.048
      },
      "rationale_metrics": {
        "rouge_l": 0.06557377049180328,
        "text_similarity": 0.028733300045132637,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction repeats that the speaker mentions needing a GP/nurse practitioner but fails to provide the requested timing or context (timestamps and that it follows discussion of new leg swelling), omitting key factual details from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to measure your ankle and calf, when does she give an example of a calf measurement that would 'perk up more interest'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.623,
        "end": 586.297
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 548.623,
        "end": 549.697,
        "average": 549.1600000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981132,
        "text_similarity": 0.17277628183364868,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the general content (speaker gives an example about calf measurement) but omits the required precise timing and segment details provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Photography', when does the speaker advise to 'expect to be asked for a photo'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 670.384,
        "end": 672.807
      },
      "pred_interval": {
        "start": 510.0,
        "end": 720.0
      },
      "iou": 0.011538095238095247,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 160.38400000000001,
        "end": 47.192999999999984,
        "average": 103.7885
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814817,
        "text_similarity": 0.2403181493282318,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that the speaker says to 'expect to be asked for a photo' but fails to provide the required timing information (the slide transition at ~650.676s and the utterance at 670.384\u2013672.807s), omitting key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions some GP practices use video consultations, when does she state that a good quality photograph is better than a video?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.278,
        "end": 717.251
      },
      "pred_interval": {
        "start": 690.0,
        "end": 738.4
      },
      "iou": 0.06142561983470987,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.27800000000002,
        "end": 21.149,
        "average": 22.71350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.29787234042553196,
        "text_similarity": 0.45178064703941345,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction references a slide change ('Photography tips') rather than providing the time or stating the event relative to the GP video-consultation mention; it fails to answer when (714.278s) and thus does not match the correct response."
      }
    },
    {
      "question_id": "002",
      "question": "Once the slide changes to 'Photography tips', when does the speaker begin discussing taking a close-up and further-away picture?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 738.601,
        "end": 740.91
      },
      "pred_interval": {
        "start": 738.4,
        "end": 848.4
      },
      "iou": 0.02099090909090881,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.20100000000002183,
        "end": 107.49000000000001,
        "average": 53.845500000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.6129405498504639,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction omits the required timestamps and incorrectly implies the discussion starts immediately with the slide change; the correct answer specifies the slide changes at 736.057s and the speaker begins at 738.601s (i.e., after the change)."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide changes to 'General top tips- face to face appointments', when does the speaker advise to 'Go suitably dressed'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 860.136,
        "end": 860.846
      },
      "pred_interval": {
        "start": 848.4,
        "end": 900.0
      },
      "iou": 0.013759689922481319,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.73599999999999,
        "end": 39.153999999999996,
        "average": 25.444999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.4810628294944763,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly conveys the qualitative relation ('after') but omits the key factual elements\u2014the specific timestamps for the slide change (805.957s) and the advice (860.136s)\u2014so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises not to wear tight socks, trousers, or wellies, when does she suggest wearing something with quick access to lower limbs?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.0,
        "end": 877.5
      },
      "pred_interval": {
        "start": 870.0,
        "end": 900.0
      },
      "iou": 0.15,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 22.5,
        "average": 12.75
      },
      "rationale_metrics": {
        "rouge_l": 0.09523809523809522,
        "text_similarity": 0.1787293702363968,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is unrelated and incorrect: it mentions chit-chat about the weather rather than the timing/relative relation of wearing easily accessible clothing after advising against tight clothes, and omits all required temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes advising not to make chit-chat about the weather, when does she advise not to dodge the real problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 893.0,
        "end": 894.5
      },
      "pred_interval": {
        "start": 900.0,
        "end": 930.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 35.5,
        "average": 21.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3555555555555555,
        "text_similarity": 0.30361512303352356,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction contradicts the reference and omits all timing and relation details; it incorrectly states the speaker finishes advising not to dodge the real problem instead of saying that advice occurs after the chit-chat warning."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker advises to take a list of the medications you are actually taking, when does she advise against describing tablets by their appearance?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 948.0,
        "end": 969.0
      },
      "pred_interval": {
        "start": 930.0,
        "end": 960.0
      },
      "iou": 0.3076923076923077,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.0,
        "end": 9.0,
        "average": 13.5
      },
      "rationale_metrics": {
        "rouge_l": 0.19607843137254902,
        "text_similarity": 0.5755571126937866,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction only restates that the speaker finishes advising to take a medication list and omits any information about when she advises against describing tablets by appearance or the time interval for that advice, so it fails to answer the question."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker advises speaking to the practice in advance about a relative, when does she explain the reason for this advance arrangement due to confidentiality?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1065.0,
        "end": 1095.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.14285714285714285,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.0,
        "end": 165.0,
        "average": 90.0
      },
      "rationale_metrics": {
        "rouge_l": 0.1851851851851852,
        "text_similarity": 0.48162132501602173,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the speaker first advises advance notice and then gives the confidentiality-based reason, but it omits the key temporal details (exact timestamps and the 'once_finished' relation mapping) specified in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker suggests writing things down before an appointment to help structure what you say, when does she first ask 'How did it start?' regarding the leg problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1130.415,
        "end": 1131.738
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.0063000000000004415,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 80.41499999999996,
        "end": 128.26199999999994,
        "average": 104.33849999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.2931068539619446,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the sequence (suggest writing then asking), but it omits the critical temporal details and the explicit 'once_finished' relation (timestamps and relative timing) present in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes advising to ask to be referred to a specialist service, when does she start introducing the referrals examples?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.105,
        "end": 1249.385
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.006095238095237965,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.105000000000018,
        "end": 190.615,
        "average": 104.36000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.13043478260869565,
        "text_similarity": 0.29049283266067505,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the sequence (introducing referrals after finishing advice) but omits the key factual timing details given in the reference (timestamps around 1248.105\u20131249.385) and thus fails to answer the 'when' specifically."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that lymphoedema services can be patchy, when does she first advise writing to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.0,
        "end": 1378.0
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.004761904761904762,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 147.0,
        "end": 62.0,
        "average": 104.5
      },
      "rationale_metrics": {
        "rouge_l": 0.35555555555555557,
        "text_similarity": 0.5873475074768066,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer simply restates the question and provides no timing information; it omits the key factual element (the timestamp ~1377\u20131378s) required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions that a GP will assess new leg swelling for onward referral, when does she explain there are many different causes?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1429.846,
        "end": 1432.0
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.01025714285714284,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 199.846,
        "end": 8.0,
        "average": 103.923
      },
      "rationale_metrics": {
        "rouge_l": 0.27692307692307694,
        "text_similarity": 0.7951297760009766,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the explanation occurs after the GP comment) but fails to provide the specific timing/timestamps (1429.846\u20131432.0) required by the reference, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what information you could take with you, when does she suggest looking up the National Wound Care Strategy Lower Limb Recommendations?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1465.0,
        "end": 1469.5
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1520.0
      },
      "iou": 0.04090909090909091,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.0,
        "end": 50.5,
        "average": 52.75
      },
      "rationale_metrics": {
        "rouge_l": 0.22580645161290322,
        "text_similarity": 0.19668439030647278,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys the order (the suggestion comes after the question) but fails to provide the key factual details from the reference\u2014namely the precise timestamps and explicit 'after' relation\u2014so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions escalating concerns to the practice manager, when does she mention escalating concerns to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.6,
        "end": 1525.7
      },
      "pred_interval": {
        "start": 1530.0,
        "end": 1620.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.400000000000091,
        "end": 94.29999999999995,
        "average": 50.35000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.5167158842086792,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly conveys the sequence (practice manager followed by MP) but omits the precise timestamps, duration boundaries, and the explicit 'next' temporal relation provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'I'll stop sharing', when does she start reading the first question from a viewer?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1574.5,
        "end": 1578.5
      },
      "pred_interval": {
        "start": 1630.0,
        "end": 1770.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.5,
        "end": 191.5,
        "average": 123.5
      },
      "rationale_metrics": {
        "rouge_l": 0.31578947368421056,
        "text_similarity": 0.5296622514724731,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the basic temporal ordering (reading follows the remark) but omits the precise timestamps and the explicit 'once_finished' relation indicating the read starts at 1574.5s; key factual timing details are missing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially suggests the mum needs compression hosiery, when does she mention asking for an appointment with the nurse for stronger compression?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1654.942,
        "end": 1664.2
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1638.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.94200000000001,
        "end": 25.799999999999955,
        "average": 45.37099999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2711864406779661,
        "text_similarity": 0.5245507955551147,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the nurse appointment suggestion comes after the hosiery advice) but omits the key factual timing details (the specific start/end timestamps), so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'That is such a good question', when does she state that self-diagnosis via the internet is never a good idea?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1757.815,
        "end": 1762.821
      },
      "pred_interval": {
        "start": 1638.4,
        "end": 1708.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 119.41499999999996,
        "end": 54.82099999999991,
        "average": 87.11799999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2622950819672131,
        "text_similarity": 0.44433796405792236,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the temporal relation (the self-diagnosis remark occurs after 'That is such a good question') but omits the key factual details \u2014 the precise start/end timestamps and the exact timing information requested."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes that approaching a GP is about framing the conversation, when does she tell the viewer not to worry about being labeled a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1795.335,
        "end": 1798.383
      },
      "pred_interval": {
        "start": 1708.0,
        "end": 1800.0
      },
      "iou": 0.033130434782608714,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 87.33500000000004,
        "end": 1.6169999999999618,
        "average": 44.476
      },
      "rationale_metrics": {
        "rouge_l": 0.08333333333333333,
        "text_similarity": 0.19866721332073212,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction correctly captures the key relation that the 'don't worry' remark occurs after the comment about framing the conversation, but it omits the precise timestamps and quoted wording given in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker first says, 'Please don't worry about things like that', when does she next advise not to worry about being labelled as a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1827.66,
        "end": 1831.19
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1822.46,
        "end": 1794.5900000000001,
        "average": 1808.525
      },
      "rationale_metrics": {
        "rouge_l": 0.060606060606060615,
        "text_similarity": 0.10829287767410278,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction does not identify the next instance of the advice or provide the correct timestamps; instead it gives an unrelated intervening question and fails to match the reference, so it is essentially incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks, 'What can I do to maintain healthy legs or feet so I don't get any problems?', when does she start listing actions like 'walk' and 'legs up'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1865.412,
        "end": 1883.383
      },
      "pred_interval": {
        "start": 35.0,
        "end": 74.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1830.412,
        "end": 1808.583,
        "average": 1819.4975
      },
      "rationale_metrics": {
        "rouge_l": 0.09195402298850576,
        "text_similarity": 0.2959648072719574,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that she lists actions like 'walk' and 'legs up' after the question, but it fails to provide the required precise timing (the given timestamps) and is vague about the order and boundaries of those actions, omitting key factual details from the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks how much is in the GP curriculum, when does she say 'I don't know'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1983.7,
        "end": 1984.201
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2060.0
      },
      "iou": 0.004554545454545239,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.700000000000045,
        "end": 75.79899999999998,
        "average": 54.74950000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.08695652173913043,
        "text_similarity": 0.16100740432739258,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the required timestamps and precise relation (target immediately follows the anchor); it even implies a pause, which contradicts the correct answer's timing detail."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'I think it is something that Legs Matter can help with', when does she discuss Legs Matter influencing GP curriculums?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2004.063,
        "end": 2009.063
      },
      "pred_interval": {
        "start": 2060.0,
        "end": 2160.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.9369999999999,
        "end": 150.9369999999999,
        "average": 103.4369999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.10256410256410256,
        "text_similarity": 0.1197299212217331,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only gives a vague relative description ('after a brief pause') and omits the required anchor/target timestamps and explicit ordering details; it minimally matches the fact that the target follows the anchor but lacks the essential timing information."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks if seeing a nurse practitioner is appropriate, when does she state that nurse practitioners are 'extremely experienced clinicians'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2062.584,
        "end": 2066.851
      },
      "pred_interval": {
        "start": 2160.0,
        "end": 2260.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.41600000000017,
        "end": 193.1489999999999,
        "average": 145.28250000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.045454545454545456,
        "text_similarity": -0.03398924320936203,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the precise timing and identification of the immediate explanation given in the correct answer; describing it as 'after a brief pause' is ambiguous and fails to capture the specified timestamps or the target utterance."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I understand the issue of smartphones and taking pictures too\", when does she first ask \"is there somebody who can help you?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2174.0,
        "end": 2176.0
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2319.5
      },
      "iou": 0.010554089709762533,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.0,
        "end": 143.5,
        "average": 93.75
      },
      "rationale_metrics": {
        "rouge_l": 0.10526315789473684,
        "text_similarity": 0.021388575434684753,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the question occurs after the prior remark (after a pause) but fails to provide the required precise timing/anchor-target timestamps and relative timing detail given in the correct answer, so it is largely incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "During the period when the speaker discusses the importance of planning phone calls to the GP, when does she ask, \"What am I feeling?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2197.721,
        "end": 2198.663
      },
      "pred_interval": {
        "start": 2164.5,
        "end": 2319.5
      },
      "iou": 0.006077419354838757,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.221000000000004,
        "end": 120.83699999999999,
        "average": 77.029
      },
      "rationale_metrics": {
        "rouge_l": 0.10909090909090909,
        "text_similarity": 0.0854436457157135,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the key factual detail (the precise timing/timestamps and that the question occurs at 2197.721\u20132198.663 within the anchor span); it neither provides the required absolute/relative times nor matches the specificity of the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once Dr. Angelos finishes introducing Dr. Tolchin, when does Dr. Tolchin begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.128,
        "end": 109.393
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 99.928,
        "end": 72.793,
        "average": 86.3605
      },
      "rationale_metrics": {
        "rouge_l": 0.15151515151515152,
        "text_similarity": 0.6011353135108948,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: the event timings, speakers, and quoted utterance do not match the reference (100.128s vs 5.2s and 105.128s vs 35.0s), and it hallucinates content; only the generic 'after' relation loosely aligns with 'once_finished.'"
      }
    },
    {
      "question_id": "002",
      "question": "After Dr. Angelos describes Dr. Tolchin's research on crisis standards of care, when does he describe his research on functional neurological disorders and epilepsy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.426,
        "end": 116.456
      },
      "pred_interval": {
        "start": 35.0,
        "end": 84.5
      },
      "iou": 0.34465232763700643,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.426000000000002,
        "end": 31.956000000000003,
        "average": 26.691000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.535618782043457,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps and labels do not match the reference: E1 is given at 35.0s instead of 44.732\u201354.143s, and E2 is 35.0\u201384.5s instead of 56.426\u2013116.456s; the predicted overlap/labels contradict the correct segmentation and content."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating the second learning objective, when does he start explaining the third learning objective?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 181.0
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 161.8,
        "end": 144.4,
        "average": 153.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5991219282150269,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer is largely incorrect: it gives entirely different timestamps and events (intro and an unrelated sentence) rather than the second objective finishing at 16.4s and the third explanation from 17.0\u201331.0s; only the vague 'after' relation matches."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'Why conduct clinical ethics consultations?' is displayed, when does the speaker discuss moral distress among clinicians and staff?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.4,
        "end": 304.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 48.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 250.39999999999998,
        "end": 255.2,
        "average": 252.79999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3859649122807018,
        "text_similarity": 0.6914836764335632,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (35.0s) is incorrect and falls well outside the correct interval (285.4\u2013304.0s) when the speaker discusses moral distress during the 'Why conduct clinical ethics consultations?' slide, so the prediction contradicts the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that clinical ethics consultations were helpful, when does he state that they were more likely to achieve consensus in clinical decisions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 350.2,
        "end": 357.0
      },
      "pred_interval": {
        "start": 332.7,
        "end": 489.6
      },
      "iou": 0.043339706819630404,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.5,
        "end": 132.60000000000002,
        "average": 75.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.07407407407407408,
        "text_similarity": 0.01929384097456932,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives a completely incorrect timestamp (489.6s) versus the correct interval (350.2\u2013357.0s) despite matching the 'after' relation, so it fails to identify the right moment."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of resource utilization, when does he specifically state that there was a reduced length of stay?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 438.9,
        "end": 450.3
      },
      "pred_interval": {
        "start": 489.6,
        "end": 510.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.700000000000045,
        "end": 60.0,
        "average": 55.35000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.0392156862745098,
        "text_similarity": 0.24036544561386108,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a single time (510.3s) that contradicts the correct target interval (438.9\u2013450.3s) and omits the anchor timing (369.0s); it therefore misstates the timing and includes unfounded detail."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'to look at disparities', when does he begin to introduce Ellen Fox's team and their survey?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 493.5,
        "end": 499.0
      },
      "pred_interval": {
        "start": 510.3,
        "end": 540.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.80000000000001,
        "end": 41.0,
        "average": 28.900000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.18518518518518517,
        "text_similarity": 0.22122053802013397,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gives a single start time (540.0s) that contradicts the correct target start (493.5s) and omits the end time and relationship; it is therefore largely incorrect though it attempts to answer when the introduction begins."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'hospitals with less than 400 beds', when does he mention 'little or no growth over that two decade period'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 527.809,
        "end": 530.91
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 522.6089999999999,
        "end": 494.30999999999995,
        "average": 508.45949999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.1081081081081081,
        "text_similarity": 0.545093297958374,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely incorrect: it gives entirely different timestamps and quotes unrelated content ('I am a final year medical student') instead of the referenced phrases, and misstates the temporal relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide titled 'Prior Healthcare System Ethics Committees' is fully displayed, when do the images of the six hospitals with their bed counts appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.7,
        "end": 552.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 48.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 516.7,
        "end": 503.4,
        "average": 510.05
      },
      "rationale_metrics": {
        "rouge_l": 0.2682926829268293,
        "text_similarity": 0.7259383201599121,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction identifies both anchor and target but gives completely different timestamps (35.0\u201348.6s vs. 536.2\u2013552.0s) and incorrectly states they occur at the same time instead of the target occurring after the anchor, so it fails factual alignment."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the number of ethics consults at Yale New Haven Hospital increased from 50 to 239, when does he describe this as 'approximately a five-fold increase in consult volume'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.7,
        "end": 624.7
      },
      "pred_interval": {
        "start": 65.2,
        "end": 88.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 557.5,
        "end": 535.9000000000001,
        "average": 546.7
      },
      "rationale_metrics": {
        "rouge_l": 0.4742268041237114,
        "text_similarity": 0.7118558883666992,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps and segment boundaries are completely incorrect (65.2\u201388.8s vs the correct 614.8\u2013621.0s and 622.7\u2013624.7s) and it misaligns the target to start with the anchor; only the 'after' relation is conceptually similar."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially mentions the 'Community Bioethics Forum', when does he start describing its community members?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 887.216,
        "end": 905.918
      },
      "pred_interval": {
        "start": 870.0,
        "end": 960.0
      },
      "iou": 0.20779999999999998,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.216000000000008,
        "end": 54.081999999999994,
        "average": 35.649
      },
      "rationale_metrics": {
        "rouge_l": 0.1846153846153846,
        "text_similarity": 0.4593051075935364,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction does not provide the required timing or identify when the community members are described; it omits the cited time span and introduces an unrelated forum (hallucination), so it fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that the primary focus of the Center for Clinical Ethics has been ethics education, when does he start listing 'Systemwide Ethics Forum and Newsletter'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1055.54,
        "end": 1069.28
      },
      "pred_interval": {
        "start": 960.0,
        "end": 1080.0
      },
      "iou": 0.11450000000000007,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 95.53999999999996,
        "end": 10.720000000000027,
        "average": 53.129999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.14457831325301204,
        "text_similarity": 0.2649472951889038,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer does not identify the 'Systemwide Ethics Forum and Newsletter' or its timing and instead lists unrelated/hallucinated resources, so it fails to match the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"ethics consultation services,\" when does he start talking about collecting feedback?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.8,
        "end": 1249.8
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.04285714285714286,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.799999999999955,
        "end": 190.20000000000005,
        "average": 100.5
      },
      "rationale_metrics": {
        "rouge_l": 0.4210526315789474,
        "text_similarity": 0.6284856796264648,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that discussion of collecting feedback follows the phrase), but it omits the specific timestamps (1238.9s and 1240.8s) and the absolute\u2192relative timing detail provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that participant satisfaction is not the \"be-all and end-all,\" when does he say they have begun the survey process with clinicians?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.3,
        "end": 1282.8
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.02142857142857143,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.299999999999955,
        "end": 157.20000000000005,
        "average": 102.75
      },
      "rationale_metrics": {
        "rouge_l": 0.43636363636363634,
        "text_similarity": 0.597309947013855,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that he says they began the survey process but fails to provide the required timestamps/temporal relation (1275.0s and 1278.3s), omitting key factual details from the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes describing the first pie chart about helpful advice/guidance, when does the second pie chart about communication appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1367.5,
        "end": 1367.9
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.0019047619047623378,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 137.5,
        "end": 72.09999999999991,
        "average": 104.79999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.5217391304347826,
        "text_similarity": 0.576990008354187,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly states the temporal relation (the second pie appears once the first is finished) but omits key factual details\u2014specifically the timestamps (E1=1356.0s, E2=1376.5s) and the absolute\u2192relative timing judgment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he wants to turn to some of the organizational ethics consultation work, when does the slide showing the 'Organizational ethics consultations' table appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1472.0,
        "end": 1472.5
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1620.0
      },
      "iou": 0.002380952380952381,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.0,
        "end": 147.5,
        "average": 104.75
      },
      "rationale_metrics": {
        "rouge_l": 0.21875,
        "text_similarity": 0.3580278754234314,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the relative order (the slide appears after the speaker's introduction) but omits the key factual elements of the correct answer\u2014namely the specific timestamps for the speaker turn and the slide appearance."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining that organizational ethics work is new to them, when do they state that it began during the COVID pandemic?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1469.5,
        "end": 1472.0
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1620.0
      },
      "iou": 0.011904761904761904,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.5,
        "end": 148.0,
        "average": 103.75
      },
      "rationale_metrics": {
        "rouge_l": 0.11320754716981132,
        "text_similarity": 0.15379390120506287,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction does not provide the requested timing information or mention that the work began during COVID; instead it refers to a slide appearing, which omits key factual elements and fails to answer the question."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the 'Organizational ethics consultations' table, when does the speaker mention the 'Blood products scarcity protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1510.0,
        "end": 1513.0
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1620.0
      },
      "iou": 0.014285714285714285,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 100.0,
        "end": 107.0,
        "average": 103.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.7190030813217163,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the mention occurs while the 'Organizational ethics consultations' table is displayed, matching the key relation, but it omits the specific timestamps (1510\u20131513s and 1474\u20131573s) given in the correct answer, so it's incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the 'sequential organ failure assessment or SOFA score', when does he begin to explain what it is?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1647.6,
        "end": 1697.0
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1790.0
      },
      "iou": 0.24700000000000044,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.59999999999991,
        "end": 93.0,
        "average": 75.29999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.09090909090909091,
        "text_similarity": 0.2724497318267822,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction roughly overlaps the correct interval but is imprecise and factually incorrect about the start/end times (it begins much earlier and ends later than the annotated explanation), so it fails to accurately locate when the explanation begins."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that '70% of publicly available crisis standards of care used either the SOFA score or a modified version', when does he mention the SOFA score being used in Alaska?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1726.0,
        "end": 1733.0
      },
      "pred_interval": {
        "start": 1740.0,
        "end": 1950.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.0,
        "end": 217.0,
        "average": 115.5
      },
      "rationale_metrics": {
        "rouge_l": 0.05714285714285714,
        "text_similarity": 0.1712508201599121,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (1740.0\u20131950.0s) do not match the correct segments (1705.0\u20131712.0s and 1726.0\u20131733.0s) and thus fail to identify the next specific example after the general percentage."
      }
    },
    {
      "question_id": "003",
      "question": "Once the 'SOFA Disparities' slide appears, when does the speaker begin discussing concerns about the score's accuracy and contributions to disparities?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1770.0,
        "end": 1776.606
      },
      "pred_interval": {
        "start": 1680.0,
        "end": 1890.0
      },
      "iou": 0.03145714285714283,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.0,
        "end": 113.394,
        "average": 101.697
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814817,
        "text_similarity": 0.33173689246177673,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction roughly covers the correct interval but gives a much earlier start and much later end (1680\u20131890s) instead of the precise 1770.0\u20131776.606s; this overbroad, inaccurate timing contradicts the key factual details. "
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that the center was able to test the triage protocol before it was used, when does he state that they developed a SOFA calculation system?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1799.553,
        "end": 1807.997
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1834.5
      },
      "iou": 0.1309147286821699,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.55300000000011,
        "end": 26.50299999999993,
        "average": 28.02800000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2647058823529412,
        "text_similarity": 0.6961843967437744,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer simply repeats the question and provides no timing information or the E1/E2 times given in the correct answer, thus failing to answer the question."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the retrospective cohort study, when does he detail the demographic breakdown of the patients?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1846.122,
        "end": 1858.077
      },
      "pred_interval": {
        "start": 1834.5,
        "end": 1980.0
      },
      "iou": 0.08216494845360775,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.622000000000071,
        "end": 121.923,
        "average": 66.77250000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.5735662579536438,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer simply restates the question and provides no timing information or content; it fails to match the correct answer's specific timestamps and details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker highlights that non-Hispanic Black patients had greater odds of an elevated SOFA score, when does he state that no significant difference by race in mortality was found when controlling for other factors?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.642,
        "end": 1879.694
      },
      "pred_interval": {
        "start": 1980.0,
        "end": 2100.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 106.35799999999995,
        "end": 220.30600000000004,
        "average": 163.332
      },
      "rationale_metrics": {
        "rouge_l": 0.25974025974025977,
        "text_similarity": 0.7533040046691895,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer merely repeats the question instead of providing the requested timestamps or content; it omits the key factual details (the end time 1866.0s and the start/end times 1873.642\u20131879.694s) present in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the early small cohort out of Wuhan, China, when does he state that subsequent larger cohorts in the United States did not show such high accuracy rates?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.0,
        "end": 1966.5
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1953.8,
        "end": 1929.9,
        "average": 1941.85
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.5680821537971497,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction completely mismatches the referenced events and timestamps (different start/end times and unrelated utterances), so it fails to identify the correct anchor/target; only the generic 'after' relation matches."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'This graph here is a calibration curve', when does he explain that the diagonal line shows a perfectly calibrated predictor of mortality?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2014.0,
        "end": 2020.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 48.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1979.0,
        "end": 1971.6,
        "average": 1975.3
      },
      "rationale_metrics": {
        "rouge_l": 0.24719101123595505,
        "text_similarity": 0.6727489233016968,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect: it gives wrong anchor/target timestamps, identifies an unrelated target utterance, and mislabels the temporal relation (should follow, not overlap)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that SOFA predicted mortality with less accuracy than age in their own COVID cohort, when does he mention that SOFA predicted mortality with better accuracy than age in the pre-COVID eICU cohort?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2066.0,
        "end": 2069.0
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2060.8,
        "end": 2032.4,
        "average": 2046.6000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.29885057471264365,
        "text_similarity": 0.7819662094116211,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives completely different timestamps and quotes the wrong segment (refers to the COVID cohort rather than the pre-COVID eICU contrast), and thus contradicts the correct temporal anchors and content."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the Omicron surge increasing, when does he talk about working with the healthcare system's legal team?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2153.6,
        "end": 2174.93
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2160.0
      },
      "iou": 0.14244380146895425,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.59999999999991,
        "end": 14.929999999999836,
        "average": 19.264999999999873
      },
      "rationale_metrics": {
        "rouge_l": 0.3673469387755102,
        "text_similarity": 0.5549201965332031,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the sequence (he talks about the legal team after mentioning Omicron) but omits the required timestamps and specific time window (E1 ends ~2132.0s; E2 2153.6\u20132174.93s), so key factual details are missing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the policy was active until late February of 2022, when does the first 'Scope of protocol' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2194.0,
        "end": 2234.0
      },
      "pred_interval": {
        "start": 2160.0,
        "end": 2185.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 49.0,
        "average": 41.5
      },
      "rationale_metrics": {
        "rouge_l": 0.39999999999999997,
        "text_similarity": 0.7648100852966309,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction merely restates the question and provides no timing information; it omits the key timestamps (E1 at 2192.0s and E2 from 2194.0s\u20132234.0s) required by the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the second 'Scope of protocol' slide appears, when does the speaker mention 'renal replacement therapy'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2263.679,
        "end": 2254.733
      },
      "pred_interval": {
        "start": 2185.0,
        "end": 2210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.67900000000009,
        "end": 44.733000000000175,
        "average": 61.70600000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.4150943396226415,
        "text_similarity": 0.737127959728241,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the speaker mentions 'renal replacement therapy' but omits the required timing information relative to the second slide (the precise timestamps and the noted 3s offset), so it fails to match the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that goals of care discussions significantly changed, when does the speaker mention that patients were more likely to choose limited life-sustaining interventions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2320.0,
        "end": 2327.0
      },
      "pred_interval": {
        "start": 2370.0,
        "end": 2406.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.0,
        "end": 79.0,
        "average": 64.5
      },
      "rationale_metrics": {
        "rouge_l": 0.3142857142857143,
        "text_similarity": 0.5563420653343201,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys that the mention of choosing limited interventions comes later (after the goals-of-care comment), but it fails to provide the required timestamps and instead gives vague slide references and an unverified quote, omitting the key factual timing details in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states he wants to highlight some takeaway points, when does the first takeaway point appear on the screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "pred_interval": {
        "start": 2406.0,
        "end": 2430.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 30.0,
        "average": 20.5
      },
      "rationale_metrics": {
        "rouge_l": 0.19999999999999998,
        "text_similarity": 0.6232336759567261,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction vaguely identifies the event ('takeaway 1') but omits the required timestamps and adds an unsupported detail ('after slide 25'), so it does not match the precise timing given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I'll stop and take questions,\" when does an audience member begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2541.6,
        "end": 2544.0
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2580.0
      },
      "iou": 0.026666666666667678,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.59999999999991,
        "end": 36.0,
        "average": 43.799999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.4230769230769231,
        "text_similarity": 0.6843783855438232,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the audience speaks after the speaker, but falsely claims it happens 'immediately' and omits the provided timestamps (actual start ~23.7s later at 2541.6s), so it is misleading and incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the audience member finishes complimenting the center, when does he ask a specific question about local hospital ethics committees?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2571.5,
        "end": 2580.5
      },
      "pred_interval": {
        "start": 2580.0,
        "end": 2634.0
      },
      "iou": 0.008,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.5,
        "end": 53.5,
        "average": 31.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4897959183673469,
        "text_similarity": 0.5436819791793823,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the semantic relation that the question follows the compliment, but it omits the key temporal details (the specific start/end timestamps and duration) provided in the reference answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the audience member mentions the low numbers of ethics consultations, when does the speaker begin to answer the question?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2624.0,
        "end": 2634.8
      },
      "pred_interval": {
        "start": 2634.0,
        "end": 2700.0
      },
      "iou": 0.010526315789476078,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 65.19999999999982,
        "average": 37.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.4814814814814815,
        "text_similarity": 0.5327589511871338,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the relation (the speaker answers after the audience member), but it omits the key factual details\u2014specific start/end times (2621.0s, 2624.0s\u20132634.8s) required by the question."
      }
    },
    {
      "question_id": "002",
      "question": "After the listener asks about assessing the quality of care across the system, when does the speaker respond by calling it a 'great question'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.1,
        "end": 2745.7
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2880.0
      },
      "iou": 0.007619047619047186,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.09999999999991,
        "end": 134.30000000000018,
        "average": 104.20000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.41379310344827586,
        "text_similarity": 0.7505523562431335,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction correctly conveys the relative timing (the speaker responds about one second later), but it omits the precise timestamps given in the reference (listener 2739.0\u20132743.0s, speaker at 2744.1s) and slightly rounds the interval."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions starting to survey clinicians for feedback, when does he mention planning to survey patients and families?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2807.8,
        "end": 2821.6
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2880.0
      },
      "iou": 0.06571428571428442,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 137.80000000000018,
        "end": 58.40000000000009,
        "average": 98.10000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.34210526315789475,
        "text_similarity": 0.7460620403289795,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that patients and families are mentioned next, but it gives an incorrect timing ('after 1 second') that contradicts the reference (about 5.8+ seconds later) and omits the actual time range."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that hospitals in the healthcare system can join together, when does he state that they will preferentially present cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2854.49,
        "end": 2856.13
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 3060.0
      },
      "iou": 0.007809523809525368,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.489999999999782,
        "end": 203.8699999999999,
        "average": 104.17999999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.29988741874694824,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the event follows the mention (i.e., occurs after), but it omits the requested timing details (specific timestamps and span) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces 'a third method of feedback', when does he describe it as 'formal needs assessments'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2877.53,
        "end": 2879.53
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 3060.0
      },
      "iou": 0.009523809523809525,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.5300000000002,
        "end": 180.4699999999998,
        "average": 104.0
      },
      "rationale_metrics": {
        "rouge_l": 0.34615384615384615,
        "text_similarity": 0.5871462821960449,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states that the speaker labels it 'formal needs assessments' after introducing 'a third method of feedback', but it omits the required temporal details (the specific timestamps and the anchor\u2192target timing) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'the overwhelming response was number one', when does he specify the first response as 'a lack of ethics education'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2901.56,
        "end": 2903.46
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 3060.0
      },
      "iou": 0.009047619047619481,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.559999999999945,
        "end": 156.53999999999996,
        "average": 104.04999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.43333333333333335,
        "text_similarity": 0.7104110717773438,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is factually consistent but omits the required timing details and the explicit relative timing (timestamps and that the target occurs after the anchor), so it fails to fully answer the 'when' aspect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"The more medically complex cases tend to transfer,\" when does he start listing examples of such cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3044.3,
        "end": 3048.2
      },
      "pred_interval": {
        "start": 3030.0,
        "end": 3240.0
      },
      "iou": 0.018571428571426837,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.300000000000182,
        "end": 191.80000000000018,
        "average": 103.05000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.03508771929824561,
        "text_similarity": 0.2569688856601715,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is incorrect and off-topic: it references an 'escalation of care' slide rather than the timing of when the speaker starts listing examples and provides no timestamps, contradicting the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the questioner asks about the 'escalation of care policy', when does the slide titled 'Escalation of Care Protocol' appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3114.8,
        "end": 3117.8
      },
      "pred_interval": {
        "start": 3030.0,
        "end": 3240.0
      },
      "iou": 0.014285714285714285,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 84.80000000000018,
        "end": 122.19999999999982,
        "average": 103.5
      },
      "rationale_metrics": {
        "rouge_l": 0.12121212121212122,
        "text_similarity": 0.371206670999527,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer does not state any timings or say when the slide appears and instead gives unrelated content about patient boarding, thus failing to match or answer the reference information."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions \"boarding 190 patients in the emergency department\", when does he discuss concerns about the level of care?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3154.983,
        "end": 3143.945
      },
      "pred_interval": {
        "start": 3030.0,
        "end": 3240.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 124.98300000000017,
        "end": 96.05499999999984,
        "average": 110.519
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962265,
        "text_similarity": 0.5150562524795532,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that concerns are discussed after the boarding remark, but it omits the crucial timing details and immediacy indicated in the reference (specific second ranges and that the discussion occurs immediately after the anchor)."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker mentions 'in all 26 of those cases', when does he then talk about 'many more cases'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3214.9,
        "end": 3215.4
      },
      "pred_interval": {
        "start": 3216.0,
        "end": 3416.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.099999999999909,
        "end": 200.5999999999999,
        "average": 100.84999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.2682926829268293,
        "text_similarity": 0.525835394859314,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') but omits the required precise timestamps and introduces an unsupported visual cue (hand gesture), thereby missing key factual details from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker states that the 'escalation of care protocol' was nice, when does he mention a 'SOFA-based protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3246.0,
        "end": 3249.0
      },
      "pred_interval": {
        "start": 3216.0,
        "end": 3416.0
      },
      "iou": 0.015,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.0,
        "end": 167.0,
        "average": 98.5
      },
      "rationale_metrics": {
        "rouge_l": 0.09195402298850576,
        "text_similarity": 0.3211030066013336,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only captures a vague temporal relation ('after') but fails to identify the SOFA-based protocol or provide the required timestamps, and adds an unsupported visual-cue detail; it omits key factual elements from the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the second speaker says 'SOFA is horrendous', when does he mention 'SOFA's AUC goes up'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3322.32,
        "end": 3324.71
      },
      "pred_interval": {
        "start": 3216.0,
        "end": 3416.0
      },
      "iou": 0.011949999999999364,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 106.32000000000016,
        "end": 91.28999999999996,
        "average": 98.80500000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.11363636363636365,
        "text_similarity": 0.3473209738731384,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction fails to identify the correct events, speakers, quoted phrases, and timestamps given in the reference; it only correctly states the temporal relation ('after') and adds unrelated visual commentary, so it largely doesn't match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the question about equity monitoring is asked, when does the speaker begin explaining the logging process for patient cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3401.583,
        "end": 3406.09
      },
      "pred_interval": {
        "start": 3408.5,
        "end": 3548.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.916999999999916,
        "end": 141.90999999999985,
        "average": 74.41349999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.07692307692307693,
        "text_similarity": 0.22133314609527588,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated and incorrect: it mentions slides ('Escalation of Care Protocol' and 'Conscientious Practice Policy') rather than the timing relation between the equity-monitoring question and the speaker's logging explanation, and it omits the required time details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the 'Escalation of Care Protocol', when does the 'Conscientious Practice Policy' slide appear on screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3429.8,
        "end": 3430.5
      },
      "pred_interval": {
        "start": 3548.0,
        "end": 3607.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 118.19999999999982,
        "end": 177.0,
        "average": 147.5999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.24999999999999994,
        "text_similarity": 0.7270001173019409,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the slide appears after the speaker finishes) but omits the specific timestamps (around 3424.0s and 3429.8s) given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Conscientious Practice Policy' slide appears, when does the speaker mention tracking outcomes and looking back retrospectively for this policy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3444.0,
        "end": 3492.0
      },
      "pred_interval": {
        "start": 3607.5,
        "end": 3767.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 163.5,
        "end": 275.0,
        "average": 219.25
      },
      "rationale_metrics": {
        "rouge_l": 0.39999999999999997,
        "text_similarity": 0.7345436811447144,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the mention occurs after the slide), but it omits the key factual details of the specific timestamps and time range (3444.0s\u20133492.0s) given in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions an increasing disparity over time, when does he discuss how they can provide support to all hospitals?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 707.399,
        "end": 742.972
      },
      "pred_interval": {
        "start": 690.0,
        "end": 735.0
      },
      "iou": 0.5210488559993961,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.399,
        "end": 7.97199999999998,
        "average": 12.68549999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.41666666666666663,
        "text_similarity": 0.8895997405052185,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the two events and the 'after' relationship, and the predicted target start (715s) falls within the correct target interval, but the anchor timing is inaccurate (starts too early and lacks an end time) and the target start is offset from the precise reference times."
      }
    },
    {
      "question_id": "002",
      "question": "While the organizational chart for the Center for Clinical Ethics is displayed, when does the speaker describe the Ethics Education program?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.177,
        "end": 786.763
      },
      "pred_interval": {
        "start": 715.0,
        "end": 740.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.17700000000002,
        "end": 46.763000000000034,
        "average": 50.47000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.23880597014925373,
        "text_similarity": 0.41991645097732544,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it claims the program discussion starts at 715.0s (before the slide appears at 749s) and labels anchors/relations inaccurately, whereas the correct timing is 769.177\u2013786.763s during the slide; thus it contradicts the reference timing and omits the true interval."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says he will go into depth on the programs, when does he first mention the Yale Interdisciplinary Center for Bioethics?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 837.605,
        "end": 845.26
      },
      "pred_interval": {
        "start": 740.0,
        "end": 765.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 97.60500000000002,
        "end": 80.25999999999999,
        "average": 88.9325
      },
      "rationale_metrics": {
        "rouge_l": 0.2926829268292683,
        "text_similarity": 0.656408965587616,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misidentifies the anchor (it should be the 'go into depth' utterance at ~805.8\u2013809s) and gives an incorrect target timestamp (740.0s, which is before the anchor), so the timing and event labels are largely wrong despite claiming an 'after' relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the title 'Systemwide Ethics Forum and Newsletter', when does he describe it as a hybrid meeting?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1070.5,
        "end": 1076.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.02857142857142857,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.5,
        "end": 183.5,
        "average": 102.0
      },
      "rationale_metrics": {
        "rouge_l": 0.12658227848101267,
        "text_similarity": 0.5337579250335693,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely fails: it misidentifies E2 (quotes 'I am a final year medical student' instead of the 'hybrid in-person and online meeting' statement) and provides incorrect timestamps for both events; only the relation 'after' is correct. This includes hallucinated content and omission of the key factual element."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining that they looked through the 26 specific patient cases individually, when does the slide transition to 'Scope of protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3425.8,
        "end": 3429.0
      },
      "pred_interval": {
        "start": 3390.0,
        "end": 3547.2
      },
      "iou": 0.02035623409669098,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.80000000000018,
        "end": 118.19999999999982,
        "average": 77.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3137254901960784,
        "text_similarity": 0.5906891226768494,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the qualitative relation ('after') but omits all key timing details (the exact E1/E2 timestamps and transition time) provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Once the 'Scope of protocol' slide finishes being displayed, when does the 'Conscientious Practice Policy' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3429.0,
        "end": 3519.5
      },
      "pred_interval": {
        "start": 3547.2,
        "end": 3604.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 118.19999999999982,
        "end": 84.90000000000009,
        "average": 101.54999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.6740158796310425,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the relation that the Conscientious Practice Policy slide appears once the Scope of protocol slide finishes, but it omits the crucial timing details (appearance at 3429.0s and duration until 3519.5s) provided in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes discussing the tracking of equity, socioeconomic status, and other demographic characteristics, when is the presentation window minimized?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3530.0,
        "end": 3531.0
      },
      "pred_interval": {
        "start": 3604.4,
        "end": 3660.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 74.40000000000009,
        "end": 129.0,
        "average": 101.70000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.32653061224489793,
        "text_similarity": 0.5391203165054321,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation that the window is minimized after the discussion, but it omits the key timestamp details (E1 at 3508.5s and E2 at 3530.0\u20133531.0) provided in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the audience will be on mute, when does he mention that the live event can be paused?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 38.524,
        "end": 43.729
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.324,
        "end": 7.128999999999998,
        "average": 20.226499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.5786195397377014,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (pausing is mentioned after the audience is put on mute) but omits the specific timestamps and target span provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses changing the speed of presentations and speakers, when does he advise on what to do if Wi-Fi or connection is lost?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 55.563,
        "end": 59.787
      },
      "pred_interval": {
        "start": 104.7,
        "end": 138.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.137,
        "end": 79.013,
        "average": 64.075
      },
      "rationale_metrics": {
        "rouge_l": 0.28571428571428575,
        "text_similarity": 0.4623008370399475,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the temporal relation (that the advice comes after the discussion of playback speed) but omits the crucial timing details and span (55.563s\u201359.787s) provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the presenter mentions Tom Gardner in the background, when does he mention Stephanie Fraser joining in place of Jane Preston?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.258,
        "end": 171.201
      },
      "pred_interval": {
        "start": 150.0,
        "end": 210.0
      },
      "iou": 0.049049999999999726,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.25800000000001,
        "end": 38.79900000000001,
        "average": 28.528500000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.29850746268656714,
        "text_similarity": 0.4538365304470062,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the sequence and that Stephanie Fraser is introduced (and replaces Jane Preston), but it omits the crucial timing details (start/end timestamps and explicit 'after' relation) provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male presenter finishes introducing Stephanie Fraser, when does Stephanie Fraser begin speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 223.86,
        "end": 224.8
      },
      "pred_interval": {
        "start": 210.0,
        "end": 360.0
      },
      "iou": 0.006266666666666651,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.860000000000014,
        "end": 135.2,
        "average": 74.53
      },
      "rationale_metrics": {
        "rouge_l": 0.17391304347826086,
        "text_similarity": 0.3914017081260681,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction states she speaks after the presenter but is overly vague and omits all required timing details and the explicit 'after' relation specified in the correct answer, so it fails to provide the key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker is discussing the recent research undertaken by the Neurological Alliance of Scotland, when does she state that 57% of respondents reported not being able to access a face-to-face appointment?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 433.0,
        "end": 434.9
      },
      "pred_interval": {
        "start": 330.0,
        "end": 480.0
      },
      "iou": 0.012666666666666515,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 103.0,
        "end": 45.10000000000002,
        "average": 74.05000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1558441558441558,
        "text_similarity": 0.1993740200996399,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly restates the content (that 57% reported not accessing face-to-face appointments) but fails to answer the question's core temporal requirement\u2014the specific timestamps (around 433.0\u2013434.9s within the 383.3\u2013443.3s anchor) are omitted."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that nearly two-thirds of respondents had not had a video appointment, when does she state that telephone appointments were the most common way to access care?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.8,
        "end": 452.9
      },
      "pred_interval": {
        "start": 480.0,
        "end": 690.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.19999999999999,
        "end": 237.10000000000002,
        "average": 134.65
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.3412390351295471,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer simply restates the question and provides no timing information; it fails to supply the specific timestamps (E1 end 346.8s, E2 start 447.8s\u2013452.9s) given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the blue slide with the speaker's title disappears, when does the speaker begin to mention what factors clinicians should consider for appointment formats?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 479.3,
        "end": 480.3
      },
      "pred_interval": {
        "start": 690.0,
        "end": 900.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 210.7,
        "end": 419.7,
        "average": 315.2
      },
      "rationale_metrics": {
        "rouge_l": 0.2413793103448276,
        "text_similarity": 0.2991308271884918,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly indicates the mention occurs after the blue slide disappears but omits the critical timing details (E1 at 476.3s and E2 starting at 479.3s), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stephanie finishes speaking and hands over to Mark, when does Mark begin to speak?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 606.5,
        "end": 607.0
      },
      "pred_interval": {
        "start": 510.0,
        "end": 690.0
      },
      "iou": 0.002777777777777778,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 96.5,
        "end": 83.0,
        "average": 89.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.649962842464447,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction claims a 190-second gap, which directly contradicts the ground-truth timestamps showing Mark starts ~12.8\u201313.3 seconds after Stephanie; the timing is completely incorrect and omits the provided timestamps."
      }
    },
    {
      "question_id": "002",
      "question": "Once Mark finishes introducing Calum Duncan, when does Calum Duncan start speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 638.3,
        "end": 639.3
      },
      "pred_interval": {
        "start": 600.0,
        "end": 720.0
      },
      "iou": 0.008333333333333333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.299999999999955,
        "end": 80.70000000000005,
        "average": 59.5
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.557566225528717,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and hallucinates a 120s delay; the correct answer indicates Calum starts ~2.0\u20133.0 seconds after Mark finishes (638.3\u2013639.3s vs 636.3\u2013636.6s), so the timing contradicts the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once Calum Duncan says 'Next slide please', when does the second presentation slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 685.7,
        "end": 686.0
      },
      "pred_interval": {
        "start": 690.0,
        "end": 800.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.2999999999999545,
        "end": 114.0,
        "average": 59.14999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.6224917769432068,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect: the correct delay is about 0.5 seconds (685.7s vs 685.2s), whereas the prediction states 110 seconds, which contradicts the ground truth and adds a fabricated duration."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 'near me is what we're going to focus on today', when does he describe it as 'internet-based'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 702.7,
        "end": 703.5
      },
      "pred_interval": {
        "start": 690.0,
        "end": 738.4
      },
      "iou": 0.016528925619833778,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.700000000000045,
        "end": 34.89999999999998,
        "average": 23.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1081081081081081,
        "text_similarity": 0.28979527950286865,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted interval [690.0s, 738.4s] does include the correct timestamp (702.7s) but is overly broad and fails to provide the precise time (702.7s) or the after relation to the anchor at 699.8s, so it is only partially correct."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states there were '330 consultations per week' before the pandemic, when does he mention it went up to '10,000'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 737.0,
        "end": 739.0
      },
      "pred_interval": {
        "start": 738.4,
        "end": 786.8
      },
      "iou": 0.012048192771084805,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3999999999999773,
        "end": 47.799999999999955,
        "average": 24.599999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.041666666666666664,
        "text_similarity": 0.05381082370877266,
        "llm_judge_score": 6,
        "llm_judge_justification": "The predicted interval (738.4\u2013786.8s) overlaps and includes the correct target (737.0\u2013739.0s), so it identifies the right moment, but it is imprecise and overly long, and it omits the anchor timing (731.5\u2013733.0s)."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' for the first time, when does he point to the map on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.0,
        "end": 767.5
      },
      "pred_interval": {
        "start": 786.8,
        "end": 825.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.799999999999955,
        "end": 57.700000000000045,
        "average": 38.75
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.3364272117614746,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction only gives an incorrect time interval for when he says 'Next slide' (786.8\u2013825.2s vs the correct 756.0s) and fails to state when he points to the map (767.0s), so it is incorrect and incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'go back to the next slide', when does the slide titled 'Video consulting using near me via attend anywhere platform' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 874.0,
        "end": 874.1
      },
      "pred_interval": {
        "start": 870.0,
        "end": 960.0
      },
      "iou": 0.0011111111111113637,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 85.89999999999998,
        "average": 44.94999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1702127659574468,
        "text_similarity": 0.4819161891937256,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly conveys that the slide appears immediately when the speaker says 'go back to the next slide,' matching the correct answer's timing; although it omits numeric timestamps, it preserves the essential meaning."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that 'Stephanie Fraser has talked about' the survey, when does he then say 'Back to next slide, Mark, please'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 884.0
      },
      "pred_interval": {
        "start": 930.0,
        "end": 1080.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.0,
        "end": 196.0,
        "average": 121.5
      },
      "rationale_metrics": {
        "rouge_l": 0.10344827586206898,
        "text_similarity": 0.23721683025360107,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction does not provide the requested timing or the relative anchor/target timestamps, instead mentioning a slide title (unrelated detail) and only vaguely stating order; it omits key factual elements from the correct answer and adds unsupported content."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'Next slide, please' at the 42-second mark, when does the slide titled 'Clinician and patient experience - Scotland' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 913.0,
        "end": 913.1
      },
      "pred_interval": {
        "start": 870.0,
        "end": 1080.0
      },
      "iou": 0.00047619047619058445,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 43.0,
        "end": 166.89999999999998,
        "average": 104.94999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.1818181818181818,
        "text_similarity": 0.40436023473739624,
        "llm_judge_score": 2,
        "llm_judge_justification": "Incorrect\u2014the ground truth indicates the slide appears immediately after the instruction (one second later, at 913.0s / ~43s), whereas the prediction wrongly states it appears at the same 42s moment as the cue."
      }
    },
    {
      "question_id": "001",
      "question": "During the discussion of what works well with video calls, when does the speaker express finding it much easier to interact with groups on a video call than on the telephone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1053.0,
        "end": 1062.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.04523809523809524,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 197.5,
        "average": 100.25
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.4419137239456177,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the main content that the speaker finds group interaction easier on video than telephone, but it omits the required precise timestamps/temporal relation and adds an unsupported claim about efficiency, so it is incomplete relative to the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions technical issues with patient bandwidth, when does he advise to choose patients correctly to avoid those difficulties?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1134.0,
        "end": 1135.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.007142857142857143,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 84.0,
        "end": 124.5,
        "average": 104.25
      },
      "rationale_metrics": {
        "rouge_l": 0.25352112676056343,
        "text_similarity": 0.602382481098175,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys that the advice comes after discussing bandwidth issues but omits the precise timestamps and incorrectly frames it as following a remark about video calls being more efficient, adding an unfounded detail."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' to introduce the smart phone camera, when does he specifically point out his wife's iPhone on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1213.0,
        "end": 1215.0
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1260.0
      },
      "iou": 0.009523809523809525,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 163.0,
        "end": 45.0,
        "average": 104.0
      },
      "rationale_metrics": {
        "rouge_l": 0.36065573770491804,
        "text_similarity": 0.6164101362228394,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction asserts the speaker pointed out his wife's iPhone 'at that moment,' contradicting the ground truth which places that action 10 seconds later (1213\u20131215s) and omits the provided timestamps and temporal relation."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying 'Next slide please', when does the 'Sharing content' slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.574,
        "end": 1249.574
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.004761904761904762,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.57400000000007,
        "end": 190.42599999999993,
        "average": 104.5
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.48513883352279663,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and contradictory: it names a different slide ('High-quality camera on phone') and provides no timing, whereas the correct answer specifies the 'Sharing content' slide appearing at 1248.574s."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'You can share things', when does he point towards the screen showing the brain scan?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1252.25,
        "end": 1252.85
      },
      "pred_interval": {
        "start": 1380.0,
        "end": 1440.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 127.75,
        "end": 187.1500000000001,
        "average": 157.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.24489795918367344,
        "text_similarity": 0.5946239233016968,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the pointing occurs after the phrase, but it omits the key factual details (the precise timestamps and interval) provided in the correct answer, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "During the discussion about poor picture quality, when does the speaker suggest clearing browser history?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1313.823,
        "end": 1315.286
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1440.0
      },
      "iou": 0.006966666666666502,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.82300000000009,
        "end": 124.71399999999994,
        "average": 104.26850000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.7029920816421509,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly indicates the suggestion comes after the discussion (matching the relative order) but omits the key factual details\u2014the exact timestamps and timing window\u2014required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying \"Thank you very much for that\", when does he state he is handing over to Jane?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.837,
        "end": 1430.682
      },
      "pred_interval": {
        "start": 1410.0,
        "end": 1520.0
      },
      "iou": 0.016772727272727522,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.83699999999999,
        "end": 89.31799999999998,
        "average": 54.077499999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.3921568627450981,
        "text_similarity": 0.5459414720535278,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the sequence (he hands over to Jane after thanking), but it omits the precise timestamps and incorrectly implies an immediate handover, whereas the ground truth specifies a ~1.8s delay and exact start/end times."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman (Jane) describes the challenges of managing patients over the telephone, when does she mention that they had a pilot of 'Near Me' even prior to Covid?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1609.855,
        "end": 1624.692
      },
      "pred_interval": {
        "start": 1520.0,
        "end": 1620.0
      },
      "iou": 0.09690329729110134,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 89.85500000000002,
        "end": 4.692000000000007,
        "average": 47.27350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.26865671641791045,
        "text_similarity": 0.5755163431167603,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the relative relation (she mentions the pilot after describing telephone challenges) but omits the key factual details and timestamps provided in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that using 'Near Me' felt quite adventurous, when does she state that its use became vital to their whole service?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1636.0,
        "end": 1643.0
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1800.0
      },
      "iou": 0.03333333333333333,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.0,
        "end": 157.0,
        "average": 101.5
      },
      "rationale_metrics": {
        "rouge_l": 0.393939393939394,
        "text_similarity": 0.6726405620574951,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction restates that she said Near Me felt adventurous and later became vital, but it omits the required timing details and relation specifics (timestamps and 'after' relation), so key factual elements are missing."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes asking Mark to go back to the previous slide, when does she say 'Thank you'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1676.54,
        "end": 1678.02
      },
      "pred_interval": {
        "start": 1590.0,
        "end": 1800.0
      },
      "iou": 0.007047619047619134,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 86.53999999999996,
        "end": 121.98000000000002,
        "average": 104.25999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.6939042806625366,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that she says 'Thank you' once she finishes asking Mark to go back, but it omits all required timing information and the target span specified in the correct answer, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the 'Training and preparation' slide appears, when does the speaker mention the 'Level 1' training?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1791.0,
        "end": 1791.5
      },
      "pred_interval": {
        "start": 5.2,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1785.8,
        "end": 1754.9,
        "average": 1770.35
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.5235295295715332,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely mismatched: the anchor/target times and described events (speaker intro and 'I am a final year medical student') do not correspond to the slide change at 1774.4s or the 'Level 1 training' utterance at 1791.0s in the reference. Only the vague 'after' relation coincides, but the core temporal and content details are wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing tele-swallowing partners as 'our eyes and our hands and our ears', when does she start talking about preparing the clinical room?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1897.0,
        "end": 1901.0
      },
      "pred_interval": {
        "start": 35.0,
        "end": 36.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1862.0,
        "end": 1864.4,
        "average": 1863.2
      },
      "rationale_metrics": {
        "rouge_l": 0.19354838709677422,
        "text_similarity": 0.5897998213768005,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is wholly inconsistent with the reference: it cites different utterances and timestamps (5\u201336s) instead of the correct ~1895\u20131901s segment, and the stated relation/content do not match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses tele-swallowing partners preparing the clinical room, when does she next talk about them providing reassurance to patients?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1906.0,
        "end": 1910.0
      },
      "pred_interval": {
        "start": 74.4,
        "end": 81.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1831.6,
        "end": 1828.2,
        "average": 1829.9
      },
      "rationale_metrics": {
        "rouge_l": 0.12307692307692308,
        "text_similarity": 0.5283424854278564,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely mismatched: it gives different timestamps and content (speaker introduction and 'final year medical student') rather than the described 'preparing the clinical room' and later 'providing reassurance', so it fails to identify the correct segments or relation."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning emergency procedures in place onsite, when does the slide change to 'Technology/equipment'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1971.6,
        "end": 1972.0
      },
      "pred_interval": {
        "start": 1950.0,
        "end": 2160.0
      },
      "iou": 0.0019047619047623378,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.59999999999991,
        "end": 188.0,
        "average": 104.79999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.33798128366470337,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted time (210.0s) contradicts the correct visual slide change at ~1971.6\u20131972.0s and omits the anchor interval and the once_finished relation, so it is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "During the time the 'Technology/equipment' slide is displayed, when does the speaker discuss the need for a device with a webcam and microphone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2024.079,
        "end": 2026.579
      },
      "pred_interval": {
        "start": 2160.0,
        "end": 2160.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 135.92100000000005,
        "end": 133.42100000000005,
        "average": 134.67100000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.12698412698412698,
        "text_similarity": 0.33262038230895996,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the mention occurs during the 'Technology/equipment' slide, but it omits the key factual timestamps (anchor 1971.600\u20132148.197 and target 2024.079\u20132026.579) requested by the question."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the general category of 'certain resources' for teleswallow sessions, when does she mention 'appropriate diet and fluid consistencies'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.952,
        "end": 2061.952
      },
      "pred_interval": {
        "start": 2160.0,
        "end": 2160.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 101.04799999999977,
        "end": 98.04799999999977,
        "average": 99.54799999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.19672131147540983,
        "text_similarity": 0.17961332201957703,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamp (210.0s) is far from the correct target window (2058.952s\u20132061.952s) and omits the anchor timestamp and the specified 'next' relation, so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that remote swallowing assessments are not intended to fully replace face-to-face assessments, when does she mention that they are a very useful addition?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2159.677,
        "end": 2162.619
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.014009523809523845,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.677000000000135,
        "end": 177.38099999999986,
        "average": 103.529
      },
      "rationale_metrics": {
        "rouge_l": 0.3870967741935484,
        "text_similarity": 0.4064497947692871,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates that she mentions it but omits the key factual details in the correct answer (the precise timestamps and that the target immediately follows the anchor's speech), so it fails to provide the required timing information."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning gathering feedback from those who completed the training, when does she start talking about evaluating quantitative data?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2164.643,
        "end": 2186.427
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.10373333333333383,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.64300000000003,
        "end": 153.57299999999987,
        "average": 94.10799999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.5207555294036865,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction restates the event sequence but provides no timing or the immediate-follow relation given in the correct answer (timestamps 2185.427s \u2192 2186.427s), so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes her presentation by saying 'thank you very much for listening', when does the video visually transition to the male presenter?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2257.0,
        "end": 2258.0
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.004761904761904762,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 127.0,
        "end": 82.0,
        "average": 104.5
      },
      "rationale_metrics": {
        "rouge_l": 0.41509433962264153,
        "text_similarity": 0.651172399520874,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that the video transitions to the male presenter after the first speaker, but it omits the crucial timestamps (E1=2256.0s, E2=2257.0s) and the note that the transition immediately follows the anchor's speech, making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that picking up cues is difficult, when does she start talking about 'points to consider' for virtual technology?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2491.8,
        "end": 2498.2
      },
      "pred_interval": {
        "start": 2490.0,
        "end": 2670.0
      },
      "iou": 0.035555555555553536,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.800000000000182,
        "end": 171.80000000000018,
        "average": 86.80000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333334,
        "text_similarity": 0.34795117378234863,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the sequence (she finishes and then starts discussing 'points to consider'), but it omits the key factual elements from the correct answer\u2014specifically the precise timestamps (start at 2491.8s and duration until 2498.2s) and the explicit 'once_finished' timing relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions conducting a 'sprint audit' with patients, when does she state that 'most were very satisfied' with the virtual appointments?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2515.0,
        "end": 2516.0
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 155.0,
        "end": 184.0,
        "average": 169.5
      },
      "rationale_metrics": {
        "rouge_l": 0.37931034482758624,
        "text_similarity": 0.5965785980224609,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the temporal relation (that the 'most were very satisfied' remark comes after the 'sprint audit' mention) but omits the required precise timestamps (E1 at 2509.5s and E2 between 2515.0\u20132516.0), leaving out key factual details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that patients found virtual technology 'more acceptable', when does she say 'So moving on to the next slide'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2638.0,
        "end": 2639.3
      },
      "pred_interval": {
        "start": 2700.0,
        "end": 2730.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.0,
        "end": 90.69999999999982,
        "average": 76.34999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.43333333333333335,
        "text_similarity": 0.47047457098960876,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (that the 'moving on' remark follows the 'more acceptable' line) but omits the key factual details \u2014 the required timestamps (2637.6s and 2638.0\u20132639.3s) \u2014 making it incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing confidentiality, when does she begin to mention the subtlety of the therapeutic relationship?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2693.583,
        "end": 2697.126
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2880.0
      },
      "iou": 0.016871428571429144,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.583000000000084,
        "end": 182.8739999999998,
        "average": 103.22849999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.6176354885101318,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the topics but erroneously states the transition is immediate; the ground truth shows a ~5-second gap (confidentiality ends at 2688.583s, therapeutic relationship begins at 2693.583s), so the timing is incorrect and key temporal detail is omitted."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'It all comes down to Wi-Fi', when does she state that 'delivery of remote therapy is very, very difficult'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.0,
        "end": 2729.0
      },
      "pred_interval": {
        "start": 2670.0,
        "end": 2880.0
      },
      "iou": 0.009523809523809525,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.0,
        "end": 151.0,
        "average": 104.0
      },
      "rationale_metrics": {
        "rouge_l": 0.5396825396825397,
        "text_similarity": 0.6109870672225952,
        "llm_judge_score": 10,
        "llm_judge_justification": "The prediction correctly states that the target utterance occurs after the anchor and conveys the short delay ('quickly'), matching the reference's relative timing without adding or contradicting facts."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'So next slide', when does the slide visually change to 'Practical considerations'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2884.0,
        "end": 2884.2
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 3060.0
      },
      "iou": 0.0009523809523800862,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.0,
        "end": 175.80000000000018,
        "average": 104.90000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.6344192028045654,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly states the slide changes after the verbal cue, but it omits the precise timestamps (2883.0s and 2884.0s) and the detail that the change is immediate."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing 'Practical considerations', when does she first mention 'increasing reflective feedback'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2913.483,
        "end": 2916.268
      },
      "pred_interval": {
        "start": 2850.0,
        "end": 3060.0
      },
      "iou": 0.013261904761904069,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.483000000000175,
        "end": 143.73199999999997,
        "average": 103.60750000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.2926829268292683,
        "text_similarity": 0.725396990776062,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and lacks the required timestamps; it also implies the mention occurs after the discussion rather than during it (the correct answer states the mention at 2913.483s falls within the practical considerations discussion), so it is largely incomplete and imprecise."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"for the patients\", when does the slide change to \"WHERE WE ARE NOW\"?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3067.769,
        "end": 3068.2
      },
      "pred_interval": {
        "start": 3030.0,
        "end": 3240.0
      },
      "iou": 0.002052380952381143,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.76899999999978,
        "end": 171.80000000000018,
        "average": 104.78449999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.37499999999999994,
        "text_similarity": 0.6516342163085938,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the slide changes after the speaker says 'for the patients' (matching the relation), but it omits the precise timing details and visibility timing provided in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says \"open up for some discussion\", when does the discussion slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3163.435,
        "end": 3163.7
      },
      "pred_interval": {
        "start": 3240.0,
        "end": 3450.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.56500000000005,
        "end": 286.3000000000002,
        "average": 181.43250000000012
      },
      "rationale_metrics": {
        "rouge_l": 0.35000000000000003,
        "text_similarity": 0.6271111965179443,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the temporal relation (the slide appears after the phrase) but omits the key factual details\u2014explicit timestamps and the exact moment the slide becomes fully visible\u2014provided in the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the first male speaker asks about attendees' experience with Near Me, when does the second male speaker begin talking about starting to use NearMe?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.9,
        "end": 3312.0
      },
      "pred_interval": {
        "start": 3210.0,
        "end": 3420.0
      },
      "iou": 0.2052380952380948,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.90000000000009,
        "end": 108.0,
        "average": 83.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.4313725490196078,
        "text_similarity": 0.4657377600669861,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the second speaker speaks after the first, but the timing is wildly incorrect (210s vs the actual ~20.1s difference and the provided absolute timestamps), so it fails on key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second male speaker finishes stating the advantages and utility of NearMe, when does he mention supplementing normal activities?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.4,
        "end": 3293.32
      },
      "pred_interval": {
        "start": 3420.0,
        "end": 3630.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 131.5999999999999,
        "end": 336.67999999999984,
        "average": 234.13999999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.42279791831970215,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly indicates the event occurs after the speaker finishes, but gives a grossly incorrect time (210s) whereas the reference shows a 5s gap (3288.40 \u2212 3283.40), so the timing is factually wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the first man finishes reading Jenny's chat message, when does he ask the audience if they would find guidance helpful?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3411.0,
        "end": 3415.0
      },
      "pred_interval": {
        "start": 3400.0,
        "end": 3600.0
      },
      "iou": 0.02,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 185.0,
        "average": 98.0
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705882,
        "text_similarity": 0.477848619222641,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly conveys the sequence (he asks after reading), but it omits all required numeric timestamps, the target span, and the absolute\u2192relative timing information, so it is incomplete for the task."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first man finishes reading John Hogan's comment about clinical interviewing, when does he state he was quite skeptical?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3434.9,
        "end": 3437.7
      },
      "pred_interval": {
        "start": 3510.0,
        "end": 3600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 75.09999999999991,
        "end": 162.30000000000018,
        "average": 118.70000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.39285714285714285,
        "text_similarity": 0.4440957009792328,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction merely restates the event without providing the required timing or relation details (target span and timestamps) present in the correct answer, omitting all key factual elements."
      }
    },
    {
      "question_id": "003",
      "question": "After the second woman mentions neuropsychology bringing out guidance, when is the next time a woman speaks about professional guidance?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3511.043,
        "end": 3528.447
      },
      "pred_interval": {
        "start": 3600.0,
        "end": 3600.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 88.95699999999988,
        "end": 71.55299999999988,
        "average": 80.25499999999988
      },
      "rationale_metrics": {
        "rouge_l": 0.22641509433962262,
        "text_similarity": 0.5275750160217285,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction directly contradicts the ground truth: there is a later mention of professional guidance by the third woman starting around 3500s (target span 3511.043\u20133528.447), so claiming no further mention is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 36 people joined the session, when does he talk about taking the next steps with Richard and the team?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3574.7,
        "end": 3576.5
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3618.0
      },
      "iou": 0.03750000000000379,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.699999999999818,
        "end": 41.5,
        "average": 23.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.10344827586206896,
        "text_similarity": 0.2322838455438614,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the remark about next steps follows the mention of 36 people, but it fails to provide the requested precise timing information (start/end timestamps) given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker makes a plea to fill in the survey, when does he ask if listeners would like to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3592.9,
        "end": 3594.1
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3618.0
      },
      "iou": 0.02499999999999621,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.90000000000009,
        "end": 23.90000000000009,
        "average": 23.40000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.21874999999999997,
        "text_similarity": 0.1973710060119629,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the event occurs after the plea, but it omits the specific timestamps (3586.5\u20133588.0 and 3592.9\u20133594.1) and the required timing detail, so it is incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes thanking everyone for joining the session today, when does he mention that the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3599.8,
        "end": 3603.2
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3618.0
      },
      "iou": 0.07083333333332575,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.800000000000182,
        "end": 14.800000000000182,
        "average": 22.300000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.1791044776119403,
        "text_similarity": 0.19788259267807007,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the content (that the speaker says the session will be recorded and resources provided after thanking attendees) but fails to provide the crucial timing details and exact timestamps/phrase required by the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'where did we start?', when does she mention considering moving to Near Me for patient contacts?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2332.719,
        "end": 2336.344
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2520.0
      },
      "iou": 0.017261904761904763,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.71900000000005,
        "end": 183.65599999999995,
        "average": 103.1875
      },
      "rationale_metrics": {
        "rouge_l": 0.12244897959183673,
        "text_similarity": 0.13412339985370636,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction acknowledges that the speaker mentions moving to Near Me after asking 'where did we start?', but it fails to provide the required timing information (anchor and target timestamps) and thus omits key factual details from the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says the pandemic came along, when does she mention adopting Near Me as their default for routine people?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2367.217,
        "end": 2412.045
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2520.0
      },
      "iou": 0.21346666666666655,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.2170000000001,
        "end": 107.95499999999993,
        "average": 82.58600000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.14545454545454545,
        "text_similarity": 0.1467791497707367,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the semantic content (that Near Me was adopted after the pandemic) but omits the key factual details from the reference\u2014specifically the anchor/target time intervals (2349.476\u20132350.756s and 2367.217\u20132412.045s) and the explicit anchor\u2192target relation."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the results of the focus groups for the qualitative study, when does she introduce the quotes from the participants?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2511.0,
        "end": 2512.0
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2520.0
      },
      "iou": 0.004761904761904762,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 201.0,
        "end": 8.0,
        "average": 104.5
      },
      "rationale_metrics": {
        "rouge_l": 0.21428571428571427,
        "text_similarity": 0.31934410333633423,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that quotes are introduced after the results description but omits the key factual details (the exact timing: E1 ends ~2469.0s and E2 starts at 2511.0s\u20132512.0s), so it is incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks to fill in the survey, when does he ask if listeners want to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3591.7,
        "end": 3595.8
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3617.0
      },
      "iou": 0.08723404255319923,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.699999999999818,
        "end": 21.199999999999818,
        "average": 21.449999999999818
      },
      "rationale_metrics": {
        "rouge_l": 0.3098591549295775,
        "text_similarity": 0.30872640013694763,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the engagement question occurs later, but it misidentifies the anchor (saying 'after discussing the survey results' instead of after a plea to fill the survey) and adds an unfounded detail ('show of hands'), so it is largely incorrect or incomplete."
      }
    },
    {
      "question_id": "002",
      "question": "Before the speaker thanks the speakers for their expertise, when does he mention the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3599.9,
        "end": 3603.7
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3617.0
      },
      "iou": 0.08085106382978142,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.90000000000009,
        "end": 13.300000000000182,
        "average": 21.600000000000136
      },
      "rationale_metrics": {
        "rouge_l": 0.2972972972972973,
        "text_similarity": 0.33728229999542236,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction fails to state that the recording/resources mention occurs before the thanks and instead implies they happen together or after discussing the topic, contradicting the correct answer's explicit ordering and timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker initially thanks the audience for joining, when does he deliver his final 'thank you very much' for the session?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3614.6,
        "end": 3615.4
      },
      "pred_interval": {
        "start": 3570.0,
        "end": 3617.0
      },
      "iou": 0.01702127659574855,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.59999999999991,
        "end": 1.599999999999909,
        "average": 23.09999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.2962962962962963,
        "text_similarity": 0.4176338315010071,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction is vague and omits the required timestamps and the explicit relation that the final 'thank you very much' occurs at 3614.6\u20133615.4 after the earlier anchor; it also adds unsupported details about covering points and audience engagement."
      }
    },
    {
      "question_id": "001",
      "question": "After Mark introduces Dr. John Mckeown and Dr. Naomi Dow, when does he ask Dr. Dow to describe how they've been using Near Me?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.48,
        "end": 34.4
      },
      "pred_interval": {
        "start": 3.8,
        "end": 45.7
      },
      "iou": 0.069689737470167,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.68,
        "end": 11.300000000000004,
        "average": 19.490000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.23333333333333334,
        "text_similarity": 0.7226905822753906,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the temporal relation ('after') right but misidentifies both events and their timestamps (E1/E2 times and content differ significantly from the reference), so it largely fails to match the correct annotations."
      }
    },
    {
      "question_id": "002",
      "question": "Once Dr. Naomi Dow finishes explaining how students take part in consultations, when does Mark ask Dr. Mckeown about the impact on the teaching team?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.96,
        "end": 124.4
      },
      "pred_interval": {
        "start": 45.0,
        "end": 60.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.96,
        "end": 64.4,
        "average": 69.18
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.6171209812164307,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is incorrect: it cites entirely different timestamps and event content (5.2s/35.0s vs. 117.60s/118.96s) and mislabels the relation, so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker introduces the concept of emotions in the session, when does the female speaker first mention 'real patients'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.9,
        "end": 202.6
      },
      "pred_interval": {
        "start": 150.0,
        "end": 360.0
      },
      "iou": 0.0033333333333332793,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.900000000000006,
        "end": 157.4,
        "average": 104.65
      },
      "rationale_metrics": {
        "rouge_l": 0.10126582278481011,
        "text_similarity": 0.31877678632736206,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect and contradicts the ground truth: the reference gives precise timestamps (male at 150.0s, female 'real patients' at 201.9\u2013202.6s, relation=after), whereas the prediction denies any mention and provides irrelevant visual description."
      }
    },
    {
      "question_id": "002",
      "question": "Once the interviewer finishes asking the question about comparing models, when does the female speaker finish explaining the advantages of 'Near Me' regarding real patients and capacity?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 198.7,
        "end": 306.9
      },
      "pred_interval": {
        "start": 150.0,
        "end": 360.0
      },
      "iou": 0.5152380952380952,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.69999999999999,
        "end": 53.10000000000002,
        "average": 50.900000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.05,
        "text_similarity": 0.1272023767232895,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated to the question\u2014providing irrelevant visual description and denying mentions of patients\u2014while the correct answer specifies precise timestamps and a relation; it fails to address or match any required information."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the man is speaking on screen, when does he mention 'Near Me'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 342.0,
        "end": 344.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 361.0
      },
      "iou": 0.06451612903225806,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.0,
        "end": 17.0,
        "average": 14.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2448979591836735,
        "text_similarity": 0.38243287801742554,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and factually incorrect: the man does not speak 'throughout the video' and saying 'towards the end' contradicts the correct precise timing (E2 at 342.0\u2013344.0 during the man's speech 337.0\u2013350.7); it also omits all exact times."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying 'Thank you and goodbye', when do the 'NHS Scotland' and 'Near Me' logos appear with text links?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 361.0,
        "end": 392.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 32.0,
        "average": 21.0
      },
      "rationale_metrics": {
        "rouge_l": 0.14035087719298248,
        "text_similarity": 0.2876822352409363,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly states the logos appear after the man finishes (matching the 'once_finished' relation) but omits the key timing details (350.0\u2013350.7 for speech end and 351.0\u2013360.0 for logos) given in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the initial voiceover concludes with 'patient that day', when does the man on screen begin to say 'Thanks very much John and Amy'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 336.4,
        "end": 341.6
      },
      "pred_interval": {
        "start": 392.0,
        "end": 423.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.60000000000002,
        "end": 81.39999999999998,
        "average": 68.5
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.5581719875335693,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the phrase occurs after the voiceover (the relation), but it omits the key factual timing details (334.40s end, 336.40s\u2013341.6s for the phrase) required by the question."
      }
    }
  ]
}