{
  "topic_id": 2,
  "topic_name": "Job Interviews",
  "num_evaluated": 21,
  "aggregated_metrics": {
    "detailed": {
      "rouge_l_mean": 0.09740008634482093,
      "rouge_l_std": 0.023095994510806444,
      "text_similarity_mean": 0.2107645067430678,
      "text_similarity_std": 0.059204278415817435,
      "llm_judge_score_mean": 0.09523809523809523,
      "llm_judge_score_std": 0.42591770999996
    },
    "short": {
      "rouge_l_mean": 0.07669673258248785,
      "rouge_l_std": 0.03644407595707945,
      "text_similarity_mean": 0.1570721184391351,
      "text_similarity_std": 0.08916873150297012,
      "llm_judge_score_mean": 0.047619047619047616,
      "llm_judge_score_std": 0.21295885499998
    },
    "cider": {
      "cider_detailed": 4.478917468477902e-12,
      "cider_short": 0.00043433473999363704
    }
  },
  "per_entry_results": [
    {
      "video_id": "xliS9BijbOs",
      "video_number": "001",
      "detailed": {
        "rouge_l": 0.09411764705882353,
        "text_similarity": 0.16257363557815552,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only gives vague visual/mood descriptions and omits the video's core content: the 'sell me this pen' sales exercise, the man's challenge, the woman's initial generic pitch, and the crucial lesson of asking 'Why do you need this pen?' and selling the customer's solution rather than the product."
      },
      "short": {
        "rouge_l": 0.019801980198019802,
        "text_similarity": 0.07586976885795593,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is vague and focuses on ambient details (talking, music) while omitting all key plot points about the pen-selling challenge, the shift to customer-needs questioning, and the concluding lesson to ask \"Why do you need this pen?\"."
      }
    },
    {
      "video_id": "2Ba98C_Zess",
      "video_number": "002",
      "detailed": {
        "rouge_l": 0.10852713178294573,
        "text_similarity": 0.1449645608663559,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated\u2014the correct answer discusses preparing for U.S. visa interviews and confident presentation, while the prediction describes a speech about recycling and plastic waste, contradicting and omitting all key facts."
      },
      "short": {
        "rouge_l": 0.112,
        "text_similarity": 0.14217740297317505,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated\u2014it discusses recycling and plastic waste while the correct answer summarizes tips for presenting at a U.S. visa interview, omitting all key points and facts."
      }
    },
    {
      "video_id": "IwGQoK9v5AA",
      "video_number": "003",
      "detailed": {
        "rouge_l": 0.09740259740259741,
        "text_similarity": 0.21004901826381683,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated to the correct summary\u2014it describes a casual group conversation, whereas the correct answer details meeting 'House Rules' and an introduction to TTEC; key factual elements are missing and contradicted."
      },
      "short": {
        "rouge_l": 0.0625,
        "text_similarity": 0.18496304750442505,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated to the correct summary: it describes a conversation among women, while the correct answer lists meeting protocols and company/location details, so it omits all key factual elements."
      }
    },
    {
      "video_id": "2dgx53kiOBQ",
      "video_number": "004",
      "detailed": {
        "rouge_l": 0.05185185185185186,
        "text_similarity": 0.16442859172821045,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely mismatched\u2014it describes two men having a general conversation, whereas the correct answer describes a woman presenting three specific scenarios about lying in job interviews and advising a professional response; it omits all key details and contradicts the video's content."
      },
      "short": {
        "rouge_l": 0.12213740458015268,
        "text_similarity": 0.2242995947599411,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated to the correct summary: it omits all key points about reasons for leaving a job, recommended professional phrasing, and advice to keep answers short and positive, instead describing a generic conversation."
      }
    },
    {
      "video_id": "qKctM_6Ymbw",
      "video_number": "005",
      "detailed": {
        "rouge_l": 0.06015037593984963,
        "text_similarity": 0.10622359812259674,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated and only describes who speaks and background music; it omits all key content about Mandarin job-related phrases, vocabulary, interview questions, and outcomes from the correct summary."
      },
      "short": {
        "rouge_l": 0.08849557522123892,
        "text_similarity": 0.06687256693840027,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely about who is speaking and background music, and contains none of the Mandarin job-hunting phrases or content from the correct summary, so it fails to match semantically or factually."
      }
    },
    {
      "video_id": "VV9MlsraXmA",
      "video_number": "006",
      "detailed": {
        "rouge_l": 0.10309278350515463,
        "text_similarity": 0.2464081048965454,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated and contradictory to the correct summary: it describes a hair loss treatment and metadata features, omitting all three job-fair tips and the speaker's identity, so it fails to capture any key elements."
      },
      "short": {
        "rouge_l": 0.06060606060606061,
        "text_similarity": 0.1532253623008728,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated and incorrect: it describes a hair-loss topic and metadata rather than the three job-fair tips (dress to impress, research companies, engage and ask questions), omitting all key factual elements."
      }
    },
    {
      "video_id": "9u2lc73bWzI",
      "video_number": "007",
      "detailed": {
        "rouge_l": 0.07973421926910298,
        "text_similarity": 0.30550986528396606,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely different and contradictory: it describes a personal wartime/military account, whereas the correct answer outlines an interview-preparation video with Q&A and pronunciation practice; there is no substantive overlap."
      },
      "short": {
        "rouge_l": 0.04444444444444444,
        "text_similarity": 0.297693133354187,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is wholly unrelated and contradictory to the correct summary: it describes a personal military/war account, while the video actually provides interview Q&A, model responses, and pronunciation practice, so it omits all key elements and introduces incorrect content."
      }
    },
    {
      "video_id": "WOx3B-LSI3o",
      "video_number": "008",
      "detailed": {
        "rouge_l": 0.07352941176470588,
        "text_similarity": 0.28723859786987305,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated: it describes a woman recounting flight-attendant travel stories, whereas the correct answer details Kate Teves giving specific virtual interview tips (background, sound/internet, attire); all key elements are missing or contradicted."
      },
      "short": {
        "rouge_l": 0.0970873786407767,
        "text_similarity": 0.31679022312164307,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct answer: the reference outlines virtual interview tips (background, sound/connection, attire) while the prediction describes a flight attendant and airport scenes, omitting all key points."
      }
    },
    {
      "video_id": "N6M3gm6A4lw",
      "video_number": "009",
      "detailed": {
        "rouge_l": 0.09053497942386832,
        "text_similarity": 0.1895747035741806,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated and contradictory: it describes a war captivity narrative, while the correct answer summarizes interview and sales-career advice from a former car salesman, with no overlapping content."
      },
      "short": {
        "rouge_l": 0.096,
        "text_similarity": 0.017474250867962837,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated and factually contradicts the correct summary about automotive sales interview advice from Andy Elliott, instead describing a wartime captivity narrative that omits all key points from the reference."
      }
    },
    {
      "video_id": "Yl4s9AIrijU",
      "video_number": "010",
      "detailed": {
        "rouge_l": 0.10596026490066225,
        "text_similarity": 0.16987282037734985,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated: it describes a wartime speech about conflict and peace, whereas the reference summarizes advice about casual job interviews and preparation, with no overlap in content."
      },
      "short": {
        "rouge_l": 0.039999999999999994,
        "text_similarity": 0.02249496430158615,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct summary: it describes war and atrocities while the correct answer concerns casual job interviews and preparation, thus omitting and contradicting all key elements."
      }
    },
    {
      "video_id": "FMWQ0jSOX8I",
      "video_number": "011",
      "detailed": {
        "rouge_l": 0.12244897959183673,
        "text_similarity": 0.21524927020072937,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the reference summary: the correct video is about salon interview preparation, outfits, and tips, whereas the prediction describes a speech on recycling and plastic waste, omitting all key details and contradicting the topic."
      },
      "short": {
        "rouge_l": 0.13793103448275862,
        "text_similarity": 0.21307681500911713,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated to the correct answer: it discusses recycling and plastic waste while the correct answer summarizes salon interview preparation, omitting all key details and contradicting the video's topic."
      }
    },
    {
      "video_id": "jW__kov1qZs",
      "video_number": "012",
      "detailed": {
        "rouge_l": 0.08695652173913043,
        "text_similarity": 0.2627008855342865,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated and incorrect: it fabricates content about recycling, a phone number, weather, and pizza while omitting all key details about take-home UX design exercises, the four action items, the speaker's opinions, and calls to engage."
      },
      "short": {
        "rouge_l": 0.05555555555555555,
        "text_similarity": 0.20825794339179993,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely unrelated to the correct summary, omitting all key points about UX take-home design exercises and instead introducing irrelevant, fabricated content (recycling, a phone number, and weather)."
      }
    },
    {
      "video_id": "W6NUlYvx-C0",
      "video_number": "013",
      "detailed": {
        "rouge_l": 0.136986301369863,
        "text_similarity": 0.1774955540895462,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated\u2014describing a POW wartime interview\u2014whereas the correct answer summarizes HR advice on job applications, ATS keywords, and in-demand tech skills in Dubai; there is no semantic overlap."
      },
      "short": {
        "rouge_l": 0.058823529411764705,
        "text_similarity": 0.12243970483541489,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct summary; it describes a prisoner-of-war account while the correct answer discusses recruitment, ATS keyword matching, resume tailoring, and in-demand tech skills in Dubai, so it fails to capture any key elements."
      }
    },
    {
      "video_id": "VLxZYcza_Cg",
      "video_number": "014",
      "detailed": {
        "rouge_l": 0.1348314606741573,
        "text_similarity": 0.10597015917301178,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated: it describes a speech about recycling, while the correct answer details a LinkedIn job-search tutorial by Vaishali; key facts are missing and the content contradicts the reference."
      },
      "short": {
        "rouge_l": 0.08247422680412371,
        "text_similarity": 0.10745850950479507,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct answer: it discusses recycling and plastic waste instead of job-search tips on LinkedIn for architects, so it fails to match any key facts or topics."
      }
    },
    {
      "video_id": "TLIoOLOjqwg",
      "video_number": "015",
      "detailed": {
        "rouge_l": 0.10752688172043011,
        "text_similarity": 0.2043430358171463,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated to the correct summary: it describes an environmental speech about recycling, omitting all key details about Adora's interview strategy, phases (before/during/after), and specific advice on preparation and interview conduct."
      },
      "short": {
        "rouge_l": 0.01639344262295082,
        "text_similarity": 0.054978303611278534,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct summary: it discusses recycling and plastic waste while the correct answer outlines interview strategies and advice, so there is no semantic overlap and all key elements are missing."
      }
    },
    {
      "video_id": "btNqPT6-P0U",
      "video_number": "016",
      "detailed": {
        "rouge_l": 0.0958904109589041,
        "text_similarity": 0.25831127166748047,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct summary: it describes a man recounting military/war experiences, whereas the ground truth is a detailed guide on interview preparation (dress, punctuality, STAR method, body language, company research). It omits all key points and introduces unrelated content."
      },
      "short": {
        "rouge_l": 0.12499999999999997,
        "text_similarity": 0.30594223737716675,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated to the correct answer\u2014it describes a wartime/military personal account while the correct summary covers interview presentation, punctuality, technical checks, and the STAR method\u2014thus it omits all key elements and contradicts the topic."
      }
    },
    {
      "video_id": "JEBRZq1hbY0",
      "video_number": "017",
      "detailed": {
        "rouge_l": 0.07006369426751592,
        "text_similarity": 0.2307504117488861,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated\u2014it describes a war testimony, while the correct answer details construction interview advice and preparation; it omits all key points and contradicts the video's actual content."
      },
      "short": {
        "rouge_l": 0.06504065040650407,
        "text_similarity": 0.10001771152019501,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated to the correct summary\u2014describing a war-time speech rather than construction job interview advice\u2014and thus fails to capture any key points or facts from the reference."
      }
    },
    {
      "video_id": "JQlpVKkKC_M",
      "video_number": "018",
      "detailed": {
        "rouge_l": 0.07843137254901959,
        "text_similarity": 0.15616759657859802,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is unrelated and generic, failing to capture any of the specific content, guidance, or details about the resume and cover letter workshop described in the correct answer."
      },
      "short": {
        "rouge_l": 0.047058823529411764,
        "text_similarity": 0.08355820178985596,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct summary, omitting all details about resume and cover letter guidance and instead giving an incorrect description of scenes and a bogus video length."
      }
    },
    {
      "video_id": "ZgVeEGCJ9s4",
      "video_number": "019",
      "detailed": {
        "rouge_l": 0.09966777408637875,
        "text_similarity": 0.3143955171108246,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely different from the correct answer: the reference describes HR guidance on competency-based interviews by Michael Emery, while the prediction narrates a prisoner-of-war account; there is no semantic overlap and the prediction contradicts/omits all key elements."
      },
      "short": {
        "rouge_l": 0.05102040816326531,
        "text_similarity": 0.1362590789794922,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct answer \u2014 it describes a POW experience while the correct summary covers competency-based interviews, frameworks, and tips; there is no overlap or shared facts."
      }
    },
    {
      "video_id": "k7uk0udlw2U",
      "video_number": "020",
      "detailed": {
        "rouge_l": 0.11267605633802816,
        "text_similarity": 0.26629260182380676,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated and contradictory to the correct answer: it describes a POW narrative in first person, whereas the correct answer summarizes an interview-preparation workshop with specific topics and speakers, so it omits all key elements."
      },
      "short": {
        "rouge_l": 0.07826086956521738,
        "text_similarity": 0.2588074207305908,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is entirely unrelated and contradicts the correct summary: it hallucinates a prisoner-of-war narrative and omits all key elements of the interview-prep workshop, STAR method, SAR examples, and mock-interview procedures."
      }
    },
    {
      "video_id": "Dwj3JwVroJU",
      "video_number": "021",
      "detailed": {
        "rouge_l": 0.13502109704641352,
        "text_similarity": 0.247534841299057,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated and incorrect: it describes a speech about recycling rather than the video about TEFL interview tips, Rita Engleza's hiring approach and pandemic-driven shift to online teaching, and Gallery Teachers' promotion."
      },
      "short": {
        "rouge_l": 0.15000000000000002,
        "text_similarity": 0.2058582454919815,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer is completely unrelated to the correct summary, discussing recycling and plastic waste instead of interview tips, online teaching, Rita Engleza, and the TEFL/ Gallery Teachers content, thus missing all key elements."
      }
    }
  ]
}