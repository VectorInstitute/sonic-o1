{
  "topic_id": 1,
  "topic_name": "Patient-Doctor Consultations",
  "num_evaluated": 269,
  "aggregated_metrics": {
    "mean_iou": 0.02986531400140805,
    "std_iou": 0.10997005041355774,
    "median_iou": 0.0,
    "R@0.3": {
      "recall": 0.048327137546468404,
      "count": 13,
      "total": 269
    },
    "R@0.5": {
      "recall": 0.01486988847583643,
      "count": 4,
      "total": 269
    },
    "R@0.7": {
      "recall": 0.0037174721189591076,
      "count": 1,
      "total": 269
    },
    "mae": {
      "start_mean": 65.26784758364315,
      "end_mean": 3544.6137769516727,
      "average_mean": 1804.940812267658
    },
    "rationale": {
      "rouge_l_mean": 0.27990188003164024,
      "rouge_l_std": 0.08373637803401601,
      "text_similarity_mean": 0.6718292528257938,
      "text_similarity_std": 0.12087755290710565,
      "llm_judge_score_mean": 2.6654275092936803,
      "llm_judge_score_std": 1.478329806903486
    },
    "rationale_cider": 0.1434114991191054
  },
  "per_question_results": [
    {
      "question_id": "001",
      "question": "After the speaker welcomes viewers and introduces himself as 'Karma Medic', when does he state that he is a 'final year medical student'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 35.0,
        "end": 36.62
      },
      "pred_interval": {
        "start": 28.0,
        "end": 30.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 6.619999999999997,
        "average": 6.809999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3555555555555556,
        "text_similarity": 0.789007306098938,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two events and their 'after' relationship, but the timestamps for both the anchor and target are substantially incorrect (target given ~28\u201330s vs correct 35.00\u201336.62s), so it is factually inaccurate on key details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes saying 'Now with that lovely disclaimer out of the way, let's get right into it', when does the text 'before the history' appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.06,
        "end": 57.06
      },
      "pred_interval": {
        "start": 55.0,
        "end": 56.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.0600000000000023,
        "end": 1.0600000000000023,
        "average": 1.0600000000000023
      },
      "rationale_metrics": {
        "rouge_l": 0.22916666666666666,
        "text_similarity": 0.7127400636672974,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the immediate/once-finished relationship, but it gives significantly incorrect timestamps for both the anchor (54.8s vs 56.03s) and the target (55.0s vs 56.06s), thus contradicting key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'So before starting the history, there's generally two things that I try and keep in mind', when does he begin describing 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 206.36,
        "end": 207.36
      },
      "pred_interval": {
        "start": 118.0,
        "end": 120.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 88.36000000000001,
        "end": 87.36000000000001,
        "average": 87.86000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.24742268041237112,
        "text_similarity": 0.7682579159736633,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor phrase and the 'after' relation and gives a close anchor time, but it places the target ('washing your hands') at a substantially incorrect timestamp (118s vs ~206s), omitting the key factual timing of E2."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the acronym 'ICE', when does he explain what it stands for?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 155.7,
        "end": 158.7
      },
      "pred_interval": {
        "start": 34.4,
        "end": 39.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 121.29999999999998,
        "end": 118.89999999999999,
        "average": 120.1
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.6287058591842651,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the explanation follows the mention and even gives the explanatory text, but the timestamps are substantially wrong (34.4\u201339.8s vs. 155.7\u2013158.7s in the reference) and thus the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the components of the WIPER acronym, when does he start elaborating on 'washing your hands'?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 207.0,
        "end": 212.0
      },
      "pred_interval": {
        "start": 64.1,
        "end": 69.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 142.9,
        "end": 142.4,
        "average": 142.65
      },
      "rationale_metrics": {
        "rouge_l": 0.3733333333333333,
        "text_similarity": 0.7429462671279907,
        "llm_judge_score": 1,
        "llm_judge_justification": "While the predicted answer captures the relative relation ('immediately after'), its timestamps for E1 and E2 (64.1s / 65.0\u201369.6s) are substantially different from the ground truth (205.0s / 207.0\u2013212.0s), so the prediction is factually incorrect on key temporal details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what brought the patient in, when does he explain what the 'history of presenting complaint' is about?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 346.0,
        "end": 351.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 350.0
      },
      "iou": 0.19047619047619047,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.0,
        "end": 1.0,
        "average": 8.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2033898305084746,
        "text_similarity": 0.6870709657669067,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the temporal relation ('after') and the general content right, but the timestamps are substantially off (predicted E2 at 334.4s vs gold 346.0s, and E1 timing also differs), so the timing alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "How long after the speaker says he'll put a picture of all possible questions does the \"REVIEW OF SYSTEMS\" checklist first appear on screen?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 539.8,
        "end": 543.7
      },
      "pred_interval": {
        "start": 510.0,
        "end": 510.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.799999999999955,
        "end": 33.200000000000045,
        "average": 31.5
      },
      "rationale_metrics": {
        "rouge_l": 0.1836734693877551,
        "text_similarity": 0.638994574546814,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the vague 'after' relation but the timestamps are significantly incorrect (E1 predicted 510.0s vs correct 534.817s; E2 predicted 510.5s vs correct 29.8s\u201333.7s relative), and the timing/visibility claim contradicts the reference."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is giving examples of systems review questions, when does he ask about \"tummy pain\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 565.74,
        "end": 566.422
      },
      "pred_interval": {
        "start": 530.0,
        "end": 531.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.74000000000001,
        "end": 35.422000000000025,
        "average": 35.58100000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.16,
        "text_similarity": 0.6214765310287476,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events but gives incorrect timestamps for both (predicts 530.0s vs ground truth 543.16\u2013567.70s for E1 and 555.74\u2013556.42s for E2), wrongly labels the relation as 'simultaneously' rather than 'during', and adds an unsupported audio cue; overall largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions the \"JAM THREADS\" mnemonic, when does he say the name \"Sketchy Medical\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 696.0,
        "end": 699.531
      },
      "pred_interval": {
        "start": 645.0,
        "end": 646.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.0,
        "end": 53.53099999999995,
        "average": 52.265499999999975
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.6685633063316345,
        "llm_judge_score": 1,
        "llm_judge_justification": "Both event timestamps are substantially incorrect (E1 off by ~10s, E2 off by ~50s and missing the correct end time) and the predicted 'immediately after' relation contradicts the true ~61s gap, so it fails to match the key timing facts."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker describes Sketchy Medical, when does he mention drugs' mechanism of action and side effects?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 701.0,
        "end": 703.982
      },
      "pred_interval": {
        "start": 690.0,
        "end": 695.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.0,
        "end": 8.481999999999971,
        "average": 9.740999999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.2696629213483146,
        "text_similarity": 0.8071969747543335,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation ('during') right but the timestamps are substantially incorrect and non-overlapping with the reference (predicted 690.0\u2013695.5s vs. reference 701.0\u2013703.982s and anchor mismatch), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks a general question about family health, when does he suggest being specific about asthma, diabetes, and hypertension?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 742.914,
        "end": 745.914
      },
      "pred_interval": {
        "start": 705.5,
        "end": 715.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.41399999999999,
        "end": 30.913999999999987,
        "average": 34.16399999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.20952380952380953,
        "text_similarity": 0.6098589897155762,
        "llm_judge_score": 3,
        "llm_judge_justification": "While the prediction correctly identifies that the specific mention occurs after the general question, the timestamps are significantly incorrect and even overlap the events (E2 starts with E1) rather than matching the later interval given in the reference, so the timing is not accurate."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the importance of signposting, when does he ask if the patient uses any recreational drugs?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 811.123,
        "end": 812.664
      },
      "pred_interval": {
        "start": 728.0,
        "end": 733.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 83.12300000000005,
        "end": 79.16399999999999,
        "average": 81.14350000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.6997267007827759,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the question follows immediately after signposting, but it incorrectly reports and misaligns the timestamps (both events at 728.0s and different end time), introducing factual errors and timing contradictions with the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"concerns from ICE\", when does he start saying \"Just generally, if you're feeling stuck\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 880.187,
        "end": 883.471
      },
      "pred_interval": {
        "start": 911.22,
        "end": 911.88
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.033000000000015,
        "end": 28.408999999999992,
        "average": 29.721000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.5333333333333333,
        "text_similarity": 0.656446099281311,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor/target and the 'after' relation, but the timestamps are substantially inaccurate (about 31s later for both anchor and target), so the timing does not match the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says \"golden rulebook\", when does he open both hands outwards in a gesture?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 895.8,
        "end": 897.5
      },
      "pred_interval": {
        "start": 918.2,
        "end": 918.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.40000000000009,
        "end": 20.899999999999977,
        "average": 21.650000000000034
      },
      "rationale_metrics": {
        "rouge_l": 0.339622641509434,
        "text_similarity": 0.7102811336517334,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events and correct 'after' relation, but the timestamps are substantially off for both anchor and target (and the target duration is much shorter), so it fails to match the ground-truth timing details."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying \"I hope you find this video useful\", when does he say \"Peace\"?",
      "video_id": "STnLNbRHYhw",
      "video_number": "001",
      "segment": {
        "start": 870.0,
        "end": 923.0
      },
      "gt_interval": {
        "start": 910.148,
        "end": 910.609
      },
      "pred_interval": {
        "start": 921.88,
        "end": 922.06
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.731999999999971,
        "end": 11.450999999999908,
        "average": 11.59149999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.456140350877193,
        "text_similarity": 0.6955643892288208,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the ordering right ('after'/'once_finished') but the timestamps are substantially inaccurate (anchor ~921.8s vs 909.546s and target ~922.06s vs 910.148s, ~12s error), so it fails on factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying he has an appointment at 10 am, when does the green text 'Sure, what's your name?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 6.1,
        "end": 8.2
      },
      "pred_interval": {
        "start": 6.0,
        "end": 6.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.09999999999999964,
        "end": 2.1999999999999993,
        "average": 1.1499999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.380952380952381,
        "text_similarity": 0.8120597004890442,
        "llm_judge_score": 9,
        "llm_judge_justification": "The prediction preserves the key relation (appears immediately after) and roughly correct timing, but has minor timestamp inaccuracies (predicts both events at 6.0s, whereas ground truth is 5.9s and 6.1s), implying simultaneity rather than a brief after interval."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes stating his name, when does the green text 'Thank you, Lucas. Please take a seat...' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 11.9,
        "end": 19.0
      },
      "pred_interval": {
        "start": 14.0,
        "end": 14.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.0999999999999996,
        "end": 5.0,
        "average": 3.55
      },
      "rationale_metrics": {
        "rouge_l": 0.24,
        "text_similarity": 0.6078048348426819,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the green text follows the man saying his name, but it gives incorrect times (14.0s vs ground-truth 10.6s anchor and 11.9\u201319.0s target) and wrongly claims the text appears immediately at 14.0s, contradicting the true onset and relation."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks 'How long is the wait?', when does the green text 'About 10 minutes. Would you like some water while you wait?' appear?",
      "video_id": "6PAwe6jndns",
      "video_number": "002",
      "segment": {
        "start": 0.0,
        "end": 37.0
      },
      "gt_interval": {
        "start": 22.1,
        "end": 25.3
      },
      "pred_interval": {
        "start": 21.0,
        "end": 21.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.1000000000000014,
        "end": 4.300000000000001,
        "average": 2.700000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.15384615384615385,
        "text_similarity": 0.6122469902038574,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the order but misstates both timestamps (anchor is given as 21.0s vs 19.5\u201320.7s; target as 21.0s vs 22.1\u201325.3s) and incorrectly claims the text appears immediately after instead of after a slight pause, so it contradicts key temporal details."
      }
    },
    {
      "question_id": "002",
      "question": "After the video explains the 'we're a team' approach with animated graphics, when does the speaker appear at his desk looking at a computer?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 34.6,
        "end": 36.0
      },
      "pred_interval": {
        "start": 42.5,
        "end": 44.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.899999999999999,
        "end": 8.200000000000003,
        "average": 8.05
      },
      "rationale_metrics": {
        "rouge_l": 0.2363636363636364,
        "text_similarity": 0.8092459440231323,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the order and relationship ('animated explanation' then speaker) correct but the timestamps are substantially off (about 8\u20139s later) and durations contradict the reference, so it is largely incorrect on the required temporal alignment."
      }
    },
    {
      "question_id": "003",
      "question": "While the speaker says 'take that extra bit of time to listen', when does the 'OK' hand gesture emoji appear?",
      "video_id": "WR5dACe-spg",
      "video_number": "003",
      "segment": {
        "start": 0.0,
        "end": 59.0
      },
      "gt_interval": {
        "start": 44.0,
        "end": 45.5
      },
      "pred_interval": {
        "start": 38.0,
        "end": 39.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.0,
        "end": 6.0,
        "average": 6.0
      },
      "rationale_metrics": {
        "rouge_l": 0.42105263157894735,
        "text_similarity": 0.8378279209136963,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the temporal relationship right ('during') but the timestamps are substantially incorrect (both events are ~6\u20137s earlier than the ground truth), so it is largely factually wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After Nurse Kim mentions graduating as a registered nurse, when does she talk about working for many different pharmaceutical companies?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 43.0,
        "end": 50.475
      },
      "pred_interval": {
        "start": 32.2,
        "end": 41.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.799999999999997,
        "end": 8.575000000000003,
        "average": 9.6875
      },
      "rationale_metrics": {
        "rouge_l": 0.16216216216216217,
        "text_similarity": 0.6187038421630859,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction identifies the same events and the 'after' relation, but the timestamps are inaccurate (E1 ~3s late, E2 ~1.1s early), it omits the E2 end time, and incorrectly asserts the target begins immediately after the anchor, which contradicts the reference timeline."
      }
    },
    {
      "question_id": "002",
      "question": "Once Nurse Kim finishes describing her background as an 'incredible journey', when does she mention training side-by-side with Dr. Jugenberg for five years?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 149.87,
        "end": 153.25
      },
      "pred_interval": {
        "start": 96.9,
        "end": 97.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 52.97,
        "end": 55.55,
        "average": 54.26
      },
      "rationale_metrics": {
        "rouge_l": 0.14285714285714285,
        "text_similarity": 0.5741079449653625,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the event content and general ordering right (target occurs after the anchor) but the timestamps and boundaries are incorrect (predicts ~96.9\u201397.7s vs ground truth anchor end at 108.275s and target 109.870\u2013113.25s), and it wrongly asserts immediate adjacency and uses the anchor start time instead of the correct end time."
      }
    },
    {
      "question_id": "001",
      "question": "While Nurse Kim explains options and possible outcomes, when does she begin examining the patient's stomach?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 157.5,
        "end": 160.5
      },
      "pred_interval": {
        "start": 177.2,
        "end": 180.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.69999999999999,
        "end": 19.5,
        "average": 19.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.21818181818181817,
        "text_similarity": 0.6257117390632629,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies both events but gives times ~20s later and states the exam occurs after the explanation, contradicting the ground truth that the stomach exam occurs during her speech; thus it is mostly incorrect though it references relevant cues."
      }
    },
    {
      "question_id": "002",
      "question": "After Nurse Kim finishes discussing the benefits, risks, and possible complications of the procedure, when does she start talking about asymmetry?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 169.7,
        "end": 172.0
      },
      "pred_interval": {
        "start": 185.0,
        "end": 187.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.300000000000011,
        "end": 15.0,
        "average": 15.150000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.25490196078431376,
        "text_similarity": 0.808320164680481,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') but the key timestamps are significantly off (~15\u201317s later than the reference) and it adds unsupported detail about an audio cue, so it does not match the ground truth. "
      }
    },
    {
      "question_id": "003",
      "question": "Once Nurse Kim finishes explaining that the one-hour consultation cannot provide everything you need to know, when does she mention that they are always available?",
      "video_id": "5KcshgQ45XU",
      "video_number": "004",
      "segment": {
        "start": 150.0,
        "end": 269.0
      },
      "gt_interval": {
        "start": 201.5,
        "end": 203.71
      },
      "pred_interval": {
        "start": 194.8,
        "end": 197.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.699999999999989,
        "end": 6.710000000000008,
        "average": 6.704999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.32432432432432434,
        "text_similarity": 0.6527441143989563,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same phrases but gives significantly different timestamps (194.8/197.0s vs 201.5/201.5s) and incorrectly labels the relation as 'after' rather than the immediate transition; it also adds visual/audio cues not present in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces himself and the topic, when does the slide change to 'Objectives for today's lesson'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 24.379,
        "end": 24.5
      },
      "pred_interval": {
        "start": 15.44,
        "end": 15.88
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.939000000000002,
        "end": 8.62,
        "average": 8.7795
      },
      "rationale_metrics": {
        "rouge_l": 0.22727272727272727,
        "text_similarity": 0.7215542793273926,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps for both E1 and E2 contradict the ground truth (predicted ~15s vs correct E1 ends at 14.567s and E2 at 24.379s) and wrongly asserts the slide appears immediately after the introduction, so it is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes listing the objectives for the lesson, when does the slide change to 'Brain storming time'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 46.529,
        "end": 47.0
      },
      "pred_interval": {
        "start": 63.96,
        "end": 64.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.430999999999997,
        "end": 17.400000000000006,
        "average": 17.4155
      },
      "rationale_metrics": {
        "rouge_l": 0.3055555555555556,
        "text_similarity": 0.7099992632865906,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer preserves the correct relation (slide change occurs immediately after the objectives), but the timestamps are significantly off (predicted ~64s vs ground truth 45.8\u201346.53s), so the key factual elements (correct times) are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes defining communication as the successful passage of a message from one person to another, when does he start explaining how good communication manifests in medical practice by informing patients of their diagnosis?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 153.0,
        "end": 177.0
      },
      "pred_interval": {
        "start": 150.0,
        "end": 151.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 25.80000000000001,
        "average": 14.400000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.4850802719593048,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the anchor content and the subsequent target statement, but the time boundaries are misaligned (predicted anchor ends and target starts 1.8s earlier than the reference), so the temporal relationship is imprecise."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the 'Importance of communication' slide, when does he begin discussing that good doctor-patient communication has been linked to improved patient satisfaction?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 190.0,
        "end": 198.0
      },
      "pred_interval": {
        "start": 186.0,
        "end": 187.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 10.699999999999989,
        "average": 7.349999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.17721518987341772,
        "text_similarity": 0.6910418272018433,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction\u2019s timestamps and quoted utterances conflict significantly with the reference (anchor should be ~177.5\u2013179.5s and target ~190\u2013198s); it misplaces the target immediately after the anchor and therefore omits the actual brief intervening explanation, so the timing relationship is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker starts talking about how a lot of malpractice lawsuits have been documented, when does he explicitly advise being aware of communication's importance to avoid lawsuits?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 226.0,
        "end": 271.0
      },
      "pred_interval": {
        "start": 230.0,
        "end": 232.8
      },
      "iou": 0.06222222222222248,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.0,
        "end": 38.19999999999999,
        "average": 21.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222227,
        "text_similarity": 0.8025026321411133,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the advice phrase as the target and that it follows the lawsuits comment, but it mislocates the anchor (should be at 198\u2013212s) and thus gives an incorrect timeline for the initial statement, a significant factual error."
      }
    },
    {
      "question_id": "001",
      "question": "After the initial slide 'Communication is not just talking' is displayed, when does the speaker mention that physicians can improve health outcomes?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 339.28,
        "end": 346.0
      },
      "pred_interval": {
        "start": 373.3,
        "end": 387.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.02000000000004,
        "end": 41.0,
        "average": 37.51000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.3296703296703297,
        "text_similarity": 0.7906550765037537,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the mention occurs after the slide, but it fails on key factual details: it omits a precise timestamp for E1 and gives substantially incorrect start/end times for E2 compared to the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "During the display of the slide showing two images (bored girl vs. smiling doctor/patient), when does the speaker describe the first image as depicting a 'horribly bored' lady?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 354.8,
        "end": 359.0
      },
      "pred_interval": {
        "start": 428.3,
        "end": 438.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.5,
        "end": 79.39999999999998,
        "average": 76.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7818925380706787,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction misstates the event timings: E1 is given much later (399.0s vs 347.8s) and E2 is placed at 428.3\u2013438.4s instead of 354.8\u2013359.0s, so the timestamps contradict the ground truth; it correctly asserts a 'during' relationship qualitatively but is factually incorrect on key temporal details."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker defines verbal communication as 'using spoken words', when is the next time they define non-verbal communication?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 428.87,
        "end": 433.596
      },
      "pred_interval": {
        "start": 517.3,
        "end": 527.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 88.42999999999995,
        "end": 93.404,
        "average": 90.91699999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.27906976744186046,
        "text_similarity": 0.7608639597892761,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the non\u2011verbal definition occurs after the verbal definition, but its timestamps substantially conflict with the reference (major factual mismatch), so it is not a close match."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker introduces the 'golden minute', when does he describe the patient's hypothetical response?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 613.818,
        "end": 630.0
      },
      "pred_interval": {
        "start": 551.48,
        "end": 556.54
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 62.337999999999965,
        "end": 73.46000000000004,
        "average": 67.899
      },
      "rationale_metrics": {
        "rouge_l": 0.380952380952381,
        "text_similarity": 0.8742332458496094,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer matches only the high-level relation ('after') but misidentifies both anchor and target time spans by large margins (predicted times do not overlap the ground-truth intervals), so it fails to correctly align the events."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions 'Checking facts', when does he mention the next essential element of listening?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 641.157,
        "end": 642.461
      },
      "pred_interval": {
        "start": 576.44,
        "end": 580.64
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 64.71699999999998,
        "end": 61.821000000000026,
        "average": 63.269000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.3098591549295775,
        "text_similarity": 0.7709628939628601,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it misidentifies the anchor (saying 'checking feelings' at ~576s instead of 'Checking facts' at ~613s), gives wrong timestamps, and hallucinates 'checking the motivation of the patient' instead of the correct next element 'Checking feelings'."
      }
    },
    {
      "question_id": "003",
      "question": "Before the speaker says 'So, for example, we have three main types of reflective listening', when does he explain what reflective listening involves?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 667.457,
        "end": 687.051
      },
      "pred_interval": {
        "start": 594.12,
        "end": 605.68
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 73.33699999999999,
        "end": 81.3710000000001,
        "average": 77.35400000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.20512820512820512,
        "text_similarity": 0.7837141156196594,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is completely incorrect: timestamps and entity roles (anchor/target) do not match the ground truth, and the relationship is wrong\u2014ground truth says the definition occurs before the examples, while the prediction places and labels them differently."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the three main types of reflective listening, when does he start explaining the 'Repeating' example?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 710.0,
        "end": 737.0
      },
      "pred_interval": {
        "start": 736.56,
        "end": 737.36
      },
      "iou": 0.016081871345031227,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.559999999999945,
        "end": 0.36000000000001364,
        "average": 13.45999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.18666666666666665,
        "text_similarity": 0.5934798121452332,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer only matches the qualitative relation ('after') but the timestamps are substantially incorrect (predicted list end 736.56s vs correct 696.1s; predicted start 737.36s vs correct 710.0s) and it adds an unsupported quoted phrase, so it contradicts key factual details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the 'Repeating' example, when does he introduce 'Rephrasing'?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 720.0,
        "end": 720.4
      },
      "pred_interval": {
        "start": 752.96,
        "end": 753.92
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.960000000000036,
        "end": 33.51999999999998,
        "average": 33.24000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.26865671641791045,
        "text_similarity": 0.7031478881835938,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the ordering (Rephrasing occurs after Repeating) but gives substantially different timestamps and a slightly altered quoted phrase, contradicting the key factual timing in the reference, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes discussing 'Reflection of feeling by showing empathy', when does the 'Non-verbal' slide appear?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 780.0,
        "end": 821.5
      },
      "pred_interval": {
        "start": 814.56,
        "end": 815.68
      },
      "iou": 0.026987951807229026,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.559999999999945,
        "end": 5.82000000000005,
        "average": 20.189999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.30985915492957744,
        "text_similarity": 0.6600131392478943,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer gets the relation correct (the slide appears after the empathy discussion) but the timestamps are substantially off from the reference (\u224836s difference for both events), so the key factual timing information is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises to smile, when does he mention checking for signs of pain?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.045,
        "end": 882.0
      },
      "pred_interval": {
        "start": 870.0,
        "end": 877.2
      },
      "iou": 0.3462500000000072,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.044999999999959,
        "end": 4.7999999999999545,
        "average": 3.922499999999957
      },
      "rationale_metrics": {
        "rouge_l": 0.19444444444444445,
        "text_similarity": 0.6350187063217163,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly captures the events and the 'after' relationship and roughly matches end times, but it misstates the start time of E2 (predicts ~878.4s vs reference 873.045s) and adds an extra detail ('dress') not in the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses the cultural interpretations of folding arms, when does he advise to avoid folding arms?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 932.0,
        "end": 936009.0
      },
      "pred_interval": {
        "start": 909.6,
        "end": 916.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.399999999999977,
        "end": 935093.0,
        "average": 467557.7
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.7619228959083557,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events and the advice content, but the timestamps are substantially misaligned: predicted E2 is placed much earlier (within the cultural discussion) rather than at 932.0\u2013936.0s as in the reference, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker instructs to introduce yourself to the patient, when does he advise to explain your role as a student or intern?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 985.0,
        "end": 990.853
      },
      "pred_interval": {
        "start": 933.2,
        "end": 938.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.799999999999955,
        "end": 52.452999999999975,
        "average": 52.126499999999965
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.6723605394363403,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the events and their ordering (E2 occurs after E1 and matches the described content), but the provided timestamps are substantially different from the reference, so the temporal information is factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"if you're in the hospital\", when does he refer to \"inpatient patients\"?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1059.6,
        "end": 1059.8
      },
      "pred_interval": {
        "start": 1061.64,
        "end": 1065.36
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.040000000000191,
        "end": 5.559999999999945,
        "average": 3.800000000000068
      },
      "rationale_metrics": {
        "rouge_l": 0.2622950819672131,
        "text_similarity": 0.6620440483093262,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the target comes after, but the predicted target timestamps (1061.64\u20131065.36s) are substantially later than the reference (1059.6\u20131059.8s) and the added claim of 'immediately following' is unsupported, so key temporal details are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is explaining how to start a consultation, when does he give the example \"how can I help you today?\"",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1069.0,
        "end": 1070.0
      },
      "pred_interval": {
        "start": 1073.88,
        "end": 1076.34
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.880000000000109,
        "end": 6.339999999999918,
        "average": 5.610000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.175,
        "text_similarity": 0.7699395418167114,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the target phrase and the 'after' relationship, but both the anchor and target timestamps (and the anchor content) are substantially incorrect compared to the reference, so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes explaining the 'golden minute', when does he announce the end of the lecture?",
      "video_id": "junFruKQWI0",
      "video_number": "005",
      "segment": {
        "start": 1050.0,
        "end": 1121.0
      },
      "gt_interval": {
        "start": 1090.0,
        "end": 1094.0
      },
      "pred_interval": {
        "start": 1109.44,
        "end": 1114.86
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.440000000000055,
        "end": 20.8599999999999,
        "average": 20.149999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.2597402597402597,
        "text_similarity": 0.7749512195587158,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (the announcement occurs after and immediately following the anchor), but the provided timestamps are significantly different from the reference (off by ~17\u201320 seconds) and thus factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "While Raquel is talking about the hospital providing opportunities for nurses, when is she shown smiling and opening a package?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 2.0,
        "end": 4.5
      },
      "pred_interval": {
        "start": 10.16,
        "end": 11.82
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.16,
        "end": 7.32,
        "average": 7.74
      },
      "rationale_metrics": {
        "rouge_l": 0.17721518987341772,
        "text_similarity": 0.2913607358932495,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction grossly mislocates the visual event (10.16\u201311.82s vs correct 2.0\u20134.5s) and thus gives the wrong temporal relation ('after' rather than 'during'), although the anchor speech timing is roughly similar; this major error renders the answer incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Maria finishes saying that new nurses will be nudged to become lifelong learners, when does Precious state that the teamwork is strong?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 14.321,
        "end": 16.486
      },
      "pred_interval": {
        "start": 14.72,
        "end": 15.88
      },
      "iou": 0.5357967667436488,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.3990000000000009,
        "end": 0.6059999999999999,
        "average": 0.5025000000000004
      },
      "rationale_metrics": {
        "rouge_l": 0.1904761904761905,
        "text_similarity": 0.4810776710510254,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction is roughly in the same time region but gives incorrect timestamps (off by ~0.4\u20130.6s) and wrongly asserts the events are simultaneous, contradicting the reference which shows Precious starts immediately after Maria rather than exactly together."
      }
    },
    {
      "question_id": "003",
      "question": "After Reny states that the hospital does things up to a magnet level, when does Raquel say her values align with the hospital's values?",
      "video_id": "afTFvR7pRqg",
      "video_number": "006",
      "segment": {
        "start": 0.0,
        "end": 53.0
      },
      "gt_interval": {
        "start": 42.854,
        "end": 50.692
      },
      "pred_interval": {
        "start": 35.08,
        "end": 37.94
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.774000000000001,
        "end": 12.752000000000002,
        "average": 10.263000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.186046511627907,
        "text_similarity": 0.40766748785972595,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the relative order ('after') correct but the provided timestamps are significantly different from the reference (off by ~10s) and it omits the detail that Raquel's speech continues over the logo, so the timing information is incorrect/incomplete."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states that healthcare in Siem Reap is not the best, when is the Royal Angkor International Hospital first shown on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 94.0,
        "end": 99.1
      },
      "pred_interval": {
        "start": 103.53,
        "end": 117.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.530000000000001,
        "end": 18.10000000000001,
        "average": 13.815000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2653061224489796,
        "text_similarity": 0.6908897161483765,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction largely contradicts the reference: it gives incorrect timestamps for E1 and E2, misidentifies which hospital is shown/described when, and adds unsupported sequence details, so it fails to match the correct timing and events."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he begin describing the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 180.289,
        "end": 185.074
      },
      "pred_interval": {
        "start": 151.93,
        "end": 153.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.35899999999998,
        "end": 31.674000000000007,
        "average": 30.016499999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.23255813953488372,
        "text_similarity": 0.6089927554130554,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies a sequential relationship (one hospital described before the next), but the timestamps and quoted utterance for both events conflict substantially with the ground truth and the predicted E2 text does not match the reference, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he visited a clinic for chest congestion, when does he mention the Paschern Dental Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 209.8,
        "end": 211.4
      },
      "pred_interval": {
        "start": 148.0,
        "end": 148.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 61.80000000000001,
        "end": 63.400000000000006,
        "average": 62.60000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.1839080459770115,
        "text_similarity": 0.7522964477539062,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the high-level relation ('after') but is largely incorrect: it gives wrong timestamps (148.0s vs correct ~203.6\u2013209.8s), claims simultaneous starts/transition rather than the specified timing, and mislabels the anchor\u2014so it fails to match the reference details."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker finishes describing the Neak Tep Hospital, when does he introduce the Ly Sreyvyna II Clinic?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 184.0,
        "end": 184.8
      },
      "pred_interval": {
        "start": 112.0,
        "end": 112.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.0,
        "end": 72.80000000000001,
        "average": 72.4
      },
      "rationale_metrics": {
        "rouge_l": 0.3218390804597701,
        "text_similarity": 0.7093335390090942,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the qualitative relation ('after') correct but contradicts the ground-truth timestamps (predicts 112.0s vs the correct 182.0s and 184.0\u2013184.8s) and even implies simultaneous starts, so it is largely factually incorrect about timing and adds unsupported detail."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker introduces the Cigna International Health Policy, when is the insurance quote form displayed with personal information?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 130.0,
        "end": 130.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 221.0,
        "end": 230.0,
        "average": 225.5
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.7529153823852539,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction notes the same two events (speaker introducing Cigna and the form appearing) but gives completely different timestamps and asserts simultaneity/incorrect relation and an unsupported audio cue, contradicting the ground-truth timing and relation."
      }
    },
    {
      "question_id": "002",
      "question": "After the voiceover states that the Cigna policy is \"fairly typical of policies of this type\", when does the Cigna website display the form for inputting personal details to get a quote?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 352.9,
        "end": 358.0
      },
      "pred_interval": {
        "start": 21.238,
        "end": 21.238
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 331.662,
        "end": 336.762,
        "average": 334.212
      },
      "rationale_metrics": {
        "rouge_l": 0.20779220779220778,
        "text_similarity": 0.7234069108963013,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives incorrect timestamps (21.238s vs correct ~351\u2013352.9s), marks the anchor and target as simultaneous (contradicting the correct 'after' relation), and thus fails to match the key temporal details in the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the voiceover mentions \"evacuation service, also part of Cigna plan\", when is the Global Rescue website displayed on screen?",
      "video_id": "NiGj1YBR4Y4",
      "video_number": "007",
      "segment": {
        "start": 330.0,
        "end": 456.0
      },
      "gt_interval": {
        "start": 384.0,
        "end": 431.0
      },
      "pred_interval": {
        "start": 44.622,
        "end": 44.622
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 339.378,
        "end": 386.378,
        "average": 362.878
      },
      "rationale_metrics": {
        "rouge_l": 0.26966292134831465,
        "text_similarity": 0.7913650274276733,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: the timestamps are completely different from the reference (44.622s vs 379.0s/384.0s), it incorrectly claims the website appears simultaneously with the anchor, and it omits the longer onscreen duration (until 431.0s). These factual and temporal discrepancies contradict the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the host concludes his introduction about the fight in modern healthcare, when does he introduce Sarah?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 19.4,
        "end": 22.0
      },
      "pred_interval": {
        "start": 17.0,
        "end": 21.0
      },
      "iou": 0.3200000000000003,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.3999999999999986,
        "end": 1.0,
        "average": 1.6999999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.24691358024691357,
        "text_similarity": 0.5644674301147461,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the qualitative relation (Sarah is introduced after the host's remarks) but gives incorrect timestamps (17.0s vs correct 18.0s for host end, and 18.0s vs correct 19.4s start for Sarah), omits the correct end time, and includes a likely hallucinated quote."
      }
    },
    {
      "question_id": "002",
      "question": "While Sarah is introducing herself and her genetic condition, when does she mention having her very first surgery?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 104.08,
        "end": 108.8
      },
      "pred_interval": {
        "start": 57.2,
        "end": 61.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 46.879999999999995,
        "end": 47.0,
        "average": 46.94
      },
      "rationale_metrics": {
        "rouge_l": 0.22535211267605634,
        "text_similarity": 0.6648905277252197,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives times that contradict the reference by about 40 seconds, so the temporal information is incorrect; although it correctly identifies the content of the first-surgery remark, the timing is factually wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once Sarah finishes describing her role as a volunteer patient representative for a non-profit organization, when does the static image showing her behind a 'CHILDREN'S TUMOR FOUNDATION' table appear?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 185.0,
        "end": 190.0
      },
      "pred_interval": {
        "start": 206.89,
        "end": 211.01
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.889999999999986,
        "end": 21.00999999999999,
        "average": 21.44999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.3799843192100525,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives the wrong anchor content and times (206.89s vs correct 150s) and places the static image at the wrong moment (206.89s vs correct 185.0\u2013190.0s), so it fails to match the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once Sarah finishes explaining the purpose of the 'Shine a Light Walk' to raise money and awareness, when does the video clip showing children running at an outdoor event play?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 189.0,
        "end": 192.0
      },
      "pred_interval": {
        "start": 214.62,
        "end": 218.06
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.620000000000005,
        "end": 26.060000000000002,
        "average": 25.840000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3333333333333333,
        "text_similarity": 0.5761339664459229,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly preserves the sequence (clip follows Sarah's explanation) but gives substantially different timestamps and adds unsupported details (Steve's question timing); therefore it is largely incorrect relative to the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once Steve asks if the 'Shine a Light Walk' goes throughout the world, when does Sarah begin to explain that the walks do not?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 253.2,
        "end": 258.88
      },
      "pred_interval": {
        "start": 222.64,
        "end": 225.89
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.560000000000002,
        "end": 32.99000000000001,
        "average": 31.775000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.20512820512820512,
        "text_similarity": 0.41179898381233215,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the semantic fact that Sarah immediately responds that the walks do not go worldwide, but it gives incorrect timestamps (off by ~30s) and a wrong end time, so the key factual timing information is inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes asking Sarah what things in miscommunication can lead to delays or misdiagnosis, when does the woman start responding?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 362.48,
        "end": 365.44
      },
      "pred_interval": {
        "start": 330.0,
        "end": 340.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.48000000000002,
        "end": 25.439999999999998,
        "average": 28.960000000000008
      },
      "rationale_metrics": {
        "rouge_l": 0.20454545454545453,
        "text_similarity": 0.6115648150444031,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer gets the qualitative relation ('immediately after') right but the absolute timestamps are incorrect (330.0s/340.0s vs. 356.48s/362.48s) and the timing gap is misrepresented, so it only partially matches the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman gives the example of writing 'hyperthyroid instead of hypothyroid', when does the man respond with 'That that's pretty bad'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 389.2,
        "end": 432.5
      },
      "pred_interval": {
        "start": 380.0,
        "end": 390.0
      },
      "iou": 0.015238095238095455,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.199999999999989,
        "end": 42.5,
        "average": 25.849999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.18181818181818182,
        "text_similarity": 0.4939350485801697,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly approximates the man's response time but misstates the woman's example timing (370\u2013380s vs correct 385.28\u2013388.44s) and incorrectly labels the relation as 'immediately after' despite a short pause; key temporal details are therefore wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the man says he tried researching miscommunication problems, when does he state his finding about thousands of preventable deaths?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 446.56,
        "end": 535.68
      },
      "pred_interval": {
        "start": 420.0,
        "end": 450.0
      },
      "iou": 0.029737206085753795,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.560000000000002,
        "end": 85.67999999999995,
        "average": 56.119999999999976
      },
      "rationale_metrics": {
        "rouge_l": 0.1714285714285714,
        "text_similarity": 0.5291772484779358,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly locates the man's finding about thousands of preventable deaths (around 450s) and the temporal 'after' relationship, but it misplaces the initial research comment (predicts 420\u2013430s vs. the correct 435.0\u2013440.6s), so it's a partial but not fully accurate match."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman asks, \"What's in my budget to fix it?\", when does she start asking, \"How important is it to me to fix this issue?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 518.66,
        "end": 522.26
      },
      "pred_interval": {
        "start": 63.6,
        "end": 65.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 455.05999999999995,
        "end": 456.86,
        "average": 455.96
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.5610830783843994,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly states the target question occurs after the anchor and gives a start time for E2, but its timestamps differ from the reference and it omits E1's start time and E2's span, so it is not fully aligned with the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the man finishes saying, \"not continuing medical bills,\" when does he start asking, \"So, what does successful self-advocacy look like?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 643.04,
        "end": 646.32
      },
      "pred_interval": {
        "start": 106.1,
        "end": 107.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 536.9399999999999,
        "end": 538.62,
        "average": 537.78
      },
      "rationale_metrics": {
        "rouge_l": 0.2268041237113402,
        "text_similarity": 0.5106356143951416,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly identifies the temporal relation ('after') but gives substantially incorrect timestamps (106.1s/107.7s vs. 634.36s/643.04s) and understates the pause duration, so it fails on the key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the man finishes explaining what a doctor's follow-up might entail, when does the woman start asking, \"Or will I actually be able to get into your office in two weeks?\"",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 679.0,
        "end": 683.92
      },
      "pred_interval": {
        "start": 133.4,
        "end": 135.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 545.6,
        "end": 548.3199999999999,
        "average": 546.96
      },
      "rationale_metrics": {
        "rouge_l": 0.20618556701030927,
        "text_similarity": 0.7339208722114563,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the woman's question follows the man's, but the timestamp values are substantially different from the reference (133.4/135.6s vs. 677.92/679.00s), so the answer is factually incorrect on the key timing details."
      }
    },
    {
      "question_id": "001",
      "question": "Immediately after the woman asks if she should follow up if she is still experiencing symptoms, when does the man ask what if the symptoms go away?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 699.38,
        "end": 707.15
      },
      "pred_interval": {
        "start": 690.0,
        "end": 692.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.379999999999995,
        "end": 15.149999999999977,
        "average": 12.264999999999986
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.7783541083335876,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the order (man speaks after the woman) but the timestamps are substantially incorrect (off by ~7\u20139 seconds), omits the end times, and fails to reflect the reference's 'immediately follows' relation."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying to voice symptoms and concerns clearly, when does he give an example about shoulder pain?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 734.59,
        "end": 737.0
      },
      "pred_interval": {
        "start": 701.0,
        "end": 703.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.59000000000003,
        "end": 34.0,
        "average": 33.795000000000016
      },
      "rationale_metrics": {
        "rouge_l": 0.1797752808988764,
        "text_similarity": 0.7171947956085205,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the example immediately follows the anchor, but the reported timecodes are significantly different from the reference (off by ~31\u201333s) and thus fail to match the key factual timestamps."
      }
    },
    {
      "question_id": "003",
      "question": "Once the man finishes warning not to try putting a hand in an electrical outlet, when does the woman agree and say not to try that?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 810.0,
        "end": 812.0
      },
      "pred_interval": {
        "start": 731.0,
        "end": 733.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.0,
        "end": 79.0,
        "average": 79.0
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.7546591758728027,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures the dialogue content and that the woman's line immediately follows the man's, but the timestamps are significantly off (731/733s vs. the correct 808/810s), so it fails to provide the correct timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the woman finishes saying to assume benevolence of your doctor, when does the man begin to speak?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 878.9,
        "end": 879.1
      },
      "pred_interval": {
        "start": 870.0,
        "end": 870.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.899999999999977,
        "end": 9.100000000000023,
        "average": 9.0
      },
      "rationale_metrics": {
        "rouge_l": 0.27450980392156865,
        "text_similarity": 0.5655546188354492,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates the man speaks after the woman, but it gives substantially wrong timestamps (870.0s vs correct 878.0s/878.9s) and mischaracterizes timing as 'immediately after' coincident with the woman's end, which contradicts the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man asks about trying non-surgical options first, when does the woman reply 'Yes'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 899.7,
        "end": 900.1
      },
      "pred_interval": {
        "start": 904.4,
        "end": 905.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.699999999999932,
        "end": 5.0,
        "average": 4.849999999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.3174603174603175,
        "text_similarity": 0.7055522203445435,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction preserves the ordering and immediacy (woman replies right after the man), but the provided timestamps are incorrect by about 4.9\u20135.4 seconds compared with the reference, so the answer is factually inaccurate on key temporal details."
      }
    },
    {
      "question_id": "003",
      "question": "After the man concludes his statement about how to ask for another opinion, when does the woman respond that asking for another opinion is definitely valid?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 982.0,
        "end": 988.72
      },
      "pred_interval": {
        "start": 933.4,
        "end": 934.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.60000000000002,
        "end": 54.51999999999998,
        "average": 51.56
      },
      "rationale_metrics": {
        "rouge_l": 0.3188405797101449,
        "text_similarity": 0.6168112754821777,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the order and content (woman agrees it's valid) but the timestamps are substantially incorrect and the temporal relation ('immediately after') contradicts the reference timing and relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the man suggests bringing someone along if you're not feeling safe, when does the woman agree that it's advisable?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1127.0,
        "end": 1130.0
      },
      "pred_interval": {
        "start": 1161.48,
        "end": 1170.88
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.48000000000002,
        "end": 40.88000000000011,
        "average": 37.680000000000064
      },
      "rationale_metrics": {
        "rouge_l": 0.225,
        "text_similarity": 0.6944858431816101,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the dialogue content and the 'after' relationship between anchor and target, but the reported start times for both events differ substantially (by ~37\u201341 seconds) from the ground truth, so the temporal information is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman talks about a doctor not trusting a patient's pain because they don't act like they're in pain, when does she give an example of a loved one vouching for the patient?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1167.68,
        "end": 1174.48
      },
      "pred_interval": {
        "start": 1202.36,
        "end": 1213.64
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.679999999999836,
        "end": 39.16000000000008,
        "average": 36.91999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306123,
        "text_similarity": 0.6073876023292542,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the example and the 'after' relationship and even quotes the line, but the provided timestamps are substantially off (about 40 seconds later) from the ground-truth times, so the timing is factually incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks if it is legal to be given your own medical records, when does the woman confirm that it is?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1268.6,
        "end": 1270.7
      },
      "pred_interval": {
        "start": 1251.47,
        "end": 1253.69
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.12999999999988,
        "end": 17.00999999999999,
        "average": 17.069999999999936
      },
      "rationale_metrics": {
        "rouge_l": 0.15789473684210528,
        "text_similarity": 0.187687948346138,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives substantially different timestamps and asserts an immediate confirmation at ~1252s, which contradicts the ground-truth timings (~1264\u20131270s) and the correct temporal relation; thus it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman mentions that things have changed a lot with electronic medical records, when does the man state that bureaucracy reminds him of common barriers?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1333.0,
        "end": 1339.5
      },
      "pred_interval": {
        "start": 1283.85,
        "end": 1284.62
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.15000000000009,
        "end": 54.88000000000011,
        "average": 52.0150000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.20253164556962025,
        "text_similarity": 0.5122329592704773,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction directly contradicts the ground truth: it places the man's remark immediately after (~1283.85\u20131284.62s) while the correct answer places that statement much later (1333.0\u20131339.5s), so the timing and relationship are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the man asks about common barriers and how to overcome them, when does the woman share her fear of ants?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.36,
        "end": 1383.7
      },
      "pred_interval": {
        "start": 1305.25,
        "end": 1307.75
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.1099999999999,
        "end": 75.95000000000005,
        "average": 74.02999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.5002458095550537,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly identifies the temporal relation ('after') but the provided timestamps contradict the reference by a large margin (predicted ~1305\u20131307s vs. reference 1377.36\u20131383.7s), so key factual timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says to write things down on paper and give it to the doctor, when does he mention a doctor refusing to look at the paper?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1484.96,
        "end": 1490.0
      },
      "pred_interval": {
        "start": 1541.3,
        "end": 1547.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 56.33999999999992,
        "end": 57.90000000000009,
        "average": 57.120000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.4339622641509434,
        "text_similarity": 0.8353874683380127,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the target phrase and the relative order ('after'), but both event timestamps are substantially off and the anchor quote differs from the reference, so it mostly fails to match the correct anchor and timing."
      }
    },
    {
      "question_id": "002",
      "question": "While the woman discusses prioritizing cognition, when does she state that she would rather be in pain than have her mental capacity harmed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1534.64,
        "end": 1542.24
      },
      "pred_interval": {
        "start": 1583.7,
        "end": 1587.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.059999999999945,
        "end": 44.8599999999999,
        "average": 46.95999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.4158415841584159,
        "text_similarity": 0.7685854434967041,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction picks up the correct wording of the target sentence but misidentifies the anchor (uses the target phrase as E1), gives timestamps that are ~60s off from the reference, and therefore fails to correctly align the two events."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks 'Nord, what is that?', when does the woman state what NORD stands for?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1613.4,
        "end": 1615.4
      },
      "pred_interval": {
        "start": 1600.0,
        "end": 1603.77
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.400000000000091,
        "end": 11.63000000000011,
        "average": 12.5150000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.39999999999999997,
        "text_similarity": 0.8035900592803955,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the content and the 'immediately after' relationship, but the timestamps are significantly incorrect and internally inconsistent (E1/E2 at 1600s vs ground truth ~1611\u20131615s), and it slightly alters the phrase ('Diseases' vs 'Disease'). These factual timing errors warrant a low score."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman says 'I read that I need to start this at 30', when does she explain why she needs the doctor to order it?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1692.24,
        "end": 1711.28
      },
      "pred_interval": {
        "start": 1652.79,
        "end": 1659.97
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.450000000000045,
        "end": 51.309999999999945,
        "average": 45.379999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.3559322033898305,
        "text_similarity": 0.6700977087020874,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted anchor text matches the quoted line, the timestamps are substantially incorrect and the predicted explanation contradicts and hallucinates details (mentions insurance approval instead of asking the doctor to order it), so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the woman explains how to mirror a planned course of action, when does she suggest asking the doctor what they heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1797.0,
        "end": 1799.8
      },
      "pred_interval": {
        "start": 1806.3,
        "end": 1811.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.299999999999955,
        "end": 11.600000000000136,
        "average": 10.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.16363636363636364,
        "text_similarity": 0.6106464862823486,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies that the suggestion occurs after the mirroring explanation, but it misreports the precise timestamps and durations (anchor and target times differ substantially from the ground truth) and thus includes incorrect factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the man advises to 'just dig' and not use a medical dictionary, when does he ask if medical language can be 'dumbed down'?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1836.56,
        "end": 1841.52
      },
      "pred_interval": {
        "start": 1847.0,
        "end": 1862.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.440000000000055,
        "end": 21.279999999999973,
        "average": 15.860000000000014
      },
      "rationale_metrics": {
        "rouge_l": 0.1714285714285714,
        "text_similarity": 0.5845490097999573,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the qualitative relation ('after') and the quoted question roughly right, but the anchor and target timestamps are substantially incorrect and misaligned with the ground truth, so it fails to accurately locate the segments."
      }
    },
    {
      "question_id": "001",
      "question": "After the man asks what to do when doctors look rushed, when does the woman describe slowing down and capturing their attention?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1965.6,
        "end": 1973.5
      },
      "pred_interval": {
        "start": 1999.62,
        "end": 2002.97
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.01999999999998,
        "end": 29.470000000000027,
        "average": 31.745000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.3218390804597701,
        "text_similarity": 0.7378629446029663,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the same anchor and target actions and the temporal relation ('after'), but the provided timestamps deviate substantially from the ground-truth times (anchor and target are tens of seconds later), so timing is inaccurate despite semantic match."
      }
    },
    {
      "question_id": "002",
      "question": "Once the woman finishes suggesting a doctor might be having a bad day, when does the man humorously ask if doctors have bad days?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2002.5,
        "end": 2004.0
      },
      "pred_interval": {
        "start": 2023.87,
        "end": 2025.23
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.36999999999989,
        "end": 21.230000000000018,
        "average": 21.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.21739130434782608,
        "text_similarity": 0.6463983654975891,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the temporal relationship ('immediately after') and that the man's line directly follows the woman's, but it provides incorrect absolute timestamps (off by ~22 seconds) compared to the reference, so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the man introduces the 'five practical tips to advocate for yourself', when does the woman begin talking about writing down questions?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2195.28,
        "end": 2199.7
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.02104761904761723,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.2800000000002,
        "end": 140.30000000000018,
        "average": 102.79000000000019
      },
      "rationale_metrics": {
        "rouge_l": 0.1935483870967742,
        "text_similarity": 0.5617954730987549,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the two events and that the woman speaks after the man, but the provided timestamps are substantially earlier than the ground truth ranges and thus inaccurate, so it fails on temporal precision."
      }
    },
    {
      "question_id": "002",
      "question": "During the man's explanation about preparing beforehand, when does he demonstrate by pointing to his neck?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2235.0,
        "end": 2237.0
      },
      "pred_interval": {
        "start": 2130.0,
        "end": 2340.0
      },
      "iou": 0.009523809523809525,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 105.0,
        "end": 103.0,
        "average": 104.0
      },
      "rationale_metrics": {
        "rouge_l": 0.4705882352941177,
        "text_similarity": 0.8384565114974976,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the 'during' relationship and the action (pointing to his neck) but gives completely different and incorrect timestamps for both anchor and target compared to the ground truth, so it is largely factually wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the man describes getting dizzy when walking up and down stairs, when does the woman mention repeating back what was heard?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2316.0,
        "end": 2317.0
      },
      "pred_interval": {
        "start": 2454.36,
        "end": 2461.32
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 138.36000000000013,
        "end": 144.32000000000016,
        "average": 141.34000000000015
      },
      "rationale_metrics": {
        "rouge_l": 0.1794871794871795,
        "text_similarity": 0.6902543306350708,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer largely misidentifies both events (wrong speaker, wrong content and incorrect timestamps) and thus fails to match the reference; it only correctly states the temporal relation ('after')."
      }
    },
    {
      "question_id": "002",
      "question": "After the woman expresses her inability to distract herself from the pain, when does the man advise her to be specific?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2368.7,
        "end": 2369.5
      },
      "pred_interval": {
        "start": 2468.28,
        "end": 2471.36
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 99.58000000000038,
        "end": 101.86000000000013,
        "average": 100.72000000000025
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.7355843186378479,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and the 'after' relation, but the absolute timestamps are substantially shifted and the predicted events are adjacent (E1 ends when E2 starts), which contradicts the reference timing and reduces factual accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "After the man says 'document everything', when does the woman affirm the advice and tell viewers to take notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2504.5,
        "end": 2506.0
      },
      "pred_interval": {
        "start": 2529.4,
        "end": 2531.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.90000000000009,
        "end": 25.699999999999818,
        "average": 25.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.367816091954023,
        "text_similarity": 0.6833757758140564,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction matches the woman's affirmative content but gets the crucial timestamps wrong by ~25\u201330 seconds and incorrectly labels the response as simultaneous with the man's line; thus key temporal details are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes asking if one should ask permission before recording their doctor, when does the woman respond?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2531.6,
        "end": 2533.5
      },
      "pred_interval": {
        "start": 2561.4,
        "end": 2564.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 29.800000000000182,
        "end": 31.199999999999818,
        "average": 30.5
      },
      "rationale_metrics": {
        "rouge_l": 0.21505376344086022,
        "text_similarity": 0.6238285303115845,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the content and that the woman's reply is immediate, but the timestamps differ substantially (about 30 seconds later) from the reference, so the key factual timing is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman begins explaining the hope that doctors will focus more on patients with AI recording, when does she explain why she almost always checks her online appointment notes?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2566.0,
        "end": 2579.0
      },
      "pred_interval": {
        "start": 2593.7,
        "end": 2605.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.699999999999818,
        "end": 26.90000000000009,
        "average": 27.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.20512820512820515,
        "text_similarity": 0.5201447010040283,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction reproduces the correct quoted phrase but both E1 and E2 timestamps are significantly off and E2 is misaligned to start with E1; the claimed 'immediately after' relationship contradicts the reference timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man asks if one should be assertive, when does he introduce the topic of emotional intelligence?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2701.0,
        "end": 2710.0
      },
      "pred_interval": {
        "start": 2821.0,
        "end": 2826.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 120.0,
        "end": 116.0,
        "average": 118.0
      },
      "rationale_metrics": {
        "rouge_l": 0.2708333333333333,
        "text_similarity": 0.648881733417511,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures an immediate 'after' transition but has substantially wrong timestamps, misidentifies the event content (introducing a generic 'last topic' and attributing causality to the woman's 'Yes'), and includes unsupported/hallucinated details, so it largely disagrees with the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man says 'You wanna learn some breathing control', when does he start describing box breathing?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2740.0,
        "end": 2747.0
      },
      "pred_interval": {
        "start": 2840.0,
        "end": 2849.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 100.0,
        "end": 102.0,
        "average": 101.0
      },
      "rationale_metrics": {
        "rouge_l": 0.34615384615384615,
        "text_similarity": 0.7688452005386353,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly shifts both event timestamps by ~110s, mislabels the start of E2 (including the woman's 'Yeah') and asserts a 'simultaneous' relationship contrary to the reference that E2 follows the suggestion; these substantive temporal and relational errors make it largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the man is saying 'If you want, share your story in the comments', when is the 'COMMENT BELOW' graphic displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2883.16,
        "end": 2884.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 36.840000000000146,
        "end": 38.19999999999982,
        "average": 37.51999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.1272727272727273,
        "text_similarity": 0.6385332345962524,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the relationship (graphic displayed simultaneously/during the speech), but it gives substantially incorrect timestamps and duration (\u22482883.16\u20132884.8s) that conflict with the reference times around 2920.0\u20132923.0s, so it is factually incorrect on key details."
      }
    },
    {
      "question_id": "003",
      "question": "After the thumbs up icon appears on screen, when is the next graphic ('COMMENT BELOW') displayed?",
      "video_id": "9DJXPJsuPsc",
      "video_number": "008",
      "segment": {
        "start": 2850.0,
        "end": 2992.0
      },
      "gt_interval": {
        "start": 2920.0,
        "end": 2923.0
      },
      "pred_interval": {
        "start": 2957.0,
        "end": 2959.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.0,
        "end": 36.0,
        "average": 36.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2921348314606742,
        "text_similarity": 0.808741569519043,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states that the 'COMMENT BELOW' graphic follows the thumbs-up, but it gives entirely incorrect timestamps and durations (2957\u20132959s vs. the reference 2862s and 2920\u20132923s), so it contradicts key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "After Marissa Fourie introduces herself, when does she mention cross-cultural communication?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 34.2,
        "end": 36.5
      },
      "pred_interval": {
        "start": 31.93,
        "end": 35.59
      },
      "iou": 0.3041575492341358,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.270000000000003,
        "end": 0.9099999999999966,
        "average": 1.5899999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.7305870056152344,
        "llm_judge_score": 7,
        "llm_judge_justification": "The prediction correctly identifies the mention of 'cross-cultural communication' and the temporal relation 'after', and its E2 timestamps are close to the reference, but it mislocates E1 by several seconds (13.9s vs 8.1s), so the anchor timing is notably inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After mentioning cross-cultural communication, when does Marissa Fourie next mention personality-specific communication skills?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 37.0,
        "end": 39.0
      },
      "pred_interval": {
        "start": 36.42,
        "end": 39.46
      },
      "iou": 0.6578947368421054,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.5799999999999983,
        "end": 0.46000000000000085,
        "average": 0.5199999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.4166666666666667,
        "text_similarity": 0.6957858800888062,
        "llm_judge_score": 8,
        "llm_judge_justification": "The prediction captures the correct relation (next/immediately after) and the event sequence, with only small timing discrepancies (E2 start/end off by <0.6s and E1 start omitted), so it is largely accurate but not exact."
      }
    },
    {
      "question_id": "003",
      "question": "After encouraging viewers to join PhysioPlus, when does Marissa Fourie say 'See you there!'?",
      "video_id": "Lu_yCNjFZmU",
      "video_number": "009",
      "segment": {
        "start": 0.0,
        "end": 72.0
      },
      "gt_interval": {
        "start": 62.9,
        "end": 63.7
      },
      "pred_interval": {
        "start": 61.72,
        "end": 63.08
      },
      "iou": 0.09090909090909058,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.1799999999999997,
        "end": 0.6200000000000045,
        "average": 0.9000000000000021
      },
      "rationale_metrics": {
        "rouge_l": 0.4383561643835617,
        "text_similarity": 0.7019392251968384,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the two phrases and their order, but the timestamps disagree notably with the reference (predicted E2 starts 61.72s vs reference 62.9s and ends earlier), and it asserts 'immediately after' despite the timing mismatch, so accuracy is partial."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes mentioning \"the dosage in each area\", when does the woman in blue gloves point to the glabella area of the patient's forehead?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 4.469,
        "end": 4.8
      },
      "pred_interval": {
        "start": 5.0,
        "end": 5.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.5309999999999997,
        "end": 0.7000000000000002,
        "average": 0.6154999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2888888888888889,
        "text_similarity": 0.6237382888793945,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation (after) but the timestamps are substantially off (predicted ~0.8\u20131.0s later) and the pointer duration/visual cue details contradict the ground truth, so key factual timing elements are incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining the dosage for the brow lift, when does the woman in blue gloves point to the patient's upper lip?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 12.121,
        "end": 12.5
      },
      "pred_interval": {
        "start": 11.2,
        "end": 11.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.9210000000000012,
        "end": 0.8000000000000007,
        "average": 0.8605000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.2680412371134021,
        "text_similarity": 0.6866177320480347,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer matches the causal relation ('immediately after') but gives substantially incorrect timestamps (about 1s earlier) and a shorter pointer duration, and it adds a likely hallucinated visual cue (speaker's hand) not stated in the ground truth, so it is only loosely correct."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes explaining the dosage for the lip flip, when does the text \"TIME TO INJECT!\" appear on screen?",
      "video_id": "KjUhUHfcT_w",
      "video_number": "010",
      "segment": {
        "start": 0.0,
        "end": 21.0
      },
      "gt_interval": {
        "start": 18.291,
        "end": 21.0
      },
      "pred_interval": {
        "start": 17.0,
        "end": 18.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2910000000000004,
        "end": 3.0,
        "average": 2.1455
      },
      "rationale_metrics": {
        "rouge_l": 0.3076923076923077,
        "text_similarity": 0.6739588975906372,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the text appears after the explanation, but both timestamps and duration are substantially incorrect (E1 given as 16.8s vs 15.067s; E2 given as 17.0\u201318.0s vs 18.291s onward), and it introduces timing/duration details that contradict the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "Once the host welcomes Rich, when does Rich begin his response?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 33.015,
        "end": 34.078
      },
      "pred_interval": {
        "start": 33.2,
        "end": 33.4
      },
      "iou": 0.18814675446848098,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.18500000000000227,
        "end": 0.6780000000000044,
        "average": 0.4315000000000033
      },
      "rationale_metrics": {
        "rouge_l": 0.3157894736842105,
        "text_similarity": 0.8043556809425354,
        "llm_judge_score": 5,
        "llm_judge_justification": "The predicted answer gives a response start (33.2s) very close to the ground truth (33.015s), but it misstates the host timestamp (33.2s vs 31.333s), contradicts itself by placing anchor and response at the same time while claiming 'immediately after', and adds an unfounded quote\u2014so partially correct but inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "While Rich is explaining how medicine may have let relationships with patients deteriorate, when does he say that scientific facts will protect us?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 89.0,
        "end": 93.76
      },
      "pred_interval": {
        "start": 72.9,
        "end": 74.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 16.099999999999994,
        "end": 19.560000000000002,
        "average": 17.83
      },
      "rationale_metrics": {
        "rouge_l": 0.14814814814814814,
        "text_similarity": 0.6433156728744507,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly locates E2 (puts it at ~72.9\u201374.2s) whereas the reference places E2 at 89.0\u201393.76s; although it roughly notes the explanatory phrase and slightly mis-states E1 start, the major timing error contradicts the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the host asks what trust looks like in the future with intermediaries, when does Rich first discuss the stethoscope in relation to technology in medicine?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 112.0,
        "end": 113.0
      },
      "pred_interval": {
        "start": 89.4,
        "end": 96.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.599999999999994,
        "end": 16.5,
        "average": 19.549999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.24,
        "text_similarity": 0.7265088558197021,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the reference timestamps and relationship: the correct answer places the host at 106.718s and Rich's stethoscope remark at 112.700s, whereas the prediction incorrectly places both around 89.4\u201396.5s and claims immediate succession, so the timing/relationship is wrong despite mentioning the stethoscope."
      }
    },
    {
      "question_id": "001",
      "question": "After the man in glasses finishes describing the giant TV screen in a new hospital exam room, when does the video show a patient interacting with a screen in a hospital bed?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 167.6,
        "end": 177.6
      },
      "pred_interval": {
        "start": 202.8,
        "end": 206.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.20000000000002,
        "end": 29.099999999999994,
        "average": 32.150000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.3434343434343435,
        "text_similarity": 0.8653402328491211,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that the target occurs after the anchor and describes the patient interaction, but it substantially misreports the key timestamps (anchor and target times are shifted by ~33\u201335s from the ground truth), so it fails on precise temporal accuracy."
      }
    },
    {
      "question_id": "002",
      "question": "While the interviewer asks if technology can bring doctors and patients closer together, when is he holding a small white 'Trust tv' card?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 178.0,
        "end": 183.5
      },
      "pred_interval": {
        "start": 193.4,
        "end": 196.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.400000000000006,
        "end": 13.0,
        "average": 14.200000000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.23076923076923075,
        "text_similarity": 0.7837802767753601,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation right (the card shown 'during' the question) but gives substantially incorrect timestamps (starts ~15s later and different end time) and thus contradicts the ground-truth temporal intervals."
      }
    },
    {
      "question_id": "003",
      "question": "Once the interviewer thanks Rich and says viewers learned a lot, when does Rich respond 'It's really a pleasure'?",
      "video_id": "Xu67ngXWLXI",
      "video_number": "011",
      "segment": {
        "start": 150.0,
        "end": 228.0
      },
      "gt_interval": {
        "start": 210.3,
        "end": 212.1
      },
      "pred_interval": {
        "start": 217.0,
        "end": 219.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.699999999999989,
        "end": 7.099999999999994,
        "average": 6.8999999999999915
      },
      "rationale_metrics": {
        "rouge_l": 0.40816326530612246,
        "text_similarity": 0.8765180110931396,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction contradicts the ground truth on key facts: the timestamps and the interviewer's line differ (ground truth: anchor ends ~200.0s and target 210.3\u2013212.1s with 'Thank you'; prediction: 217.0\u2013219.2s with a different interviewer phrase), so it fails to match the reference."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker mentions learning about 'patient rapport', when does he discuss charting and interacting with other healthcare providers?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 2.075,
        "end": 9.55
      },
      "pred_interval": {
        "start": 0.0,
        "end": 2.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.075,
        "end": 7.550000000000001,
        "average": 4.8125
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.7146821022033691,
        "llm_judge_score": 10,
        "llm_judge_justification": "The predicted answer matches the reference in timing and sequence (E1 around 0s\u20131.7s, E2 around 2s) and conveys the same immediate 'after/once_finished' relation; wording differences (physicians vs healthcare providers, start times rounded) are minor paraphrases."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker talks about developing skills like putting an IV, when does he mention getting a patient discharged?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 15.42,
        "end": 24.583
      },
      "pred_interval": {
        "start": 9.0,
        "end": 10.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.42,
        "end": 14.582999999999998,
        "average": 10.5015
      },
      "rationale_metrics": {
        "rouge_l": 0.17582417582417584,
        "text_similarity": 0.6268966197967529,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor topic (putting an IV) and the target topic (patient discharge) but gives inaccurate timestamps and an incorrect relation\u2014placing the target inside the anchor span at 10.0s and labeling it 'after' rather than the ground-truth immediate 'once_finished' with target starting ~15.42s\u2014so it largely mismatches the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Make their problem, your problem', when does he introduce the importance of self-care?",
      "video_id": "6vqzBk6z6U4",
      "video_number": "012",
      "segment": {
        "start": 0.0,
        "end": 60.0
      },
      "gt_interval": {
        "start": 45.009,
        "end": 48.396
      },
      "pred_interval": {
        "start": 33.0,
        "end": 34.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.009,
        "end": 14.396,
        "average": 13.2025
      },
      "rationale_metrics": {
        "rouge_l": 0.43999999999999995,
        "text_similarity": 0.578994870185852,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly identifies the transition cue ('Next') and that the self-care comment follows the previous point, but it gives substantially incorrect timestamps (33s/34s vs. ~39\u201345s) and thus mislocalizes the events, so it is only partially correct."
      }
    },
    {
      "question_id": "001",
      "question": "During the speaker's introduction of herself, when does she mention specializing in wounds?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 22.605,
        "end": 26.329
      },
      "pred_interval": {
        "start": 23.0,
        "end": 26.5
      },
      "iou": 0.8546854942233636,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 1
      },
      "mae": {
        "start": 0.3949999999999996,
        "end": 0.17099999999999937,
        "average": 0.2829999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.21978021978021978,
        "text_similarity": 0.40287238359451294,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction reasonably locates the specialization statement (E2) with similar timestamps, but it misidentifies the anchor (E1) \u2014 giving a 23.0s name/role instead of the speaker saying her name at 0:18.120 \u2014 and introduces an incorrect quote/relationship, so it is only a partial match."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of 'getting the most out of your GP consultation', when does she mention that GP practices are getting a huge injection of funding?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 67.82,
        "end": 75.533
      },
      "pred_interval": {
        "start": 69.0,
        "end": 71.2
      },
      "iou": 0.28523272397251404,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.1800000000000068,
        "end": 4.332999999999998,
        "average": 2.7565000000000026
      },
      "rationale_metrics": {
        "rouge_l": 0.2777777777777778,
        "text_similarity": 0.6735278964042664,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly locates the funding mention (E2) within the true interval, but it misplaces the topic introduction (E1) at 69.0s instead of 62.0\u201365.0s and incorrectly claims they occur simultaneously/immediately adjacent, so the temporal relationship is wrong."
      }
    },
    {
      "question_id": "003",
      "question": "While the slide titled 'Appointments are precious' is on screen, when does the speaker mention that GP practices are moving back towards face-to-face appointments?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 123.0,
        "end": 129.0
      },
      "pred_interval": {
        "start": 130.0,
        "end": 133.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 4.5,
        "average": 5.75
      },
      "rationale_metrics": {
        "rouge_l": 0.3469387755102041,
        "text_similarity": 0.6554878950119019,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the utterance content but misplaces both the anchor (130.0s vs ~100.74s) and the target interval (130\u2013133.5s vs 123\u2013129s) and gives an incorrect temporal relation, so the timing/relationship information is largely wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that GP practices are very different places now, when does she begin listing the specific roles in a GP practice?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 203.0,
        "end": 204.0
      },
      "pred_interval": {
        "start": 160.4,
        "end": 160.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.599999999999994,
        "end": 43.19999999999999,
        "average": 42.89999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.20952380952380953,
        "text_similarity": 0.5556812882423401,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the quoted phrases and the 'after' relation, but the timestamps for both E1 and E2 are substantially incorrect (off by ~25\u201342 seconds) and thus fail to match the key factual timing in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide displays the question 'Does it need to be a GP?', when does the speaker mention that paramedics work in primary care?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 235.0,
        "end": 240.0
      },
      "pred_interval": {
        "start": 171.1,
        "end": 171.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.900000000000006,
        "end": 68.6,
        "average": 66.25
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6552936434745789,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives the wrong timestamps, quotes a different utterance (about GP practices) rather than the speaker saying 'Paramedics... work in primary care', and wrongly asserts the speaker addresses the slide immediately instead of much later; key factual elements are missing or contradicted."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker talks about paramedics working in primary care, when does she begin to explain the role of Advanced Clinical Practitioners?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 241.0,
        "end": 249.0
      },
      "pred_interval": {
        "start": 195.9,
        "end": 196.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 45.099999999999994,
        "end": 52.69999999999999,
        "average": 48.89999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.14583333333333334,
        "text_similarity": 0.6340184807777405,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives completely different timestamps and mislabels E2 (still about paramedics at ~196s) rather than the correct start of Advanced Clinical Practitioners at ~241s, so it contradicts the reference despite both saying 'after'."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the problem of a wound on your foot, when does she strongly advise mentioning if you are diabetic?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 337.875,
        "end": 343.0
      },
      "pred_interval": {
        "start": 330.0,
        "end": 347.2
      },
      "iou": 0.29796511627906996,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.875,
        "end": 4.199999999999989,
        "average": 6.037499999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2298850574712644,
        "text_similarity": 0.6303237676620483,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies that the diabetic-warning follows the wound-introduction and captures the content, but the provided timestamps are substantially off (E1 ~5s earlier, E2 start ~6s earlier and end ~4s later) so it is not temporally accurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses having a new wound on your leg, when does she suggest going to a local pharmacist for simple dressings?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 363.968,
        "end": 366.552
      },
      "pred_interval": {
        "start": 382.0,
        "end": 393.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.031999999999982,
        "end": 26.44799999999998,
        "average": 22.23999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.29545454545454547,
        "text_similarity": 0.8795682787895203,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the pharmacist advice follows the nurse appointment, but the reported timecodes are incorrect/inconsistent (do not match the reference absolute\u2192relative mapping) and the target/anchor timings overlap improperly, so it fails to match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker explains that a nurse's appointment is needed for long-standing wounds, when does she advise to clearly state how long the wound has been there?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 409.579,
        "end": 439.62
      },
      "pred_interval": {
        "start": 415.0,
        "end": 427.0
      },
      "iou": 0.39945407942478617,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 5.420999999999992,
        "end": 12.620000000000005,
        "average": 9.020499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2526315789473684,
        "text_similarity": 0.7051612138748169,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the advice to state how long the wound has been present, but the timestamps and anchor/target alignment are incorrect, it misstates the temporal relationship, and it adds an unsupported detail about being 'not embarrassed.'"
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks if you feel more short of breath, when does she state that a GP or nurse practitioner might be needed the same day?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 522.783,
        "end": 525.113
      },
      "pred_interval": {
        "start": 538.21,
        "end": 542.24
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.427000000000021,
        "end": 17.126999999999953,
        "average": 16.276999999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.1075268817204301,
        "text_similarity": 0.6109391450881958,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the target utterance and that it follows the anchor, but the timestamps and segment boundaries are substantially incorrect (predicted ~536\u2013542s vs correct 514\u2013525s) and it fails to align with the referenced discussion of new leg swelling."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker advises to measure your ankle and calf, when does she give an example of a calf measurement that would 'perk up more interest'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 583.623,
        "end": 586.297
      },
      "pred_interval": {
        "start": 557.53,
        "end": 564.93
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 26.093000000000075,
        "end": 21.367000000000075,
        "average": 23.730000000000075
      },
      "rationale_metrics": {
        "rouge_l": 0.13513513513513511,
        "text_similarity": 0.5893430113792419,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction captures the general content (an example about swollen calves following the advice) but gives incorrect/missing timestamps for both anchor and target and incorrectly states the example 'immediately follows' the advice, whereas the ground truth places the target much later (\u2248583.6s)."
      }
    },
    {
      "question_id": "003",
      "question": "Once the slide changes to 'Photography', when does the speaker advise to 'expect to be asked for a photo'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 670.384,
        "end": 672.807
      },
      "pred_interval": {
        "start": 577.78,
        "end": 583.18
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 92.60400000000004,
        "end": 89.62700000000007,
        "average": 91.11550000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.28169014084507044,
        "text_similarity": 0.8221362233161926,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the relative order ('after') right but the anchor and target timestamps are both substantially incorrect (off by ~73s) and the target end time is omitted, so it fails to match the correct timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions some GP practices use video consultations, when does she state that a good quality photograph is better than a video?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 714.278,
        "end": 717.251
      },
      "pred_interval": {
        "start": 690.0,
        "end": 690.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.27800000000002,
        "end": 27.250999999999976,
        "average": 25.764499999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.6703219413757324,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation ('after') but the timestamps are incorrect and contradictory (both events at 690.0s and claimed to start immediately), failing to match the correct times ~708.98s and ~714.278s and omitting the required temporal offset."
      }
    },
    {
      "question_id": "002",
      "question": "Once the slide changes to 'Photography tips', when does the speaker begin discussing taking a close-up and further-away picture?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 738.601,
        "end": 740.91
      },
      "pred_interval": {
        "start": 720.0,
        "end": 720.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.601,
        "end": 20.909999999999968,
        "average": 19.755499999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.34666666666666673,
        "text_similarity": 0.6608165502548218,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted answer gives incorrect timestamps (720.0s vs the correct 736.057s and 738.601s) and wrongly states the events are simultaneous, contradicting the correct 'once_finished' (speaker begins after the slide change)."
      }
    },
    {
      "question_id": "003",
      "question": "After the slide changes to 'General top tips- face to face appointments', when does the speaker advise to 'Go suitably dressed'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 860.136,
        "end": 860.846
      },
      "pred_interval": {
        "start": 760.0,
        "end": 760.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 100.13599999999997,
        "end": 100.846,
        "average": 100.49099999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.30379746835443044,
        "text_similarity": 0.6964364647865295,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction is incorrect: it fabricates both events at 760.0s and claims they occur simultaneously, whereas the ground truth gives 805.957s (slide change) and 860.136s (advice) with the advice occurring after the slide change."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker advises not to wear tight socks, trousers, or wellies, when does she suggest wearing something with quick access to lower limbs?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 873.0,
        "end": 877.5
      },
      "pred_interval": {
        "start": 870.0,
        "end": 900.0
      },
      "iou": 0.15,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 22.5,
        "average": 12.75
      },
      "rationale_metrics": {
        "rouge_l": 0.26315789473684204,
        "text_similarity": 0.6891880035400391,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction captures the correct semantic content and 'after' relation, but it misstates the temporal boundaries\u2014especially placing E2 at 900.0s instead of the correct 873.0\u2013877.5s\u2014so the timing is inaccurate and partly hallucinated."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes advising not to make chit-chat about the weather, when does she advise not to dodge the real problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 893.0,
        "end": 894.5
      },
      "pred_interval": {
        "start": 930.0,
        "end": 970.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.0,
        "end": 75.5,
        "average": 56.25
      },
      "rationale_metrics": {
        "rouge_l": 0.3055555555555555,
        "text_similarity": 0.6480412483215332,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the two utterances' content but the timestamps are vastly shifted and durations incorrect (off by tens of seconds), and the relation 'after' is a weaker/mismatched framing versus the specified 'once_finished', so the answer is largely temporally incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker advises to take a list of the medications you are actually taking, when does she advise against describing tablets by their appearance?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 948.0,
        "end": 969.0
      },
      "pred_interval": {
        "start": 970.0,
        "end": 1010.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.0,
        "end": 41.0,
        "average": 31.5
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.7036675214767456,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the semantic content and the 'after' relation correct, but the temporal annotations are substantially wrong (non-overlapping/mismatched timestamps versus the ground truth), so it fails on key factual details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker advises speaking to the practice in advance about a relative, when does she explain the reason for this advance arrangement due to confidentiality?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1065.0,
        "end": 1095.0
      },
      "pred_interval": {
        "start": 1173.0,
        "end": 1198.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 108.0,
        "end": 103.0,
        "average": 105.5
      },
      "rationale_metrics": {
        "rouge_l": 0.208955223880597,
        "text_similarity": 0.632768452167511,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events and their order, but the timestamps are substantially different from the reference (off by ~118s) and the relation 'after' is less precise than the correct 'once_finished', so it is not accurately aligned."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker suggests writing things down before an appointment to help structure what you say, when does she first ask 'How did it start?' regarding the leg problem?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1130.415,
        "end": 1131.738
      },
      "pred_interval": {
        "start": 1221.0,
        "end": 1224.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 90.58500000000004,
        "end": 92.26199999999994,
        "average": 91.42349999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.3466666666666666,
        "text_similarity": 0.6365382671356201,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly links the two utterances content-wise (writing things down and the question 'How did it start?') but gives substantially incorrect timestamps and the wrong temporal relation ('at the same time' vs. 'once_finished'), so it fails on key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes advising to ask to be referred to a specialist service, when does she start introducing the referrals examples?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.105,
        "end": 1249.385
      },
      "pred_interval": {
        "start": 1268.85,
        "end": 1270.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.74499999999989,
        "end": 21.0150000000001,
        "average": 20.879999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2033898305084746,
        "text_similarity": 0.5229308605194092,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events and the 'after' relation, but the provided timestamps are significantly (~32s) later than the ground truth, so the timing is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that lymphoedema services can be patchy, when does she first advise writing to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1377.0,
        "end": 1378.0
      },
      "pred_interval": {
        "start": 1306.6,
        "end": 1308.75
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 70.40000000000009,
        "end": 69.25,
        "average": 69.82500000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.15625000000000003,
        "text_similarity": 0.5089719891548157,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer misidentifies both events and timestamps (the anchor and advice occur much earlier and with different wording than the reference), so it fails to match the correct E1/E2\u2014only the temporal relation 'after' coincidentally aligns."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions that a GP will assess new leg swelling for onward referral, when does she explain there are many different causes?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1429.846,
        "end": 1432.0
      },
      "pred_interval": {
        "start": 1346.85,
        "end": 1349.15
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 82.9960000000001,
        "end": 82.84999999999991,
        "average": 82.923
      },
      "rationale_metrics": {
        "rouge_l": 0.21951219512195125,
        "text_similarity": 0.6389975547790527,
        "llm_judge_score": 4,
        "llm_judge_justification": "The predicted answer correctly captures the semantic relation (the explanation occurs after the GP referral mention) and paraphrases the cause explanation, but the provided timestamps are substantially different from the reference, so the timing is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks what information you could take with you, when does she suggest looking up the National Wound Care Strategy Lower Limb Recommendations?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1465.0,
        "end": 1469.5
      },
      "pred_interval": {
        "start": 1420.5,
        "end": 1429.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.5,
        "end": 40.200000000000045,
        "average": 42.35000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.7070131301879883,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same utterances and the correct 'after' relation, but the timestamps are substantially incorrect (\u224830\u201340s earlier than the reference) and the predicted answer omits the E2 end time, so it is factually inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions escalating concerns to the practice manager, when does she mention escalating concerns to your MP?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1523.6,
        "end": 1525.7
      },
      "pred_interval": {
        "start": 1444.4,
        "end": 1455.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 79.19999999999982,
        "end": 69.90000000000009,
        "average": 74.54999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2528735632183908,
        "text_similarity": 0.6704286932945251,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events (practice manager then MP) and the MP quote, but the event timestamps and boundaries differ substantially from the ground truth and the predicted timings are factually incorrect; the relation label ('after' vs 'next') is a minor mismatch compared to the major timing errors."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'I'll stop sharing', when does she start reading the first question from a viewer?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1574.5,
        "end": 1578.5
      },
      "pred_interval": {
        "start": 1477.8,
        "end": 1485.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 96.70000000000005,
        "end": 92.79999999999995,
        "average": 94.75
      },
      "rationale_metrics": {
        "rouge_l": 0.32,
        "text_similarity": 0.7162625789642334,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the order and that the question follows immediately after the stop-sharing remark, but the timestamps are substantially incorrect (off by ~86 seconds) and it omits the correct event end times, so key factual timing details are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially suggests the mum needs compression hosiery, when does she mention asking for an appointment with the nurse for stronger compression?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1654.942,
        "end": 1664.2
      },
      "pred_interval": {
        "start": 1686.7,
        "end": 1693.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.758000000000038,
        "end": 29.200000000000045,
        "average": 30.479000000000042
      },
      "rationale_metrics": {
        "rouge_l": 0.3584905660377359,
        "text_similarity": 0.7878938913345337,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the high-level relation (the nurse appointment suggestion occurs after the initial advice) but mischaracterizes the anchor (calls it a stronger-compression suggestion) and gives an incorrect E2 timestamp (1686.7s vs. 1654.942\u20131664.2), so it contains significant factual timing and content errors."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'That is such a good question', when does she state that self-diagnosis via the internet is never a good idea?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1757.815,
        "end": 1762.821
      },
      "pred_interval": {
        "start": 1748.2,
        "end": 1752.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.615000000000009,
        "end": 10.120999999999867,
        "average": 9.867999999999938
      },
      "rationale_metrics": {
        "rouge_l": 0.392156862745098,
        "text_similarity": 0.8490036725997925,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction captures the relation and the content of the statement, but the anchor and target timestamps are significantly incorrect (E1 at 1742.3s vs 1683.0s; E2 start at 1748.2s vs 1757.815s) and the correct end time is omitted, so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker emphasizes that approaching a GP is about framing the conversation, when does she tell the viewer not to worry about being labeled a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1795.335,
        "end": 1798.383
      },
      "pred_interval": {
        "start": 1784.2,
        "end": 1787.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.134999999999991,
        "end": 11.182999999999993,
        "average": 11.158999999999992
      },
      "rationale_metrics": {
        "rouge_l": 0.38596491228070173,
        "text_similarity": 0.686827540397644,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly captures the semantic relation (the reassurance comes after the framing remark) and the quoted line, but it omits the anchor timestamp and gives an incorrect start time for E2 (1784.2s vs correct 1795.335s), so key temporal details are wrong/missing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker first says, 'Please don't worry about things like that', when does she next advise not to worry about being labelled as a difficult patient?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1827.66,
        "end": 1831.19
      },
      "pred_interval": {
        "start": 1829.5,
        "end": 1843.2
      },
      "iou": 0.10875160875161252,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.8399999999999181,
        "end": 12.009999999999991,
        "average": 6.9249999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.2318840579710145,
        "text_similarity": 0.6225889325141907,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly identifies the anchor time (claims 1829.5s) and asserts E2 is the same event rather than the later instance at 1827.66\u20131831.19s; it contradicts the correct timing and omits the required distinction."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker asks, 'What can I do to maintain healthy legs or feet so I don't get any problems?', when does she start listing actions like 'walk' and 'legs up'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1865.412,
        "end": 1883.383
      },
      "pred_interval": {
        "start": 1876.3,
        "end": 1881.7
      },
      "iou": 0.3004841132936448,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.88799999999992,
        "end": 1.6829999999999927,
        "average": 6.285499999999956
      },
      "rationale_metrics": {
        "rouge_l": 0.24324324324324323,
        "text_similarity": 0.7219260931015015,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the 'walk' action and that the target follows the question, but it significantly misplaces the anchor time (1876.3s vs 1847.85\u20131853.02s) and gives a later target start (1881.7s vs 1865.412s), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker asks how much is in the GP curriculum, when does she say 'I don't know'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1983.7,
        "end": 1984.201
      },
      "pred_interval": {
        "start": 2018.0,
        "end": 2019.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.299999999999955,
        "end": 34.79899999999998,
        "average": 34.549499999999966
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947367,
        "text_similarity": 0.6490882635116577,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the target as immediately after the question, but the provided timestamps are significantly offset from the ground truth (anchor/target times differ by ~36s), so the answer is largely incorrect. "
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'I think it is something that Legs Matter can help with', when does she discuss Legs Matter influencing GP curriculums?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2004.063,
        "end": 2009.063
      },
      "pred_interval": {
        "start": 2037.0,
        "end": 2041.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 32.9369999999999,
        "end": 31.936999999999898,
        "average": 32.4369999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.18604651162790697,
        "text_similarity": 0.5892999172210693,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the target follows the anchor and mentions the content about influencing GP curriculums, but the timestamps are substantially wrong (both anchor and target times do not match the reference) and the temporal relationship is mischaracterized as 'immediately after' when the ground truth places the target ~10s later."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker asks if seeing a nurse practitioner is appropriate, when does she state that nurse practitioners are 'extremely experienced clinicians'?",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2062.584,
        "end": 2066.851
      },
      "pred_interval": {
        "start": 2081.0,
        "end": 2082.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.416000000000167,
        "end": 15.148999999999887,
        "average": 16.782500000000027
      },
      "rationale_metrics": {
        "rouge_l": 0.2784810126582279,
        "text_similarity": 0.476957231760025,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the immediate-following relationship and the quoted phrase, but the provided anchor and target timestamps are substantially incorrect (off by ~20s and wrong duration), so it fails on the key timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I understand the issue of smartphones and taking pictures too\", when does she first ask \"is there somebody who can help you?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2174.0,
        "end": 2176.0
      },
      "pred_interval": {
        "start": 2178.4,
        "end": 2180.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.400000000000091,
        "end": 4.5,
        "average": 4.4500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.2127659574468085,
        "text_similarity": 0.4796336889266968,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the temporal relation ('after') but gives substantially different timestamps for both events (off by ~13s), so it fails to provide the correct timing of when the question was first asked."
      }
    },
    {
      "question_id": "002",
      "question": "During the period when the speaker discusses the importance of planning phone calls to the GP, when does she ask, \"What am I feeling?\"",
      "video_id": "htFE6LPBdHY",
      "video_number": "013",
      "segment": {
        "start": 2130.0,
        "end": 2320.0
      },
      "gt_interval": {
        "start": 2197.721,
        "end": 2198.663
      },
      "pred_interval": {
        "start": 2219.9,
        "end": 2221.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.179000000000087,
        "end": 22.83699999999999,
        "average": 22.508000000000038
      },
      "rationale_metrics": {
        "rouge_l": 0.20408163265306123,
        "text_similarity": 0.5380759835243225,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the utterance as part of the planning list and labels the relation as 'during', but it gives incorrect timestamps for both the anchor and target (both are later than the ground truth), so the temporal information is factually wrong."
      }
    },
    {
      "question_id": "001",
      "question": "Once Dr. Angelos finishes introducing Dr. Tolchin, when does Dr. Tolchin begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 105.128,
        "end": 109.393
      },
      "pred_interval": {
        "start": 27.0,
        "end": 28.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 78.128,
        "end": 81.393,
        "average": 79.76050000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2926829268292683,
        "text_similarity": 0.6804345846176147,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that Dr. Tolchin speaks after Dr. Angelos, but the timestamps are grossly off (28s vs. the ground-truth ~105.128s) and it omits the correct duration, so it is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After Dr. Angelos describes Dr. Tolchin's research on crisis standards of care, when does he describe his research on functional neurological disorders and epilepsy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 56.426,
        "end": 116.456
      },
      "pred_interval": {
        "start": 47.0,
        "end": 52.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.426000000000002,
        "end": 64.456,
        "average": 36.941
      },
      "rationale_metrics": {
        "rouge_l": 0.2574257425742574,
        "text_similarity": 0.6958483457565308,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the two segments and that the functional neurological disorders description comes after the crisis-standards segment, but the provided timestamps are notably inaccurate (both E1 end and E2 start differ from the ground truth) and it adds a quoted phrase not present in the reference."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes stating the second learning objective, when does he start explaining the third learning objective?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 167.0,
        "end": 181.0
      },
      "pred_interval": {
        "start": 317.24,
        "end": 318.52
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 150.24,
        "end": 137.51999999999998,
        "average": 143.88
      },
      "rationale_metrics": {
        "rouge_l": 0.35000000000000003,
        "text_similarity": 0.6286751627922058,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction correctly identifies that the third objective starts after the second, but it gives completely different absolute timestamps (317s vs 16\u201317s), an incorrect event span, and adds specific quoted words not present in the reference, so it is largely inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "While the slide titled 'Why conduct clinical ethics consultations?' is displayed, when does the speaker discuss moral distress among clinicians and staff?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 285.4,
        "end": 304.0
      },
      "pred_interval": {
        "start": 218.28,
        "end": 222.08
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 67.11999999999998,
        "end": 81.91999999999999,
        "average": 74.51999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.367816091954023,
        "text_similarity": 0.7793890833854675,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the slide and gives an E1 window that falls within the true slide duration, but it mislocates the speaker segment (predicted 218.28\u2013222.08s vs true 285.4\u2013304.0s) and thus the temporal relation and timestamps are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that clinical ethics consultations were helpful, when does he state that they were more likely to achieve consensus in clinical decisions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 350.2,
        "end": 357.0
      },
      "pred_interval": {
        "start": 473.78,
        "end": 482.76
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 123.57999999999998,
        "end": 125.75999999999999,
        "average": 124.66999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.21052631578947364,
        "text_similarity": 0.525958776473999,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives completely different timestamps (473.78s vs. the correct 337.0s and 350.2\u2013357.0s) and misstates the temporal relationship by implying immediate succession/overlap; thus it is largely incorrect and inconsistent with the reference."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the topic of resource utilization, when does he specifically state that there was a reduced length of stay?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 438.9,
        "end": 450.3
      },
      "pred_interval": {
        "start": 502.44,
        "end": 506.44
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.54000000000002,
        "end": 56.139999999999986,
        "average": 59.84
      },
      "rationale_metrics": {
        "rouge_l": 0.22429906542056077,
        "text_similarity": 0.6794294714927673,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction is largely incorrect: it gives completely different timestamps, asserts E1/E2 coincide and that E2 continues E1, and adds details not in the reference, contradicting the correct 'after' relationship and the specified times."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying 'to look at disparities', when does he begin to introduce Ellen Fox's team and their survey?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 493.5,
        "end": 499.0
      },
      "pred_interval": {
        "start": 512.24,
        "end": 513.36
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.74000000000001,
        "end": 14.360000000000014,
        "average": 16.55000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2391304347826087,
        "text_similarity": 0.655357301235199,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly identifies that E2 begins immediately after E1, but the timestamps conflict substantially with the reference (predicted ~512s/513s vs reference 393.0s/493.5s) and it adds unsupported audio/visual detail; major factual elements (accurate times) are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'hospitals with less than 400 beds', when does he mention 'little or no growth over that two decade period'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 527.809,
        "end": 530.91
      },
      "pred_interval": {
        "start": 545.12,
        "end": 549.68
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.311000000000035,
        "end": 18.769999999999982,
        "average": 18.04050000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.4313725490196078,
        "text_similarity": 0.7987881898880005,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the semantic relation right (the target immediately follows the anchor) and quotes the phrases, but the provided timestamps are significantly different from the ground truth (about ~20s off) and durations do not match, so the answer is largely temporally incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the slide titled 'Prior Healthcare System Ethics Committees' is fully displayed, when do the images of the six hospitals with their bed counts appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 551.7,
        "end": 552.0
      },
      "pred_interval": {
        "start": 574.0,
        "end": 585.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.299999999999955,
        "end": 33.0,
        "average": 27.649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.23728813559322032,
        "text_similarity": 0.7783731818199158,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target events but gives completely incorrect timing and temporal relation\u2014placing both at 574.0s and simultaneous\u2014whereas the ground truth has E1 at 536.2s and E2 at 551.7\u2013552.0s with the target occurring after the anchor."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker states the number of ethics consults at Yale New Haven Hospital increased from 50 to 239, when does he describe this as 'approximately a five-fold increase in consult volume'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 622.7,
        "end": 624.7
      },
      "pred_interval": {
        "start": 601.36,
        "end": 604.08
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.340000000000032,
        "end": 20.620000000000005,
        "average": 20.980000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.4807692307692307,
        "text_similarity": 0.8714742660522461,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor and target utterances and their immediate sequential relationship, but the timestamps are substantially incorrect (off by ~13+ seconds), so the answer is factually misaligned with the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker initially mentions the 'Community Bioethics Forum', when does he start describing its community members?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 887.216,
        "end": 905.918
      },
      "pred_interval": {
        "start": 870.0,
        "end": 875.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.216000000000008,
        "end": 30.118000000000052,
        "average": 23.66700000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.3055555555555555,
        "text_similarity": 0.8954510688781738,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the relation ('after') and a plausible description of the community members, but both anchor and target timestamps are substantially incorrect (off by ~12s and ~11s respectively) and therefore fail to match the correct temporal spans."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that the primary focus of the Center for Clinical Ethics has been ethics education, when does he start listing 'Systemwide Ethics Forum and Newsletter'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1055.54,
        "end": 1069.28
      },
      "pred_interval": {
        "start": 947.9,
        "end": 967.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 107.63999999999999,
        "end": 102.17999999999995,
        "average": 104.90999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.33333333333333337,
        "text_similarity": 0.8924628496170044,
        "llm_judge_score": 3,
        "llm_judge_justification": "The anchor timing is acceptable (within the referenced range) and the relation 'after' is correct, but the predicted start for E2 (967.1s) is far earlier than the ground truth (1055.54s), so the target timing is substantially incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker lists 'ICU Walk Rounds', when does he mention 'HEC-C Certification'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 1048.0,
        "end": 1052.0
      },
      "pred_interval": {
        "start": 1032.9,
        "end": 1048.5
      },
      "iou": 0.026178010471204313,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.099999999999909,
        "end": 3.5,
        "average": 9.299999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.2894736842105263,
        "text_similarity": 0.8906735181808472,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the HEC-C mention and relation ('after' ~ 'next'), but it gives a substantially incorrect timestamp for the anchor 'ICU Walk Rounds' (1032.9s vs 1042.0\u20131045.43s), so the anchor timing is factually wrong while the target timing is close."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying \"ethics consultation services,\" when does he start talking about collecting feedback?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1240.8,
        "end": 1249.8
      },
      "pred_interval": {
        "start": 1262.0,
        "end": 1263.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.200000000000045,
        "end": 13.700000000000045,
        "average": 17.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.18604651162790697,
        "text_similarity": 0.6732984185218811,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that discussion of collecting feedback immediately follows the mention of 'ethics consultation services' and quotes the relevant line, but its timestamps are significantly off from the ground truth (about 23s later) and it uses a less precise relation label ('after' vs 'once_finished')."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that participant satisfaction is not the \"be-all and end-all,\" when does he say they have begun the survey process with clinicians?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1278.3,
        "end": 1282.8
      },
      "pred_interval": {
        "start": 1342.0,
        "end": 1343.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 63.700000000000045,
        "end": 60.700000000000045,
        "average": 62.200000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.24444444444444446,
        "text_similarity": 0.6349478960037231,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly preserves the order (E2 occurs after E1) but gives substantially incorrect timestamps (1343.5s vs correct 1278.3s for E2 and 1342.0s vs 1275.0s for E1) and adds an unwarranted note about a pause; key factual timing is wrong."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes describing the first pie chart about helpful advice/guidance, when does the second pie chart about communication appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1367.5,
        "end": 1367.9
      },
      "pred_interval": {
        "start": 1381.0,
        "end": 1382.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.5,
        "end": 14.099999999999909,
        "average": 13.799999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.21978021978021975,
        "text_similarity": 0.6837332248687744,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly captures the sequential relationship, but both timestamps do not match the reference\u2014E1 is off by ~25s and E2 by ~5.5s\u2014so the anchors are materially incorrect despite the right relation."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says he wants to turn to some of the organizational ethics consultation work, when does the slide showing the 'Organizational ethics consultations' table appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1472.0,
        "end": 1472.5
      },
      "pred_interval": {
        "start": 1433.0,
        "end": 1435.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.0,
        "end": 37.5,
        "average": 38.25
      },
      "rationale_metrics": {
        "rouge_l": 0.22429906542056074,
        "text_similarity": 0.6768014430999756,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the speaker's anchor but assigns the slide to 1434.0s, whereas the ground truth places the slide much later at 1472.0s (a ~38s difference); thus it incorrectly states the slide appears immediately after the introduction. The small ~0.9s anchor timing error is minor, but the major slide-timing discrepancy warrants a low score."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes explaining that organizational ethics work is new to them, when do they state that it began during the COVID pandemic?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1469.5,
        "end": 1472.0
      },
      "pred_interval": {
        "start": 1458.0,
        "end": 1461.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.5,
        "end": 11.0,
        "average": 11.25
      },
      "rationale_metrics": {
        "rouge_l": 0.22916666666666666,
        "text_similarity": 0.639611005783081,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer contains the correct verbal content but the timestamps are substantially misaligned with the ground truth (off by ~9\u201312 seconds) and thus contradict the specified event boundaries; therefore it is largely incorrect despite matching wording."
      }
    },
    {
      "question_id": "003",
      "question": "During the display of the 'Organizational ethics consultations' table, when does the speaker mention the 'Blood products scarcity protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1510.0,
        "end": 1513.0
      },
      "pred_interval": {
        "start": 1473.0,
        "end": 1475.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.0,
        "end": 38.0,
        "average": 37.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2831858407079646,
        "text_similarity": 0.6209145188331604,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the protocol is spoken while the table is visible, but it gives substantially different timestamps (1474s vs. the ground-truth 1510\u20131513s) and thus is temporally inaccurate. The mismatch in event timing warrants a low score despite semantic agreement."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker introduces the 'sequential organ failure assessment or SOFA score', when does he begin to explain what it is?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1647.6,
        "end": 1697.0
      },
      "pred_interval": {
        "start": 1636.83,
        "end": 1642.93
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.769999999999982,
        "end": 54.069999999999936,
        "average": 32.41999999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.22988505747126436,
        "text_similarity": 0.6422358155250549,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that the explanation follows the introduction, but the anchor and target timestamps are substantially off from the reference (differences of ~10\u201350+ seconds) and the predicted target duration/definition contradicts the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states that '70% of publicly available crisis standards of care used either the SOFA score or a modified version', when does he mention the SOFA score being used in Alaska?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1726.0,
        "end": 1733.0
      },
      "pred_interval": {
        "start": 1678.19,
        "end": 1686.67
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 47.809999999999945,
        "end": 46.32999999999993,
        "average": 47.069999999999936
      },
      "rationale_metrics": {
        "rouge_l": 0.26666666666666666,
        "text_similarity": 0.5780657529830933,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the general '70%' anchor line but gives incorrect timestamps and a different follow-up example (hemodialysis allocation) rather than the Alaska example at 1726\u20131733, so it largely misaligns with the reference."
      }
    },
    {
      "question_id": "003",
      "question": "Once the 'SOFA Disparities' slide appears, when does the speaker begin discussing concerns about the score's accuracy and contributions to disparities?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1770.0,
        "end": 1776.606
      },
      "pred_interval": {
        "start": 1744.43,
        "end": 1755.09
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 25.569999999999936,
        "end": 21.516000000000076,
        "average": 23.543000000000006
      },
      "rationale_metrics": {
        "rouge_l": 0.3888888888888889,
        "text_similarity": 0.7810091376304626,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the speaker immediately discusses concerns about SOFA accuracy and disparities, but it gives substantially incorrect anchor and target timestamps (off by ~17\u201326 seconds) and thus fails on key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that the center was able to test the triage protocol before it was used, when does he state that they developed a SOFA calculation system?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1799.553,
        "end": 1807.997
      },
      "pred_interval": {
        "start": 1775.2,
        "end": 1776.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 24.353000000000065,
        "end": 31.99700000000007,
        "average": 28.175000000000068
      },
      "rationale_metrics": {
        "rouge_l": 0.24742268041237114,
        "text_similarity": 0.8219082951545715,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly identifies the temporal relation as 'after', but the provided timestamps are substantially incorrect (off by ~20s) and it adds an unwarranted causal claim; thus it fails on factual timing accuracy and completeness."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces the retrospective cohort study, when does he detail the demographic breakdown of the patients?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1846.122,
        "end": 1858.077
      },
      "pred_interval": {
        "start": 1803.7,
        "end": 1804.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.422000000000025,
        "end": 53.577,
        "average": 47.99950000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.26966292134831465,
        "text_similarity": 0.7064669728279114,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction only matches the high-level relation that demographics occur after the study introduction, but it gives substantially incorrect timestamps and incorrectly claims the demographics immediately follow the introduction, contradicting the ground-truth times."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker highlights that non-Hispanic Black patients had greater odds of an elevated SOFA score, when does he state that no significant difference by race in mortality was found when controlling for other factors?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1873.642,
        "end": 1879.694
      },
      "pred_interval": {
        "start": 1812.8,
        "end": 1813.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 60.8420000000001,
        "end": 66.19399999999996,
        "average": 63.51800000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.22857142857142856,
        "text_similarity": 0.7534410953521729,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer reproduces the relevant quoted phrase and the 'after' relationship, but the timestamps and event boundaries are substantially incorrect compared to the ground truth, so the timing information is largely wrong."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the early small cohort out of Wuhan, China, when does he state that subsequent larger cohorts in the United States did not show such high accuracy rates?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1959.0,
        "end": 1966.5
      },
      "pred_interval": {
        "start": 13.85,
        "end": 17.12
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1945.15,
        "end": 1949.38,
        "average": 1947.265
      },
      "rationale_metrics": {
        "rouge_l": 0.16842105263157894,
        "text_similarity": 0.6989438533782959,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the temporal relation right (the 'subsequent larger cohorts' remark follows the Wuhan mention) but mislabels the events and gives incorrect timestamps and boundaries (does not match the ground-truth times or event assignment), so it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'This graph here is a calibration curve', when does he explain that the diagonal line shows a perfectly calibrated predictor of mortality?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2014.0,
        "end": 2020.0
      },
      "pred_interval": {
        "start": 72.08,
        "end": 74.23
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1941.92,
        "end": 1945.77,
        "average": 1943.845
      },
      "rationale_metrics": {
        "rouge_l": 0.2181818181818182,
        "text_similarity": 0.7354642152786255,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the semantic relation that the explanation follows the graph, but the provided timestamps substantially diverge from the reference (major mismatches in the anchor/target times), so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states that SOFA predicted mortality with less accuracy than age in their own COVID cohort, when does he mention that SOFA predicted mortality with better accuracy than age in the pre-COVID eICU cohort?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2066.0,
        "end": 2069.0
      },
      "pred_interval": {
        "start": 101.11,
        "end": 102.68
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1964.89,
        "end": 1966.32,
        "average": 1965.605
      },
      "rationale_metrics": {
        "rouge_l": 0.1954887218045113,
        "text_similarity": 0.7253050804138184,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the semantic contrast but gives entirely incorrect timestamps and misplaces the target utterance as immediately after the anchor rather than at the much later times specified in the reference, a major factual error."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions the Omicron surge increasing, when does he talk about working with the healthcare system's legal team?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2153.6,
        "end": 2174.93
      },
      "pred_interval": {
        "start": 2155.4,
        "end": 2155.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.800000000000182,
        "end": 19.529999999999745,
        "average": 10.664999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.17073170731707316,
        "text_similarity": 0.6679636240005493,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly places the legal-team remark within the correct interval (~2155s) but incorrectly timestamps the Omicron surge (predicts 2154.7s vs reference ~2132.0s) and thus wrongly claims the two events occur 'immediately' adjacent. This misalignment of the anchor event is a significant factual error."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating the policy was active until late February of 2022, when does the first 'Scope of protocol' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2194.0,
        "end": 2234.0
      },
      "pred_interval": {
        "start": 2185.2,
        "end": 2185.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.800000000000182,
        "end": 48.80000000000018,
        "average": 28.800000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.30985915492957744,
        "text_similarity": 0.8260365128517151,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted times conflict with the reference: the speaker end is given as 2185.0 vs the correct 2192.0, and the slide is placed at 2185.2 instead of 2194.0\u20132234.0; the claim of immediate appearance contradicts the correct timing."
      }
    },
    {
      "question_id": "003",
      "question": "After the second 'Scope of protocol' slide appears, when does the speaker mention 'renal replacement therapy'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2263.679,
        "end": 2254.733
      },
      "pred_interval": {
        "start": 2203.7,
        "end": 2203.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 59.97900000000027,
        "end": 51.03300000000036,
        "average": 55.50600000000031
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.75078284740448,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted timestamps directly conflict with the reference: it places the slide and mention around 2199.9\u20132203.7s/2203.7s, whereas the ground truth locates the slide at 2230.0s and the mention around 2255\u20132264s (with a noted 3s offset). This is a substantive factual mismatch rather than a harmless rephrasing."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that goals of care discussions significantly changed, when does the speaker mention that patients were more likely to choose limited life-sustaining interventions?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2320.0,
        "end": 2327.0
      },
      "pred_interval": {
        "start": 2347.0,
        "end": 2354.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.0,
        "end": 27.0,
        "average": 27.0
      },
      "rationale_metrics": {
        "rouge_l": 0.23529411764705885,
        "text_similarity": 0.49762868881225586,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves a similar temporal offset but incorrectly labels and timestamps the events (both times are ~34s later than the reference and the anchor/target are swapped), and it gives a contradictory relation description ('after' yet 'during the same sentence'), so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker states he wants to highlight some takeaway points, when does the first takeaway point appear on the screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2395.0,
        "end": 2400.0
      },
      "pred_interval": {
        "start": 2364.0,
        "end": 2372.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.0,
        "end": 28.0,
        "average": 29.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2608695652173913,
        "text_similarity": 0.5338893532752991,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events but gives timestamps that are substantially wrong (E1 at 2364s vs 2392\u20132394s; E2 at 2372s vs 2395\u20132400s) and provides an inconsistent relationship, so it is largely inaccurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says, \"I'll stop and take questions,\" when does an audience member begin speaking?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2541.6,
        "end": 2544.0
      },
      "pred_interval": {
        "start": 2676.6,
        "end": 2677.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 135.0,
        "end": 133.5,
        "average": 134.25
      },
      "rationale_metrics": {
        "rouge_l": 0.34146341463414637,
        "text_similarity": 0.6737847328186035,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the event order right ('after') and paraphrases the speaker line, but the timestamps are significantly incorrect and it incorrectly claims the audience speaks immediately after; it also omits the audience speech end time given in the correct answer."
      }
    },
    {
      "question_id": "002",
      "question": "Once the audience member finishes complimenting the center, when does he ask a specific question about local hospital ethics committees?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2571.5,
        "end": 2580.5
      },
      "pred_interval": {
        "start": 2696.9,
        "end": 2697.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 125.40000000000009,
        "end": 116.69999999999982,
        "average": 121.04999999999995
      },
      "rationale_metrics": {
        "rouge_l": 0.2891566265060241,
        "text_similarity": 0.6405618190765381,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the compliment then the specific question and that the question immediately follows, but it gives substantially different timestamps (off by ~131s) and uses a less precise relation label ('after' vs 'once_finished'), so it has important factual timing errors."
      }
    },
    {
      "question_id": "003",
      "question": "After the audience member mentions the low numbers of ethics consultations, when does the speaker begin to answer the question?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2624.0,
        "end": 2634.8
      },
      "pred_interval": {
        "start": 2700.0,
        "end": 2700.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.0,
        "end": 65.19999999999982,
        "average": 70.59999999999991
      },
      "rationale_metrics": {
        "rouge_l": 0.40909090909090906,
        "text_similarity": 0.6859935522079468,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relation but the timestamps are substantially wrong (correct E1/E2 around 2621.0/2624.0s vs predicted 2700.0s) and it incorrectly states the speaker begins exactly at the audience statement's end rather than a few seconds later, so it fails on factual timing details."
      }
    },
    {
      "question_id": "002",
      "question": "After the listener asks about assessing the quality of care across the system, when does the speaker respond by calling it a 'great question'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2744.1,
        "end": 2745.7
      },
      "pred_interval": {
        "start": 2709.12,
        "end": 2713.94
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.98000000000002,
        "end": 31.759999999999764,
        "average": 33.36999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.32941176470588235,
        "text_similarity": 0.7287123203277588,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly captures that the speaker responds immediately after the listener, but the timestamps are substantially incorrect (~30s earlier than the reference), so it fails to match the key temporal evidence in the correct answer."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker mentions starting to survey clinicians for feedback, when does he mention planning to survey patients and families?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2807.8,
        "end": 2821.6
      },
      "pred_interval": {
        "start": 2752.62,
        "end": 2766.76
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.18000000000029,
        "end": 54.83999999999969,
        "average": 55.00999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.41509433962264153,
        "text_similarity": 0.8323540687561035,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures the sequential relationship (the patients/families survey is mentioned immediately after clinicians), but the timestamps are factually incorrect and the predicted time range for the patients/families mention does not match the reference, so it is only partially accurate."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that hospitals in the healthcare system can join together, when does he state that they will preferentially present cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2854.49,
        "end": 2856.13
      },
      "pred_interval": {
        "start": 2877.6,
        "end": 2885.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.110000000000127,
        "end": 29.269999999999982,
        "average": 26.190000000000055
      },
      "rationale_metrics": {
        "rouge_l": 0.3191489361702127,
        "text_similarity": 0.6566205024719238,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mentions the correct phrase but misidentifies timestamps and asserts the anchor and target are simultaneous, contradicting the reference which places the target after the anchor; thus it partially matches wording but is factually incorrect on timing/relationship."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker introduces 'a third method of feedback', when does he describe it as 'formal needs assessments'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2877.53,
        "end": 2879.53
      },
      "pred_interval": {
        "start": 2900.0,
        "end": 2909.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.4699999999998,
        "end": 29.86999999999989,
        "average": 26.169999999999845
      },
      "rationale_metrics": {
        "rouge_l": 0.3958333333333333,
        "text_similarity": 0.7353483438491821,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor and that the target occurs after it, but the timestamps are substantially off (by ~23\u201330s) and the target wording/duration is inconsistent (adds 'is being' and an incorrect end time), so it is largely temporally inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'the overwhelming response was number one', when does he specify the first response as 'a lack of ethics education'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2901.56,
        "end": 2903.46
      },
      "pred_interval": {
        "start": 2928.9,
        "end": 2932.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.340000000000146,
        "end": 28.73999999999978,
        "average": 28.039999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.33962264150943394,
        "text_similarity": 0.766933798789978,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same anchor and target content but gives substantially incorrect timestamps and incorrectly states the target is simultaneous with the anchor, contradicting the ground truth that the target starts ~1.56s after the anchor."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says, \"The more medically complex cases tend to transfer,\" when does he start listing examples of such cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3044.3,
        "end": 3048.2
      },
      "pred_interval": {
        "start": 3037.0,
        "end": 3038.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.300000000000182,
        "end": 10.199999999999818,
        "average": 8.75
      },
      "rationale_metrics": {
        "rouge_l": 0.25974025974025977,
        "text_similarity": 0.5830131769180298,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the examples follow the anchor and even cites example content, but the timestamps are off by ~6\u20137 seconds (predicted 3037\u20133038s vs correct ~3044.3s) and it fails to note the immediate succession indicated in the ground truth."
      }
    },
    {
      "question_id": "002",
      "question": "After the questioner asks about the 'escalation of care policy', when does the slide titled 'Escalation of Care Protocol' appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3114.8,
        "end": 3117.8
      },
      "pred_interval": {
        "start": 3079.0,
        "end": 3080.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 35.80000000000018,
        "end": 37.80000000000018,
        "average": 36.80000000000018
      },
      "rationale_metrics": {
        "rouge_l": 0.3661971830985915,
        "text_similarity": 0.7177995443344116,
        "llm_judge_score": 2,
        "llm_judge_justification": "While the predicted answer correctly marks the relation as 'after', its timestamps are roughly 34 seconds earlier than the ground truth and it omits the slide's end time, so the timing information is factually incorrect and incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker mentions \"boarding 190 patients in the emergency department\", when does he discuss concerns about the level of care?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3154.983,
        "end": 3143.945
      },
      "pred_interval": {
        "start": 3106.0,
        "end": 3107.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 48.983000000000175,
        "end": 36.945000000000164,
        "average": 42.96400000000017
      },
      "rationale_metrics": {
        "rouge_l": 0.30588235294117644,
        "text_similarity": 0.7172719240188599,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures that the target occurs immediately after the anchor (relationship 'after'), but the reported timestamps are materially incorrect compared to the ground truth, so it fails to match the required temporal anchors."
      }
    },
    {
      "question_id": "001",
      "question": "After the first speaker mentions 'in all 26 of those cases', when does he then talk about 'many more cases'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3214.9,
        "end": 3215.4
      },
      "pred_interval": {
        "start": 3213.04,
        "end": 3217.12
      },
      "iou": 0.12254901960784532,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.8600000000001273,
        "end": 1.7199999999998,
        "average": 1.7899999999999636
      },
      "rationale_metrics": {
        "rouge_l": 0.48275862068965525,
        "text_similarity": 0.6445257067680359,
        "llm_judge_score": 6,
        "llm_judge_justification": "The predicted answer correctly identifies the relation as 'after' and roughly locates both events, but both timestamps are ~2\u20133 seconds later than the reference and it omits the E2 end time, so it is only a partial match."
      }
    },
    {
      "question_id": "002",
      "question": "After the first speaker states that the 'escalation of care protocol' was nice, when does he mention a 'SOFA-based protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3246.0,
        "end": 3249.0
      },
      "pred_interval": {
        "start": 3236.8,
        "end": 3239.44
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 9.199999999999818,
        "end": 9.559999999999945,
        "average": 9.379999999999882
      },
      "rationale_metrics": {
        "rouge_l": 0.3934426229508196,
        "text_similarity": 0.7545459270477295,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relation and gives timestamps for both events, but the provided times deviate substantially from the reference (E1 end 3236.8 vs 3233.0; E2 start 3239.44 vs 3246.0), so the timing is inaccurate."
      }
    },
    {
      "question_id": "003",
      "question": "After the second speaker says 'SOFA is horrendous', when does he mention 'SOFA's AUC goes up'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3322.32,
        "end": 3324.71
      },
      "pred_interval": {
        "start": 3255.52,
        "end": 3258.24
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 66.80000000000018,
        "end": 66.47000000000025,
        "average": 66.63500000000022
      },
      "rationale_metrics": {
        "rouge_l": 0.4444444444444445,
        "text_similarity": 0.7663921117782593,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two utterances and their temporal relation ('after'), but the reported timestamps are substantially incorrect (off by ~65\u201367 seconds), so it fails on factual timing accuracy."
      }
    },
    {
      "question_id": "001",
      "question": "After the question about equity monitoring is asked, when does the speaker begin explaining the logging process for patient cases?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3401.583,
        "end": 3406.09
      },
      "pred_interval": {
        "start": 3401.5,
        "end": 3402.2
      },
      "iou": 0.13442265795200758,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.08300000000008367,
        "end": 3.8900000000003274,
        "average": 1.9865000000002055
      },
      "rationale_metrics": {
        "rouge_l": 0.2916666666666667,
        "text_similarity": 0.7138426303863525,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction substantially misstates the question timing (E1) by about 5 seconds versus the reference, although the E2 start is only ~0.6s off; it also adds unsupported audio-cue details and asserts an 'immediately after' relation that conflicts with the ground-truth timing/ordering."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing the 'Escalation of Care Protocol', when does the 'Conscientious Practice Policy' slide appear on screen?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3429.8,
        "end": 3430.5
      },
      "pred_interval": {
        "start": 3423.5,
        "end": 3424.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.300000000000182,
        "end": 6.5,
        "average": 6.400000000000091
      },
      "rationale_metrics": {
        "rouge_l": 0.4086021505376344,
        "text_similarity": 0.7702641487121582,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the order (slide appears after the speaker) and E1 time is close, but the E2 timestamp is incorrect (3424.0s vs reference 3429.8s) and the 'immediately after' relation contradicts the actual timing difference."
      }
    },
    {
      "question_id": "003",
      "question": "After the 'Conscientious Practice Policy' slide appears, when does the speaker mention tracking outcomes and looking back retrospectively for this policy?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3548.0
      },
      "gt_interval": {
        "start": 3444.0,
        "end": 3492.0
      },
      "pred_interval": {
        "start": 3430.8,
        "end": 3431.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 13.199999999999818,
        "end": 60.40000000000009,
        "average": 36.799999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.3829787234042553,
        "text_similarity": 0.7842532396316528,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer correctly identifies the relation as 'after' but substantially misreports both timestamps (slide at 3424.0s vs 3434.0s) and places the tracking/retrospective remarks at ~3430.8\u20133431.6s rather than the correct 3444.0\u20133492.0s, omitting the correct E2 time window."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions an increasing disparity over time, when does he discuss how they can provide support to all hospitals?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 707.399,
        "end": 742.972
      },
      "pred_interval": {
        "start": 745.68,
        "end": 764.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 38.28099999999995,
        "end": 21.52800000000002,
        "average": 29.904499999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.3191489361702128,
        "text_similarity": 0.9030760526657104,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the same phrases and the 'after' relationship, but the timestamps are significantly wrong: the predicted anchor and target occur much later than the ground-truth, and the predicted anchor falls inside the ground-truth target, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "While the organizational chart for the Center for Clinical Ethics is displayed, when does the speaker describe the Ethics Education program?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 769.177,
        "end": 786.763
      },
      "pred_interval": {
        "start": 834.22,
        "end": 841.16
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 65.043,
        "end": 54.396999999999935,
        "average": 59.71999999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.25641025641025644,
        "text_similarity": 0.35963916778564453,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction incorrectly shifts both the slide display and the speaker's timing by ~65s and gives wrong start/end times, contradicting the ground-truth timestamps; while it notes simultaneity, the temporal details are largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says he will go into depth on the programs, when does he first mention the Yale Interdisciplinary Center for Bioethics?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 837.605,
        "end": 845.26
      },
      "pred_interval": {
        "start": 893.56,
        "end": 897.64
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 55.95499999999993,
        "end": 52.379999999999995,
        "average": 54.16749999999996
      },
      "rationale_metrics": {
        "rouge_l": 0.4727272727272728,
        "text_similarity": 0.7083033323287964,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct utterances but gives timestamps that are substantially different from the reference and incorrectly characterizes the temporal relation as 'immediately after'; major factual timing errors make it largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the title 'Systemwide Ethics Forum and Newsletter', when does he describe it as a hybrid meeting?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1070.5,
        "end": 1076.5
      },
      "pred_interval": {
        "start": 1050.0,
        "end": 1051.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.5,
        "end": 24.799999999999955,
        "average": 22.649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.4,
        "text_similarity": 0.6500371694564819,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly quotes the hybrid statement but gives incorrect timings and wrongly labels the relation as 'immediately after' rather than the later 'after' (there is a noticeable time gap), so it misrepresents the temporal information."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes explaining that they looked through the 26 specific patient cases individually, when does the slide transition to 'Scope of protocol'?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3425.8,
        "end": 3429.0
      },
      "pred_interval": {
        "start": 3418.19,
        "end": 3418.19
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.610000000000127,
        "end": 10.809999999999945,
        "average": 9.210000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.25,
        "text_similarity": 0.6956229209899902,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly matches the speaker finish time but incorrectly claims the slide appears immediately at 3418.20s; the correct slide begins at 3425.8s and transitions at 3429.0s, so the timing is substantially wrong and contradicts the reference."
      }
    },
    {
      "question_id": "002",
      "question": "Once the 'Scope of protocol' slide finishes being displayed, when does the 'Conscientious Practice Policy' slide appear?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3429.0,
        "end": 3519.5
      },
      "pred_interval": {
        "start": 3426.03,
        "end": 3426.03
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.9699999999998,
        "end": 93.4699999999998,
        "average": 48.2199999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.29729729729729726,
        "text_similarity": 0.7474046349525452,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the immediate 'once_finished' transition, but its timestamps disagree with the reference (3426.03s vs 3429.0s) and it omits the Conscientious Practice Policy slide's end time, making it partially incorrect and incomplete."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker finishes discussing the tracking of equity, socioeconomic status, and other demographic characteristics, when is the presentation window minimized?",
      "video_id": "zq-hPiBgadw",
      "video_number": "014",
      "segment": {
        "start": 3390.0,
        "end": 3547.1899999999996
      },
      "gt_interval": {
        "start": 3530.0,
        "end": 3531.0
      },
      "pred_interval": {
        "start": 3522.45,
        "end": 3522.45
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.550000000000182,
        "end": 8.550000000000182,
        "average": 8.050000000000182
      },
      "rationale_metrics": {
        "rouge_l": 0.2816901408450704,
        "text_similarity": 0.5975013971328735,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the 'after' relation but gives incorrect timestamps and wrongly asserts an immediate minimization; the correct end time is 3508.5s and minimization occurs at 3530.0\u20133531.0s, not at 3522.46s."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker states the audience will be on mute, when does he mention that the live event can be paused?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 38.524,
        "end": 43.729
      },
      "pred_interval": {
        "start": 26.44,
        "end": 29.6
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.084,
        "end": 14.128999999999998,
        "average": 13.106499999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.2,
        "text_similarity": 0.6544662714004517,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer misidentifies and mis-times both events (swap and wrong timestamps), gives an incorrect relation and target span, and adds unsupported phrasing; it does not match the ground-truth timing and labels."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker discusses changing the speed of presentations and speakers, when does he advise on what to do if Wi-Fi or connection is lost?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 55.563,
        "end": 59.787
      },
      "pred_interval": {
        "start": 57.16,
        "end": 63.32
      },
      "iou": 0.33866185380946284,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.5969999999999942,
        "end": 3.5330000000000013,
        "average": 2.5649999999999977
      },
      "rationale_metrics": {
        "rouge_l": 0.16438356164383564,
        "text_similarity": 0.6936927437782288,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction largely misidentifies events and times: it places E1 at 57.16s instead of 44.691s and conflates the anchor with the reconnect advice. While the predicted E2 partly overlaps the correct target span, the event labels, timings, and stated relation are incorrect or inconsistent."
      }
    },
    {
      "question_id": "001",
      "question": "After the presenter mentions Tom Gardner in the background, when does he mention Stephanie Fraser joining in place of Jane Preston?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 168.258,
        "end": 171.201
      },
      "pred_interval": {
        "start": 186.0,
        "end": 192.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 17.74199999999999,
        "end": 20.799000000000007,
        "average": 19.2705
      },
      "rationale_metrics": {
        "rouge_l": 0.4222222222222222,
        "text_similarity": 0.8271998167037964,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the correct anchor and target mentions and the 'after' relation, but the timestamps are grossly incorrect (off by ~173s), so the temporal alignment is largely wrong."
      }
    },
    {
      "question_id": "002",
      "question": "Once the male presenter finishes introducing Stephanie Fraser, when does Stephanie Fraser begin speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 223.86,
        "end": 224.8
      },
      "pred_interval": {
        "start": 192.0,
        "end": 193.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 31.860000000000014,
        "end": 31.80000000000001,
        "average": 31.830000000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.523076923076923,
        "text_similarity": 0.8239208459854126,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies Stephanie Fraser saying 'Good morning everybody' and that she speaks after the male presenter, but the anchor utterance text and all timestamps are substantially different (192/193s vs 222/223.86s), and the timing/relationship detail is therefore largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "While the speaker is discussing the recent research undertaken by the Neurological Alliance of Scotland, when does she state that 57% of respondents reported not being able to access a face-to-face appointment?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 433.0,
        "end": 434.9
      },
      "pred_interval": {
        "start": 395.84,
        "end": 400.08
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 37.160000000000025,
        "end": 34.81999999999999,
        "average": 35.99000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.13636363636363635,
        "text_similarity": 0.18464013934135437,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction locates the line within the general discussion but places the '57%' utterance much earlier (395.8\u2013400.1s) than the correct 433.0\u2013434.9s; it therefore fails to match the specific timing despite correct context."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes stating that nearly two-thirds of respondents had not had a video appointment, when does she state that telephone appointments were the most common way to access care?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 447.8,
        "end": 452.9
      },
      "pred_interval": {
        "start": 407.88,
        "end": 408.78
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.920000000000016,
        "end": 44.120000000000005,
        "average": 42.02000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2894736842105263,
        "text_similarity": 0.44044339656829834,
        "llm_judge_score": 0,
        "llm_judge_justification": "The predicted timestamps (408.78\u2013414.9s) do not match the reference (447.8\u2013452.9s) and wrongly asserts the sentence immediately follows the anchor; therefore the response is incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the blue slide with the speaker's title disappears, when does the speaker begin to mention what factors clinicians should consider for appointment formats?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 330.0,
        "end": 540.0
      },
      "gt_interval": {
        "start": 479.3,
        "end": 480.3
      },
      "pred_interval": {
        "start": 524.08,
        "end": 525.72
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 44.78000000000003,
        "end": 45.420000000000016,
        "average": 45.10000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.37209302325581395,
        "text_similarity": 0.28149500489234924,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly quotes the phrase but gives timestamps that are ~46 seconds later than the reference and misidentifies the anchor time, so it contradicts the correct timing and is therefore largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once Stephanie finishes speaking and hands over to Mark, when does Mark begin to speak?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 606.5,
        "end": 607.0
      },
      "pred_interval": {
        "start": 720.0,
        "end": 723.2
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 113.5,
        "end": 116.20000000000005,
        "average": 114.85000000000002
      },
      "rationale_metrics": {
        "rouge_l": 0.19047619047619047,
        "text_similarity": 0.6660501956939697,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly indicates Mark speaks after Stephanie, but the timestamps are completely different from the reference (predicted ~720\u2013723s vs correct ~594\u2013607s) and it adds unsupported detail about an audio cut; thus it is largely incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once Mark finishes introducing Calum Duncan, when does Calum Duncan start speaking?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 638.3,
        "end": 639.3
      },
      "pred_interval": {
        "start": 758.7,
        "end": 760.8
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 120.40000000000009,
        "end": 121.5,
        "average": 120.95000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.21875000000000003,
        "text_similarity": 0.6662672758102417,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the temporal relation (Calum speaks immediately after Mark) and approximate relative offset, but it gives incorrect absolute timestamps (758.7/760.8s vs. 636.3-639.3s) and omits the ground-truth intervals, so it is only partially correct."
      }
    },
    {
      "question_id": "003",
      "question": "Once Calum Duncan says 'Next slide please', when does the second presentation slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 510.0,
        "end": 720.0
      },
      "gt_interval": {
        "start": 685.7,
        "end": 686.0
      },
      "pred_interval": {
        "start": 808.6,
        "end": 810.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 122.89999999999998,
        "end": 124.70000000000005,
        "average": 123.80000000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.2727272727272727,
        "text_similarity": 0.672044575214386,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the slide follows Calum's cue (same ordering), but the timestamps are substantially different from the reference (\u2248124s later) and the onset interval and extra chime detail contradict the given timings, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 'near me is what we're going to focus on today', when does he describe it as 'internet-based'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 702.7,
        "end": 703.5
      },
      "pred_interval": {
        "start": 690.0,
        "end": 691.4
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 12.700000000000045,
        "end": 12.100000000000023,
        "average": 12.400000000000034
      },
      "rationale_metrics": {
        "rouge_l": 0.3389830508474576,
        "text_similarity": 0.6923502087593079,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the event and the 'after' relation, but both anchor and target timestamps are off by about 10\u201312 seconds compared to the reference, so the timing is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker states there were '330 consultations per week' before the pandemic, when does he mention it went up to '10,000'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 737.0,
        "end": 739.0
      },
      "pred_interval": {
        "start": 709.1,
        "end": 710.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 27.899999999999977,
        "end": 28.5,
        "average": 28.19999999999999
      },
      "rationale_metrics": {
        "rouge_l": 0.25925925925925924,
        "text_similarity": 0.6153818368911743,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer gets the qualitative relation ('after') right but the timestamps and segment alignments are significantly incorrect (709\u2013710s vs. the correct 731.5\u2013739s range) and thus fails to match the reference anchoring of the '10,000' remark."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' for the first time, when does he point to the map on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 690.0,
        "end": 900.0
      },
      "gt_interval": {
        "start": 767.0,
        "end": 767.5
      },
      "pred_interval": {
        "start": 732.2,
        "end": 734.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 34.799999999999955,
        "end": 33.5,
        "average": 34.14999999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.2950819672131148,
        "text_similarity": 0.7333025932312012,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction misstates both timestamps (anchor 732.2s vs 756.0s, target 734.0s vs 767.0s) and wrongly identifies the target as spoken commentary rather than the visual pointing action; only the 'after' relation matches."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker says 'go back to the next slide', when does the slide titled 'Video consulting using near me via attend anywhere platform' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 874.0,
        "end": 874.1
      },
      "pred_interval": {
        "start": 877.0,
        "end": 880.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 3.0,
        "end": 5.899999999999977,
        "average": 4.449999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.3380281690140845,
        "text_similarity": 0.5647705793380737,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures the immediate relationship (slide appears right after the instruction) but the absolute timestamps are incorrect by about 3\u20134 seconds (predicted 877.0/878.0 vs correct 873.91/874.0), so it's partially accurate but temporally imprecise."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions that 'Stephanie Fraser has talked about' the survey, when does he then say 'Back to next slide, Mark, please'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 883.0,
        "end": 884.0
      },
      "pred_interval": {
        "start": 893.0,
        "end": 896.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.0,
        "end": 12.0,
        "average": 11.0
      },
      "rationale_metrics": {
        "rouge_l": 0.17500000000000002,
        "text_similarity": 0.4461563527584076,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction gets the ordering right (target after anchor) but the timestamps are significantly off (~10s difference) and it adds an unverified detail about an immediate slide change, so it is partially correct but factually inaccurate on key elements."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker says 'Next slide, please' at the 42-second mark, when does the slide titled 'Clinician and patient experience - Scotland' appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 870.0,
        "end": 1080.0
      },
      "gt_interval": {
        "start": 913.0,
        "end": 913.1
      },
      "pred_interval": {
        "start": 920.0,
        "end": 923.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.0,
        "end": 9.899999999999977,
        "average": 8.449999999999989
      },
      "rationale_metrics": {
        "rouge_l": 0.2903225806451613,
        "text_similarity": 0.526171088218689,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states the slide appears immediately after the verbal cue, but both reported timestamps (920.0s/921.0s) are inaccurate compared to the reference (912.0s/913.0s), so key factual elements are wrong."
      }
    },
    {
      "question_id": "001",
      "question": "During the discussion of what works well with video calls, when does the speaker express finding it much easier to interact with groups on a video call than on the telephone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1053.0,
        "end": 1062.5
      },
      "pred_interval": {
        "start": 1151.42,
        "end": 1168.38
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 98.42000000000007,
        "end": 105.88000000000011,
        "average": 102.15000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.25263157894736843,
        "text_similarity": 0.6382654905319214,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the target phrase and the 'during' relation, but the anchor and target timestamps are significantly offset (~100s) from the ground truth, so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions technical issues with patient bandwidth, when does he advise to choose patients correctly to avoid those difficulties?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1134.0,
        "end": 1135.5
      },
      "pred_interval": {
        "start": 1191.72,
        "end": 1196.92
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 57.72000000000003,
        "end": 61.42000000000007,
        "average": 59.57000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.36363636363636365,
        "text_similarity": 0.6382988691329956,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the same events but gives substantially different timestamps (shifted ~72s) and places E2 within the E1 interval, contradicting the correct 'after' relation; minor credit for matching event content but timing and relation are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker says 'Next slide, please' to introduce the smart phone camera, when does he specifically point out his wife's iPhone on the screen?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1050.0,
        "end": 1260.0
      },
      "gt_interval": {
        "start": 1213.0,
        "end": 1215.0
      },
      "pred_interval": {
        "start": 1236.82,
        "end": 1242.84
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 23.819999999999936,
        "end": 27.839999999999918,
        "average": 25.829999999999927
      },
      "rationale_metrics": {
        "rouge_l": 0.35820895522388063,
        "text_similarity": 0.69306480884552,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the two events and their temporal relation ('after'), but the timestamps are substantially off (each ~28\u201334 seconds later than the reference) and the predicted answer omits the correct E2 interval, so it is factually inaccurate on timing."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying 'Next slide please', when does the 'Sharing content' slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1248.574,
        "end": 1249.574
      },
      "pred_interval": {
        "start": 1230.0,
        "end": 1230.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 18.57400000000007,
        "end": 19.57400000000007,
        "average": 19.07400000000007
      },
      "rationale_metrics": {
        "rouge_l": 0.2888888888888889,
        "text_similarity": 0.798470139503479,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gets the relationship qualitatively (slide appears as speaker finishes) but the timestamps are nearly 18 seconds off for both anchor and target versus the ground truth, so the factual timing is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'You can share things', when does he point towards the screen showing the brain scan?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1252.25,
        "end": 1252.85
      },
      "pred_interval": {
        "start": 1233.0,
        "end": 1234.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 19.25,
        "end": 18.84999999999991,
        "average": 19.049999999999955
      },
      "rationale_metrics": {
        "rouge_l": 0.3181818181818182,
        "text_similarity": 0.6823206543922424,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives completely different timestamps (1233.0s vs ground-truth 1249.255s anchor and 1252.250\u20131252.850s target) and incorrectly claims the point is simultaneous with the utterance, so it hallucinates timings and contradicts the ground truth despite noting a pointing gesture."
      }
    },
    {
      "question_id": "003",
      "question": "During the discussion about poor picture quality, when does the speaker suggest clearing browser history?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1230.0,
        "end": 1440.0
      },
      "gt_interval": {
        "start": 1313.823,
        "end": 1315.286
      },
      "pred_interval": {
        "start": 1285.0,
        "end": 1287.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 28.823000000000093,
        "end": 28.286000000000058,
        "average": 28.554500000000075
      },
      "rationale_metrics": {
        "rouge_l": 0.35443037974683544,
        "text_similarity": 0.8020108342170715,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies that the speaker suggests clearing browser history and the relation ('during'), but the provided timestamps are incorrect and do not match the reference times (off by ~28s) and omit the precise target interval, so it is largely wrong on the key timing detail."
      }
    },
    {
      "question_id": "001",
      "question": "Once the man finishes saying \"Thank you very much for that\", when does he state he is handing over to Jane?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1428.837,
        "end": 1430.682
      },
      "pred_interval": {
        "start": 1440.0,
        "end": 1446.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.163000000000011,
        "end": 15.317999999999984,
        "average": 13.240499999999997
      },
      "rationale_metrics": {
        "rouge_l": 0.4556962025316456,
        "text_similarity": 0.6355659365653992,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the utterances and their sequential relation, but it gives incorrect timestamps (1440.0s) that conflict with the ground-truth times (1427.0s and 1428.837\u20131430.682s), so the timing information is factually wrong."
      }
    },
    {
      "question_id": "003",
      "question": "After the woman (Jane) describes the challenges of managing patients over the telephone, when does she mention that they had a pilot of 'Near Me' even prior to Covid?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1410.0,
        "end": 1620.0
      },
      "gt_interval": {
        "start": 1609.855,
        "end": 1624.692
      },
      "pred_interval": {
        "start": 1560.0,
        "end": 1566.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 49.85500000000002,
        "end": 58.69200000000001,
        "average": 54.27350000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.3888888888888889,
        "text_similarity": 0.6890339255332947,
        "llm_judge_score": 4,
        "llm_judge_justification": "The prediction correctly captures that Jane mentions the 'Near Me' pilot immediately after describing telephone-management challenges and even quotes the line, but the timestamps are substantially off (predicted ~1540\u20131560s vs. reference ~1605\u20131610s), so the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that using 'Near Me' felt quite adventurous, when does she state that its use became vital to their whole service?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1636.0,
        "end": 1643.0
      },
      "pred_interval": {
        "start": 1602.1,
        "end": 1603.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.90000000000009,
        "end": 39.5,
        "average": 36.700000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.39506172839506176,
        "text_similarity": 0.7149602174758911,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gets the relation ('after') right but the anchor/event times and quoted content are incorrect and do not match the reference spans, so it fails to identify the correct anchor and target."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes asking Mark to go back to the previous slide, when does she say 'Thank you'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1590.0,
        "end": 1800.0
      },
      "gt_interval": {
        "start": 1676.54,
        "end": 1678.02
      },
      "pred_interval": {
        "start": 1615.7,
        "end": 1616.7
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 60.83999999999992,
        "end": 61.319999999999936,
        "average": 61.07999999999993
      },
      "rationale_metrics": {
        "rouge_l": 0.4000000000000001,
        "text_similarity": 0.7816781997680664,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction identifies similar utterances but misreports both event timestamps by large margins and the target span, and only roughly matches the temporal relation; therefore it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the 'Training and preparation' slide appears, when does the speaker mention the 'Level 1' training?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1791.0,
        "end": 1791.5
      },
      "pred_interval": {
        "start": 1770.0,
        "end": 1775.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.0,
        "end": 16.5,
        "average": 18.75
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.560228705406189,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives incorrect timestamps for both the slide (1770.0s vs 1774.4\u20131774.5s) and the utterance (claims immediate at 1770.0s vs actual 1791.0\u20131791.5s), falsely stating the remark occurred directly after the slide; significant factual errors and fabricated timing details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes describing tele-swallowing partners as 'our eyes and our hands and our ears', when does she start talking about preparing the clinical room?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1897.0,
        "end": 1901.0
      },
      "pred_interval": {
        "start": 1789.0,
        "end": 1791.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 108.0,
        "end": 110.0,
        "average": 109.0
      },
      "rationale_metrics": {
        "rouge_l": 0.30985915492957744,
        "text_similarity": 0.4434932470321655,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the ordering (finishing the phrase then discussing preparing the clinical room) but gives timestamps that are substantially incorrect (~100 seconds earlier) and wrongly asserts an immediate transition, so it largely contradicts the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker discusses tele-swallowing partners preparing the clinical room, when does she next talk about them providing reassurance to patients?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1770.0,
        "end": 1980.0
      },
      "gt_interval": {
        "start": 1906.0,
        "end": 1910.0
      },
      "pred_interval": {
        "start": 1800.0,
        "end": 1802.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 106.0,
        "end": 108.0,
        "average": 107.0
      },
      "rationale_metrics": {
        "rouge_l": 0.34285714285714286,
        "text_similarity": 0.6469393372535706,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction references the same two events in the correct order but the timestamps are substantially wrong (off by ~100 seconds), contradicting the ground-truth intervals and thus failing to provide the key factual timing details."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes mentioning emergency procedures in place onsite, when does the slide change to 'Technology/equipment'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 1971.6,
        "end": 1972.0
      },
      "pred_interval": {
        "start": 1966.84,
        "end": 1967.14
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.759999999999991,
        "end": 4.8599999999999,
        "average": 4.809999999999945
      },
      "rationale_metrics": {
        "rouge_l": 0.1875,
        "text_similarity": 0.4368416368961334,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction roughly matches the speaker end time (1966.84s vs 1966.619s) but incorrectly timestamps the slide change (1967.14s vs actual 1971.6\u20131972.0s) and thus wrongly labels the relation as 'immediately after', which is a significant factual error."
      }
    },
    {
      "question_id": "002",
      "question": "During the time the 'Technology/equipment' slide is displayed, when does the speaker discuss the need for a device with a webcam and microphone?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2024.079,
        "end": 2026.579
      },
      "pred_interval": {
        "start": 1982.06,
        "end": 1985.07
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 42.019000000000005,
        "end": 41.509000000000015,
        "average": 41.76400000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.17948717948717946,
        "text_similarity": 0.45716559886932373,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction incorrectly reports both the slide and mention timestamps (the speaker mention is ~42s earlier and the slide end ~133s earlier than the ground truth), so the timing is wrong; it only correctly states the mention occurs 'during' the slide."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker introduces the general category of 'certain resources' for teleswallow sessions, when does she mention 'appropriate diet and fluid consistencies'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 1950.0,
        "end": 2160.0
      },
      "gt_interval": {
        "start": 2058.952,
        "end": 2061.952
      },
      "pred_interval": {
        "start": 2019.76,
        "end": 2022.21
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 39.192000000000235,
        "end": 39.74200000000019,
        "average": 39.46700000000021
      },
      "rationale_metrics": {
        "rouge_l": 0.1492537313432836,
        "text_similarity": 0.31958669424057007,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer misidentifies both anchor and target timestamps (2017\u20132022s vs. correct 2052\u20132062s) and thus gets the key factual elements wrong; only the temporal relation ('after') aligns, so the match is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that remote swallowing assessments are not intended to fully replace face-to-face assessments, when does she mention that they are a very useful addition?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2159.677,
        "end": 2162.619
      },
      "pred_interval": {
        "start": 2231.68,
        "end": 2234.36
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 72.0029999999997,
        "end": 71.74099999999999,
        "average": 71.87199999999984
      },
      "rationale_metrics": {
        "rouge_l": 0.3777777777777777,
        "text_similarity": 0.49615350365638733,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly captures that the target phrase immediately follows the anchor and preserves the wording, but the provided timestamps conflict with the reference (off by ~72 seconds), so the timing information is factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the speaker finishes mentioning gathering feedback from those who completed the training, when does she start talking about evaluating quantitative data?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2164.643,
        "end": 2186.427
      },
      "pred_interval": {
        "start": 2252.08,
        "end": 2254.08
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 87.4369999999999,
        "end": 67.65299999999979,
        "average": 77.54499999999985
      },
      "rationale_metrics": {
        "rouge_l": 0.3137254901960784,
        "text_similarity": 0.6020928621292114,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures that the discussion of quantitative data immediately follows the remark about completed training, but it gives incorrect timestamps (off by ~66 s), incorrectly asserts no pause (correct shows a 1 s gap), and adds unsupported details about types of data, so it is largely incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "Once the first speaker finishes her presentation by saying 'thank you very much for listening', when does the video visually transition to the male presenter?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2130.0,
        "end": 2340.0
      },
      "gt_interval": {
        "start": 2257.0,
        "end": 2258.0
      },
      "pred_interval": {
        "start": 2265.44,
        "end": 2266.24
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.440000000000055,
        "end": 8.239999999999782,
        "average": 8.339999999999918
      },
      "rationale_metrics": {
        "rouge_l": 0.24242424242424243,
        "text_similarity": 0.551099956035614,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly states the visual transition follows immediately after the woman finishes, but the provided timestamps are substantially wrong (2265.44/2266.24s vs. 2256.0/2257.0s) and it adds unwarranted specific dialogue, so key factual elements are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "Once the speaker finishes saying that picking up cues is difficult, when does she start talking about 'points to consider' for virtual technology?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2491.8,
        "end": 2498.2
      },
      "pred_interval": {
        "start": 2524.99,
        "end": 2526.54
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.1899999999996,
        "end": 28.340000000000146,
        "average": 30.764999999999873
      },
      "rationale_metrics": {
        "rouge_l": 0.20560747663551404,
        "text_similarity": 0.4831840395927429,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the speaker moves to 'points to consider' after mentioning difficulty, but the timestamps are off by ~33 seconds, the relation is labeled 'after' with a claimed pause rather than the ground-truth 'once_finished' immediate continuation, so it is temporally inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker mentions conducting a 'sprint audit' with patients, when does she state that 'most were very satisfied' with the virtual appointments?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2515.0,
        "end": 2516.0
      },
      "pred_interval": {
        "start": 2545.39,
        "end": 2549.28
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 30.389999999999873,
        "end": 33.2800000000002,
        "average": 31.835000000000036
      },
      "rationale_metrics": {
        "rouge_l": 0.2173913043478261,
        "text_similarity": 0.567940890789032,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the general relation (after) and the target phrase, but it misidentifies the anchor utterance and both timestamps (off by ~36s) and adds extraneous details about questionnaires; key temporal and anchor facts do not match the ground truth."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes saying that patients found virtual technology 'more acceptable', when does she say 'So moving on to the next slide'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2490.0,
        "end": 2700.0
      },
      "gt_interval": {
        "start": 2638.0,
        "end": 2639.3
      },
      "pred_interval": {
        "start": 2626.22,
        "end": 2627.76
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 11.7800000000002,
        "end": 11.539999999999964,
        "average": 11.660000000000082
      },
      "rationale_metrics": {
        "rouge_l": 0.2708333333333333,
        "text_similarity": 0.6123156547546387,
        "llm_judge_score": 0,
        "llm_judge_justification": "The prediction references a different anchor phrase and incorrect timestamps (\u224810s earlier) and thus fails to match the ground-truth event or timing; the relation and E2 timing also do not align with the correct answer."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker finishes discussing confidentiality, when does she begin to mention the subtlety of the therapeutic relationship?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2693.583,
        "end": 2697.126
      },
      "pred_interval": {
        "start": 2691.42,
        "end": 2691.42
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 2.163000000000011,
        "end": 5.706000000000131,
        "average": 3.934500000000071
      },
      "rationale_metrics": {
        "rouge_l": 0.19718309859154928,
        "text_similarity": 0.7633517980575562,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the events and their order (the therapeutic relationship is mentioned after confidentiality) and preserves meaning, but the provided timestamps are notably offset from the ground truth (E1 ~2.8s late, E2 ~1.5s early), so the temporal alignment is inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says 'It all comes down to Wi-Fi', when does she state that 'delivery of remote therapy is very, very difficult'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2670.0,
        "end": 2880.0
      },
      "gt_interval": {
        "start": 2727.0,
        "end": 2729.0
      },
      "pred_interval": {
        "start": 2712.76,
        "end": 2713.96
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 14.239999999999782,
        "end": 15.039999999999964,
        "average": 14.639999999999873
      },
      "rationale_metrics": {
        "rouge_l": 0.4395604395604396,
        "text_similarity": 0.9061479568481445,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction preserves the phrasing and correctly identifies the target as occurring after the anchor, but both the anchor (\u22489.3s early) and target (\u224813.6s early) timestamps are substantially incorrect and the E2 time window does not match the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says 'So next slide', when does the slide visually change to 'Practical considerations'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2884.0,
        "end": 2884.2
      },
      "pred_interval": {
        "start": 3048.5,
        "end": 3050.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 164.5,
        "end": 165.80000000000018,
        "average": 165.1500000000001
      },
      "rationale_metrics": {
        "rouge_l": 0.42500000000000004,
        "text_similarity": 0.7613322734832764,
        "llm_judge_score": 3,
        "llm_judge_justification": "The predicted answer correctly preserves the immediate sequential relationship (slide changes right after the cue) but gives substantially different timestamps (3048.5s/3050.0s vs. 2883.0s/2884.0s), so it is factually incorrect on the key timing details."
      }
    },
    {
      "question_id": "002",
      "question": "While the speaker is discussing 'Practical considerations', when does she first mention 'increasing reflective feedback'?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2850.0,
        "end": 3060.0
      },
      "gt_interval": {
        "start": 2913.483,
        "end": 2916.268
      },
      "pred_interval": {
        "start": 3059.7,
        "end": 3062.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 146.21699999999964,
        "end": 146.23199999999997,
        "average": 146.2244999999998
      },
      "rationale_metrics": {
        "rouge_l": 0.32432432432432434,
        "text_similarity": 0.7880345582962036,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted timestamps are significantly incorrect (reference: 2850.0 start and 2913.483 mention; prediction: 3050.0 and 3059.7\u20133062.5). Although it correctly states the mention occurs within the broader discussion, the timing errors and added duration make it largely mismatched to the ground truth."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker says \"for the patients\", when does the slide change to \"WHERE WE ARE NOW\"?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3067.769,
        "end": 3068.2
      },
      "pred_interval": {
        "start": 3143.88,
        "end": 3144.02
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 76.11100000000033,
        "end": 75.82000000000016,
        "average": 75.96550000000025
      },
      "rationale_metrics": {
        "rouge_l": 0.37037037037037035,
        "text_similarity": 0.7505460381507874,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies that the slide change occurs immediately after the speaker says 'for the patients', but it gives timestamps that are substantially different from the ground truth and omits the detail about the slide being fully visible by 3068.2s, so the temporal coordinates are factually incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the man says \"open up for some discussion\", when does the discussion slide appear?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3030.0,
        "end": 3240.0
      },
      "gt_interval": {
        "start": 3163.435,
        "end": 3163.7
      },
      "pred_interval": {
        "start": 3184.98,
        "end": 3185.08
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 21.545000000000073,
        "end": 21.38000000000011,
        "average": 21.46250000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.3,
        "text_similarity": 0.6695765256881714,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the direction right (slide appears after the utterance) but the timestamps are substantially incorrect and it erroneously states the slide appears immediately, contradicting the correct ~43s delay; key factual timing details are missing/incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the first male speaker asks about attendees' experience with Near Me, when does the second male speaker begin talking about starting to use NearMe?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3268.9,
        "end": 3312.0
      },
      "pred_interval": {
        "start": 3210.0,
        "end": 3210.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 58.90000000000009,
        "end": 102.0,
        "average": 80.45000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.29333333333333333,
        "text_similarity": 0.6401196718215942,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct second-speaker utterance but gives entirely incorrect timestamps (both at 3210.0s vs reference 3248.8s and 3268.9s) and wrongly claims they are simultaneous/immediately adjacent rather than occurring later, so it fails on key timing and relation details."
      }
    },
    {
      "question_id": "002",
      "question": "Once the second male speaker finishes stating the advantages and utility of NearMe, when does he mention supplementing normal activities?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3210.0,
        "end": 3420.0
      },
      "gt_interval": {
        "start": 3288.4,
        "end": 3293.32
      },
      "pred_interval": {
        "start": 3234.0,
        "end": 3234.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 54.40000000000009,
        "end": 59.320000000000164,
        "average": 56.86000000000013
      },
      "rationale_metrics": {
        "rouge_l": 0.2028985507246377,
        "text_similarity": 0.5850852727890015,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the speaker and the quoted phrase but gives incorrect and inconsistent timestamps (both events at 3234.0s vs correct 3283.40s and 3288.40s) and misrepresents the temporal relation, so it fails on key factual elements."
      }
    },
    {
      "question_id": "001",
      "question": "After the first man finishes reading Jenny's chat message, when does he ask the audience if they would find guidance helpful?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3411.0,
        "end": 3415.0
      },
      "pred_interval": {
        "start": 3417.5,
        "end": 3423.9
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.5,
        "end": 8.900000000000091,
        "average": 7.7000000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.25316455696202533,
        "text_similarity": 0.7110816240310669,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the anchor (E1) roughly around the true time and the relation 'after', but the predicted target (E2) timing (3417.5\u20133423.9s) does not match the correct target span (3411.0\u20133415.0s) and even adds an unfounded 'immediately after' qualifier; key temporal alignment for E2 is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the first man finishes reading John Hogan's comment about clinical interviewing, when does he state he was quite skeptical?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3434.9,
        "end": 3437.7
      },
      "pred_interval": {
        "start": 3433.7,
        "end": 3437.7
      },
      "iou": 0.6999999999999318,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 1,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.2000000000002728,
        "end": 0.0,
        "average": 0.6000000000001364
      },
      "rationale_metrics": {
        "rouge_l": 0.36781609195402293,
        "text_similarity": 0.7632949352264404,
        "llm_judge_score": 5,
        "llm_judge_justification": "The prediction correctly identifies the skeptical utterance and the 'after' relation, but it misplaces the anchor (E1) by about 6\u201310s and starts E2 ~1.2s earlier than the ground truth, so the event timings do not precisely match."
      }
    },
    {
      "question_id": "003",
      "question": "After the second woman mentions neuropsychology bringing out guidance, when is the next time a woman speaks about professional guidance?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3390.0,
        "end": 3600.0
      },
      "gt_interval": {
        "start": 3511.043,
        "end": 3528.447
      },
      "pred_interval": {
        "start": 3477.5,
        "end": 3495.3
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 33.54300000000012,
        "end": 33.146999999999935,
        "average": 33.34500000000003
      },
      "rationale_metrics": {
        "rouge_l": 0.2857142857142857,
        "text_similarity": 0.8511157035827637,
        "llm_judge_score": 1,
        "llm_judge_justification": "The predicted answer gives completely different timestamps for both E1 and E2 (off by ~45\u201390s) and a target span that doesn't match the reference; although the temporal relation ('after') is similar, the key timing details are incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker mentions that 36 people joined the session, when does he talk about taking the next steps with Richard and the team?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3574.7,
        "end": 3576.5
      },
      "pred_interval": {
        "start": 3578.83,
        "end": 3586.19
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 4.130000000000109,
        "end": 9.690000000000055,
        "average": 6.910000000000082
      },
      "rationale_metrics": {
        "rouge_l": 0.26373626373626374,
        "text_similarity": 0.7224183082580566,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction identifies the same two events but the timestamps are substantially off (several seconds) and it even lists the anchor and target as starting simultaneously, contradicting the reference which has the target clearly after the anchor; therefore the temporal alignment is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker makes a plea to fill in the survey, when does he ask if listeners would like to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3592.9,
        "end": 3594.1
      },
      "pred_interval": {
        "start": 3603.88,
        "end": 3611.35
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 10.980000000000018,
        "end": 17.25,
        "average": 14.115000000000009
      },
      "rationale_metrics": {
        "rouge_l": 0.3673469387755102,
        "text_similarity": 0.7905967235565186,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction identifies the correct events (survey plea and advisory-committee question) but gives substantially incorrect timestamps and an inconsistent temporal relation (starts listed identical rather than the target occurring after the anchor), so it fails to match the ground truth timing and ordering."
      }
    },
    {
      "question_id": "003",
      "question": "Once the speaker finishes thanking everyone for joining the session today, when does he mention that the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3618.0
      },
      "gt_interval": {
        "start": 3599.8,
        "end": 3603.2
      },
      "pred_interval": {
        "start": 3615.08,
        "end": 3618.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 15.279999999999745,
        "end": 14.800000000000182,
        "average": 15.039999999999964
      },
      "rationale_metrics": {
        "rouge_l": 0.2637362637362637,
        "text_similarity": 0.8153470754623413,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction captures the content and that the remark comes after the thanks, but the timestamps are off by ~15 seconds and it incorrectly aligns the start/end times (E2 start equals E1 end rather than immediately following the given correct times), so it fails on precise temporal alignment."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks 'where did we start?', when does she mention considering moving to Near Me for patient contacts?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2332.719,
        "end": 2336.344
      },
      "pred_interval": {
        "start": 2310.0,
        "end": 2312.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 22.71900000000005,
        "end": 24.34400000000005,
        "average": 23.53150000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2898550724637681,
        "text_similarity": 0.7219375371932983,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the utterances but the timestamps are substantially incorrect (anchor 2310s vs correct 2320s; target 2312s vs correct 2332.719\u20132336.344s), so the temporal alignment and implied relationship are wrong."
      }
    },
    {
      "question_id": "002",
      "question": "After the speaker says the pandemic came along, when does she mention adopting Near Me as their default for routine people?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2367.217,
        "end": 2412.045
      },
      "pred_interval": {
        "start": 2388.0,
        "end": 2391.0
      },
      "iou": 0.06692245917729994,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 20.7829999999999,
        "end": 21.045000000000073,
        "average": 20.913999999999987
      },
      "rationale_metrics": {
        "rouge_l": 0.2222222222222222,
        "text_similarity": 0.7931760549545288,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly identifies the 'after' relationship, but both the anchor and target timestamps are substantially different from the reference (anchor ~2349s vs 2388s; target start 2367s vs 2391s) and the predicted answer omits the target end time, so key factual timing details are incorrect."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker describes the results of the focus groups for the qualitative study, when does she introduce the quotes from the participants?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 2310.0,
        "end": 2520.0
      },
      "gt_interval": {
        "start": 2511.0,
        "end": 2512.0
      },
      "pred_interval": {
        "start": 2416.0,
        "end": 2418.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 95.0,
        "end": 94.0,
        "average": 94.5
      },
      "rationale_metrics": {
        "rouge_l": 0.2571428571428571,
        "text_similarity": 0.7474458813667297,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction gets the qualitative relation ('after') right but the anchor and target timestamps are substantially wrong (off by tens of seconds to over a minute), so it fails to match the correct temporal boundaries."
      }
    },
    {
      "question_id": "001",
      "question": "After the speaker asks to fill in the survey, when does he ask if listeners want to engage with the advisory committee?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3591.7,
        "end": 3595.8
      },
      "pred_interval": {
        "start": 3593.1,
        "end": 3599.5
      },
      "iou": 0.34615384615387307,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.400000000000091,
        "end": 3.699999999999818,
        "average": 2.5499999999999545
      },
      "rationale_metrics": {
        "rouge_l": 0.288135593220339,
        "text_similarity": 0.7710732221603394,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction roughly identifies the same utterance content but gives inaccurate event boundaries (E2 shifted later and extended) and incorrectly states the temporal relation ('during' same sentence) contrary to the reference that the target occurs after the anchor."
      }
    },
    {
      "question_id": "002",
      "question": "Before the speaker thanks the speakers for their expertise, when does he mention the session will be recorded and resources will be provided?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3599.9,
        "end": 3603.7
      },
      "pred_interval": {
        "start": 3592.2,
        "end": 3594.5
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 7.700000000000273,
        "end": 9.199999999999818,
        "average": 8.450000000000045
      },
      "rationale_metrics": {
        "rouge_l": 0.26373626373626374,
        "text_similarity": 0.8493696451187134,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction mentions the same topical elements (recording and resources) but gives substantially incorrect timestamps, swaps/labels the events inconsistently, and gets the temporal relationship wrong, so it fails to match the reference."
      }
    },
    {
      "question_id": "003",
      "question": "After the speaker initially thanks the audience for joining, when does he deliver his final 'thank you very much' for the session?",
      "video_id": "cOpdhlVsyM8",
      "video_number": "015",
      "segment": {
        "start": 3570.0,
        "end": 3617.017
      },
      "gt_interval": {
        "start": 3614.6,
        "end": 3615.4
      },
      "pred_interval": {
        "start": 3614.2,
        "end": 3615.9
      },
      "iou": 0.4705882352941491,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.40000000000009095,
        "end": 0.5,
        "average": 0.4500000000000455
      },
      "rationale_metrics": {
        "rouge_l": 0.5,
        "text_similarity": 0.8613439798355103,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies both utterances and their ordering and the target timing is close, but the anchor timestamp is substantially off (3580.0s vs 3597.2\u20133599.5s), a significant factual mismatch."
      }
    },
    {
      "question_id": "001",
      "question": "After Mark introduces Dr. John Mckeown and Dr. Naomi Dow, when does he ask Dr. Dow to describe how they've been using Near Me?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 31.48,
        "end": 34.4
      },
      "pred_interval": {
        "start": 32.8,
        "end": 35.2
      },
      "iou": 0.43010752688172055,
      "recall_at_threshold": {
        "R@0.3": 1,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 1.3199999999999967,
        "end": 0.8000000000000043,
        "average": 1.0600000000000005
      },
      "rationale_metrics": {
        "rouge_l": 0.2898550724637681,
        "text_similarity": 0.508659839630127,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly states that Mark asks Dr. Dow to describe Near Me, but it gives incorrect timing and ordering (claims introduction ends at 32.7s and the question is immediate thereafter), which contradicts the reference timestamps (intro ends at 15.72s; question at 31.48s\u201334.4s)."
      }
    },
    {
      "question_id": "002",
      "question": "Once Dr. Naomi Dow finishes explaining how students take part in consultations, when does Mark ask Dr. Mckeown about the impact on the teaching team?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 0.0,
        "end": 210.0
      },
      "gt_interval": {
        "start": 118.96,
        "end": 124.4
      },
      "pred_interval": {
        "start": 68.4,
        "end": 69.1
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 50.55999999999999,
        "end": 55.30000000000001,
        "average": 52.93
      },
      "rationale_metrics": {
        "rouge_l": 0.22222222222222224,
        "text_similarity": 0.5537073016166687,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction preserves the general ordering (question follows Dow's explanation) but gives incorrect timestamps (68.4s vs 117.6s and no match to 118.96\u2013124.4s), misidentifies the question content, and introduces unsupported details, so it is largely incorrect."
      }
    },
    {
      "question_id": "001",
      "question": "After the male speaker introduces the concept of emotions in the session, when does the female speaker first mention 'real patients'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 201.9,
        "end": 202.6
      },
      "pred_interval": {
        "start": 150.0,
        "end": 150.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 51.900000000000006,
        "end": 52.599999999999994,
        "average": 52.25
      },
      "rationale_metrics": {
        "rouge_l": 0.19607843137254902,
        "text_similarity": 0.7066419720649719,
        "llm_judge_score": 2,
        "llm_judge_justification": "The prediction correctly identifies E1 and the temporal relation as 'after', but it misidentifies E2's timing and utterance\u2014the female speaker's 'real patients' occurs at ~201.9\u2013202.6s, not 155.2s, and the quoted phrase does not match the ground truth, so the key target event is incorrect."
      }
    },
    {
      "question_id": "002",
      "question": "Once the interviewer finishes asking the question about comparing models, when does the female speaker finish explaining the advantages of 'Near Me' regarding real patients and capacity?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 150.0,
        "end": 360.0
      },
      "gt_interval": {
        "start": 198.7,
        "end": 306.9
      },
      "pred_interval": {
        "start": 205.0,
        "end": 205.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 6.300000000000011,
        "end": 101.89999999999998,
        "average": 54.099999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.2298850574712644,
        "text_similarity": 0.6706501841545105,
        "llm_judge_score": 2,
        "llm_judge_justification": "The predicted answer's timestamps for E1 and E2 differ substantially from the reference (205.0 vs 186.4; 225.8 vs 306.9) and it gives a different relation ('before' vs 'once_finished'), so it is largely incorrect though it at least implies the anchor precedes the target's end."
      }
    },
    {
      "question_id": "001",
      "question": "During the time the man is speaking on screen, when does he mention 'Near Me'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 342.0,
        "end": 344.0
      },
      "pred_interval": {
        "start": 341.2,
        "end": 342.3
      },
      "iou": 0.10714285714286077,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 0.8000000000000114,
        "end": 1.6999999999999886,
        "average": 1.25
      },
      "rationale_metrics": {
        "rouge_l": 0.2686567164179105,
        "text_similarity": 0.6778538823127747,
        "llm_judge_score": 6,
        "llm_judge_justification": "The prediction correctly identifies the 'during' relation and labels the events, and gives a plausible E2 interval, but it omits E1's explicit times and the predicted E2 timing substantially deviates from the reference interval (only a small overlap), so it is partially inaccurate."
      }
    },
    {
      "question_id": "002",
      "question": "Once the man finishes saying 'Thank you and goodbye', when do the 'NHS Scotland' and 'Near Me' logos appear with text links?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 351.0,
        "end": 360.0
      },
      "pred_interval": {
        "start": 359.2,
        "end": 361.0
      },
      "iou": 0.08000000000000114,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.199999999999989,
        "end": 1.0,
        "average": 4.599999999999994
      },
      "rationale_metrics": {
        "rouge_l": 0.3218390804597701,
        "text_similarity": 0.6839669942855835,
        "llm_judge_score": 3,
        "llm_judge_justification": "The prediction correctly captures the temporal relation ('immediately after') and the event identities, but it gives substantially incorrect timestamps (E1 and E2 start times are ~8 seconds later than the reference), so it contradicts key factual timing details."
      }
    },
    {
      "question_id": "003",
      "question": "After the initial voiceover concludes with 'patient that day', when does the man on screen begin to say 'Thanks very much John and Amy'?",
      "video_id": "YJFNgX2pmAw",
      "video_number": "016",
      "segment": {
        "start": 330.0,
        "end": 361.0
      },
      "gt_interval": {
        "start": 336.4,
        "end": 341.6
      },
      "pred_interval": {
        "start": 344.5,
        "end": 346.0
      },
      "iou": 0.0,
      "recall_at_threshold": {
        "R@0.3": 0,
        "R@0.5": 0,
        "R@0.7": 0
      },
      "mae": {
        "start": 8.100000000000023,
        "end": 4.399999999999977,
        "average": 6.25
      },
      "rationale_metrics": {
        "rouge_l": 0.4761904761904763,
        "text_similarity": 0.7499021291732788,
        "llm_judge_score": 1,
        "llm_judge_justification": "The prediction gives timestamps that are about 10 seconds later than the reference and misstates both E2's start/end times and the temporal relation (claims 'immediately after' rather than the referenced offset); therefore it is largely incorrect despite naming the same events."
      }
    }
  ]
}